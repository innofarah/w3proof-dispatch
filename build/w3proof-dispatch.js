/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@assemblyscript/loader/index.js":
/*!******************************************************!*\
  !*** ./node_modules/@assemblyscript/loader/index.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval(" // Runtime header offsets\n\nconst ID_OFFSET = -8;\nconst SIZE_OFFSET = -4; // Runtime ids\n\nconst ARRAYBUFFER_ID = 0;\nconst STRING_ID = 1;\nconst ARRAYBUFFERVIEW_ID = 2; // Runtime type information\n\nconst ARRAYBUFFERVIEW = 1 << 0;\nconst ARRAY = 1 << 1;\nconst SET = 1 << 2;\nconst MAP = 1 << 3;\nconst VAL_ALIGN_OFFSET = 5;\nconst VAL_ALIGN = 1 << VAL_ALIGN_OFFSET;\nconst VAL_SIGNED = 1 << 10;\nconst VAL_FLOAT = 1 << 11;\nconst VAL_NULLABLE = 1 << 12;\nconst VAL_MANAGED = 1 << 13;\nconst KEY_ALIGN_OFFSET = 14;\nconst KEY_ALIGN = 1 << KEY_ALIGN_OFFSET;\nconst KEY_SIGNED = 1 << 19;\nconst KEY_FLOAT = 1 << 20;\nconst KEY_NULLABLE = 1 << 21;\nconst KEY_MANAGED = 1 << 22; // Array(BufferView) layout\n\nconst ARRAYBUFFERVIEW_BUFFER_OFFSET = 0;\nconst ARRAYBUFFERVIEW_DATASTART_OFFSET = 4;\nconst ARRAYBUFFERVIEW_DATALENGTH_OFFSET = 8;\nconst ARRAYBUFFERVIEW_SIZE = 12;\nconst ARRAY_LENGTH_OFFSET = 12;\nconst ARRAY_SIZE = 16;\nconst BIGINT = typeof BigUint64Array !== \"undefined\";\nconst THIS = Symbol();\nconst CHUNKSIZE = 1024;\n/** Gets a string from an U32 and an U16 view on a memory. */\n\nfunction getStringImpl(buffer, ptr) {\n  const U32 = new Uint32Array(buffer);\n  const U16 = new Uint16Array(buffer);\n  var length = U32[ptr + SIZE_OFFSET >>> 2] >>> 1;\n  var offset = ptr >>> 1;\n  if (length <= CHUNKSIZE) return String.fromCharCode.apply(String, U16.subarray(offset, offset + length));\n  const parts = [];\n\n  do {\n    const last = U16[offset + CHUNKSIZE - 1];\n    const size = last >= 0xD800 && last < 0xDC00 ? CHUNKSIZE - 1 : CHUNKSIZE;\n    parts.push(String.fromCharCode.apply(String, U16.subarray(offset, offset += size)));\n    length -= size;\n  } while (length > CHUNKSIZE);\n\n  return parts.join(\"\") + String.fromCharCode.apply(String, U16.subarray(offset, offset + length));\n}\n/** Prepares the base module prior to instantiation. */\n\n\nfunction preInstantiate(imports) {\n  const baseModule = {};\n\n  function getString(memory, ptr) {\n    if (!memory) return \"<yet unknown>\";\n    return getStringImpl(memory.buffer, ptr);\n  } // add common imports used by stdlib for convenience\n\n\n  const env = imports.env = imports.env || {};\n\n  env.abort = env.abort || function abort(mesg, file, line, colm) {\n    const memory = baseModule.memory || env.memory; // prefer exported, otherwise try imported\n\n    throw Error(\"abort: \" + getString(memory, mesg) + \" at \" + getString(memory, file) + \":\" + line + \":\" + colm);\n  };\n\n  env.trace = env.trace || function trace(mesg, n) {\n    const memory = baseModule.memory || env.memory;\n    console.log(\"trace: \" + getString(memory, mesg) + (n ? \" \" : \"\") + Array.prototype.slice.call(arguments, 2, 2 + n).join(\", \"));\n  };\n\n  imports.Math = imports.Math || Math;\n  imports.Date = imports.Date || Date;\n  return baseModule;\n}\n/** Prepares the final module once instantiation is complete. */\n\n\nfunction postInstantiate(baseModule, instance) {\n  const rawExports = instance.exports;\n  const memory = rawExports.memory;\n  const table = rawExports.table;\n  const alloc = rawExports[\"__alloc\"];\n  const retain = rawExports[\"__retain\"];\n  const rttiBase = rawExports[\"__rtti_base\"] || ~0; // oob if not present\n\n  /** Gets the runtime type info for the given id. */\n\n  function getInfo(id) {\n    const U32 = new Uint32Array(memory.buffer);\n    const count = U32[rttiBase >>> 2];\n    if ((id >>>= 0) >= count) throw Error(\"invalid id: \" + id);\n    return U32[(rttiBase + 4 >>> 2) + id * 2];\n  }\n  /** Gets the runtime base id for the given id. */\n\n\n  function getBase(id) {\n    const U32 = new Uint32Array(memory.buffer);\n    const count = U32[rttiBase >>> 2];\n    if ((id >>>= 0) >= count) throw Error(\"invalid id: \" + id);\n    return U32[(rttiBase + 4 >>> 2) + id * 2 + 1];\n  }\n  /** Gets the runtime alignment of a collection's values. */\n\n\n  function getValueAlign(info) {\n    return 31 - Math.clz32(info >>> VAL_ALIGN_OFFSET & 31); // -1 if none\n  }\n  /** Gets the runtime alignment of a collection's keys. */\n\n\n  function getKeyAlign(info) {\n    return 31 - Math.clz32(info >>> KEY_ALIGN_OFFSET & 31); // -1 if none\n  }\n  /** Allocates a new string in the module's memory and returns its retained pointer. */\n\n\n  function __allocString(str) {\n    const length = str.length;\n    const ptr = alloc(length << 1, STRING_ID);\n    const U16 = new Uint16Array(memory.buffer);\n\n    for (var i = 0, p = ptr >>> 1; i < length; ++i) U16[p + i] = str.charCodeAt(i);\n\n    return ptr;\n  }\n\n  baseModule.__allocString = __allocString;\n  /** Reads a string from the module's memory by its pointer. */\n\n  function __getString(ptr) {\n    const buffer = memory.buffer;\n    const id = new Uint32Array(buffer)[ptr + ID_OFFSET >>> 2];\n    if (id !== STRING_ID) throw Error(\"not a string: \" + ptr);\n    return getStringImpl(buffer, ptr);\n  }\n\n  baseModule.__getString = __getString;\n  /** Gets the view matching the specified alignment, signedness and floatness. */\n\n  function getView(alignLog2, signed, float) {\n    const buffer = memory.buffer;\n\n    if (float) {\n      switch (alignLog2) {\n        case 2:\n          return new Float32Array(buffer);\n\n        case 3:\n          return new Float64Array(buffer);\n      }\n    } else {\n      switch (alignLog2) {\n        case 0:\n          return new (signed ? Int8Array : Uint8Array)(buffer);\n\n        case 1:\n          return new (signed ? Int16Array : Uint16Array)(buffer);\n\n        case 2:\n          return new (signed ? Int32Array : Uint32Array)(buffer);\n\n        case 3:\n          return new (signed ? BigInt64Array : BigUint64Array)(buffer);\n      }\n    }\n\n    throw Error(\"unsupported align: \" + alignLog2);\n  }\n  /** Allocates a new array in the module's memory and returns its retained pointer. */\n\n\n  function __allocArray(id, values) {\n    const info = getInfo(id);\n    if (!(info & (ARRAYBUFFERVIEW | ARRAY))) throw Error(\"not an array: \" + id + \" @ \" + info);\n    const align = getValueAlign(info);\n    const length = values.length;\n    const buf = alloc(length << align, ARRAYBUFFER_ID);\n    const arr = alloc(info & ARRAY ? ARRAY_SIZE : ARRAYBUFFERVIEW_SIZE, id);\n    const U32 = new Uint32Array(memory.buffer);\n    U32[arr + ARRAYBUFFERVIEW_BUFFER_OFFSET >>> 2] = retain(buf);\n    U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2] = buf;\n    U32[arr + ARRAYBUFFERVIEW_DATALENGTH_OFFSET >>> 2] = length << align;\n    if (info & ARRAY) U32[arr + ARRAY_LENGTH_OFFSET >>> 2] = length;\n    const view = getView(align, info & VAL_SIGNED, info & VAL_FLOAT);\n\n    if (info & VAL_MANAGED) {\n      for (let i = 0; i < length; ++i) view[(buf >>> align) + i] = retain(values[i]);\n    } else {\n      view.set(values, buf >>> align);\n    }\n\n    return arr;\n  }\n\n  baseModule.__allocArray = __allocArray;\n  /** Gets a live view on an array's values in the module's memory. Infers the array type from RTTI. */\n\n  function __getArrayView(arr) {\n    const U32 = new Uint32Array(memory.buffer);\n    const id = U32[arr + ID_OFFSET >>> 2];\n    const info = getInfo(id);\n    if (!(info & ARRAYBUFFERVIEW)) throw Error(\"not an array: \" + id);\n    const align = getValueAlign(info);\n    var buf = U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];\n    const length = info & ARRAY ? U32[arr + ARRAY_LENGTH_OFFSET >>> 2] : U32[buf + SIZE_OFFSET >>> 2] >>> align;\n    return getView(align, info & VAL_SIGNED, info & VAL_FLOAT).subarray(buf >>>= align, buf + length);\n  }\n\n  baseModule.__getArrayView = __getArrayView;\n  /** Copies an array's values from the module's memory. Infers the array type from RTTI. */\n\n  function __getArray(arr) {\n    const input = __getArrayView(arr);\n\n    const len = input.length;\n    const out = new Array(len);\n\n    for (let i = 0; i < len; i++) out[i] = input[i];\n\n    return out;\n  }\n\n  baseModule.__getArray = __getArray;\n  /** Copies an ArrayBuffer's value from the module's memory. */\n\n  function __getArrayBuffer(ptr) {\n    const buffer = memory.buffer;\n    const length = new Uint32Array(buffer)[ptr + SIZE_OFFSET >>> 2];\n    return buffer.slice(ptr, ptr + length);\n  }\n\n  baseModule.__getArrayBuffer = __getArrayBuffer;\n  /** Copies a typed array's values from the module's memory. */\n\n  function getTypedArray(Type, alignLog2, ptr) {\n    return new Type(getTypedArrayView(Type, alignLog2, ptr));\n  }\n  /** Gets a live view on a typed array's values in the module's memory. */\n\n\n  function getTypedArrayView(Type, alignLog2, ptr) {\n    const buffer = memory.buffer;\n    const U32 = new Uint32Array(buffer);\n    const bufPtr = U32[ptr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];\n    return new Type(buffer, bufPtr, U32[bufPtr + SIZE_OFFSET >>> 2] >>> alignLog2);\n  }\n\n  baseModule.__getInt8Array = getTypedArray.bind(null, Int8Array, 0);\n  baseModule.__getInt8ArrayView = getTypedArrayView.bind(null, Int8Array, 0);\n  baseModule.__getUint8Array = getTypedArray.bind(null, Uint8Array, 0);\n  baseModule.__getUint8ArrayView = getTypedArrayView.bind(null, Uint8Array, 0);\n  baseModule.__getUint8ClampedArray = getTypedArray.bind(null, Uint8ClampedArray, 0);\n  baseModule.__getUint8ClampedArrayView = getTypedArrayView.bind(null, Uint8ClampedArray, 0);\n  baseModule.__getInt16Array = getTypedArray.bind(null, Int16Array, 1);\n  baseModule.__getInt16ArrayView = getTypedArrayView.bind(null, Int16Array, 1);\n  baseModule.__getUint16Array = getTypedArray.bind(null, Uint16Array, 1);\n  baseModule.__getUint16ArrayView = getTypedArrayView.bind(null, Uint16Array, 1);\n  baseModule.__getInt32Array = getTypedArray.bind(null, Int32Array, 2);\n  baseModule.__getInt32ArrayView = getTypedArrayView.bind(null, Int32Array, 2);\n  baseModule.__getUint32Array = getTypedArray.bind(null, Uint32Array, 2);\n  baseModule.__getUint32ArrayView = getTypedArrayView.bind(null, Uint32Array, 2);\n\n  if (BIGINT) {\n    baseModule.__getInt64Array = getTypedArray.bind(null, BigInt64Array, 3);\n    baseModule.__getInt64ArrayView = getTypedArrayView.bind(null, BigInt64Array, 3);\n    baseModule.__getUint64Array = getTypedArray.bind(null, BigUint64Array, 3);\n    baseModule.__getUint64ArrayView = getTypedArrayView.bind(null, BigUint64Array, 3);\n  }\n\n  baseModule.__getFloat32Array = getTypedArray.bind(null, Float32Array, 2);\n  baseModule.__getFloat32ArrayView = getTypedArrayView.bind(null, Float32Array, 2);\n  baseModule.__getFloat64Array = getTypedArray.bind(null, Float64Array, 3);\n  baseModule.__getFloat64ArrayView = getTypedArrayView.bind(null, Float64Array, 3);\n  /** Tests whether an object is an instance of the class represented by the specified base id. */\n\n  function __instanceof(ptr, baseId) {\n    const U32 = new Uint32Array(memory.buffer);\n    var id = U32[ptr + ID_OFFSET >>> 2];\n\n    if (id <= U32[rttiBase >>> 2]) {\n      do if (id == baseId) return true; while (id = getBase(id));\n    }\n\n    return false;\n  }\n\n  baseModule.__instanceof = __instanceof; // Pull basic exports to baseModule so code in preInstantiate can use them\n\n  baseModule.memory = baseModule.memory || memory;\n  baseModule.table = baseModule.table || table; // Demangle exports and provide the usual utility on the prototype\n\n  return demangle(rawExports, baseModule);\n}\n\nfunction isResponse(o) {\n  return typeof Response !== \"undefined\" && o instanceof Response;\n}\n/** Asynchronously instantiates an AssemblyScript module from anything that can be instantiated. */\n\n\nasync function instantiate(source, imports) {\n  if (isResponse(source = await source)) return instantiateStreaming(source, imports);\n  return postInstantiate(preInstantiate(imports || (imports = {})), await WebAssembly.instantiate(source instanceof WebAssembly.Module ? source : await WebAssembly.compile(source), imports));\n}\n\nexports.instantiate = instantiate;\n/** Synchronously instantiates an AssemblyScript module from a WebAssembly.Module or binary buffer. */\n\nfunction instantiateSync(source, imports) {\n  return postInstantiate(preInstantiate(imports || (imports = {})), new WebAssembly.Instance(source instanceof WebAssembly.Module ? source : new WebAssembly.Module(source), imports));\n}\n\nexports.instantiateSync = instantiateSync;\n/** Asynchronously instantiates an AssemblyScript module from a response, i.e. as obtained by `fetch`. */\n\nasync function instantiateStreaming(source, imports) {\n  if (!WebAssembly.instantiateStreaming) {\n    return instantiate(isResponse(source = await source) ? source.arrayBuffer() : source, imports);\n  }\n\n  return postInstantiate(preInstantiate(imports || (imports = {})), (await WebAssembly.instantiateStreaming(source, imports)).instance);\n}\n\nexports.instantiateStreaming = instantiateStreaming;\n/** Demangles an AssemblyScript module's exports to a friendly object structure. */\n\nfunction demangle(exports, baseModule) {\n  var module = baseModule ? Object.create(baseModule) : {};\n  var setArgumentsLength = exports[\"__argumentsLength\"] ? function (length) {\n    exports[\"__argumentsLength\"].value = length;\n  } : exports[\"__setArgumentsLength\"] || exports[\"__setargc\"] || function () {};\n\n  for (let internalName in exports) {\n    if (!Object.prototype.hasOwnProperty.call(exports, internalName)) continue;\n    const elem = exports[internalName];\n    let parts = internalName.split(\".\");\n    let curr = module;\n\n    while (parts.length > 1) {\n      let part = parts.shift();\n      if (!Object.prototype.hasOwnProperty.call(curr, part)) curr[part] = {};\n      curr = curr[part];\n    }\n\n    let name = parts[0];\n    let hash = name.indexOf(\"#\");\n\n    if (hash >= 0) {\n      let className = name.substring(0, hash);\n      let classElem = curr[className];\n\n      if (typeof classElem === \"undefined\" || !classElem.prototype) {\n        let ctor = function (...args) {\n          return ctor.wrap(ctor.prototype.constructor(0, ...args));\n        };\n\n        ctor.prototype = {\n          valueOf: function valueOf() {\n            return this[THIS];\n          }\n        };\n\n        ctor.wrap = function (thisValue) {\n          return Object.create(ctor.prototype, {\n            [THIS]: {\n              value: thisValue,\n              writable: false\n            }\n          });\n        };\n\n        if (classElem) Object.getOwnPropertyNames(classElem).forEach(name => Object.defineProperty(ctor, name, Object.getOwnPropertyDescriptor(classElem, name)));\n        curr[className] = ctor;\n      }\n\n      name = name.substring(hash + 1);\n      curr = curr[className].prototype;\n\n      if (/^(get|set):/.test(name)) {\n        if (!Object.prototype.hasOwnProperty.call(curr, name = name.substring(4))) {\n          let getter = exports[internalName.replace(\"set:\", \"get:\")];\n          let setter = exports[internalName.replace(\"get:\", \"set:\")];\n          Object.defineProperty(curr, name, {\n            get: function () {\n              return getter(this[THIS]);\n            },\n            set: function (value) {\n              setter(this[THIS], value);\n            },\n            enumerable: true\n          });\n        }\n      } else {\n        if (name === 'constructor') {\n          (curr[name] = (...args) => {\n            setArgumentsLength(args.length);\n            return elem(...args);\n          }).original = elem;\n        } else {\n          // instance method\n          (curr[name] = function (...args) {\n            // !\n            setArgumentsLength(args.length);\n            return elem(this[THIS], ...args);\n          }).original = elem;\n        }\n      }\n    } else {\n      if (/^(get|set):/.test(name)) {\n        if (!Object.prototype.hasOwnProperty.call(curr, name = name.substring(4))) {\n          Object.defineProperty(curr, name, {\n            get: exports[internalName.replace(\"set:\", \"get:\")],\n            set: exports[internalName.replace(\"get:\", \"set:\")],\n            enumerable: true\n          });\n        }\n      } else if (typeof elem === \"function\" && elem !== setArgumentsLength) {\n        (curr[name] = (...args) => {\n          setArgumentsLength(args.length);\n          return elem(...args);\n        }).original = elem;\n      } else {\n        curr[name] = elem;\n      }\n    }\n  }\n\n  return module;\n}\n\nexports.demangle = demangle;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@assemblyscript/loader/index.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/car.js":
/*!*******************************************!*\
  !*** ./node_modules/@ipld/car/cjs/car.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar reader = __webpack_require__(/*! ./lib/reader.js */ \"./node_modules/@ipld/car/cjs/lib/reader.js\");\n\nvar indexer = __webpack_require__(/*! ./lib/indexer.js */ \"./node_modules/@ipld/car/cjs/lib/indexer.js\");\n\nvar iterator = __webpack_require__(/*! ./lib/iterator.js */ \"./node_modules/@ipld/car/cjs/lib/iterator.js\");\n\nvar writer = __webpack_require__(/*! ./lib/writer.js */ \"./node_modules/@ipld/car/cjs/lib/writer.js\");\n\nvar indexedReader = __webpack_require__(/*! ./lib/indexed-reader.js */ \"./node_modules/@ipld/car/cjs/lib/indexed-reader.js\");\n\nexports.CarReader = reader.CarReader;\nexports.CarIndexer = indexer.CarIndexer;\nexports.CarBlockIterator = iterator.CarBlockIterator;\nexports.CarCIDIterator = iterator.CarCIDIterator;\nexports.CarWriter = writer.CarWriter;\nexports.CarIndexedReader = indexedReader.CarIndexedReader;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/car.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/decoder.js":
/*!***************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/decoder.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar varint = __webpack_require__(/*! varint */ \"./node_modules/varint/index.js\");\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar Digest = __webpack_require__(/*! multiformats/hashes/digest */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nvar dagCbor = __webpack_require__(/*! @ipld/dag-cbor */ \"./node_modules/@ipld/dag-cbor/cjs/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar varint__default = /*#__PURE__*/_interopDefaultLegacy(varint);\n\nvar Digest__namespace = /*#__PURE__*/_interopNamespace(Digest);\n\nconst CIDV0_BYTES = {\n  SHA2_256: 18,\n  LENGTH: 32,\n  DAG_PB: 112\n};\n\nasync function readVarint(reader) {\n  const bytes = await reader.upTo(8);\n  const i = varint__default[\"default\"].decode(bytes);\n  reader.seek(varint__default[\"default\"].decode.bytes);\n  return i;\n}\n\nasync function readHeader(reader) {\n  const length = await readVarint(reader);\n\n  if (length === 0) {\n    throw new Error('Invalid CAR header (zero length)');\n  }\n\n  const header = await reader.exactly(length);\n  reader.seek(length);\n  const block = dagCbor.decode(header);\n\n  if (block == null || Array.isArray(block) || typeof block !== 'object') {\n    throw new Error('Invalid CAR header format');\n  }\n\n  if (block.version !== 1) {\n    if (typeof block.version === 'string') {\n      throw new Error(`Invalid CAR version: \"${block.version}\"`);\n    }\n\n    throw new Error(`Invalid CAR version: ${block.version}`);\n  }\n\n  if (!Array.isArray(block.roots)) {\n    throw new Error('Invalid CAR header format');\n  }\n\n  if (Object.keys(block).filter(p => p !== 'roots' && p !== 'version').length) {\n    throw new Error('Invalid CAR header format');\n  }\n\n  return block;\n}\n\nasync function readMultihash(reader) {\n  const bytes = await reader.upTo(8);\n  varint__default[\"default\"].decode(bytes);\n  const codeLength = varint__default[\"default\"].decode.bytes;\n  const length = varint__default[\"default\"].decode(bytes.subarray(varint__default[\"default\"].decode.bytes));\n  const lengthLength = varint__default[\"default\"].decode.bytes;\n  const mhLength = codeLength + lengthLength + length;\n  const multihash = await reader.exactly(mhLength);\n  reader.seek(mhLength);\n  return multihash;\n}\n\nasync function readCid(reader) {\n  const first = await reader.exactly(2);\n\n  if (first[0] === CIDV0_BYTES.SHA2_256 && first[1] === CIDV0_BYTES.LENGTH) {\n    const bytes = await reader.exactly(34);\n    reader.seek(34);\n    const multihash = Digest__namespace.decode(bytes);\n    return cid.CID.create(0, CIDV0_BYTES.DAG_PB, multihash);\n  }\n\n  const version = await readVarint(reader);\n\n  if (version !== 1) {\n    throw new Error(`Unexpected CID version (${version})`);\n  }\n\n  const codec = await readVarint(reader);\n  const bytes = await readMultihash(reader);\n  const multihash = Digest__namespace.decode(bytes);\n  return cid.CID.create(version, codec, multihash);\n}\n\nasync function readBlockHead(reader) {\n  const start = reader.pos;\n  let length = await readVarint(reader);\n\n  if (length === 0) {\n    throw new Error('Invalid CAR section (zero length)');\n  }\n\n  length += reader.pos - start;\n  const cid = await readCid(reader);\n  const blockLength = length - (reader.pos - start);\n  return {\n    cid,\n    length,\n    blockLength\n  };\n}\n\nasync function readBlock(reader) {\n  const {\n    cid,\n    blockLength\n  } = await readBlockHead(reader);\n  const bytes = await reader.exactly(blockLength);\n  reader.seek(blockLength);\n  return {\n    bytes,\n    cid\n  };\n}\n\nasync function readBlockIndex(reader) {\n  const offset = reader.pos;\n  const {\n    cid,\n    length,\n    blockLength\n  } = await readBlockHead(reader);\n  const index = {\n    cid,\n    length,\n    blockLength,\n    offset,\n    blockOffset: reader.pos\n  };\n  reader.seek(index.blockLength);\n  return index;\n}\n\nfunction createDecoder(reader) {\n  const headerPromise = readHeader(reader);\n  return {\n    header: () => headerPromise,\n\n    async *blocks() {\n      await headerPromise;\n\n      while ((await reader.upTo(8)).length > 0) {\n        yield await readBlock(reader);\n      }\n    },\n\n    async *blocksIndex() {\n      await headerPromise;\n\n      while ((await reader.upTo(8)).length > 0) {\n        yield await readBlockIndex(reader);\n      }\n    }\n\n  };\n}\n\nfunction bytesReader(bytes) {\n  let pos = 0;\n  return {\n    async upTo(length) {\n      return bytes.subarray(pos, pos + Math.min(length, bytes.length - pos));\n    },\n\n    async exactly(length) {\n      if (length > bytes.length - pos) {\n        throw new Error('Unexpected end of data');\n      }\n\n      return bytes.subarray(pos, pos + length);\n    },\n\n    seek(length) {\n      pos += length;\n    },\n\n    get pos() {\n      return pos;\n    }\n\n  };\n}\n\nfunction chunkReader(readChunk) {\n  let pos = 0;\n  let have = 0;\n  let offset = 0;\n  let currentChunk = new Uint8Array(0);\n\n  const read = async length => {\n    have = currentChunk.length - offset;\n    const bufa = [currentChunk.subarray(offset)];\n\n    while (have < length) {\n      const chunk = await readChunk();\n\n      if (chunk == null) {\n        break;\n      }\n\n      if (have < 0) {\n        if (chunk.length > have) {\n          bufa.push(chunk.subarray(-have));\n        }\n      } else {\n        bufa.push(chunk);\n      }\n\n      have += chunk.length;\n    }\n\n    currentChunk = new Uint8Array(bufa.reduce((p, c) => p + c.length, 0));\n    let off = 0;\n\n    for (const b of bufa) {\n      currentChunk.set(b, off);\n      off += b.length;\n    }\n\n    offset = 0;\n  };\n\n  return {\n    async upTo(length) {\n      if (currentChunk.length - offset < length) {\n        await read(length);\n      }\n\n      return currentChunk.subarray(offset, offset + Math.min(currentChunk.length - offset, length));\n    },\n\n    async exactly(length) {\n      if (currentChunk.length - offset < length) {\n        await read(length);\n      }\n\n      if (currentChunk.length - offset < length) {\n        throw new Error('Unexpected end of data');\n      }\n\n      return currentChunk.subarray(offset, offset + length);\n    },\n\n    seek(length) {\n      pos += length;\n      offset += length;\n    },\n\n    get pos() {\n      return pos;\n    }\n\n  };\n}\n\nfunction asyncIterableReader(asyncIterable) {\n  const iterator = asyncIterable[Symbol.asyncIterator]();\n\n  async function readChunk() {\n    const next = await iterator.next();\n\n    if (next.done) {\n      return null;\n    }\n\n    return next.value;\n  }\n\n  return chunkReader(readChunk);\n}\n\nexports.asyncIterableReader = asyncIterableReader;\nexports.bytesReader = bytesReader;\nexports.chunkReader = chunkReader;\nexports.createDecoder = createDecoder;\nexports.readBlockHead = readBlockHead;\nexports.readHeader = readHeader;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/decoder.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/encoder.js":
/*!***************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/encoder.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar varint = __webpack_require__(/*! varint */ \"./node_modules/varint/index.js\");\n\nvar dagCbor = __webpack_require__(/*! @ipld/dag-cbor */ \"./node_modules/@ipld/dag-cbor/cjs/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar varint__default = /*#__PURE__*/_interopDefaultLegacy(varint);\n\nfunction createHeader(roots) {\n  const headerBytes = dagCbor.encode({\n    version: 1,\n    roots\n  });\n  const varintBytes = varint__default[\"default\"].encode(headerBytes.length);\n  const header = new Uint8Array(varintBytes.length + headerBytes.length);\n  header.set(varintBytes, 0);\n  header.set(headerBytes, varintBytes.length);\n  return header;\n}\n\nfunction createEncoder(writer) {\n  return {\n    async setRoots(roots) {\n      const bytes = createHeader(roots);\n      await writer.write(bytes);\n    },\n\n    async writeBlock(block) {\n      const {\n        cid,\n        bytes\n      } = block;\n      await writer.write(new Uint8Array(varint__default[\"default\"].encode(cid.bytes.length + bytes.length)));\n      await writer.write(cid.bytes);\n\n      if (bytes.length) {\n        await writer.write(bytes);\n      }\n    },\n\n    async close() {\n      return writer.end();\n    }\n\n  };\n}\n\nexports.createEncoder = createEncoder;\nexports.createHeader = createHeader;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/encoder.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/indexed-reader.js":
/*!**********************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/indexed-reader.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\nvar stream = __webpack_require__(/*! stream */ \"stream\");\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar indexer = __webpack_require__(/*! ./indexer.js */ \"./node_modules/@ipld/car/cjs/lib/indexer.js\");\n\nvar reader = __webpack_require__(/*! ./reader.js */ \"./node_modules/@ipld/car/cjs/lib/reader.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\n\nclass CarIndexedReader {\n  constructor(version, path, roots, index, order) {\n    this._version = version;\n    this._path = path;\n    this._roots = roots;\n    this._index = index;\n    this._order = order;\n    this._fd = null;\n  }\n\n  get version() {\n    return this._version;\n  }\n\n  async getRoots() {\n    return this._roots;\n  }\n\n  async has(key) {\n    return this._index.has(key.toString());\n  }\n\n  async get(key) {\n    const blockIndex = this._index.get(key.toString());\n\n    if (!blockIndex) {\n      return undefined;\n    }\n\n    if (!this._fd) {\n      this._fd = await fs__default[\"default\"].promises.open(this._path, 'r');\n    }\n\n    const readIndex = {\n      cid: key,\n      length: 0,\n      offset: 0,\n      blockLength: blockIndex.blockLength,\n      blockOffset: blockIndex.blockOffset\n    };\n    return reader.CarReader.readRaw(this._fd, readIndex);\n  }\n\n  async *blocks() {\n    for (const cidStr of this._order) {\n      const block = await this.get(cid.CID.parse(cidStr));\n\n      if (!block) {\n        throw new Error('Unexpected internal error');\n      }\n\n      yield block;\n    }\n  }\n\n  async *cids() {\n    for (const cidStr of this._order) {\n      yield cid.CID.parse(cidStr);\n    }\n  }\n\n  async close() {\n    if (this._fd) {\n      return this._fd.close();\n    }\n  }\n\n  static async fromFile(path) {\n    if (typeof path !== 'string') {\n      throw new TypeError('fromFile() requires a file path string');\n    }\n\n    const iterable = await indexer.CarIndexer.fromIterable(stream.Readable.from(fs__default[\"default\"].createReadStream(path)));\n    const index = new Map();\n    const order = [];\n\n    for await (const {\n      cid,\n      blockLength,\n      blockOffset\n    } of iterable) {\n      const cidStr = cid.toString();\n      index.set(cidStr, {\n        blockLength,\n        blockOffset\n      });\n      order.push(cidStr);\n    }\n\n    return new CarIndexedReader(iterable.version, path, await iterable.getRoots(), index, order);\n  }\n\n}\n\nconst __browser = false;\nexports.CarIndexedReader = CarIndexedReader;\nexports.__browser = __browser;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/indexed-reader.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/indexer.js":
/*!***************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/indexer.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar decoder = __webpack_require__(/*! ./decoder.js */ \"./node_modules/@ipld/car/cjs/lib/decoder.js\");\n\nclass CarIndexer {\n  constructor(version, roots, iterator) {\n    this._version = version;\n    this._roots = roots;\n    this._iterator = iterator;\n  }\n\n  get version() {\n    return this._version;\n  }\n\n  async getRoots() {\n    return this._roots;\n  }\n\n  [Symbol.asyncIterator]() {\n    return this._iterator;\n  }\n\n  static async fromBytes(bytes) {\n    if (!(bytes instanceof Uint8Array)) {\n      throw new TypeError('fromBytes() requires a Uint8Array');\n    }\n\n    return decodeIndexerComplete(decoder.bytesReader(bytes));\n  }\n\n  static async fromIterable(asyncIterable) {\n    if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n      throw new TypeError('fromIterable() requires an async iterable');\n    }\n\n    return decodeIndexerComplete(decoder.asyncIterableReader(asyncIterable));\n  }\n\n}\n\nasync function decodeIndexerComplete(reader) {\n  const decoder$1 = decoder.createDecoder(reader);\n  const {\n    version,\n    roots\n  } = await decoder$1.header();\n  return new CarIndexer(version, roots, decoder$1.blocksIndex());\n}\n\nexports.CarIndexer = CarIndexer;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/indexer.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/iterator-channel.js":
/*!************************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/iterator-channel.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nfunction noop() {}\n\nfunction create() {\n  const chunkQueue = [];\n  let drainer = null;\n  let drainerResolver = noop;\n  let ended = false;\n  let outWait = null;\n  let outWaitResolver = noop;\n\n  const makeDrainer = () => {\n    if (!drainer) {\n      drainer = new Promise(resolve => {\n        drainerResolver = () => {\n          drainer = null;\n          drainerResolver = noop;\n          resolve();\n        };\n      });\n    }\n\n    return drainer;\n  };\n\n  const writer = {\n    write(chunk) {\n      chunkQueue.push(chunk);\n      const drainer = makeDrainer();\n      outWaitResolver();\n      return drainer;\n    },\n\n    async end() {\n      ended = true;\n      const drainer = makeDrainer();\n      outWaitResolver();\n      return drainer;\n    }\n\n  };\n  const iterator = {\n    async next() {\n      const chunk = chunkQueue.shift();\n\n      if (chunk) {\n        if (chunkQueue.length === 0) {\n          drainerResolver();\n        }\n\n        return {\n          done: false,\n          value: chunk\n        };\n      }\n\n      if (ended) {\n        drainerResolver();\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n\n      if (!outWait) {\n        outWait = new Promise(resolve => {\n          outWaitResolver = () => {\n            outWait = null;\n            outWaitResolver = noop;\n            return resolve(iterator.next());\n          };\n        });\n      }\n\n      return outWait;\n    }\n\n  };\n  return {\n    writer,\n    iterator\n  };\n}\n\nexports.create = create;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/iterator-channel.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/iterator.js":
/*!****************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/iterator.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar decoder = __webpack_require__(/*! ./decoder.js */ \"./node_modules/@ipld/car/cjs/lib/decoder.js\");\n\nclass CarIteratorBase {\n  constructor(version, roots, iterable) {\n    this._version = version;\n    this._roots = roots;\n    this._iterable = iterable;\n    this._decoded = false;\n  }\n\n  get version() {\n    return this._version;\n  }\n\n  async getRoots() {\n    return this._roots;\n  }\n\n}\n\nclass CarBlockIterator extends CarIteratorBase {\n  [Symbol.asyncIterator]() {\n    if (this._decoded) {\n      throw new Error('Cannot decode more than once');\n    }\n\n    if (!this._iterable) {\n      throw new Error('Block iterable not found');\n    }\n\n    this._decoded = true;\n    return this._iterable[Symbol.asyncIterator]();\n  }\n\n  static async fromBytes(bytes) {\n    const {\n      version,\n      roots,\n      iterator\n    } = await fromBytes(bytes);\n    return new CarBlockIterator(version, roots, iterator);\n  }\n\n  static async fromIterable(asyncIterable) {\n    const {\n      version,\n      roots,\n      iterator\n    } = await fromIterable(asyncIterable);\n    return new CarBlockIterator(version, roots, iterator);\n  }\n\n}\n\nclass CarCIDIterator extends CarIteratorBase {\n  [Symbol.asyncIterator]() {\n    if (this._decoded) {\n      throw new Error('Cannot decode more than once');\n    }\n\n    if (!this._iterable) {\n      throw new Error('Block iterable not found');\n    }\n\n    this._decoded = true;\n\n    const iterable = this._iterable[Symbol.asyncIterator]();\n\n    return {\n      async next() {\n        const next = await iterable.next();\n\n        if (next.done) {\n          return next;\n        }\n\n        return {\n          done: false,\n          value: next.value.cid\n        };\n      }\n\n    };\n  }\n\n  static async fromBytes(bytes) {\n    const {\n      version,\n      roots,\n      iterator\n    } = await fromBytes(bytes);\n    return new CarCIDIterator(version, roots, iterator);\n  }\n\n  static async fromIterable(asyncIterable) {\n    const {\n      version,\n      roots,\n      iterator\n    } = await fromIterable(asyncIterable);\n    return new CarCIDIterator(version, roots, iterator);\n  }\n\n}\n\nasync function fromBytes(bytes) {\n  if (!(bytes instanceof Uint8Array)) {\n    throw new TypeError('fromBytes() requires a Uint8Array');\n  }\n\n  return decodeIterator(decoder.bytesReader(bytes));\n}\n\nasync function fromIterable(asyncIterable) {\n  if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n    throw new TypeError('fromIterable() requires an async iterable');\n  }\n\n  return decodeIterator(decoder.asyncIterableReader(asyncIterable));\n}\n\nasync function decodeIterator(reader) {\n  const decoder$1 = decoder.createDecoder(reader);\n  const {\n    version,\n    roots\n  } = await decoder$1.header();\n  return {\n    version,\n    roots,\n    iterator: decoder$1.blocks()\n  };\n}\n\nexports.CarBlockIterator = CarBlockIterator;\nexports.CarCIDIterator = CarCIDIterator;\nexports.CarIteratorBase = CarIteratorBase;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/iterator.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/reader-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/reader-browser.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar decoder = __webpack_require__(/*! ./decoder.js */ \"./node_modules/@ipld/car/cjs/lib/decoder.js\");\n\nclass CarReader {\n  constructor(version, roots, blocks) {\n    this._version = version;\n    this._roots = roots;\n    this._blocks = blocks;\n    this._keys = blocks.map(b => b.cid.toString());\n  }\n\n  get version() {\n    return this._version;\n  }\n\n  async getRoots() {\n    return this._roots;\n  }\n\n  async has(key) {\n    return this._keys.indexOf(key.toString()) > -1;\n  }\n\n  async get(key) {\n    const index = this._keys.indexOf(key.toString());\n\n    return index > -1 ? this._blocks[index] : undefined;\n  }\n\n  async *blocks() {\n    for (const block of this._blocks) {\n      yield block;\n    }\n  }\n\n  async *cids() {\n    for (const block of this._blocks) {\n      yield block.cid;\n    }\n  }\n\n  static async fromBytes(bytes) {\n    if (!(bytes instanceof Uint8Array)) {\n      throw new TypeError('fromBytes() requires a Uint8Array');\n    }\n\n    return decodeReaderComplete(decoder.bytesReader(bytes));\n  }\n\n  static async fromIterable(asyncIterable) {\n    if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n      throw new TypeError('fromIterable() requires an async iterable');\n    }\n\n    return decodeReaderComplete(decoder.asyncIterableReader(asyncIterable));\n  }\n\n}\n\nasync function decodeReaderComplete(reader) {\n  const decoder$1 = decoder.createDecoder(reader);\n  const {\n    version,\n    roots\n  } = await decoder$1.header();\n  const blocks = [];\n\n  for await (const block of decoder$1.blocks()) {\n    blocks.push(block);\n  }\n\n  return new CarReader(version, roots, blocks);\n}\n\nconst __browser = true;\nexports.CarReader = CarReader;\nexports.__browser = __browser;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/reader-browser.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/reader.js":
/*!**************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/reader.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\nvar util = __webpack_require__(/*! util */ \"util\");\n\nvar readerBrowser = __webpack_require__(/*! ./reader-browser.js */ \"./node_modules/@ipld/car/cjs/lib/reader-browser.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\n\nconst fsread = util.promisify(fs__default[\"default\"].read);\n\nclass CarReader extends readerBrowser.CarReader {\n  static async readRaw(fd, blockIndex) {\n    const {\n      cid,\n      blockLength,\n      blockOffset\n    } = blockIndex;\n    const bytes = new Uint8Array(blockLength);\n    let read;\n\n    if (typeof fd === 'number') {\n      read = (await fsread(fd, bytes, 0, blockLength, blockOffset)).bytesRead;\n    } else if (typeof fd === 'object' && typeof fd.read === 'function') {\n      read = (await fd.read(bytes, 0, blockLength, blockOffset)).bytesRead;\n    } else {\n      throw new TypeError('Bad fd');\n    }\n\n    if (read !== blockLength) {\n      throw new Error(`Failed to read entire block (${read} instead of ${blockLength})`);\n    }\n\n    return {\n      cid,\n      bytes\n    };\n  }\n\n}\n\nconst __browser = false;\nexports.CarReader = CarReader;\nexports.__browser = __browser;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/reader.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/writer-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/writer-browser.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar encoder = __webpack_require__(/*! ./encoder.js */ \"./node_modules/@ipld/car/cjs/lib/encoder.js\");\n\nvar iteratorChannel = __webpack_require__(/*! ./iterator-channel.js */ \"./node_modules/@ipld/car/cjs/lib/iterator-channel.js\");\n\nvar decoder = __webpack_require__(/*! ./decoder.js */ \"./node_modules/@ipld/car/cjs/lib/decoder.js\");\n\nclass CarWriter {\n  constructor(roots, encoder) {\n    this._encoder = encoder;\n    this._mutex = encoder.setRoots(roots);\n    this._ended = false;\n  }\n\n  async put(block) {\n    if (!(block.bytes instanceof Uint8Array) || !block.cid) {\n      throw new TypeError('Can only write {cid, bytes} objects');\n    }\n\n    if (this._ended) {\n      throw new Error('Already closed');\n    }\n\n    const cid$1 = cid.CID.asCID(block.cid);\n\n    if (!cid$1) {\n      throw new TypeError('Can only write {cid, bytes} objects');\n    }\n\n    this._mutex = this._mutex.then(() => this._encoder.writeBlock({\n      cid: cid$1,\n      bytes: block.bytes\n    }));\n    return this._mutex;\n  }\n\n  async close() {\n    if (this._ended) {\n      throw new Error('Already closed');\n    }\n\n    await this._mutex;\n    this._ended = true;\n    return this._encoder.close();\n  }\n\n  static create(roots) {\n    roots = toRoots(roots);\n    const {\n      encoder,\n      iterator\n    } = encodeWriter();\n    const writer = new CarWriter(roots, encoder);\n    const out = new CarWriterOut(iterator);\n    return {\n      writer,\n      out\n    };\n  }\n\n  static createAppender() {\n    const {\n      encoder,\n      iterator\n    } = encodeWriter();\n\n    encoder.setRoots = () => Promise.resolve();\n\n    const writer = new CarWriter([], encoder);\n    const out = new CarWriterOut(iterator);\n    return {\n      writer,\n      out\n    };\n  }\n\n  static async updateRootsInBytes(bytes, roots) {\n    const reader = decoder.bytesReader(bytes);\n    await decoder.readHeader(reader);\n    const newHeader = encoder.createHeader(roots);\n\n    if (reader.pos !== newHeader.length) {\n      throw new Error(`updateRoots() can only overwrite a header of the same length (old header is ${reader.pos} bytes, new header is ${newHeader.length} bytes)`);\n    }\n\n    bytes.set(newHeader, 0);\n    return bytes;\n  }\n\n}\n\nclass CarWriterOut {\n  constructor(iterator) {\n    this._iterator = iterator;\n  }\n\n  [Symbol.asyncIterator]() {\n    if (this._iterating) {\n      throw new Error('Multiple iterator not supported');\n    }\n\n    this._iterating = true;\n    return this._iterator;\n  }\n\n}\n\nfunction encodeWriter() {\n  const iw = iteratorChannel.create();\n  const {\n    writer,\n    iterator\n  } = iw;\n  const encoder$1 = encoder.createEncoder(writer);\n  return {\n    encoder: encoder$1,\n    iterator\n  };\n}\n\nfunction toRoots(roots) {\n  if (roots === undefined) {\n    return [];\n  }\n\n  if (!Array.isArray(roots)) {\n    const cid$1 = cid.CID.asCID(roots);\n\n    if (!cid$1) {\n      throw new TypeError('roots must be a single CID or an array of CIDs');\n    }\n\n    return [cid$1];\n  }\n\n  const _roots = [];\n\n  for (const root of roots) {\n    const _root = cid.CID.asCID(root);\n\n    if (!_root) {\n      throw new TypeError('roots must be a single CID or an array of CIDs');\n    }\n\n    _roots.push(_root);\n  }\n\n  return _roots;\n}\n\nconst __browser = true;\nexports.CarWriter = CarWriter;\nexports.CarWriterOut = CarWriterOut;\nexports.__browser = __browser;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/writer-browser.js?");

/***/ }),

/***/ "./node_modules/@ipld/car/cjs/lib/writer.js":
/*!**************************************************!*\
  !*** ./node_modules/@ipld/car/cjs/lib/writer.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\n\nvar util = __webpack_require__(/*! util */ \"util\");\n\nvar writerBrowser = __webpack_require__(/*! ./writer-browser.js */ \"./node_modules/@ipld/car/cjs/lib/writer-browser.js\");\n\nvar decoder = __webpack_require__(/*! ./decoder.js */ \"./node_modules/@ipld/car/cjs/lib/decoder.js\");\n\nvar encoder = __webpack_require__(/*! ./encoder.js */ \"./node_modules/@ipld/car/cjs/lib/encoder.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\n\nconst fsread = util.promisify(fs__default[\"default\"].read);\nconst fswrite = util.promisify(fs__default[\"default\"].write);\n\nclass CarWriter extends writerBrowser.CarWriter {\n  static async updateRootsInFile(fd, roots) {\n    const chunkSize = 256;\n    let bytes;\n    let offset = 0;\n    let readChunk;\n\n    if (typeof fd === 'number') {\n      readChunk = async () => (await fsread(fd, bytes, 0, chunkSize, offset)).bytesRead;\n    } else if (typeof fd === 'object' && typeof fd.read === 'function') {\n      readChunk = async () => (await fd.read(bytes, 0, chunkSize, offset)).bytesRead;\n    } else {\n      throw new TypeError('Bad fd');\n    }\n\n    const fdReader = decoder.chunkReader(async () => {\n      bytes = new Uint8Array(chunkSize);\n      const read = await readChunk();\n      offset += read;\n      return read < chunkSize ? bytes.subarray(0, read) : bytes;\n    });\n    await decoder.readHeader(fdReader);\n    const newHeader = encoder.createHeader(roots);\n\n    if (fdReader.pos !== newHeader.length) {\n      throw new Error(`updateRoots() can only overwrite a header of the same length (old header is ${fdReader.pos} bytes, new header is ${newHeader.length} bytes)`);\n    }\n\n    if (typeof fd === 'number') {\n      await fswrite(fd, newHeader, 0, newHeader.length, 0);\n    } else if (typeof fd === 'object' && typeof fd.read === 'function') {\n      await fd.write(newHeader, 0, newHeader.length, 0);\n    }\n  }\n\n}\n\nconst __browser = false;\nexports.CarWriter = CarWriter;\nexports.__browser = __browser;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/car/cjs/lib/writer.js?");

/***/ }),

/***/ "./node_modules/@ipld/dag-cbor/cjs/index.js":
/*!**************************************************!*\
  !*** ./node_modules/@ipld/dag-cbor/cjs/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar cborg = __webpack_require__(/*! cborg */ \"./node_modules/cborg/cjs/cborg.js\");\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar cborg__namespace = /*#__PURE__*/_interopNamespace(cborg);\n\nconst CID_CBOR_TAG = 42;\n\nfunction cidEncoder(obj) {\n  if (obj.asCID !== obj) {\n    return null;\n  }\n\n  const cid$1 = cid.CID.asCID(obj);\n\n  if (!cid$1) {\n    return null;\n  }\n\n  const bytes = new Uint8Array(cid$1.bytes.byteLength + 1);\n  bytes.set(cid$1.bytes, 1);\n  return [new cborg__namespace.Token(cborg__namespace.Type.tag, CID_CBOR_TAG), new cborg__namespace.Token(cborg__namespace.Type.bytes, bytes)];\n}\n\nfunction undefinedEncoder() {\n  throw new Error('`undefined` is not supported by the IPLD Data Model and cannot be encoded');\n}\n\nfunction numberEncoder(num) {\n  if (Number.isNaN(num)) {\n    throw new Error('`NaN` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n\n  if (num === Infinity || num === -Infinity) {\n    throw new Error('`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n\n  return null;\n}\n\nconst encodeOptions = {\n  float64: true,\n  typeEncoders: {\n    Object: cidEncoder,\n    undefined: undefinedEncoder,\n    number: numberEncoder\n  }\n};\n\nfunction cidDecoder(bytes) {\n  if (bytes[0] !== 0) {\n    throw new Error('Invalid CID for CBOR tag 42; expected leading 0x00');\n  }\n\n  return cid.CID.decode(bytes.subarray(1));\n}\n\nconst decodeOptions = {\n  allowIndefinite: false,\n  coerceUndefinedToNull: true,\n  allowNaN: false,\n  allowInfinity: false,\n  allowBigInt: true,\n  strict: true,\n  useMaps: false,\n  tags: []\n};\ndecodeOptions.tags[CID_CBOR_TAG] = cidDecoder;\nconst name = 'dag-cbor';\nconst code = 113;\n\nconst encode = node => cborg__namespace.encode(node, encodeOptions);\n\nconst decode = data => cborg__namespace.decode(data, decodeOptions);\n\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/dag-cbor/cjs/index.js?");

/***/ }),

/***/ "./node_modules/@ipld/dag-pb/cjs/src/index.js":
/*!****************************************************!*\
  !*** ./node_modules/@ipld/dag-pb/cjs/src/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar pbDecode = __webpack_require__(/*! ./pb-decode.js */ \"./node_modules/@ipld/dag-pb/cjs/src/pb-decode.js\");\n\nvar pbEncode = __webpack_require__(/*! ./pb-encode.js */ \"./node_modules/@ipld/dag-pb/cjs/src/pb-encode.js\");\n\nvar util = __webpack_require__(/*! ./util.js */ \"./node_modules/@ipld/dag-pb/cjs/src/util.js\");\n\nconst name = 'dag-pb';\nconst code = 112;\n\nfunction encode(node) {\n  util.validate(node);\n  const pbn = {};\n\n  if (node.Links) {\n    pbn.Links = node.Links.map(l => {\n      const link = {};\n\n      if (l.Hash) {\n        link.Hash = l.Hash.bytes;\n      }\n\n      if (l.Name !== undefined) {\n        link.Name = l.Name;\n      }\n\n      if (l.Tsize !== undefined) {\n        link.Tsize = l.Tsize;\n      }\n\n      return link;\n    });\n  }\n\n  if (node.Data) {\n    pbn.Data = node.Data;\n  }\n\n  return pbEncode.encodeNode(pbn);\n}\n\nfunction decode(bytes) {\n  const pbn = pbDecode.decodeNode(bytes);\n  const node = {};\n\n  if (pbn.Data) {\n    node.Data = pbn.Data;\n  }\n\n  if (pbn.Links) {\n    node.Links = pbn.Links.map(l => {\n      const link = {};\n\n      try {\n        link.Hash = cid.CID.decode(l.Hash);\n      } catch (e) {}\n\n      if (!link.Hash) {\n        throw new Error('Invalid Hash field found in link, expected CID');\n      }\n\n      if (l.Name !== undefined) {\n        link.Name = l.Name;\n      }\n\n      if (l.Tsize !== undefined) {\n        link.Tsize = l.Tsize;\n      }\n\n      return link;\n    });\n  }\n\n  return node;\n}\n\nexports.createLink = util.createLink;\nexports.createNode = util.createNode;\nexports.prepare = util.prepare;\nexports.validate = util.validate;\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/dag-pb/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/@ipld/dag-pb/cjs/src/pb-decode.js":
/*!********************************************************!*\
  !*** ./node_modules/@ipld/dag-pb/cjs/src/pb-decode.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nconst textDecoder = new TextDecoder();\n\nfunction decodeVarint(bytes, offset) {\n  let v = 0;\n\n  for (let shift = 0;; shift += 7) {\n    if (shift >= 64) {\n      throw new Error('protobuf: varint overflow');\n    }\n\n    if (offset >= bytes.length) {\n      throw new Error('protobuf: unexpected end of data');\n    }\n\n    const b = bytes[offset++];\n    v += shift < 28 ? (b & 127) << shift : (b & 127) * 2 ** shift;\n\n    if (b < 128) {\n      break;\n    }\n  }\n\n  return [v, offset];\n}\n\nfunction decodeBytes(bytes, offset) {\n  let byteLen;\n  [byteLen, offset] = decodeVarint(bytes, offset);\n  const postOffset = offset + byteLen;\n\n  if (byteLen < 0 || postOffset < 0) {\n    throw new Error('protobuf: invalid length');\n  }\n\n  if (postOffset > bytes.length) {\n    throw new Error('protobuf: unexpected end of data');\n  }\n\n  return [bytes.subarray(offset, postOffset), postOffset];\n}\n\nfunction decodeKey(bytes, index) {\n  let wire;\n  [wire, index] = decodeVarint(bytes, index);\n  return [wire & 7, wire >> 3, index];\n}\n\nfunction decodeLink(bytes) {\n  const link = {};\n  const l = bytes.length;\n  let index = 0;\n\n  while (index < l) {\n    let wireType, fieldNum;\n    [wireType, fieldNum, index] = decodeKey(bytes, index);\n\n    if (fieldNum === 1) {\n      if (link.Hash) {\n        throw new Error('protobuf: (PBLink) duplicate Hash section');\n      }\n\n      if (wireType !== 2) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Hash`);\n      }\n\n      if (link.Name !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Name before Hash');\n      }\n\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Tsize before Hash');\n      }\n\n      ;\n      [link.Hash, index] = decodeBytes(bytes, index);\n    } else if (fieldNum === 2) {\n      if (link.Name !== undefined) {\n        throw new Error('protobuf: (PBLink) duplicate Name section');\n      }\n\n      if (wireType !== 2) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Name`);\n      }\n\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Tsize before Name');\n      }\n\n      let byts;\n      [byts, index] = decodeBytes(bytes, index);\n      link.Name = textDecoder.decode(byts);\n    } else if (fieldNum === 3) {\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) duplicate Tsize section');\n      }\n\n      if (wireType !== 0) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Tsize`);\n      }\n\n      ;\n      [link.Tsize, index] = decodeVarint(bytes, index);\n    } else {\n      throw new Error(`protobuf: (PBLink) invalid fieldNumber, expected 1, 2 or 3, got ${fieldNum}`);\n    }\n  }\n\n  if (index > l) {\n    throw new Error('protobuf: (PBLink) unexpected end of data');\n  }\n\n  return link;\n}\n\nfunction decodeNode(bytes) {\n  const l = bytes.length;\n  let index = 0;\n  let links;\n  let linksBeforeData = false;\n  let data;\n\n  while (index < l) {\n    let wireType, fieldNum;\n    [wireType, fieldNum, index] = decodeKey(bytes, index);\n\n    if (wireType !== 2) {\n      throw new Error(`protobuf: (PBNode) invalid wireType, expected 2, got ${wireType}`);\n    }\n\n    if (fieldNum === 1) {\n      if (data) {\n        throw new Error('protobuf: (PBNode) duplicate Data section');\n      }\n\n      ;\n      [data, index] = decodeBytes(bytes, index);\n\n      if (links) {\n        linksBeforeData = true;\n      }\n    } else if (fieldNum === 2) {\n      if (linksBeforeData) {\n        throw new Error('protobuf: (PBNode) duplicate Links section');\n      } else if (!links) {\n        links = [];\n      }\n\n      let byts;\n      [byts, index] = decodeBytes(bytes, index);\n      links.push(decodeLink(byts));\n    } else {\n      throw new Error(`protobuf: (PBNode) invalid fieldNumber, expected 1 or 2, got ${fieldNum}`);\n    }\n  }\n\n  if (index > l) {\n    throw new Error('protobuf: (PBNode) unexpected end of data');\n  }\n\n  const node = {};\n\n  if (data) {\n    node.Data = data;\n  }\n\n  node.Links = links || [];\n  return node;\n}\n\nexports.decodeNode = decodeNode;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/dag-pb/cjs/src/pb-decode.js?");

/***/ }),

/***/ "./node_modules/@ipld/dag-pb/cjs/src/pb-encode.js":
/*!********************************************************!*\
  !*** ./node_modules/@ipld/dag-pb/cjs/src/pb-encode.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nconst textEncoder = new TextEncoder();\nconst maxInt32 = 2 ** 32;\nconst maxUInt32 = 2 ** 31;\n\nfunction encodeLink(link, bytes) {\n  let i = bytes.length;\n\n  if (typeof link.Tsize === 'number') {\n    if (link.Tsize < 0) {\n      throw new Error('Tsize cannot be negative');\n    }\n\n    if (!Number.isSafeInteger(link.Tsize)) {\n      throw new Error('Tsize too large for encoding');\n    }\n\n    i = encodeVarint(bytes, i, link.Tsize) - 1;\n    bytes[i] = 24;\n  }\n\n  if (typeof link.Name === 'string') {\n    const nameBytes = textEncoder.encode(link.Name);\n    i -= nameBytes.length;\n    bytes.set(nameBytes, i);\n    i = encodeVarint(bytes, i, nameBytes.length) - 1;\n    bytes[i] = 18;\n  }\n\n  if (link.Hash) {\n    i -= link.Hash.length;\n    bytes.set(link.Hash, i);\n    i = encodeVarint(bytes, i, link.Hash.length) - 1;\n    bytes[i] = 10;\n  }\n\n  return bytes.length - i;\n}\n\nfunction encodeNode(node) {\n  const size = sizeNode(node);\n  const bytes = new Uint8Array(size);\n  let i = size;\n\n  if (node.Data) {\n    i -= node.Data.length;\n    bytes.set(node.Data, i);\n    i = encodeVarint(bytes, i, node.Data.length) - 1;\n    bytes[i] = 10;\n  }\n\n  if (node.Links) {\n    for (let index = node.Links.length - 1; index >= 0; index--) {\n      const size = encodeLink(node.Links[index], bytes.subarray(0, i));\n      i -= size;\n      i = encodeVarint(bytes, i, size) - 1;\n      bytes[i] = 18;\n    }\n  }\n\n  return bytes;\n}\n\nfunction sizeLink(link) {\n  let n = 0;\n\n  if (link.Hash) {\n    const l = link.Hash.length;\n    n += 1 + l + sov(l);\n  }\n\n  if (typeof link.Name === 'string') {\n    const l = textEncoder.encode(link.Name).length;\n    n += 1 + l + sov(l);\n  }\n\n  if (typeof link.Tsize === 'number') {\n    n += 1 + sov(link.Tsize);\n  }\n\n  return n;\n}\n\nfunction sizeNode(node) {\n  let n = 0;\n\n  if (node.Data) {\n    const l = node.Data.length;\n    n += 1 + l + sov(l);\n  }\n\n  if (node.Links) {\n    for (const link of node.Links) {\n      const l = sizeLink(link);\n      n += 1 + l + sov(l);\n    }\n  }\n\n  return n;\n}\n\nfunction encodeVarint(bytes, offset, v) {\n  offset -= sov(v);\n  const base = offset;\n\n  while (v >= maxUInt32) {\n    bytes[offset++] = v & 127 | 128;\n    v /= 128;\n  }\n\n  while (v >= 128) {\n    bytes[offset++] = v & 127 | 128;\n    v >>>= 7;\n  }\n\n  bytes[offset] = v;\n  return base;\n}\n\nfunction sov(x) {\n  if (x % 2 === 0) {\n    x++;\n  }\n\n  return Math.floor((len64(x) + 6) / 7);\n}\n\nfunction len64(x) {\n  let n = 0;\n\n  if (x >= maxInt32) {\n    x = Math.floor(x / maxInt32);\n    n = 32;\n  }\n\n  if (x >= 1 << 16) {\n    x >>>= 16;\n    n += 16;\n  }\n\n  if (x >= 1 << 8) {\n    x >>>= 8;\n    n += 8;\n  }\n\n  return n + len8tab[x];\n}\n\nconst len8tab = [0, 1, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8];\nexports.encodeNode = encodeNode;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/dag-pb/cjs/src/pb-encode.js?");

/***/ }),

/***/ "./node_modules/@ipld/dag-pb/cjs/src/util.js":
/*!***************************************************!*\
  !*** ./node_modules/@ipld/dag-pb/cjs/src/util.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nconst pbNodeProperties = ['Data', 'Links'];\nconst pbLinkProperties = ['Hash', 'Name', 'Tsize'];\nconst textEncoder = new TextEncoder();\n\nfunction linkComparator(a, b) {\n  if (a === b) {\n    return 0;\n  }\n\n  const abuf = a.Name ? textEncoder.encode(a.Name) : [];\n  const bbuf = b.Name ? textEncoder.encode(b.Name) : [];\n  let x = abuf.length;\n  let y = bbuf.length;\n\n  for (let i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (abuf[i] !== bbuf[i]) {\n      x = abuf[i];\n      y = bbuf[i];\n      break;\n    }\n  }\n\n  return x < y ? -1 : y < x ? 1 : 0;\n}\n\nfunction hasOnlyProperties(node, properties) {\n  return !Object.keys(node).some(p => !properties.includes(p));\n}\n\nfunction asLink(link) {\n  if (typeof link.asCID === 'object') {\n    const Hash = cid.CID.asCID(link);\n\n    if (!Hash) {\n      throw new TypeError('Invalid DAG-PB form');\n    }\n\n    return {\n      Hash\n    };\n  }\n\n  if (typeof link !== 'object' || Array.isArray(link)) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n\n  const pbl = {};\n\n  if (link.Hash) {\n    let cid$1 = cid.CID.asCID(link.Hash);\n\n    try {\n      if (!cid$1) {\n        if (typeof link.Hash === 'string') {\n          cid$1 = cid.CID.parse(link.Hash);\n        } else if (link.Hash instanceof Uint8Array) {\n          cid$1 = cid.CID.decode(link.Hash);\n        }\n      }\n    } catch (e) {\n      throw new TypeError(`Invalid DAG-PB form: ${e.message}`);\n    }\n\n    if (cid$1) {\n      pbl.Hash = cid$1;\n    }\n  }\n\n  if (!pbl.Hash) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n\n  if (typeof link.Name === 'string') {\n    pbl.Name = link.Name;\n  }\n\n  if (typeof link.Tsize === 'number') {\n    pbl.Tsize = link.Tsize;\n  }\n\n  return pbl;\n}\n\nfunction prepare(node) {\n  if (node instanceof Uint8Array || typeof node === 'string') {\n    node = {\n      Data: node\n    };\n  }\n\n  if (typeof node !== 'object' || Array.isArray(node)) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n\n  const pbn = {};\n\n  if (node.Data !== undefined) {\n    if (typeof node.Data === 'string') {\n      pbn.Data = textEncoder.encode(node.Data);\n    } else if (node.Data instanceof Uint8Array) {\n      pbn.Data = node.Data;\n    } else {\n      throw new TypeError('Invalid DAG-PB form');\n    }\n  }\n\n  if (node.Links !== undefined) {\n    if (Array.isArray(node.Links)) {\n      pbn.Links = node.Links.map(asLink);\n      pbn.Links.sort(linkComparator);\n    } else {\n      throw new TypeError('Invalid DAG-PB form');\n    }\n  } else {\n    pbn.Links = [];\n  }\n\n  return pbn;\n}\n\nfunction validate(node) {\n  if (!node || typeof node !== 'object' || Array.isArray(node)) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n\n  if (!hasOnlyProperties(node, pbNodeProperties)) {\n    throw new TypeError('Invalid DAG-PB form (extraneous properties)');\n  }\n\n  if (node.Data !== undefined && !(node.Data instanceof Uint8Array)) {\n    throw new TypeError('Invalid DAG-PB form (Data must be a Uint8Array)');\n  }\n\n  if (!Array.isArray(node.Links)) {\n    throw new TypeError('Invalid DAG-PB form (Links must be an array)');\n  }\n\n  for (let i = 0; i < node.Links.length; i++) {\n    const link = node.Links[i];\n\n    if (!link || typeof link !== 'object' || Array.isArray(link)) {\n      throw new TypeError('Invalid DAG-PB form (bad link object)');\n    }\n\n    if (!hasOnlyProperties(link, pbLinkProperties)) {\n      throw new TypeError('Invalid DAG-PB form (extraneous properties on link object)');\n    }\n\n    if (!link.Hash) {\n      throw new TypeError('Invalid DAG-PB form (link must have a Hash)');\n    }\n\n    if (link.Hash.asCID !== link.Hash) {\n      throw new TypeError('Invalid DAG-PB form (link Hash must be a CID)');\n    }\n\n    if (link.Name !== undefined && typeof link.Name !== 'string') {\n      throw new TypeError('Invalid DAG-PB form (link Name must be a string)');\n    }\n\n    if (link.Tsize !== undefined && (typeof link.Tsize !== 'number' || link.Tsize % 1 !== 0)) {\n      throw new TypeError('Invalid DAG-PB form (link Tsize must be an integer)');\n    }\n\n    if (i > 0 && linkComparator(link, node.Links[i - 1]) === -1) {\n      throw new TypeError('Invalid DAG-PB form (links must be sorted by Name bytes)');\n    }\n  }\n}\n\nfunction createNode(data, links = []) {\n  return prepare({\n    Data: data,\n    Links: links\n  });\n}\n\nfunction createLink(name, size, cid) {\n  return asLink({\n    Hash: cid,\n    Name: name,\n    Tsize: size\n  });\n}\n\nexports.createLink = createLink;\nexports.createNode = createNode;\nexports.prepare = prepare;\nexports.validate = validate;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@ipld/dag-pb/cjs/src/util.js?");

/***/ }),

/***/ "./node_modules/@multiformats/murmur3/cjs/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/@multiformats/murmur3/cjs/index.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar hasher = __webpack_require__(/*! multiformats/hashes/hasher */ \"./node_modules/multiformats/cjs/src/hashes/hasher.js\");\n\nvar multiformats = __webpack_require__(/*! multiformats */ \"./node_modules/multiformats/cjs/src/index.js\");\n\nvar mur = __webpack_require__(/*! murmurhash3js-revisited */ \"./node_modules/murmurhash3js-revisited/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar mur__default = /*#__PURE__*/_interopDefaultLegacy(mur);\n\nfunction fromNumberTo32BitBuf(number) {\n  const bytes = new Array(4);\n\n  for (let i = 0; i < 4; i++) {\n    bytes[i] = number & 255;\n    number = number >> 8;\n  }\n\n  return new Uint8Array(bytes);\n}\n\nconst murmur332 = hasher.from({\n  name: 'murmur3-32',\n  code: 35,\n  encode: input => fromNumberTo32BitBuf(mur__default[\"default\"].x86.hash32(input))\n});\nconst murmur3128 = hasher.from({\n  name: 'murmur3-128',\n  code: 34,\n  encode: input => multiformats.bytes.fromHex(mur__default[\"default\"].x64.hash128(input))\n});\nexports.murmur3128 = murmur3128;\nexports.murmur332 = murmur332;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@multiformats/murmur3/cjs/index.js?");

/***/ }),

/***/ "./node_modules/@protobufjs/aspromise/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/@protobufjs/aspromise/index.js ***!
  \*****************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = asPromise;\n/**\r\n * Callback as used by {@link util.asPromise}.\r\n * @typedef asPromiseCallback\r\n * @type {function}\r\n * @param {Error|null} error Error, if any\r\n * @param {...*} params Additional arguments\r\n * @returns {undefined}\r\n */\n\n/**\r\n * Returns a promise from a node-style callback function.\r\n * @memberof util\r\n * @param {asPromiseCallback} fn Function to call\r\n * @param {*} ctx Function context\r\n * @param {...*} params Function arguments\r\n * @returns {Promise<*>} Promisified function\r\n */\n\nfunction asPromise(fn, ctx\n/*, varargs */\n) {\n  var params = new Array(arguments.length - 1),\n      offset = 0,\n      index = 2,\n      pending = true;\n\n  while (index < arguments.length) params[offset++] = arguments[index++];\n\n  return new Promise(function executor(resolve, reject) {\n    params[offset] = function callback(err\n    /*, varargs */\n    ) {\n      if (pending) {\n        pending = false;\n        if (err) reject(err);else {\n          var params = new Array(arguments.length - 1),\n              offset = 0;\n\n          while (offset < params.length) params[offset++] = arguments[offset];\n\n          resolve.apply(null, params);\n        }\n      }\n    };\n\n    try {\n      fn.apply(ctx || null, params);\n    } catch (err) {\n      if (pending) {\n        pending = false;\n        reject(err);\n      }\n    }\n  });\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@protobufjs/aspromise/index.js?");

/***/ }),

/***/ "./node_modules/@protobufjs/base64/index.js":
/*!**************************************************!*\
  !*** ./node_modules/@protobufjs/base64/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/**\r\n * A minimal base64 implementation for number arrays.\r\n * @memberof util\r\n * @namespace\r\n */\n\nvar base64 = exports;\n/**\r\n * Calculates the byte length of a base64 encoded string.\r\n * @param {string} string Base64 encoded string\r\n * @returns {number} Byte length\r\n */\n\nbase64.length = function length(string) {\n  var p = string.length;\n  if (!p) return 0;\n  var n = 0;\n\n  while (--p % 4 > 1 && string.charAt(p) === \"=\") ++n;\n\n  return Math.ceil(string.length * 3) / 4 - n;\n}; // Base64 encoding table\n\n\nvar b64 = new Array(64); // Base64 decoding table\n\nvar s64 = new Array(123); // 65..90, 97..122, 48..57, 43, 47\n\nfor (var i = 0; i < 64;) s64[b64[i] = i < 26 ? i + 65 : i < 52 ? i + 71 : i < 62 ? i - 4 : i - 59 | 43] = i++;\n/**\r\n * Encodes a buffer to a base64 encoded string.\r\n * @param {Uint8Array} buffer Source buffer\r\n * @param {number} start Source start\r\n * @param {number} end Source end\r\n * @returns {string} Base64 encoded string\r\n */\n\n\nbase64.encode = function encode(buffer, start, end) {\n  var parts = null,\n      chunk = [];\n  var i = 0,\n      // output index\n  j = 0,\n      // goto index\n  t; // temporary\n\n  while (start < end) {\n    var b = buffer[start++];\n\n    switch (j) {\n      case 0:\n        chunk[i++] = b64[b >> 2];\n        t = (b & 3) << 4;\n        j = 1;\n        break;\n\n      case 1:\n        chunk[i++] = b64[t | b >> 4];\n        t = (b & 15) << 2;\n        j = 2;\n        break;\n\n      case 2:\n        chunk[i++] = b64[t | b >> 6];\n        chunk[i++] = b64[b & 63];\n        j = 0;\n        break;\n    }\n\n    if (i > 8191) {\n      (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));\n      i = 0;\n    }\n  }\n\n  if (j) {\n    chunk[i++] = b64[t];\n    chunk[i++] = 61;\n    if (j === 1) chunk[i++] = 61;\n  }\n\n  if (parts) {\n    if (i) parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));\n    return parts.join(\"\");\n  }\n\n  return String.fromCharCode.apply(String, chunk.slice(0, i));\n};\n\nvar invalidEncoding = \"invalid encoding\";\n/**\r\n * Decodes a base64 encoded string to a buffer.\r\n * @param {string} string Source string\r\n * @param {Uint8Array} buffer Destination buffer\r\n * @param {number} offset Destination offset\r\n * @returns {number} Number of bytes written\r\n * @throws {Error} If encoding is invalid\r\n */\n\nbase64.decode = function decode(string, buffer, offset) {\n  var start = offset;\n  var j = 0,\n      // goto index\n  t; // temporary\n\n  for (var i = 0; i < string.length;) {\n    var c = string.charCodeAt(i++);\n    if (c === 61 && j > 1) break;\n    if ((c = s64[c]) === undefined) throw Error(invalidEncoding);\n\n    switch (j) {\n      case 0:\n        t = c;\n        j = 1;\n        break;\n\n      case 1:\n        buffer[offset++] = t << 2 | (c & 48) >> 4;\n        t = c;\n        j = 2;\n        break;\n\n      case 2:\n        buffer[offset++] = (t & 15) << 4 | (c & 60) >> 2;\n        t = c;\n        j = 3;\n        break;\n\n      case 3:\n        buffer[offset++] = (t & 3) << 6 | c;\n        j = 0;\n        break;\n    }\n  }\n\n  if (j === 1) throw Error(invalidEncoding);\n  return offset - start;\n};\n/**\r\n * Tests if the specified string appears to be base64 encoded.\r\n * @param {string} string String to test\r\n * @returns {boolean} `true` if probably base64 encoded, otherwise false\r\n */\n\n\nbase64.test = function test(string) {\n  return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(string);\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@protobufjs/base64/index.js?");

/***/ }),

/***/ "./node_modules/@protobufjs/eventemitter/index.js":
/*!********************************************************!*\
  !*** ./node_modules/@protobufjs/eventemitter/index.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = EventEmitter;\n/**\r\n * Constructs a new event emitter instance.\r\n * @classdesc A minimal event emitter.\r\n * @memberof util\r\n * @constructor\r\n */\n\nfunction EventEmitter() {\n  /**\r\n   * Registered listeners.\r\n   * @type {Object.<string,*>}\r\n   * @private\r\n   */\n  this._listeners = {};\n}\n/**\r\n * Registers an event listener.\r\n * @param {string} evt Event name\r\n * @param {function} fn Listener\r\n * @param {*} [ctx] Listener context\r\n * @returns {util.EventEmitter} `this`\r\n */\n\n\nEventEmitter.prototype.on = function on(evt, fn, ctx) {\n  (this._listeners[evt] || (this._listeners[evt] = [])).push({\n    fn: fn,\n    ctx: ctx || this\n  });\n  return this;\n};\n/**\r\n * Removes an event listener or any matching listeners if arguments are omitted.\r\n * @param {string} [evt] Event name. Removes all listeners if omitted.\r\n * @param {function} [fn] Listener to remove. Removes all listeners of `evt` if omitted.\r\n * @returns {util.EventEmitter} `this`\r\n */\n\n\nEventEmitter.prototype.off = function off(evt, fn) {\n  if (evt === undefined) this._listeners = {};else {\n    if (fn === undefined) this._listeners[evt] = [];else {\n      var listeners = this._listeners[evt];\n\n      for (var i = 0; i < listeners.length;) if (listeners[i].fn === fn) listeners.splice(i, 1);else ++i;\n    }\n  }\n  return this;\n};\n/**\r\n * Emits an event by calling its listeners with the specified arguments.\r\n * @param {string} evt Event name\r\n * @param {...*} args Arguments\r\n * @returns {util.EventEmitter} `this`\r\n */\n\n\nEventEmitter.prototype.emit = function emit(evt) {\n  var listeners = this._listeners[evt];\n\n  if (listeners) {\n    var args = [],\n        i = 1;\n\n    for (; i < arguments.length;) args.push(arguments[i++]);\n\n    for (i = 0; i < listeners.length;) listeners[i].fn.apply(listeners[i++].ctx, args);\n  }\n\n  return this;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@protobufjs/eventemitter/index.js?");

/***/ }),

/***/ "./node_modules/@protobufjs/float/index.js":
/*!*************************************************!*\
  !*** ./node_modules/@protobufjs/float/index.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = factory(factory);\n/**\r\n * Reads / writes floats / doubles from / to buffers.\r\n * @name util.float\r\n * @namespace\r\n */\n\n/**\r\n * Writes a 32 bit float to a buffer using little endian byte order.\r\n * @name util.float.writeFloatLE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\n\n/**\r\n * Writes a 32 bit float to a buffer using big endian byte order.\r\n * @name util.float.writeFloatBE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\n\n/**\r\n * Reads a 32 bit float from a buffer using little endian byte order.\r\n * @name util.float.readFloatLE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\n\n/**\r\n * Reads a 32 bit float from a buffer using big endian byte order.\r\n * @name util.float.readFloatBE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\n\n/**\r\n * Writes a 64 bit double to a buffer using little endian byte order.\r\n * @name util.float.writeDoubleLE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\n\n/**\r\n * Writes a 64 bit double to a buffer using big endian byte order.\r\n * @name util.float.writeDoubleBE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\n\n/**\r\n * Reads a 64 bit double from a buffer using little endian byte order.\r\n * @name util.float.readDoubleLE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\n\n/**\r\n * Reads a 64 bit double from a buffer using big endian byte order.\r\n * @name util.float.readDoubleBE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\n// Factory function for the purpose of node-based testing in modified global environments\n\nfunction factory(exports) {\n  // float: typed array\n  if (typeof Float32Array !== \"undefined\") (function () {\n    var f32 = new Float32Array([-0]),\n        f8b = new Uint8Array(f32.buffer),\n        le = f8b[3] === 128;\n\n    function writeFloat_f32_cpy(val, buf, pos) {\n      f32[0] = val;\n      buf[pos] = f8b[0];\n      buf[pos + 1] = f8b[1];\n      buf[pos + 2] = f8b[2];\n      buf[pos + 3] = f8b[3];\n    }\n\n    function writeFloat_f32_rev(val, buf, pos) {\n      f32[0] = val;\n      buf[pos] = f8b[3];\n      buf[pos + 1] = f8b[2];\n      buf[pos + 2] = f8b[1];\n      buf[pos + 3] = f8b[0];\n    }\n    /* istanbul ignore next */\n\n\n    exports.writeFloatLE = le ? writeFloat_f32_cpy : writeFloat_f32_rev;\n    /* istanbul ignore next */\n\n    exports.writeFloatBE = le ? writeFloat_f32_rev : writeFloat_f32_cpy;\n\n    function readFloat_f32_cpy(buf, pos) {\n      f8b[0] = buf[pos];\n      f8b[1] = buf[pos + 1];\n      f8b[2] = buf[pos + 2];\n      f8b[3] = buf[pos + 3];\n      return f32[0];\n    }\n\n    function readFloat_f32_rev(buf, pos) {\n      f8b[3] = buf[pos];\n      f8b[2] = buf[pos + 1];\n      f8b[1] = buf[pos + 2];\n      f8b[0] = buf[pos + 3];\n      return f32[0];\n    }\n    /* istanbul ignore next */\n\n\n    exports.readFloatLE = le ? readFloat_f32_cpy : readFloat_f32_rev;\n    /* istanbul ignore next */\n\n    exports.readFloatBE = le ? readFloat_f32_rev : readFloat_f32_cpy; // float: ieee754\n  })();else (function () {\n    function writeFloat_ieee754(writeUint, val, buf, pos) {\n      var sign = val < 0 ? 1 : 0;\n      if (sign) val = -val;\n      if (val === 0) writeUint(1 / val > 0 ?\n      /* positive */\n      0 :\n      /* negative 0 */\n      2147483648, buf, pos);else if (isNaN(val)) writeUint(2143289344, buf, pos);else if (val > 3.4028234663852886e+38) // +-Infinity\n        writeUint((sign << 31 | 2139095040) >>> 0, buf, pos);else if (val < 1.1754943508222875e-38) // denormal\n        writeUint((sign << 31 | Math.round(val / 1.401298464324817e-45)) >>> 0, buf, pos);else {\n        var exponent = Math.floor(Math.log(val) / Math.LN2),\n            mantissa = Math.round(val * Math.pow(2, -exponent) * 8388608) & 8388607;\n        writeUint((sign << 31 | exponent + 127 << 23 | mantissa) >>> 0, buf, pos);\n      }\n    }\n\n    exports.writeFloatLE = writeFloat_ieee754.bind(null, writeUintLE);\n    exports.writeFloatBE = writeFloat_ieee754.bind(null, writeUintBE);\n\n    function readFloat_ieee754(readUint, buf, pos) {\n      var uint = readUint(buf, pos),\n          sign = (uint >> 31) * 2 + 1,\n          exponent = uint >>> 23 & 255,\n          mantissa = uint & 8388607;\n      return exponent === 255 ? mantissa ? NaN : sign * Infinity : exponent === 0 // denormal\n      ? sign * 1.401298464324817e-45 * mantissa : sign * Math.pow(2, exponent - 150) * (mantissa + 8388608);\n    }\n\n    exports.readFloatLE = readFloat_ieee754.bind(null, readUintLE);\n    exports.readFloatBE = readFloat_ieee754.bind(null, readUintBE);\n  })(); // double: typed array\n\n  if (typeof Float64Array !== \"undefined\") (function () {\n    var f64 = new Float64Array([-0]),\n        f8b = new Uint8Array(f64.buffer),\n        le = f8b[7] === 128;\n\n    function writeDouble_f64_cpy(val, buf, pos) {\n      f64[0] = val;\n      buf[pos] = f8b[0];\n      buf[pos + 1] = f8b[1];\n      buf[pos + 2] = f8b[2];\n      buf[pos + 3] = f8b[3];\n      buf[pos + 4] = f8b[4];\n      buf[pos + 5] = f8b[5];\n      buf[pos + 6] = f8b[6];\n      buf[pos + 7] = f8b[7];\n    }\n\n    function writeDouble_f64_rev(val, buf, pos) {\n      f64[0] = val;\n      buf[pos] = f8b[7];\n      buf[pos + 1] = f8b[6];\n      buf[pos + 2] = f8b[5];\n      buf[pos + 3] = f8b[4];\n      buf[pos + 4] = f8b[3];\n      buf[pos + 5] = f8b[2];\n      buf[pos + 6] = f8b[1];\n      buf[pos + 7] = f8b[0];\n    }\n    /* istanbul ignore next */\n\n\n    exports.writeDoubleLE = le ? writeDouble_f64_cpy : writeDouble_f64_rev;\n    /* istanbul ignore next */\n\n    exports.writeDoubleBE = le ? writeDouble_f64_rev : writeDouble_f64_cpy;\n\n    function readDouble_f64_cpy(buf, pos) {\n      f8b[0] = buf[pos];\n      f8b[1] = buf[pos + 1];\n      f8b[2] = buf[pos + 2];\n      f8b[3] = buf[pos + 3];\n      f8b[4] = buf[pos + 4];\n      f8b[5] = buf[pos + 5];\n      f8b[6] = buf[pos + 6];\n      f8b[7] = buf[pos + 7];\n      return f64[0];\n    }\n\n    function readDouble_f64_rev(buf, pos) {\n      f8b[7] = buf[pos];\n      f8b[6] = buf[pos + 1];\n      f8b[5] = buf[pos + 2];\n      f8b[4] = buf[pos + 3];\n      f8b[3] = buf[pos + 4];\n      f8b[2] = buf[pos + 5];\n      f8b[1] = buf[pos + 6];\n      f8b[0] = buf[pos + 7];\n      return f64[0];\n    }\n    /* istanbul ignore next */\n\n\n    exports.readDoubleLE = le ? readDouble_f64_cpy : readDouble_f64_rev;\n    /* istanbul ignore next */\n\n    exports.readDoubleBE = le ? readDouble_f64_rev : readDouble_f64_cpy; // double: ieee754\n  })();else (function () {\n    function writeDouble_ieee754(writeUint, off0, off1, val, buf, pos) {\n      var sign = val < 0 ? 1 : 0;\n      if (sign) val = -val;\n\n      if (val === 0) {\n        writeUint(0, buf, pos + off0);\n        writeUint(1 / val > 0 ?\n        /* positive */\n        0 :\n        /* negative 0 */\n        2147483648, buf, pos + off1);\n      } else if (isNaN(val)) {\n        writeUint(0, buf, pos + off0);\n        writeUint(2146959360, buf, pos + off1);\n      } else if (val > 1.7976931348623157e+308) {\n        // +-Infinity\n        writeUint(0, buf, pos + off0);\n        writeUint((sign << 31 | 2146435072) >>> 0, buf, pos + off1);\n      } else {\n        var mantissa;\n\n        if (val < 2.2250738585072014e-308) {\n          // denormal\n          mantissa = val / 5e-324;\n          writeUint(mantissa >>> 0, buf, pos + off0);\n          writeUint((sign << 31 | mantissa / 4294967296) >>> 0, buf, pos + off1);\n        } else {\n          var exponent = Math.floor(Math.log(val) / Math.LN2);\n          if (exponent === 1024) exponent = 1023;\n          mantissa = val * Math.pow(2, -exponent);\n          writeUint(mantissa * 4503599627370496 >>> 0, buf, pos + off0);\n          writeUint((sign << 31 | exponent + 1023 << 20 | mantissa * 1048576 & 1048575) >>> 0, buf, pos + off1);\n        }\n      }\n    }\n\n    exports.writeDoubleLE = writeDouble_ieee754.bind(null, writeUintLE, 0, 4);\n    exports.writeDoubleBE = writeDouble_ieee754.bind(null, writeUintBE, 4, 0);\n\n    function readDouble_ieee754(readUint, off0, off1, buf, pos) {\n      var lo = readUint(buf, pos + off0),\n          hi = readUint(buf, pos + off1);\n      var sign = (hi >> 31) * 2 + 1,\n          exponent = hi >>> 20 & 2047,\n          mantissa = 4294967296 * (hi & 1048575) + lo;\n      return exponent === 2047 ? mantissa ? NaN : sign * Infinity : exponent === 0 // denormal\n      ? sign * 5e-324 * mantissa : sign * Math.pow(2, exponent - 1075) * (mantissa + 4503599627370496);\n    }\n\n    exports.readDoubleLE = readDouble_ieee754.bind(null, readUintLE, 0, 4);\n    exports.readDoubleBE = readDouble_ieee754.bind(null, readUintBE, 4, 0);\n  })();\n  return exports;\n} // uint helpers\n\n\nfunction writeUintLE(val, buf, pos) {\n  buf[pos] = val & 255;\n  buf[pos + 1] = val >>> 8 & 255;\n  buf[pos + 2] = val >>> 16 & 255;\n  buf[pos + 3] = val >>> 24;\n}\n\nfunction writeUintBE(val, buf, pos) {\n  buf[pos] = val >>> 24;\n  buf[pos + 1] = val >>> 16 & 255;\n  buf[pos + 2] = val >>> 8 & 255;\n  buf[pos + 3] = val & 255;\n}\n\nfunction readUintLE(buf, pos) {\n  return (buf[pos] | buf[pos + 1] << 8 | buf[pos + 2] << 16 | buf[pos + 3] << 24) >>> 0;\n}\n\nfunction readUintBE(buf, pos) {\n  return (buf[pos] << 24 | buf[pos + 1] << 16 | buf[pos + 2] << 8 | buf[pos + 3]) >>> 0;\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@protobufjs/float/index.js?");

/***/ }),

/***/ "./node_modules/@protobufjs/inquire/index.js":
/*!***************************************************!*\
  !*** ./node_modules/@protobufjs/inquire/index.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = inquire;\n/**\r\n * Requires a module only if available.\r\n * @memberof util\r\n * @param {string} moduleName Module to require\r\n * @returns {?Object} Required module if available and not empty, otherwise `null`\r\n */\n\nfunction inquire(moduleName) {\n  try {\n    var mod = eval(\"quire\".replace(/^/, \"re\"))(moduleName); // eslint-disable-line no-eval\n\n    if (mod && (mod.length || Object.keys(mod).length)) return mod;\n  } catch (e) {} // eslint-disable-line no-empty\n\n\n  return null;\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@protobufjs/inquire/index.js?");

/***/ }),

/***/ "./node_modules/@protobufjs/pool/index.js":
/*!************************************************!*\
  !*** ./node_modules/@protobufjs/pool/index.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = pool;\n/**\r\n * An allocator as used by {@link util.pool}.\r\n * @typedef PoolAllocator\r\n * @type {function}\r\n * @param {number} size Buffer size\r\n * @returns {Uint8Array} Buffer\r\n */\n\n/**\r\n * A slicer as used by {@link util.pool}.\r\n * @typedef PoolSlicer\r\n * @type {function}\r\n * @param {number} start Start offset\r\n * @param {number} end End offset\r\n * @returns {Uint8Array} Buffer slice\r\n * @this {Uint8Array}\r\n */\n\n/**\r\n * A general purpose buffer pool.\r\n * @memberof util\r\n * @function\r\n * @param {PoolAllocator} alloc Allocator\r\n * @param {PoolSlicer} slice Slicer\r\n * @param {number} [size=8192] Slab size\r\n * @returns {PoolAllocator} Pooled allocator\r\n */\n\nfunction pool(alloc, slice, size) {\n  var SIZE = size || 8192;\n  var MAX = SIZE >>> 1;\n  var slab = null;\n  var offset = SIZE;\n  return function pool_alloc(size) {\n    if (size < 1 || size > MAX) return alloc(size);\n\n    if (offset + size > SIZE) {\n      slab = alloc(SIZE);\n      offset = 0;\n    }\n\n    var buf = slice.call(slab, offset, offset += size);\n    if (offset & 7) // align to 32 bit\n      offset = (offset | 7) + 1;\n    return buf;\n  };\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@protobufjs/pool/index.js?");

/***/ }),

/***/ "./node_modules/@protobufjs/utf8/index.js":
/*!************************************************!*\
  !*** ./node_modules/@protobufjs/utf8/index.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/**\r\n * A minimal UTF8 implementation for number arrays.\r\n * @memberof util\r\n * @namespace\r\n */\n\nvar utf8 = exports;\n/**\r\n * Calculates the UTF8 byte length of a string.\r\n * @param {string} string String\r\n * @returns {number} Byte length\r\n */\n\nutf8.length = function utf8_length(string) {\n  var len = 0,\n      c = 0;\n\n  for (var i = 0; i < string.length; ++i) {\n    c = string.charCodeAt(i);\n    if (c < 128) len += 1;else if (c < 2048) len += 2;else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {\n      ++i;\n      len += 4;\n    } else len += 3;\n  }\n\n  return len;\n};\n/**\r\n * Reads UTF8 bytes as a string.\r\n * @param {Uint8Array} buffer Source buffer\r\n * @param {number} start Source start\r\n * @param {number} end Source end\r\n * @returns {string} String read\r\n */\n\n\nutf8.read = function utf8_read(buffer, start, end) {\n  var len = end - start;\n  if (len < 1) return \"\";\n  var parts = null,\n      chunk = [],\n      i = 0,\n      // char offset\n  t; // temporary\n\n  while (start < end) {\n    t = buffer[start++];\n    if (t < 128) chunk[i++] = t;else if (t > 191 && t < 224) chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;else if (t > 239 && t < 365) {\n      t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;\n      chunk[i++] = 0xD800 + (t >> 10);\n      chunk[i++] = 0xDC00 + (t & 1023);\n    } else chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;\n\n    if (i > 8191) {\n      (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));\n      i = 0;\n    }\n  }\n\n  if (parts) {\n    if (i) parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));\n    return parts.join(\"\");\n  }\n\n  return String.fromCharCode.apply(String, chunk.slice(0, i));\n};\n/**\r\n * Writes a string as UTF8 bytes.\r\n * @param {string} string Source string\r\n * @param {Uint8Array} buffer Destination buffer\r\n * @param {number} offset Destination offset\r\n * @returns {number} Bytes written\r\n */\n\n\nutf8.write = function utf8_write(string, buffer, offset) {\n  var start = offset,\n      c1,\n      // character 1\n  c2; // character 2\n\n  for (var i = 0; i < string.length; ++i) {\n    c1 = string.charCodeAt(i);\n\n    if (c1 < 128) {\n      buffer[offset++] = c1;\n    } else if (c1 < 2048) {\n      buffer[offset++] = c1 >> 6 | 192;\n      buffer[offset++] = c1 & 63 | 128;\n    } else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {\n      c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);\n      ++i;\n      buffer[offset++] = c1 >> 18 | 240;\n      buffer[offset++] = c1 >> 12 & 63 | 128;\n      buffer[offset++] = c1 >> 6 & 63 | 128;\n      buffer[offset++] = c1 & 63 | 128;\n    } else {\n      buffer[offset++] = c1 >> 12 | 224;\n      buffer[offset++] = c1 >> 6 & 63 | 128;\n      buffer[offset++] = c1 & 63 | 128;\n    }\n  }\n\n  return offset - start;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@protobufjs/utf8/index.js?");

/***/ }),

/***/ "./node_modules/@web3-storage/multipart-parser/cjs/src/index.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@web3-storage/multipart-parser/cjs/src/index.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar search = __webpack_require__(/*! ./search.js */ \"./node_modules/@web3-storage/multipart-parser/cjs/src/search.js\");\n\nvar utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/@web3-storage/multipart-parser/cjs/src/utils.js\");\n\nconst mergeArrays2 = Function.prototype.apply.bind(utils.mergeArrays, undefined);\nconst dash = utils.stringToArray('--');\nconst CRLF = utils.stringToArray('\\r\\n');\n\nfunction parseContentDisposition(header) {\n  const parts = header.split(';').map(part => part.trim());\n\n  if (parts.shift() !== 'form-data') {\n    throw new Error('malformed content-disposition header: missing \"form-data\" in `' + JSON.stringify(parts) + '`');\n  }\n\n  const out = {};\n\n  for (const part of parts) {\n    const kv = part.split('=', 2);\n\n    if (kv.length !== 2) {\n      throw new Error('malformed content-disposition header: key-value pair not found - ' + part + ' in `' + header + '`');\n    }\n\n    const [name, value] = kv;\n\n    if (value[0] === '\"' && value[value.length - 1] === '\"') {\n      out[name] = value.slice(1, -1).replace(/\\\\\"/g, '\"');\n    } else if (value[0] !== '\"' && value[value.length - 1] !== '\"') {\n      out[name] = value;\n    } else if (value[0] === '\"' && value[value.length - 1] !== '\"' || value[0] !== '\"' && value[value.length - 1] === '\"') {\n      throw new Error('malformed content-disposition header: mismatched quotations in `' + header + '`');\n    }\n  }\n\n  if (!out.name) {\n    throw new Error('malformed content-disposition header: missing field name in `' + header + '`');\n  }\n\n  return out;\n}\n\nfunction parsePartHeaders(lines) {\n  const entries = [];\n  let disposition = false;\n  let line;\n\n  while (typeof (line = lines.shift()) !== 'undefined') {\n    const colon = line.indexOf(':');\n\n    if (colon === -1) {\n      throw new Error('malformed multipart-form header: missing colon');\n    }\n\n    const header = line.slice(0, colon).trim().toLowerCase();\n    const value = line.slice(colon + 1).trim();\n\n    switch (header) {\n      case 'content-disposition':\n        disposition = true;\n        entries.push(...Object.entries(parseContentDisposition(value)));\n        break;\n\n      case 'content-type':\n        entries.push(['contentType', value]);\n    }\n  }\n\n  if (!disposition) {\n    throw new Error('malformed multipart-form header: missing content-disposition');\n  }\n\n  return Object.fromEntries(entries);\n}\n\nasync function readHeaderLines(it, needle) {\n  let firstChunk = true;\n  let lastTokenWasMatch = false;\n  const headerLines = [[]];\n  const crlfSearch = new search.StreamSearch(CRLF);\n\n  for (;;) {\n    const result = await it.next();\n\n    if (result.done) {\n      throw new Error('malformed multipart-form data: unexpected end of stream');\n    }\n\n    if (firstChunk && result.value !== search.MATCH && utils.arraysEqual(result.value.slice(0, 2), dash)) {\n      return [undefined, new Uint8Array()];\n    }\n\n    let chunk;\n\n    if (result.value !== search.MATCH) {\n      chunk = result.value;\n    } else if (!lastTokenWasMatch) {\n      chunk = needle;\n    } else {\n      throw new Error('malformed multipart-form data: unexpected boundary');\n    }\n\n    if (!chunk.length) {\n      continue;\n    }\n\n    if (firstChunk) {\n      firstChunk = false;\n    }\n\n    const tokens = crlfSearch.feed(chunk);\n\n    for (const [i, token] of tokens.entries()) {\n      const isMatch = token === search.MATCH;\n\n      if (!isMatch && !token.length) {\n        continue;\n      }\n\n      if (lastTokenWasMatch && isMatch) {\n        tokens.push(crlfSearch.end());\n        return [headerLines.filter(chunks => chunks.length).map(mergeArrays2).map(utils.arrayToString), utils.mergeArrays(...tokens.slice(i + 1).map(token => token === search.MATCH ? CRLF : token))];\n      }\n\n      if (lastTokenWasMatch = isMatch) {\n        headerLines.push([]);\n      } else {\n        headerLines[headerLines.length - 1].push(token);\n      }\n    }\n  }\n}\n\nasync function* streamMultipart(body, boundary) {\n  const needle = utils.mergeArrays(dash, utils.stringToArray(boundary));\n  const it = new search.ReadableStreamSearch(needle, body)[Symbol.asyncIterator]();\n\n  for (;;) {\n    const result = await it.next();\n\n    if (result.done) {\n      return;\n    }\n\n    if (result.value === search.MATCH) {\n      break;\n    }\n  }\n\n  const crlfSearch = new search.StreamSearch(CRLF);\n\n  for (;;) {\n    const [headerLines, tail] = await readHeaderLines(it, needle);\n\n    if (!headerLines) {\n      return;\n    }\n\n    async function nextToken() {\n      const result = await it.next();\n\n      if (result.done) {\n        throw new Error('malformed multipart-form data: unexpected end of stream');\n      }\n\n      return result;\n    }\n\n    let trailingCRLF = false;\n\n    function feedChunk(chunk) {\n      const chunks = [];\n\n      for (const token of crlfSearch.feed(chunk)) {\n        if (trailingCRLF) {\n          chunks.push(CRLF);\n        }\n\n        if (!(trailingCRLF = token === search.MATCH)) {\n          chunks.push(token);\n        }\n      }\n\n      return utils.mergeArrays(...chunks);\n    }\n\n    let done = false;\n\n    async function nextChunk() {\n      const result = await nextToken();\n      let chunk;\n\n      if (result.value !== search.MATCH) {\n        chunk = result.value;\n      } else if (!trailingCRLF) {\n        chunk = CRLF;\n      } else {\n        done = true;\n        return {\n          value: crlfSearch.end()\n        };\n      }\n\n      return {\n        value: feedChunk(chunk)\n      };\n    }\n\n    const bufferedChunks = [{\n      value: feedChunk(tail)\n    }];\n    yield { ...parsePartHeaders(headerLines),\n      data: {\n        [Symbol.asyncIterator]() {\n          return this;\n        },\n\n        async next() {\n          for (;;) {\n            const result = bufferedChunks.shift();\n\n            if (!result) {\n              break;\n            }\n\n            if (result.value.length > 0) {\n              return result;\n            }\n          }\n\n          for (;;) {\n            if (done) {\n              return {\n                done,\n                value: undefined\n              };\n            }\n\n            const result = await nextChunk();\n\n            if (result.value.length > 0) {\n              return result;\n            }\n          }\n        }\n\n      }\n    };\n\n    while (!done) {\n      bufferedChunks.push(await nextChunk());\n    }\n  }\n}\n\nasync function* iterateMultipart(body, boundary) {\n  for await (const part of streamMultipart(body, boundary)) {\n    const chunks = [];\n\n    for await (const chunk of part.data) {\n      chunks.push(chunk);\n    }\n\n    yield { ...part,\n      data: utils.mergeArrays(...chunks)\n    };\n  }\n}\n\nexports.iterateMultipart = iterateMultipart;\nexports.streamMultipart = streamMultipart;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web3-storage/multipart-parser/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/@web3-storage/multipart-parser/cjs/src/search.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@web3-storage/multipart-parser/cjs/src/search.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/@web3-storage/multipart-parser/cjs/src/utils.js\");\n\nfunction coerce(a) {\n  if (a instanceof Uint8Array) {\n    return index => a[index];\n  }\n\n  return a;\n}\n\nfunction jsmemcmp(buf1, pos1, buf2, pos2, len) {\n  const fn1 = coerce(buf1);\n  const fn2 = coerce(buf2);\n\n  for (let i = 0; i < len; ++i) {\n    if (fn1(pos1 + i) !== fn2(pos2 + i)) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction createOccurenceTable(s) {\n  const table = new Array(256).fill(s.length);\n\n  if (s.length > 1) {\n    for (let i = 0; i < s.length - 1; i++) {\n      table[s[i]] = s.length - 1 - i;\n    }\n  }\n\n  return table;\n}\n\nconst MATCH = Symbol('Match');\n\nclass StreamSearch {\n  constructor(needle) {\n    this._lookbehind = new Uint8Array();\n\n    if (typeof needle === 'string') {\n      this._needle = needle = utils.stringToArray(needle);\n    } else {\n      this._needle = needle;\n    }\n\n    this._lastChar = needle[needle.length - 1];\n    this._occ = createOccurenceTable(needle);\n  }\n\n  feed(chunk) {\n    let pos = 0;\n    let tokens;\n    const allTokens = [];\n\n    while (pos !== chunk.length) {\n      ;\n      [pos, ...tokens] = this._feed(chunk, pos);\n      allTokens.push(...tokens);\n    }\n\n    return allTokens;\n  }\n\n  end() {\n    const tail = this._lookbehind;\n    this._lookbehind = new Uint8Array();\n    return tail;\n  }\n\n  _feed(data, bufPos) {\n    const tokens = [];\n    let pos = -this._lookbehind.length;\n\n    if (pos < 0) {\n      while (pos < 0 && pos <= data.length - this._needle.length) {\n        const ch = this._charAt(data, pos + this._needle.length - 1);\n\n        if (ch === this._lastChar && this._memcmp(data, pos, this._needle.length - 1)) {\n          if (pos > -this._lookbehind.length) {\n            tokens.push(this._lookbehind.slice(0, this._lookbehind.length + pos));\n          }\n\n          tokens.push(MATCH);\n          this._lookbehind = new Uint8Array();\n          return [pos + this._needle.length, ...tokens];\n        } else {\n          pos += this._occ[ch];\n        }\n      }\n\n      if (pos < 0) {\n        while (pos < 0 && !this._memcmp(data, pos, data.length - pos)) {\n          pos++;\n        }\n      }\n\n      if (pos >= 0) {\n        tokens.push(this._lookbehind);\n        this._lookbehind = new Uint8Array();\n      } else {\n        const bytesToCutOff = this._lookbehind.length + pos;\n\n        if (bytesToCutOff > 0) {\n          tokens.push(this._lookbehind.slice(0, bytesToCutOff));\n          this._lookbehind = this._lookbehind.slice(bytesToCutOff);\n        }\n\n        this._lookbehind = Uint8Array.from(new Array(this._lookbehind.length + data.length), (_, i) => this._charAt(data, i - this._lookbehind.length));\n        return [data.length, ...tokens];\n      }\n    }\n\n    pos += bufPos;\n\n    while (pos <= data.length - this._needle.length) {\n      const ch = data[pos + this._needle.length - 1];\n\n      if (ch === this._lastChar && data[pos] === this._needle[0] && jsmemcmp(this._needle, 0, data, pos, this._needle.length - 1)) {\n        if (pos > bufPos) {\n          tokens.push(data.slice(bufPos, pos));\n        }\n\n        tokens.push(MATCH);\n        return [pos + this._needle.length, ...tokens];\n      } else {\n        pos += this._occ[ch];\n      }\n    }\n\n    if (pos < data.length) {\n      while (pos < data.length && (data[pos] !== this._needle[0] || !jsmemcmp(data, pos, this._needle, 0, data.length - pos))) {\n        ++pos;\n      }\n\n      if (pos < data.length) {\n        this._lookbehind = data.slice(pos);\n      }\n    }\n\n    if (pos > 0) {\n      tokens.push(data.slice(bufPos, pos < data.length ? pos : data.length));\n    }\n\n    return [data.length, ...tokens];\n  }\n\n  _charAt(data, pos) {\n    if (pos < 0) {\n      return this._lookbehind[this._lookbehind.length + pos];\n    }\n\n    return data[pos];\n  }\n\n  _memcmp(data, pos, len) {\n    return jsmemcmp(this._charAt.bind(this, data), pos, this._needle, 0, len);\n  }\n\n}\n\nclass ReadableStreamSearch {\n  constructor(needle, _readableStream) {\n    this._readableStream = _readableStream;\n    this._search = new StreamSearch(needle);\n  }\n\n  async *[Symbol.asyncIterator]() {\n    const reader = this._readableStream.getReader();\n\n    try {\n      while (true) {\n        const result = await reader.read();\n\n        if (result.done) {\n          break;\n        }\n\n        yield* this._search.feed(result.value);\n      }\n\n      const tail = this._search.end();\n\n      if (tail.length) {\n        yield tail;\n      }\n    } finally {\n      reader.releaseLock();\n    }\n  }\n\n}\n\nconst EOQ = Symbol('End of Queue');\n\nclass QueueableStreamSearch {\n  constructor(needle) {\n    this._chunksQueue = [];\n    this._closed = false;\n    this._search = new StreamSearch(needle);\n  }\n\n  push(...chunks) {\n    if (this._closed) {\n      throw new Error('cannot call push after close');\n    }\n\n    this._chunksQueue.push(...chunks);\n\n    if (this._notify) {\n      this._notify();\n    }\n  }\n\n  close() {\n    if (this._closed) {\n      throw new Error('close was already called');\n    }\n\n    this._closed = true;\n\n    this._chunksQueue.push(EOQ);\n\n    if (this._notify) {\n      this._notify();\n    }\n  }\n\n  async *[Symbol.asyncIterator]() {\n    while (true) {\n      let chunk;\n\n      while (!(chunk = this._chunksQueue.shift())) {\n        await new Promise(resolve => this._notify = resolve);\n        this._notify = undefined;\n      }\n\n      if (chunk === EOQ) {\n        break;\n      }\n\n      yield* this._search.feed(chunk);\n    }\n\n    const tail = this._search.end();\n\n    if (tail.length) {\n      yield tail;\n    }\n  }\n\n}\n\nfunction splitChunks(chunks, needle) {\n  const search = new StreamSearch(needle);\n  const outchunks = [[]];\n\n  for (const chunk of chunks) {\n    for (const token of search.feed(chunk)) {\n      if (token === MATCH) {\n        outchunks.push([]);\n      } else {\n        outchunks[outchunks.length - 1].push(token);\n      }\n    }\n  }\n\n  const end = search.end();\n  outchunks[outchunks.length - 1].push(end);\n  return outchunks.map(chunks => utils.mergeArrays(...chunks));\n}\n\nfunction split(buf, needle) {\n  return splitChunks([buf], needle);\n}\n\nasync function* chunksIterator(iter) {\n  let chunks = [];\n\n  for await (const value of iter) {\n    if (value === MATCH) {\n      yield chunks;\n      chunks = [];\n    } else {\n      chunks.push(value);\n    }\n  }\n\n  yield chunks;\n}\n\nasync function* stringIterator(iter) {\n  for await (const chunk of chunksIterator(iter)) {\n    yield chunk.map(utils.arrayToString).join('');\n  }\n}\n\nasync function allStrings(iter) {\n  const segments = [];\n\n  for await (const value of stringIterator(iter)) {\n    segments.push(value);\n  }\n\n  return segments;\n}\n\nasync function* arrayIterator(iter) {\n  for await (const chunk of chunksIterator(iter)) {\n    yield utils.mergeArrays(...chunk);\n  }\n}\n\nexports.MATCH = MATCH;\nexports.QueueableStreamSearch = QueueableStreamSearch;\nexports.ReadableStreamSearch = ReadableStreamSearch;\nexports.StreamSearch = StreamSearch;\nexports.allStrings = allStrings;\nexports.arrayIterator = arrayIterator;\nexports.chunksIterator = chunksIterator;\nexports.split = split;\nexports.splitChunks = splitChunks;\nexports.stringIterator = stringIterator;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web3-storage/multipart-parser/cjs/src/search.js?");

/***/ }),

/***/ "./node_modules/@web3-storage/multipart-parser/cjs/src/utils.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@web3-storage/multipart-parser/cjs/src/utils.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nfunction stringToArray(s) {\n  const utf8 = unescape(encodeURIComponent(s));\n  return Uint8Array.from(utf8, (_, i) => utf8.charCodeAt(i));\n}\n\nfunction arrayToString(a) {\n  const utf8 = String.fromCharCode.apply(null, a);\n  return decodeURIComponent(escape(utf8));\n}\n\nfunction mergeArrays(...arrays) {\n  const out = new Uint8Array(arrays.reduce((total, arr) => total + arr.length, 0));\n  let offset = 0;\n\n  for (const arr of arrays) {\n    out.set(arr, offset);\n    offset += arr.length;\n  }\n\n  return out;\n}\n\nfunction arraysEqual(a, b) {\n  if (a.length !== b.length) {\n    return false;\n  }\n\n  for (let i = 0; i < a.length; i++) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nexports.arrayToString = arrayToString;\nexports.arraysEqual = arraysEqual;\nexports.mergeArrays = mergeArrays;\nexports.stringToArray = stringToArray;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web3-storage/multipart-parser/cjs/src/utils.js?");

/***/ }),

/***/ "./node_modules/balanced-match/index.js":
/*!**********************************************!*\
  !*** ./node_modules/balanced-match/index.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = balanced;\n\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n  var r = range(a, b, str);\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\n\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    if (a === b) {\n      return [ai, bi];\n    }\n\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [begs.pop(), bi];\n      } else {\n        beg = begs.pop();\n\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [left, right];\n    }\n  }\n\n  return result;\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/balanced-match/index.js?");

/***/ }),

/***/ "./node_modules/blob-to-it/index.js":
/*!******************************************!*\
  !*** ./node_modules/blob-to-it/index.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/* eslint-env browser */\n\n\nconst browserReadableStreamToIt = __webpack_require__(/*! browser-readablestream-to-it */ \"./node_modules/browser-readablestream-to-it/index.js\");\n/**\n * @param {Blob} blob\n * @returns {AsyncIterable<Uint8Array>}\n */\n\n\nfunction blobToIt(blob) {\n  if (typeof blob.stream === 'function') {\n    // @ts-ignore missing some properties\n    return browserReadableStreamToIt(blob.stream());\n  } // firefox < 69 does not support blob.stream()\n  // @ts-ignore - response.body is optional, but in practice it's a stream.\n\n\n  return browserReadableStreamToIt(new Response(blob).body);\n}\n\nmodule.exports = blobToIt;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/blob-to-it/index.js?");

/***/ }),

/***/ "./node_modules/blockstore-core/cjs/src/base.js":
/*!******************************************************!*\
  !*** ./node_modules/blockstore-core/cjs/src/base.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar drain = __webpack_require__(/*! it-drain */ \"./node_modules/it-drain/index.js\");\n\nvar filter = __webpack_require__(/*! it-filter */ \"./node_modules/it-filter/index.js\");\n\nvar take = __webpack_require__(/*! it-take */ \"./node_modules/it-take/index.js\");\n\nvar all = __webpack_require__(/*! it-all */ \"./node_modules/it-all/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar drain__default = /*#__PURE__*/_interopDefaultLegacy(drain);\n\nvar filter__default = /*#__PURE__*/_interopDefaultLegacy(filter);\n\nvar take__default = /*#__PURE__*/_interopDefaultLegacy(take);\n\nvar all__default = /*#__PURE__*/_interopDefaultLegacy(all);\n\nconst sortAll = (iterable, sorter) => {\n  return async function* () {\n    const values = await all__default[\"default\"](iterable);\n    yield* values.sort(sorter);\n  }();\n};\n\nclass BaseBlockstore {\n  open() {\n    return Promise.reject(new Error('.open is not implemented'));\n  }\n\n  close() {\n    return Promise.reject(new Error('.close is not implemented'));\n  }\n\n  put(key, val, options) {\n    return Promise.reject(new Error('.put is not implemented'));\n  }\n\n  get(key, options) {\n    return Promise.reject(new Error('.get is not implemented'));\n  }\n\n  has(key, options) {\n    return Promise.reject(new Error('.has is not implemented'));\n  }\n\n  delete(key, options) {\n    return Promise.reject(new Error('.delete is not implemented'));\n  }\n\n  async *putMany(source, options = {}) {\n    for await (const {\n      key,\n      value\n    } of source) {\n      await this.put(key, value, options);\n      yield {\n        key,\n        value\n      };\n    }\n  }\n\n  async *getMany(source, options = {}) {\n    for await (const key of source) {\n      yield this.get(key, options);\n    }\n  }\n\n  async *deleteMany(source, options = {}) {\n    for await (const key of source) {\n      await this.delete(key, options);\n      yield key;\n    }\n  }\n\n  batch() {\n    let puts = [];\n    let dels = [];\n    return {\n      put(key, value) {\n        puts.push({\n          key,\n          value\n        });\n      },\n\n      delete(key) {\n        dels.push(key);\n      },\n\n      commit: async options => {\n        await drain__default[\"default\"](this.putMany(puts, options));\n        puts = [];\n        await drain__default[\"default\"](this.deleteMany(dels, options));\n        dels = [];\n      }\n    };\n  }\n\n  async *_all(q, options) {\n    throw new Error('._all is not implemented');\n  }\n\n  async *_allKeys(q, options) {\n    throw new Error('._allKeys is not implemented');\n  }\n\n  query(q, options) {\n    let it = this._all(q, options);\n\n    if (q.prefix != null) {\n      it = filter__default[\"default\"](it, e => e.key.toString().startsWith(q.prefix || ''));\n    }\n\n    if (Array.isArray(q.filters)) {\n      it = q.filters.reduce((it, f) => filter__default[\"default\"](it, f), it);\n    }\n\n    if (Array.isArray(q.orders)) {\n      it = q.orders.reduce((it, f) => sortAll(it, f), it);\n    }\n\n    if (q.offset != null) {\n      let i = 0;\n      it = filter__default[\"default\"](it, () => i++ >= (q.offset || 0));\n    }\n\n    if (q.limit != null) {\n      it = take__default[\"default\"](it, q.limit);\n    }\n\n    return it;\n  }\n\n  queryKeys(q, options) {\n    let it = this._allKeys(q, options);\n\n    if (q.prefix != null) {\n      it = filter__default[\"default\"](it, cid => cid.toString().startsWith(q.prefix || ''));\n    }\n\n    if (Array.isArray(q.filters)) {\n      it = q.filters.reduce((it, f) => filter__default[\"default\"](it, f), it);\n    }\n\n    if (Array.isArray(q.orders)) {\n      it = q.orders.reduce((it, f) => sortAll(it, f), it);\n    }\n\n    if (q.offset != null) {\n      let i = 0;\n      it = filter__default[\"default\"](it, () => i++ >= q.offset);\n    }\n\n    if (q.limit != null) {\n      it = take__default[\"default\"](it, q.limit);\n    }\n\n    return it;\n  }\n\n}\n\nexports.BaseBlockstore = BaseBlockstore;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/blockstore-core/cjs/src/base.js?");

/***/ }),

/***/ "./node_modules/blockstore-core/cjs/src/errors.js":
/*!********************************************************!*\
  !*** ./node_modules/blockstore-core/cjs/src/errors.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nfunction notFoundError(err) {\n  err = err || new Error('Not Found');\n  return errCode__default[\"default\"](err, 'ERR_NOT_FOUND');\n}\n\nfunction abortedError(err) {\n  err = err || new Error('Aborted');\n  return errCode__default[\"default\"](err, 'ERR_ABORTED');\n}\n\nexports.abortedError = abortedError;\nexports.notFoundError = notFoundError;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/blockstore-core/cjs/src/errors.js?");

/***/ }),

/***/ "./node_modules/blockstore-core/cjs/src/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/blockstore-core/cjs/src/index.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar errors = __webpack_require__(/*! ./errors.js */ \"./node_modules/blockstore-core/cjs/src/errors.js\");\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/blockstore-core/cjs/src/base.js\");\n\nvar memory = __webpack_require__(/*! ./memory.js */ \"./node_modules/blockstore-core/cjs/src/memory.js\");\n\nconst Errors = { ...errors\n};\nexports.BaseBlockstore = base.BaseBlockstore;\nexports.MemoryBlockstore = memory.MemoryBlockstore;\nexports.Errors = Errors;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/blockstore-core/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/blockstore-core/cjs/src/memory.js":
/*!********************************************************!*\
  !*** ./node_modules/blockstore-core/cjs/src/memory.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/blockstore-core/cjs/src/base.js\");\n\nvar base32 = __webpack_require__(/*! multiformats/bases/base32 */ \"./node_modules/multiformats/cjs/src/bases/base32.js\");\n\nvar raw = __webpack_require__(/*! multiformats/codecs/raw */ \"./node_modules/multiformats/cjs/src/codecs/raw.js\");\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar Digest = __webpack_require__(/*! multiformats/hashes/digest */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nvar errors = __webpack_require__(/*! ./errors.js */ \"./node_modules/blockstore-core/cjs/src/errors.js\");\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar raw__namespace = /*#__PURE__*/_interopNamespace(raw);\n\nvar Digest__namespace = /*#__PURE__*/_interopNamespace(Digest);\n\nclass MemoryBlockstore extends base.BaseBlockstore {\n  constructor() {\n    super();\n    this.data = {};\n  }\n\n  open() {\n    return Promise.resolve();\n  }\n\n  close() {\n    return Promise.resolve();\n  }\n\n  async put(key, val) {\n    this.data[base32.base32.encode(key.multihash.bytes)] = val;\n  }\n\n  async get(key) {\n    const exists = await this.has(key);\n    if (!exists) throw errors.notFoundError();\n    return this.data[base32.base32.encode(key.multihash.bytes)];\n  }\n\n  async has(key) {\n    return this.data[base32.base32.encode(key.multihash.bytes)] !== undefined;\n  }\n\n  async delete(key) {\n    delete this.data[base32.base32.encode(key.multihash.bytes)];\n  }\n\n  async *_all() {\n    yield* Object.entries(this.data).map(([key, value]) => ({\n      key: cid.CID.createV1(raw__namespace.code, Digest__namespace.decode(base32.base32.decode(key))),\n      value\n    }));\n  }\n\n  async *_allKeys() {\n    yield* Object.entries(this.data).map(([key]) => cid.CID.createV1(raw__namespace.code, Digest__namespace.decode(base32.base32.decode(key))));\n  }\n\n}\n\nexports.MemoryBlockstore = MemoryBlockstore;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/blockstore-core/cjs/src/memory.js?");

/***/ }),

/***/ "./node_modules/brace-expansion/index.js":
/*!***********************************************!*\
  !*** ./node_modules/brace-expansion/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var concatMap = __webpack_require__(/*! concat-map */ \"./node_modules/concat-map/index.js\");\n\nvar balanced = __webpack_require__(/*! balanced-match */ \"./node_modules/balanced-match/index.js\");\n\nmodule.exports = expandTop;\nvar escSlash = '\\0SLASH' + Math.random() + '\\0';\nvar escOpen = '\\0OPEN' + Math.random() + '\\0';\nvar escClose = '\\0CLOSE' + Math.random() + '\\0';\nvar escComma = '\\0COMMA' + Math.random() + '\\0';\nvar escPeriod = '\\0PERIOD' + Math.random() + '\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str ? parseInt(str, 10) : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash).split('\\\\{').join(escOpen).split('\\\\}').join(escClose).split('\\\\,').join(escComma).split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\').split(escOpen).join('{').split(escClose).join('}').split(escComma).join(',').split(escPeriod).join('.');\n} // Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\n\n\nfunction parseCommaParts(str) {\n  if (!str) return [''];\n  var parts = [];\n  var m = balanced('{', '}', str);\n  if (!m) return str.split(',');\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n  p[p.length - 1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n\n  if (post.length) {\n    p[p.length - 1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str) return []; // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction identity(e) {\n  return e;\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\n\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\n\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n  var m = balanced('{', '}', str);\n  if (!m || /\\$$/.test(m.pre)) return [str];\n  var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isSequence = isNumericSequence || isAlphaSequence;\n  var isOptions = m.body.indexOf(',') >= 0;\n\n  if (!isSequence && !isOptions) {\n    // {a},b}\n    if (m.post.match(/,.*\\}/)) {\n      str = m.pre + '{' + m.body + escClose + m.post;\n      return expand(str);\n    }\n\n    return [str];\n  }\n\n  var n;\n\n  if (isSequence) {\n    n = m.body.split(/\\.\\./);\n  } else {\n    n = parseCommaParts(m.body);\n\n    if (n.length === 1) {\n      // x{{a,b}}y ==> x{a}y x{b}y\n      n = expand(n[0], false).map(embrace);\n\n      if (n.length === 1) {\n        var post = m.post.length ? expand(m.post, false) : [''];\n        return post.map(function (p) {\n          return m.pre + n[0] + p;\n        });\n      }\n    }\n  } // at this point, n is the parts, and we know it's not a comma set\n  // with a single entry.\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n\n\n  var pre = m.pre;\n  var post = m.post.length ? expand(m.post, false) : [''];\n  var N;\n\n  if (isSequence) {\n    var x = numeric(n[0]);\n    var y = numeric(n[1]);\n    var width = Math.max(n[0].length, n[1].length);\n    var incr = n.length == 3 ? Math.abs(numeric(n[2])) : 1;\n    var test = lte;\n    var reverse = y < x;\n\n    if (reverse) {\n      incr *= -1;\n      test = gte;\n    }\n\n    var pad = n.some(isPadded);\n    N = [];\n\n    for (var i = x; test(i, y); i += incr) {\n      var c;\n\n      if (isAlphaSequence) {\n        c = String.fromCharCode(i);\n        if (c === '\\\\') c = '';\n      } else {\n        c = String(i);\n\n        if (pad) {\n          var need = width - c.length;\n\n          if (need > 0) {\n            var z = new Array(need + 1).join('0');\n            if (i < 0) c = '-' + z + c.slice(1);else c = z + c;\n          }\n        }\n      }\n\n      N.push(c);\n    }\n  } else {\n    N = concatMap(n, function (el) {\n      return expand(el, false);\n    });\n  }\n\n  for (var j = 0; j < N.length; j++) {\n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre + N[j] + post[k];\n      if (!isTop || isSequence || expansion) expansions.push(expansion);\n    }\n  }\n\n  return expansions;\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/brace-expansion/index.js?");

/***/ }),

/***/ "./node_modules/browser-readablestream-to-it/index.js":
/*!************************************************************!*\
  !*** ./node_modules/browser-readablestream-to-it/index.js ***!
  \************************************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Turns a browser readable stream into an async iterable. Async iteration over\n * returned iterable will lock give stream, preventing any other consumer from\n * acquiring a reader. The lock will be released if iteration loop is broken. To\n * prevent stream cancelling optional `{ preventCancel: true }` could be passed\n * as a second argument.\n * @template T\n * @param {ReadableStream<T>} stream\n * @param {Object} [options]\n * @param {boolean} [options.preventCancel=boolean]\n * @returns {AsyncIterable<T>}\n */\n\nasync function* browserReadableStreamToIt(stream, options = {}) {\n  const reader = stream.getReader();\n\n  try {\n    while (true) {\n      const result = await reader.read();\n\n      if (result.done) {\n        return;\n      }\n\n      yield result.value;\n    }\n  } finally {\n    if (options.preventCancel !== true) {\n      reader.cancel();\n    }\n\n    reader.releaseLock();\n  }\n}\n\nmodule.exports = browserReadableStreamToIt;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/browser-readablestream-to-it/index.js?");

/***/ }),

/***/ "./node_modules/carbites/cjs/lib/treewalk/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/carbites/cjs/lib/treewalk/index.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar splitter = __webpack_require__(/*! ./splitter.js */ \"./node_modules/carbites/cjs/lib/treewalk/splitter.js\");\n\nvar joiner = __webpack_require__(/*! ./joiner.js */ \"./node_modules/carbites/cjs/lib/treewalk/joiner.js\");\n\nexports.TreewalkCarSplitter = splitter.TreewalkCarSplitter;\nexports.TreewalkCarJoiner = joiner.TreewalkCarJoiner;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/carbites/cjs/lib/treewalk/index.js?");

/***/ }),

/***/ "./node_modules/carbites/cjs/lib/treewalk/joiner.js":
/*!**********************************************************!*\
  !*** ./node_modules/carbites/cjs/lib/treewalk/joiner.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar car = __webpack_require__(/*! @ipld/car */ \"./node_modules/@ipld/car/cjs/car.js\");\n\nclass TreewalkCarJoiner {\n  constructor(cars) {\n    this._cars = Array.from(cars);\n    if (!this._cars.length) throw new Error('missing CARs');\n  }\n\n  async *car() {\n    const reader = this._cars[0];\n    const roots = await reader.getRoots();\n    const {\n      writer,\n      out\n    } = car.CarWriter.create(roots);\n\n    const writeCar = async () => {\n      const written = new Set();\n\n      const writeBlocks = async reader => {\n        for await (const b of reader.blocks()) {\n          if (written.has(b.cid.toString())) continue;\n          await writer.put(b);\n          written.add(b.cid.toString());\n        }\n      };\n\n      try {\n        await writeBlocks(reader);\n\n        for (const reader of this._cars.slice(1)) {\n          await writeBlocks(reader);\n        }\n      } catch (err) {\n        console.error(err);\n      } finally {\n        await writer.close();\n      }\n    };\n\n    writeCar();\n    yield* out;\n  }\n\n}\n\nexports.TreewalkCarJoiner = TreewalkCarJoiner;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/carbites/cjs/lib/treewalk/joiner.js?");

/***/ }),

/***/ "./node_modules/carbites/cjs/lib/treewalk/splitter.js":
/*!************************************************************!*\
  !*** ./node_modules/carbites/cjs/lib/treewalk/splitter.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar car = __webpack_require__(/*! @ipld/car */ \"./node_modules/@ipld/car/cjs/car.js\");\n\nvar block = __webpack_require__(/*! multiformats/block */ \"./node_modules/multiformats/cjs/src/block.js\");\n\nvar raw = __webpack_require__(/*! multiformats/codecs/raw */ \"./node_modules/multiformats/cjs/src/codecs/raw.js\");\n\nvar dagCbor = __webpack_require__(/*! @ipld/dag-cbor */ \"./node_modules/carbites/node_modules/@ipld/dag-cbor/cjs/index.js\");\n\nvar pb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n['default'] = e;\n  return Object.freeze(n);\n}\n\nvar raw__namespace = /*#__PURE__*/_interopNamespace(raw);\n\nvar dagCbor__namespace = /*#__PURE__*/_interopNamespace(dagCbor);\n\nvar pb__namespace = /*#__PURE__*/_interopNamespace(pb);\n\nclass TreewalkCarSplitter {\n  constructor(reader, targetSize, options = {}) {\n    if (typeof targetSize !== 'number' || targetSize <= 0) {\n      throw new Error('invalid target chunk size');\n    }\n\n    this._reader = reader;\n    this._targetSize = targetSize;\n    this._decoders = [pb__namespace, raw__namespace, dagCbor__namespace, ...(options.decoders || [])];\n  }\n\n  async *cars() {\n    const roots = await this._reader.getRoots();\n    if (roots.length !== 1) throw new Error(`unexpected number of roots: ${roots.length}`);\n    let channel;\n\n    for await (const val of this._cars(roots[0])) {\n      channel = val.channel;\n      if (val.out) yield val.out;\n    }\n\n    if (!channel) {\n      throw new Error('missing CAR writer channel');\n    }\n\n    channel.writer.close();\n    yield channel.out;\n  }\n\n  async _get(cid) {\n    const rawBlock = await this._reader.get(cid);\n    if (!rawBlock) throw new Error(`missing block for ${cid}`);\n    const {\n      bytes\n    } = rawBlock;\n\n    const decoder = this._decoders.find(d => d.code === cid.code);\n\n    if (!decoder) throw new Error(`missing decoder for ${cid.code}`);\n    return new block.Block({\n      cid,\n      bytes,\n      value: decoder.decode(bytes)\n    });\n  }\n\n  async *_cars(cid, parents = [], channel = undefined) {\n    const block = await this._get(cid);\n    channel = channel || Object.assign(car.CarWriter.create(cid), {\n      size: 0\n    });\n\n    if (channel.size > 0 && channel.size + block.bytes.byteLength >= this._targetSize) {\n      channel.writer.close();\n      const {\n        out\n      } = channel;\n      channel = newCar(parents);\n      yield {\n        channel,\n        out\n      };\n    }\n\n    parents = parents.concat(block);\n    channel.size += block.bytes.byteLength;\n    channel.writer.put(block);\n\n    for (const [, cid] of block.links()) {\n      for await (const val of this._cars(cid, parents, channel)) {\n        channel = val.channel;\n        yield val;\n      }\n    }\n\n    if (!channel) {\n      throw new Error('missing CAR writer channel');\n    }\n\n    yield {\n      channel\n    };\n  }\n\n  static async fromIterable(iterable, targetSize, options) {\n    const reader = await car.CarReader.fromIterable(iterable);\n    return new TreewalkCarSplitter(reader, targetSize, options);\n  }\n\n  static async fromBlob(blob, targetSize, options) {\n    const buffer = await blob.arrayBuffer();\n    const reader = await car.CarReader.fromBytes(new Uint8Array(buffer));\n    return new TreewalkCarSplitter(reader, targetSize, options);\n  }\n\n}\n\nfunction newCar(parents) {\n  const ch = Object.assign(car.CarWriter.create(parents[0].cid), {\n    size: parents.reduce((size, b) => size + b.bytes.byteLength, 0)\n  });\n\n  for (const b of parents) {\n    ch.writer.put(b);\n  }\n\n  return ch;\n}\n\nexports.TreewalkCarSplitter = TreewalkCarSplitter;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/carbites/cjs/lib/treewalk/splitter.js?");

/***/ }),

/***/ "./node_modules/carbites/node_modules/@ipld/dag-cbor/cjs/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/carbites/node_modules/@ipld/dag-cbor/cjs/index.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar cborg = __webpack_require__(/*! cborg */ \"./node_modules/cborg/cjs/cborg.js\");\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar cborg__namespace = /*#__PURE__*/_interopNamespace(cborg);\n\nconst CID_CBOR_TAG = 42;\n\nfunction cidEncoder(obj) {\n  if (obj.asCID !== obj) {\n    return null;\n  }\n\n  const cid$1 = cid.CID.asCID(obj);\n\n  if (!cid$1) {\n    return null;\n  }\n\n  const bytes = new Uint8Array(cid$1.bytes.byteLength + 1);\n  bytes.set(cid$1.bytes, 1);\n  return [new cborg__namespace.Token(cborg__namespace.Type.tag, CID_CBOR_TAG), new cborg__namespace.Token(cborg__namespace.Type.bytes, bytes)];\n}\n\nfunction undefinedEncoder() {\n  throw new Error('`undefined` is not supported by the IPLD Data Model and cannot be encoded');\n}\n\nfunction numberEncoder(num) {\n  if (Number.isNaN(num)) {\n    throw new Error('`NaN` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n\n  if (num === Infinity || num === -Infinity) {\n    throw new Error('`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n\n  return null;\n}\n\nconst encodeOptions = {\n  float64: true,\n  typeEncoders: {\n    Object: cidEncoder,\n    undefined: undefinedEncoder,\n    number: numberEncoder\n  }\n};\n\nfunction cidDecoder(bytes) {\n  if (bytes[0] !== 0) {\n    throw new Error('Invalid CID for CBOR tag 42; expected leading 0x00');\n  }\n\n  return cid.CID.decode(bytes.subarray(1));\n}\n\nconst decodeOptions = {\n  allowIndefinite: false,\n  allowUndefined: false,\n  allowNaN: false,\n  allowInfinity: false,\n  allowBigInt: true,\n  strict: true,\n  useMaps: false,\n  tags: []\n};\ndecodeOptions.tags[CID_CBOR_TAG] = cidDecoder;\nconst name = 'dag-cbor';\nconst code = 113;\n\nconst encode = node => cborg__namespace.encode(node, encodeOptions);\n\nconst decode = data => cborg__namespace.decode(data, decodeOptions);\n\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/carbites/node_modules/@ipld/dag-cbor/cjs/index.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/cborg.js":
/*!*****************************************!*\
  !*** ./node_modules/cborg/cjs/cborg.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar encode = __webpack_require__(/*! ./lib/encode.js */ \"./node_modules/cborg/cjs/lib/encode.js\");\n\nvar decode = __webpack_require__(/*! ./lib/decode.js */ \"./node_modules/cborg/cjs/lib/decode.js\");\n\nvar token = __webpack_require__(/*! ./lib/token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nexports.encode = encode.encode;\nexports.decode = decode.decode;\nexports.Token = token.Token;\nexports.Type = token.Type;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/cborg.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/0uint.js":
/*!*********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/0uint.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nconst uintBoundaries = [24, 256, 65536, 4294967296, BigInt('18446744073709551616')];\n\nfunction readUint8(data, offset, options) {\n  common.assertEnoughData(data, offset, 1);\n  const value = data[offset];\n\n  if (options.strict === true && value < uintBoundaries[0]) {\n    throw new Error(`${common.decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);\n  }\n\n  return value;\n}\n\nfunction readUint16(data, offset, options) {\n  common.assertEnoughData(data, offset, 2);\n  const value = data[offset] << 8 | data[offset + 1];\n\n  if (options.strict === true && value < uintBoundaries[1]) {\n    throw new Error(`${common.decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);\n  }\n\n  return value;\n}\n\nfunction readUint32(data, offset, options) {\n  common.assertEnoughData(data, offset, 4);\n  const value = data[offset] * 16777216 + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n\n  if (options.strict === true && value < uintBoundaries[2]) {\n    throw new Error(`${common.decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);\n  }\n\n  return value;\n}\n\nfunction readUint64(data, offset, options) {\n  common.assertEnoughData(data, offset, 8);\n  const hi = data[offset] * 16777216 + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n  const lo = data[offset + 4] * 16777216 + (data[offset + 5] << 16) + (data[offset + 6] << 8) + data[offset + 7];\n  const value = (BigInt(hi) << BigInt(32)) + BigInt(lo);\n\n  if (options.strict === true && value < uintBoundaries[3]) {\n    throw new Error(`${common.decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`);\n  }\n\n  if (value <= Number.MAX_SAFE_INTEGER) {\n    return Number(value);\n  }\n\n  if (options.allowBigInt === true) {\n    return value;\n  }\n\n  throw new Error(`${common.decodeErrPrefix} integers outside of the safe integer range are not supported`);\n}\n\nfunction decodeUint8(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint8(data, pos + 1, options), 2);\n}\n\nfunction decodeUint16(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint16(data, pos + 1, options), 3);\n}\n\nfunction decodeUint32(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint32(data, pos + 1, options), 5);\n}\n\nfunction decodeUint64(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint64(data, pos + 1, options), 9);\n}\n\nfunction encodeUint(buf, token) {\n  return encodeUintValue(buf, 0, token.value);\n}\n\nfunction encodeUintValue(buf, major, uint) {\n  if (uint < uintBoundaries[0]) {\n    const nuint = Number(uint);\n    buf.push([major | nuint]);\n  } else if (uint < uintBoundaries[1]) {\n    const nuint = Number(uint);\n    buf.push([major | 24, nuint]);\n  } else if (uint < uintBoundaries[2]) {\n    const nuint = Number(uint);\n    buf.push([major | 25, nuint >>> 8, nuint & 255]);\n  } else if (uint < uintBoundaries[3]) {\n    const nuint = Number(uint);\n    buf.push([major | 26, nuint >>> 24 & 255, nuint >>> 16 & 255, nuint >>> 8 & 255, nuint & 255]);\n  } else {\n    const buint = BigInt(uint);\n\n    if (buint < uintBoundaries[4]) {\n      const set = [major | 27, 0, 0, 0, 0, 0, 0, 0];\n      let lo = Number(buint & BigInt(4294967295));\n      let hi = Number(buint >> BigInt(32) & BigInt(4294967295));\n      set[8] = lo & 255;\n      lo = lo >> 8;\n      set[7] = lo & 255;\n      lo = lo >> 8;\n      set[6] = lo & 255;\n      lo = lo >> 8;\n      set[5] = lo & 255;\n      set[4] = hi & 255;\n      hi = hi >> 8;\n      set[3] = hi & 255;\n      hi = hi >> 8;\n      set[2] = hi & 255;\n      hi = hi >> 8;\n      set[1] = hi & 255;\n      buf.push(set);\n    } else {\n      throw new Error(`${common.decodeErrPrefix} encountered BigInt larger than allowable range`);\n    }\n  }\n}\n\nencodeUint.encodedSize = function encodedSize(token) {\n  return encodeUintValue.encodedSize(token.value);\n};\n\nencodeUintValue.encodedSize = function encodedSize(uint) {\n  if (uint < uintBoundaries[0]) {\n    return 1;\n  }\n\n  if (uint < uintBoundaries[1]) {\n    return 2;\n  }\n\n  if (uint < uintBoundaries[2]) {\n    return 3;\n  }\n\n  if (uint < uintBoundaries[3]) {\n    return 5;\n  }\n\n  return 9;\n};\n\nencodeUint.compareTokens = function compareTokens(tok1, tok2) {\n  return tok1.value < tok2.value ? -1 : tok1.value > tok2.value ? 1 : 0;\n};\n\nexports.decodeUint16 = decodeUint16;\nexports.decodeUint32 = decodeUint32;\nexports.decodeUint64 = decodeUint64;\nexports.decodeUint8 = decodeUint8;\nexports.encodeUint = encodeUint;\nexports.encodeUintValue = encodeUintValue;\nexports.readUint16 = readUint16;\nexports.readUint32 = readUint32;\nexports.readUint64 = readUint64;\nexports.readUint8 = readUint8;\nexports.uintBoundaries = uintBoundaries;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/0uint.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/1negint.js":
/*!***********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/1negint.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nfunction decodeNegint8(data, pos, _minor, options) {\n  return new token.Token(token.Type.negint, -1 - _0uint.readUint8(data, pos + 1, options), 2);\n}\n\nfunction decodeNegint16(data, pos, _minor, options) {\n  return new token.Token(token.Type.negint, -1 - _0uint.readUint16(data, pos + 1, options), 3);\n}\n\nfunction decodeNegint32(data, pos, _minor, options) {\n  return new token.Token(token.Type.negint, -1 - _0uint.readUint32(data, pos + 1, options), 5);\n}\n\nconst neg1b = BigInt(-1);\nconst pos1b = BigInt(1);\n\nfunction decodeNegint64(data, pos, _minor, options) {\n  const int = _0uint.readUint64(data, pos + 1, options);\n\n  if (typeof int !== 'bigint') {\n    const value = -1 - int;\n\n    if (value >= Number.MIN_SAFE_INTEGER) {\n      return new token.Token(token.Type.negint, value, 9);\n    }\n  }\n\n  if (options.allowBigInt !== true) {\n    throw new Error(`${common.decodeErrPrefix} integers outside of the safe integer range are not supported`);\n  }\n\n  return new token.Token(token.Type.negint, neg1b - BigInt(int), 9);\n}\n\nfunction encodeNegint(buf, token) {\n  const negint = token.value;\n  const unsigned = typeof negint === 'bigint' ? negint * neg1b - pos1b : negint * -1 - 1;\n\n  _0uint.encodeUintValue(buf, token.type.majorEncoded, unsigned);\n}\n\nencodeNegint.encodedSize = function encodedSize(token) {\n  const negint = token.value;\n  const unsigned = typeof negint === 'bigint' ? negint * neg1b - pos1b : negint * -1 - 1;\n\n  if (unsigned < _0uint.uintBoundaries[0]) {\n    return 1;\n  }\n\n  if (unsigned < _0uint.uintBoundaries[1]) {\n    return 2;\n  }\n\n  if (unsigned < _0uint.uintBoundaries[2]) {\n    return 3;\n  }\n\n  if (unsigned < _0uint.uintBoundaries[3]) {\n    return 5;\n  }\n\n  return 9;\n};\n\nencodeNegint.compareTokens = function compareTokens(tok1, tok2) {\n  return tok1.value < tok2.value ? 1 : tok1.value > tok2.value ? -1 : 0;\n};\n\nexports.decodeNegint16 = decodeNegint16;\nexports.decodeNegint32 = decodeNegint32;\nexports.decodeNegint64 = decodeNegint64;\nexports.decodeNegint8 = decodeNegint8;\nexports.encodeNegint = encodeNegint;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/1negint.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/2bytes.js":
/*!**********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/2bytes.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nvar byteUtils = __webpack_require__(/*! ./byte-utils.js */ \"./node_modules/cborg/cjs/lib/byte-utils.js\");\n\nfunction toToken(data, pos, prefix, length) {\n  common.assertEnoughData(data, pos, prefix + length);\n  const buf = byteUtils.slice(data, pos + prefix, pos + prefix + length);\n  return new token.Token(token.Type.bytes, buf, prefix + length);\n}\n\nfunction decodeBytesCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\n\nfunction decodeBytes8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\n\nfunction decodeBytes16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\n\nfunction decodeBytes32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\n\nfunction decodeBytes64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n\n  if (typeof l === 'bigint') {\n    throw new Error(`${common.decodeErrPrefix} 64-bit integer bytes lengths not supported`);\n  }\n\n  return toToken(data, pos, 9, l);\n}\n\nfunction tokenBytes(token$1) {\n  if (token$1.encodedBytes === undefined) {\n    token$1.encodedBytes = token$1.type === token.Type.string ? byteUtils.fromString(token$1.value) : token$1.value;\n  }\n\n  return token$1.encodedBytes;\n}\n\nfunction encodeBytes(buf, token) {\n  const bytes = tokenBytes(token);\n\n  _0uint.encodeUintValue(buf, token.type.majorEncoded, bytes.length);\n\n  buf.push(bytes);\n}\n\nencodeBytes.encodedSize = function encodedSize(token) {\n  const bytes = tokenBytes(token);\n  return _0uint.encodeUintValue.encodedSize(bytes.length) + bytes.length;\n};\n\nencodeBytes.compareTokens = function compareTokens(tok1, tok2) {\n  return compareBytes(tokenBytes(tok1), tokenBytes(tok2));\n};\n\nfunction compareBytes(b1, b2) {\n  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : byteUtils.compare(b1, b2);\n}\n\nexports.compareBytes = compareBytes;\nexports.decodeBytes16 = decodeBytes16;\nexports.decodeBytes32 = decodeBytes32;\nexports.decodeBytes64 = decodeBytes64;\nexports.decodeBytes8 = decodeBytes8;\nexports.decodeBytesCompact = decodeBytesCompact;\nexports.encodeBytes = encodeBytes;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/2bytes.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/3string.js":
/*!***********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/3string.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nvar _2bytes = __webpack_require__(/*! ./2bytes.js */ \"./node_modules/cborg/cjs/lib/2bytes.js\");\n\nvar byteUtils = __webpack_require__(/*! ./byte-utils.js */ \"./node_modules/cborg/cjs/lib/byte-utils.js\");\n\nfunction toToken(data, pos, prefix, length, options) {\n  const totLength = prefix + length;\n  common.assertEnoughData(data, pos, totLength);\n  const tok = new token.Token(token.Type.string, byteUtils.toString(data, pos + prefix, pos + totLength), totLength);\n\n  if (options.retainStringBytes === true) {\n    tok.byteValue = byteUtils.slice(data, pos + prefix, pos + totLength);\n  }\n\n  return tok;\n}\n\nfunction decodeStringCompact(data, pos, minor, options) {\n  return toToken(data, pos, 1, minor, options);\n}\n\nfunction decodeString8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options), options);\n}\n\nfunction decodeString16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options), options);\n}\n\nfunction decodeString32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options), options);\n}\n\nfunction decodeString64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n\n  if (typeof l === 'bigint') {\n    throw new Error(`${common.decodeErrPrefix} 64-bit integer string lengths not supported`);\n  }\n\n  return toToken(data, pos, 9, l, options);\n}\n\nconst encodeString = _2bytes.encodeBytes;\nexports.decodeString16 = decodeString16;\nexports.decodeString32 = decodeString32;\nexports.decodeString64 = decodeString64;\nexports.decodeString8 = decodeString8;\nexports.decodeStringCompact = decodeStringCompact;\nexports.encodeString = encodeString;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/3string.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/4array.js":
/*!**********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/4array.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nfunction toToken(_data, _pos, prefix, length) {\n  return new token.Token(token.Type.array, length, prefix);\n}\n\nfunction decodeArrayCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\n\nfunction decodeArray8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\n\nfunction decodeArray16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\n\nfunction decodeArray32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\n\nfunction decodeArray64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n\n  if (typeof l === 'bigint') {\n    throw new Error(`${common.decodeErrPrefix} 64-bit integer array lengths not supported`);\n  }\n\n  return toToken(data, pos, 9, l);\n}\n\nfunction decodeArrayIndefinite(data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${common.decodeErrPrefix} indefinite length items not allowed`);\n  }\n\n  return toToken(data, pos, 1, Infinity);\n}\n\nfunction encodeArray(buf, token$1) {\n  _0uint.encodeUintValue(buf, token.Type.array.majorEncoded, token$1.value);\n}\n\nencodeArray.compareTokens = _0uint.encodeUint.compareTokens;\n\nencodeArray.encodedSize = function encodedSize(token) {\n  return _0uint.encodeUintValue.encodedSize(token.value);\n};\n\nexports.decodeArray16 = decodeArray16;\nexports.decodeArray32 = decodeArray32;\nexports.decodeArray64 = decodeArray64;\nexports.decodeArray8 = decodeArray8;\nexports.decodeArrayCompact = decodeArrayCompact;\nexports.decodeArrayIndefinite = decodeArrayIndefinite;\nexports.encodeArray = encodeArray;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/4array.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/5map.js":
/*!********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/5map.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nfunction toToken(_data, _pos, prefix, length) {\n  return new token.Token(token.Type.map, length, prefix);\n}\n\nfunction decodeMapCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\n\nfunction decodeMap8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\n\nfunction decodeMap16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\n\nfunction decodeMap32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\n\nfunction decodeMap64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n\n  if (typeof l === 'bigint') {\n    throw new Error(`${common.decodeErrPrefix} 64-bit integer map lengths not supported`);\n  }\n\n  return toToken(data, pos, 9, l);\n}\n\nfunction decodeMapIndefinite(data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${common.decodeErrPrefix} indefinite length items not allowed`);\n  }\n\n  return toToken(data, pos, 1, Infinity);\n}\n\nfunction encodeMap(buf, token$1) {\n  _0uint.encodeUintValue(buf, token.Type.map.majorEncoded, token$1.value);\n}\n\nencodeMap.compareTokens = _0uint.encodeUint.compareTokens;\n\nencodeMap.encodedSize = function encodedSize(token) {\n  return _0uint.encodeUintValue.encodedSize(token.value);\n};\n\nexports.decodeMap16 = decodeMap16;\nexports.decodeMap32 = decodeMap32;\nexports.decodeMap64 = decodeMap64;\nexports.decodeMap8 = decodeMap8;\nexports.decodeMapCompact = decodeMapCompact;\nexports.decodeMapIndefinite = decodeMapIndefinite;\nexports.encodeMap = encodeMap;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/5map.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/6tag.js":
/*!********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/6tag.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nfunction decodeTagCompact(_data, _pos, minor, _options) {\n  return new token.Token(token.Type.tag, minor, 1);\n}\n\nfunction decodeTag8(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint8(data, pos + 1, options), 2);\n}\n\nfunction decodeTag16(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint16(data, pos + 1, options), 3);\n}\n\nfunction decodeTag32(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint32(data, pos + 1, options), 5);\n}\n\nfunction decodeTag64(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint64(data, pos + 1, options), 9);\n}\n\nfunction encodeTag(buf, token$1) {\n  _0uint.encodeUintValue(buf, token.Type.tag.majorEncoded, token$1.value);\n}\n\nencodeTag.compareTokens = _0uint.encodeUint.compareTokens;\n\nencodeTag.encodedSize = function encodedSize(token) {\n  return _0uint.encodeUintValue.encodedSize(token.value);\n};\n\nexports.decodeTag16 = decodeTag16;\nexports.decodeTag32 = decodeTag32;\nexports.decodeTag64 = decodeTag64;\nexports.decodeTag8 = decodeTag8;\nexports.decodeTagCompact = decodeTagCompact;\nexports.encodeTag = encodeTag;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/6tag.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/7float.js":
/*!**********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/7float.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nconst MINOR_FALSE = 20;\nconst MINOR_TRUE = 21;\nconst MINOR_NULL = 22;\nconst MINOR_UNDEFINED = 23;\n\nfunction decodeUndefined(_data, _pos, _minor, options) {\n  if (options.allowUndefined === false) {\n    throw new Error(`${common.decodeErrPrefix} undefined values are not supported`);\n  } else if (options.coerceUndefinedToNull === true) {\n    return new token.Token(token.Type.null, null, 1);\n  }\n\n  return new token.Token(token.Type.undefined, undefined, 1);\n}\n\nfunction decodeBreak(_data, _pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${common.decodeErrPrefix} indefinite length items not allowed`);\n  }\n\n  return new token.Token(token.Type.break, undefined, 1);\n}\n\nfunction createToken(value, bytes, options) {\n  if (options) {\n    if (options.allowNaN === false && Number.isNaN(value)) {\n      throw new Error(`${common.decodeErrPrefix} NaN values are not supported`);\n    }\n\n    if (options.allowInfinity === false && (value === Infinity || value === -Infinity)) {\n      throw new Error(`${common.decodeErrPrefix} Infinity values are not supported`);\n    }\n  }\n\n  return new token.Token(token.Type.float, value, bytes);\n}\n\nfunction decodeFloat16(data, pos, _minor, options) {\n  return createToken(readFloat16(data, pos + 1), 3, options);\n}\n\nfunction decodeFloat32(data, pos, _minor, options) {\n  return createToken(readFloat32(data, pos + 1), 5, options);\n}\n\nfunction decodeFloat64(data, pos, _minor, options) {\n  return createToken(readFloat64(data, pos + 1), 9, options);\n}\n\nfunction encodeFloat(buf, token$1, options) {\n  const float = token$1.value;\n\n  if (float === false) {\n    buf.push([token.Type.float.majorEncoded | MINOR_FALSE]);\n  } else if (float === true) {\n    buf.push([token.Type.float.majorEncoded | MINOR_TRUE]);\n  } else if (float === null) {\n    buf.push([token.Type.float.majorEncoded | MINOR_NULL]);\n  } else if (float === undefined) {\n    buf.push([token.Type.float.majorEncoded | MINOR_UNDEFINED]);\n  } else {\n    let decoded;\n    let success = false;\n\n    if (!options || options.float64 !== true) {\n      encodeFloat16(float);\n      decoded = readFloat16(ui8a, 1);\n\n      if (float === decoded || Number.isNaN(float)) {\n        ui8a[0] = 249;\n        buf.push(ui8a.slice(0, 3));\n        success = true;\n      } else {\n        encodeFloat32(float);\n        decoded = readFloat32(ui8a, 1);\n\n        if (float === decoded) {\n          ui8a[0] = 250;\n          buf.push(ui8a.slice(0, 5));\n          success = true;\n        }\n      }\n    }\n\n    if (!success) {\n      encodeFloat64(float);\n      decoded = readFloat64(ui8a, 1);\n      ui8a[0] = 251;\n      buf.push(ui8a.slice(0, 9));\n    }\n  }\n}\n\nencodeFloat.encodedSize = function encodedSize(token, options) {\n  const float = token.value;\n\n  if (float === false || float === true || float === null || float === undefined) {\n    return 1;\n  }\n\n  if (!options || options.float64 !== true) {\n    encodeFloat16(float);\n    let decoded = readFloat16(ui8a, 1);\n\n    if (float === decoded || Number.isNaN(float)) {\n      return 3;\n    }\n\n    encodeFloat32(float);\n    decoded = readFloat32(ui8a, 1);\n\n    if (float === decoded) {\n      return 5;\n    }\n  }\n\n  return 9;\n};\n\nconst buffer = new ArrayBuffer(9);\nconst dataView = new DataView(buffer, 1);\nconst ui8a = new Uint8Array(buffer, 0);\n\nfunction encodeFloat16(inp) {\n  if (inp === Infinity) {\n    dataView.setUint16(0, 31744, false);\n  } else if (inp === -Infinity) {\n    dataView.setUint16(0, 64512, false);\n  } else if (Number.isNaN(inp)) {\n    dataView.setUint16(0, 32256, false);\n  } else {\n    dataView.setFloat32(0, inp);\n    const valu32 = dataView.getUint32(0);\n    const exponent = (valu32 & 2139095040) >> 23;\n    const mantissa = valu32 & 8388607;\n\n    if (exponent === 255) {\n      dataView.setUint16(0, 31744, false);\n    } else if (exponent === 0) {\n      dataView.setUint16(0, (inp & 2147483648) >> 16 | mantissa >> 13, false);\n    } else {\n      const logicalExponent = exponent - 127;\n\n      if (logicalExponent < -24) {\n        dataView.setUint16(0, 0);\n      } else if (logicalExponent < -14) {\n        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | 1 << 24 + logicalExponent, false);\n      } else {\n        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | logicalExponent + 15 << 10 | mantissa >> 13, false);\n      }\n    }\n  }\n}\n\nfunction readFloat16(ui8a, pos) {\n  if (ui8a.length - pos < 2) {\n    throw new Error(`${common.decodeErrPrefix} not enough data for float16`);\n  }\n\n  const half = (ui8a[pos] << 8) + ui8a[pos + 1];\n\n  if (half === 31744) {\n    return Infinity;\n  }\n\n  if (half === 64512) {\n    return -Infinity;\n  }\n\n  if (half === 32256) {\n    return NaN;\n  }\n\n  const exp = half >> 10 & 31;\n  const mant = half & 1023;\n  let val;\n\n  if (exp === 0) {\n    val = mant * 2 ** -24;\n  } else if (exp !== 31) {\n    val = (mant + 1024) * 2 ** (exp - 25);\n  } else {\n    val = mant === 0 ? Infinity : NaN;\n  }\n\n  return half & 32768 ? -val : val;\n}\n\nfunction encodeFloat32(inp) {\n  dataView.setFloat32(0, inp, false);\n}\n\nfunction readFloat32(ui8a, pos) {\n  if (ui8a.length - pos < 4) {\n    throw new Error(`${common.decodeErrPrefix} not enough data for float32`);\n  }\n\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 4).getFloat32(0, false);\n}\n\nfunction encodeFloat64(inp) {\n  dataView.setFloat64(0, inp, false);\n}\n\nfunction readFloat64(ui8a, pos) {\n  if (ui8a.length - pos < 8) {\n    throw new Error(`${common.decodeErrPrefix} not enough data for float64`);\n  }\n\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 8).getFloat64(0, false);\n}\n\nencodeFloat.compareTokens = _0uint.encodeUint.compareTokens;\nexports.decodeBreak = decodeBreak;\nexports.decodeFloat16 = decodeFloat16;\nexports.decodeFloat32 = decodeFloat32;\nexports.decodeFloat64 = decodeFloat64;\nexports.decodeUndefined = decodeUndefined;\nexports.encodeFloat = encodeFloat;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/7float.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/bl.js":
/*!******************************************!*\
  !*** ./node_modules/cborg/cjs/lib/bl.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar byteUtils = __webpack_require__(/*! ./byte-utils.js */ \"./node_modules/cborg/cjs/lib/byte-utils.js\");\n\nconst defaultChunkSize = 256;\n\nclass Bl {\n  constructor(chunkSize = defaultChunkSize) {\n    this.chunkSize = chunkSize;\n    this.cursor = 0;\n    this.maxCursor = -1;\n    this.chunks = [];\n    this._initReuseChunk = null;\n  }\n\n  reset() {\n    this.cursor = 0;\n    this.maxCursor = -1;\n\n    if (this.chunks.length) {\n      this.chunks = [];\n    }\n\n    if (this._initReuseChunk !== null) {\n      this.chunks.push(this._initReuseChunk);\n      this.maxCursor = this._initReuseChunk.length - 1;\n    }\n  }\n\n  push(bytes) {\n    let topChunk = this.chunks[this.chunks.length - 1];\n    const newMax = this.cursor + bytes.length;\n\n    if (newMax <= this.maxCursor + 1) {\n      const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n      topChunk.set(bytes, chunkPos);\n    } else {\n      if (topChunk) {\n        const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n\n        if (chunkPos < topChunk.length) {\n          this.chunks[this.chunks.length - 1] = topChunk.subarray(0, chunkPos);\n          this.maxCursor = this.cursor - 1;\n        }\n      }\n\n      if (bytes.length < 64 && bytes.length < this.chunkSize) {\n        topChunk = byteUtils.alloc(this.chunkSize);\n        this.chunks.push(topChunk);\n        this.maxCursor += topChunk.length;\n\n        if (this._initReuseChunk === null) {\n          this._initReuseChunk = topChunk;\n        }\n\n        topChunk.set(bytes, 0);\n      } else {\n        this.chunks.push(bytes);\n        this.maxCursor += bytes.length;\n      }\n    }\n\n    this.cursor += bytes.length;\n  }\n\n  toBytes(reset = false) {\n    let byts;\n\n    if (this.chunks.length === 1) {\n      const chunk = this.chunks[0];\n\n      if (reset && this.cursor > chunk.length / 2) {\n        byts = this.cursor === chunk.length ? chunk : chunk.subarray(0, this.cursor);\n        this._initReuseChunk = null;\n        this.chunks = [];\n      } else {\n        byts = byteUtils.slice(chunk, 0, this.cursor);\n      }\n    } else {\n      byts = byteUtils.concat(this.chunks, this.cursor);\n    }\n\n    if (reset) {\n      this.reset();\n    }\n\n    return byts;\n  }\n\n}\n\nexports.Bl = Bl;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/bl.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/byte-utils.js":
/*!**************************************************!*\
  !*** ./node_modules/cborg/cjs/lib/byte-utils.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nconst useBuffer = globalThis.process && !globalThis.process.browser && globalThis.Buffer && typeof globalThis.Buffer.isBuffer === 'function';\nconst textDecoder = new TextDecoder();\nconst textEncoder = new TextEncoder();\n\nfunction isBuffer(buf) {\n  return useBuffer && globalThis.Buffer.isBuffer(buf);\n}\n\nfunction asU8A(buf) {\n  if (!(buf instanceof Uint8Array)) {\n    return Uint8Array.from(buf);\n  }\n\n  return isBuffer(buf) ? new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength) : buf;\n}\n\nconst toString = useBuffer ? (bytes, start, end) => {\n  return end - start > 64 ? globalThis.Buffer.from(bytes.subarray(start, end)).toString('utf8') : utf8Slice(bytes, start, end);\n} : (bytes, start, end) => {\n  return end - start > 64 ? textDecoder.decode(bytes.subarray(start, end)) : utf8Slice(bytes, start, end);\n};\nconst fromString = useBuffer ? string => {\n  return string.length > 64 ? globalThis.Buffer.from(string) : utf8ToBytes(string);\n} : string => {\n  return string.length > 64 ? textEncoder.encode(string) : utf8ToBytes(string);\n};\n\nconst fromArray = arr => {\n  return Uint8Array.from(arr);\n};\n\nconst slice = useBuffer ? (bytes, start, end) => {\n  if (isBuffer(bytes)) {\n    return new Uint8Array(bytes.subarray(start, end));\n  }\n\n  return bytes.slice(start, end);\n} : (bytes, start, end) => {\n  return bytes.slice(start, end);\n};\nconst concat = useBuffer ? (chunks, length) => {\n  chunks = chunks.map(c => c instanceof Uint8Array ? c : globalThis.Buffer.from(c));\n  return asU8A(globalThis.Buffer.concat(chunks, length));\n} : (chunks, length) => {\n  const out = new Uint8Array(length);\n  let off = 0;\n\n  for (let b of chunks) {\n    if (off + b.length > out.length) {\n      b = b.subarray(0, out.length - off);\n    }\n\n    out.set(b, off);\n    off += b.length;\n  }\n\n  return out;\n};\nconst alloc = useBuffer ? size => {\n  return globalThis.Buffer.allocUnsafe(size);\n} : size => {\n  return new Uint8Array(size);\n};\nconst toHex = useBuffer ? d => {\n  if (typeof d === 'string') {\n    return d;\n  }\n\n  return globalThis.Buffer.from(toBytes(d)).toString('hex');\n} : d => {\n  if (typeof d === 'string') {\n    return d;\n  }\n\n  return Array.prototype.reduce.call(toBytes(d), (p, c) => `${p}${c.toString(16).padStart(2, '0')}`, '');\n};\nconst fromHex = useBuffer ? hex => {\n  if (hex instanceof Uint8Array) {\n    return hex;\n  }\n\n  return globalThis.Buffer.from(hex, 'hex');\n} : hex => {\n  if (hex instanceof Uint8Array) {\n    return hex;\n  }\n\n  if (!hex.length) {\n    return new Uint8Array(0);\n  }\n\n  return new Uint8Array(hex.split('').map((c, i, d) => i % 2 === 0 ? `0x${c}${d[i + 1]}` : '').filter(Boolean).map(e => parseInt(e, 16)));\n};\n\nfunction toBytes(obj) {\n  if (obj instanceof Uint8Array && obj.constructor.name === 'Uint8Array') {\n    return obj;\n  }\n\n  if (obj instanceof ArrayBuffer) {\n    return new Uint8Array(obj);\n  }\n\n  if (ArrayBuffer.isView(obj)) {\n    return new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength);\n  }\n\n  throw new Error('Unknown type, must be binary type');\n}\n\nfunction compare(b1, b2) {\n  if (isBuffer(b1) && isBuffer(b2)) {\n    return b1.compare(b2);\n  }\n\n  for (let i = 0; i < b1.length; i++) {\n    if (b1[i] === b2[i]) {\n      continue;\n    }\n\n    return b1[i] < b2[i] ? -1 : 1;\n  }\n\n  return 0;\n}\n\nfunction utf8ToBytes(string, units = Infinity) {\n  let codePoint;\n  const length = string.length;\n  let leadSurrogate = null;\n  const bytes = [];\n\n  for (let i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i);\n\n    if (codePoint > 55295 && codePoint < 57344) {\n      if (!leadSurrogate) {\n        if (codePoint > 56319) {\n          if ((units -= 3) > -1) bytes.push(239, 191, 189);\n          continue;\n        } else if (i + 1 === length) {\n          if ((units -= 3) > -1) bytes.push(239, 191, 189);\n          continue;\n        }\n\n        leadSurrogate = codePoint;\n        continue;\n      }\n\n      if (codePoint < 56320) {\n        if ((units -= 3) > -1) bytes.push(239, 191, 189);\n        leadSurrogate = codePoint;\n        continue;\n      }\n\n      codePoint = (leadSurrogate - 55296 << 10 | codePoint - 56320) + 65536;\n    } else if (leadSurrogate) {\n      if ((units -= 3) > -1) bytes.push(239, 191, 189);\n    }\n\n    leadSurrogate = null;\n\n    if (codePoint < 128) {\n      if ((units -= 1) < 0) break;\n      bytes.push(codePoint);\n    } else if (codePoint < 2048) {\n      if ((units -= 2) < 0) break;\n      bytes.push(codePoint >> 6 | 192, codePoint & 63 | 128);\n    } else if (codePoint < 65536) {\n      if ((units -= 3) < 0) break;\n      bytes.push(codePoint >> 12 | 224, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);\n    } else if (codePoint < 1114112) {\n      if ((units -= 4) < 0) break;\n      bytes.push(codePoint >> 18 | 240, codePoint >> 12 & 63 | 128, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);\n    } else {\n      throw new Error('Invalid code point');\n    }\n  }\n\n  return bytes;\n}\n\nfunction utf8Slice(buf, offset, end) {\n  const res = [];\n\n  while (offset < end) {\n    const firstByte = buf[offset];\n    let codePoint = null;\n    let bytesPerSequence = firstByte > 239 ? 4 : firstByte > 223 ? 3 : firstByte > 191 ? 2 : 1;\n\n    if (offset + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint;\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 128) {\n            codePoint = firstByte;\n          }\n\n          break;\n\n        case 2:\n          secondByte = buf[offset + 1];\n\n          if ((secondByte & 192) === 128) {\n            tempCodePoint = (firstByte & 31) << 6 | secondByte & 63;\n\n            if (tempCodePoint > 127) {\n              codePoint = tempCodePoint;\n            }\n          }\n\n          break;\n\n        case 3:\n          secondByte = buf[offset + 1];\n          thirdByte = buf[offset + 2];\n\n          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128) {\n            tempCodePoint = (firstByte & 15) << 12 | (secondByte & 63) << 6 | thirdByte & 63;\n\n            if (tempCodePoint > 2047 && (tempCodePoint < 55296 || tempCodePoint > 57343)) {\n              codePoint = tempCodePoint;\n            }\n          }\n\n          break;\n\n        case 4:\n          secondByte = buf[offset + 1];\n          thirdByte = buf[offset + 2];\n          fourthByte = buf[offset + 3];\n\n          if ((secondByte & 192) === 128 && (thirdByte & 192) === 128 && (fourthByte & 192) === 128) {\n            tempCodePoint = (firstByte & 15) << 18 | (secondByte & 63) << 12 | (thirdByte & 63) << 6 | fourthByte & 63;\n\n            if (tempCodePoint > 65535 && tempCodePoint < 1114112) {\n              codePoint = tempCodePoint;\n            }\n          }\n\n      }\n    }\n\n    if (codePoint === null) {\n      codePoint = 65533;\n      bytesPerSequence = 1;\n    } else if (codePoint > 65535) {\n      codePoint -= 65536;\n      res.push(codePoint >>> 10 & 1023 | 55296);\n      codePoint = 56320 | codePoint & 1023;\n    }\n\n    res.push(codePoint);\n    offset += bytesPerSequence;\n  }\n\n  return decodeCodePointsArray(res);\n}\n\nconst MAX_ARGUMENTS_LENGTH = 4096;\n\nfunction decodeCodePointsArray(codePoints) {\n  const len = codePoints.length;\n\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints);\n  }\n\n  let res = '';\n  let i = 0;\n\n  while (i < len) {\n    res += String.fromCharCode.apply(String, codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH));\n  }\n\n  return res;\n}\n\nexports.alloc = alloc;\nexports.asU8A = asU8A;\nexports.compare = compare;\nexports.concat = concat;\nexports.decodeCodePointsArray = decodeCodePointsArray;\nexports.fromArray = fromArray;\nexports.fromHex = fromHex;\nexports.fromString = fromString;\nexports.slice = slice;\nexports.toHex = toHex;\nexports.toString = toString;\nexports.useBuffer = useBuffer;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/byte-utils.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/common.js":
/*!**********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/common.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nconst decodeErrPrefix = 'CBOR decode error:';\nconst encodeErrPrefix = 'CBOR encode error:';\nconst uintMinorPrefixBytes = [];\nuintMinorPrefixBytes[23] = 1;\nuintMinorPrefixBytes[24] = 2;\nuintMinorPrefixBytes[25] = 3;\nuintMinorPrefixBytes[26] = 5;\nuintMinorPrefixBytes[27] = 9;\n\nfunction assertEnoughData(data, pos, need) {\n  if (data.length - pos < need) {\n    throw new Error(`${decodeErrPrefix} not enough data for type`);\n  }\n}\n\nexports.assertEnoughData = assertEnoughData;\nexports.decodeErrPrefix = decodeErrPrefix;\nexports.encodeErrPrefix = encodeErrPrefix;\nexports.uintMinorPrefixBytes = uintMinorPrefixBytes;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/common.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/decode.js":
/*!**********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/decode.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar jump = __webpack_require__(/*! ./jump.js */ \"./node_modules/cborg/cjs/lib/jump.js\");\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\n\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n\n  done() {\n    return this.pos >= this.data.length;\n  }\n\n  next() {\n    const byt = this.data[this.pos];\n    let token = jump.quick[byt];\n\n    if (token === undefined) {\n      const decoder = jump.jump[byt];\n\n      if (!decoder) {\n        throw new Error(`${common.decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, '0')})`);\n      }\n\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n\n    this.pos += token.encodedLength;\n    return token;\n  }\n\n}\n\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\n\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(`${common.decodeErrPrefix} got unexpected break to lengthed array`);\n    }\n\n    if (value === DONE) {\n      throw new Error(`${common.decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`);\n    }\n\n    arr[i] = value;\n  }\n\n  return arr;\n}\n\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(`${common.decodeErrPrefix} got unexpected break to lengthed map`);\n    }\n\n    if (key === DONE) {\n      throw new Error(`${common.decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`);\n    }\n\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${common.decodeErrPrefix} non-string keys not supported (got ${typeof key})`);\n    }\n\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === DONE) {\n      throw new Error(`${common.decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`);\n    }\n\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n\n  return useMaps ? m : obj;\n}\n\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n\n  const token$1 = tokeniser.next();\n\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n\n    throw new Error(`${common.decodeErrPrefix} tag not supported (${token$1.value})`);\n  }\n\n  throw new Error('unsupported');\n}\n\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${common.decodeErrPrefix} data to decode must be a Uint8Array`);\n  }\n\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n\n  if (decoded === DONE) {\n    throw new Error(`${common.decodeErrPrefix} did not find any content to decode`);\n  }\n\n  if (decoded === BREAK) {\n    throw new Error(`${common.decodeErrPrefix} got unexpected break`);\n  }\n\n  if (!tokeniser.done()) {\n    throw new Error(`${common.decodeErrPrefix} too many terminals, data makes no sense`);\n  }\n\n  return decoded;\n}\n\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/decode.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/encode.js":
/*!**********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/encode.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar is = __webpack_require__(/*! ./is.js */ \"./node_modules/cborg/cjs/lib/is.js\");\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar bl = __webpack_require__(/*! ./bl.js */ \"./node_modules/cborg/cjs/lib/bl.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nvar jump = __webpack_require__(/*! ./jump.js */ \"./node_modules/cborg/cjs/lib/jump.js\");\n\nvar byteUtils = __webpack_require__(/*! ./byte-utils.js */ \"./node_modules/cborg/cjs/lib/byte-utils.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nvar _1negint = __webpack_require__(/*! ./1negint.js */ \"./node_modules/cborg/cjs/lib/1negint.js\");\n\nvar _2bytes = __webpack_require__(/*! ./2bytes.js */ \"./node_modules/cborg/cjs/lib/2bytes.js\");\n\nvar _3string = __webpack_require__(/*! ./3string.js */ \"./node_modules/cborg/cjs/lib/3string.js\");\n\nvar _4array = __webpack_require__(/*! ./4array.js */ \"./node_modules/cborg/cjs/lib/4array.js\");\n\nvar _5map = __webpack_require__(/*! ./5map.js */ \"./node_modules/cborg/cjs/lib/5map.js\");\n\nvar _6tag = __webpack_require__(/*! ./6tag.js */ \"./node_modules/cborg/cjs/lib/6tag.js\");\n\nvar _7float = __webpack_require__(/*! ./7float.js */ \"./node_modules/cborg/cjs/lib/7float.js\");\n\nconst defaultEncodeOptions = {\n  float64: false,\n  mapSorter,\n  quickEncodeToken: jump.quickEncodeToken\n};\n\nfunction makeCborEncoders() {\n  const encoders = [];\n  encoders[token.Type.uint.major] = _0uint.encodeUint;\n  encoders[token.Type.negint.major] = _1negint.encodeNegint;\n  encoders[token.Type.bytes.major] = _2bytes.encodeBytes;\n  encoders[token.Type.string.major] = _3string.encodeString;\n  encoders[token.Type.array.major] = _4array.encodeArray;\n  encoders[token.Type.map.major] = _5map.encodeMap;\n  encoders[token.Type.tag.major] = _6tag.encodeTag;\n  encoders[token.Type.float.major] = _7float.encodeFloat;\n  return encoders;\n}\n\nconst cborEncoders = makeCborEncoders();\nconst buf = new bl.Bl();\n\nclass Ref {\n  constructor(obj, parent) {\n    this.obj = obj;\n    this.parent = parent;\n  }\n\n  includes(obj) {\n    let p = this;\n\n    do {\n      if (p.obj === obj) {\n        return true;\n      }\n    } while (p = p.parent);\n\n    return false;\n  }\n\n  static createCheck(stack, obj) {\n    if (stack && stack.includes(obj)) {\n      throw new Error(`${common.encodeErrPrefix} object contains circular references`);\n    }\n\n    return new Ref(obj, stack);\n  }\n\n}\n\nconst simpleTokens = {\n  null: new token.Token(token.Type.null, null),\n  undefined: new token.Token(token.Type.undefined, undefined),\n  true: new token.Token(token.Type.true, true),\n  false: new token.Token(token.Type.false, false),\n  emptyArray: new token.Token(token.Type.array, 0),\n  emptyMap: new token.Token(token.Type.map, 0)\n};\nconst typeEncoders = {\n  number(obj, _typ, _options, _refStack) {\n    if (!Number.isInteger(obj) || !Number.isSafeInteger(obj)) {\n      return new token.Token(token.Type.float, obj);\n    } else if (obj >= 0) {\n      return new token.Token(token.Type.uint, obj);\n    } else {\n      return new token.Token(token.Type.negint, obj);\n    }\n  },\n\n  bigint(obj, _typ, _options, _refStack) {\n    if (obj >= BigInt(0)) {\n      return new token.Token(token.Type.uint, obj);\n    } else {\n      return new token.Token(token.Type.negint, obj);\n    }\n  },\n\n  Uint8Array(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.bytes, obj);\n  },\n\n  string(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.string, obj);\n  },\n\n  boolean(obj, _typ, _options, _refStack) {\n    return obj ? simpleTokens.true : simpleTokens.false;\n  },\n\n  null(_obj, _typ, _options, _refStack) {\n    return simpleTokens.null;\n  },\n\n  undefined(_obj, _typ, _options, _refStack) {\n    return simpleTokens.undefined;\n  },\n\n  ArrayBuffer(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.bytes, new Uint8Array(obj));\n  },\n\n  DataView(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.bytes, new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength));\n  },\n\n  Array(obj, _typ, options, refStack) {\n    if (!obj.length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyArray, new token.Token(token.Type.break)];\n      }\n\n      return simpleTokens.emptyArray;\n    }\n\n    refStack = Ref.createCheck(refStack, obj);\n    const entries = [];\n    let i = 0;\n\n    for (const e of obj) {\n      entries[i++] = objectToTokens(e, options, refStack);\n    }\n\n    if (options.addBreakTokens) {\n      return [new token.Token(token.Type.array, obj.length), entries, new token.Token(token.Type.break)];\n    }\n\n    return [new token.Token(token.Type.array, obj.length), entries];\n  },\n\n  Object(obj, typ, options, refStack) {\n    const isMap = typ !== 'Object';\n    const keys = isMap ? obj.keys() : Object.keys(obj);\n    const length = isMap ? obj.size : keys.length;\n\n    if (!length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyMap, new token.Token(token.Type.break)];\n      }\n\n      return simpleTokens.emptyMap;\n    }\n\n    refStack = Ref.createCheck(refStack, obj);\n    const entries = [];\n    let i = 0;\n\n    for (const key of keys) {\n      entries[i++] = [objectToTokens(key, options, refStack), objectToTokens(isMap ? obj.get(key) : obj[key], options, refStack)];\n    }\n\n    sortMapEntries(entries, options);\n\n    if (options.addBreakTokens) {\n      return [new token.Token(token.Type.map, length), entries, new token.Token(token.Type.break)];\n    }\n\n    return [new token.Token(token.Type.map, length), entries];\n  }\n\n};\ntypeEncoders.Map = typeEncoders.Object;\ntypeEncoders.Buffer = typeEncoders.Uint8Array;\n\nfor (const typ of 'Uint8Clamped Uint16 Uint32 Int8 Int16 Int32 BigUint64 BigInt64 Float32 Float64'.split(' ')) {\n  typeEncoders[`${typ}Array`] = typeEncoders.DataView;\n}\n\nfunction objectToTokens(obj, options = {}, refStack) {\n  const typ = is.is(obj);\n  const customTypeEncoder = options && options.typeEncoders && options.typeEncoders[typ] || typeEncoders[typ];\n\n  if (typeof customTypeEncoder === 'function') {\n    const tokens = customTypeEncoder(obj, typ, options, refStack);\n\n    if (tokens != null) {\n      return tokens;\n    }\n  }\n\n  const typeEncoder = typeEncoders[typ];\n\n  if (!typeEncoder) {\n    throw new Error(`${common.encodeErrPrefix} unsupported type: ${typ}`);\n  }\n\n  return typeEncoder(obj, typ, options, refStack);\n}\n\nfunction sortMapEntries(entries, options) {\n  if (options.mapSorter) {\n    entries.sort(options.mapSorter);\n  }\n}\n\nfunction mapSorter(e1, e2) {\n  const keyToken1 = Array.isArray(e1[0]) ? e1[0][0] : e1[0];\n  const keyToken2 = Array.isArray(e2[0]) ? e2[0][0] : e2[0];\n\n  if (keyToken1.type !== keyToken2.type) {\n    return keyToken1.type.compare(keyToken2.type);\n  }\n\n  const major = keyToken1.type.major;\n  const tcmp = cborEncoders[major].compareTokens(keyToken1, keyToken2);\n\n  if (tcmp === 0) {\n    console.warn('WARNING: complex key types used, CBOR key sorting guarantees are gone');\n  }\n\n  return tcmp;\n}\n\nfunction tokensToEncoded(buf, tokens, encoders, options) {\n  if (Array.isArray(tokens)) {\n    for (const token of tokens) {\n      tokensToEncoded(buf, token, encoders, options);\n    }\n  } else {\n    encoders[tokens.type.major](buf, tokens, options);\n  }\n}\n\nfunction encodeCustom(data, encoders, options) {\n  const tokens = objectToTokens(data, options);\n\n  if (!Array.isArray(tokens) && options.quickEncodeToken) {\n    const quickBytes = options.quickEncodeToken(tokens);\n\n    if (quickBytes) {\n      return quickBytes;\n    }\n\n    const encoder = encoders[tokens.type.major];\n\n    if (encoder.encodedSize) {\n      const size = encoder.encodedSize(tokens, options);\n      const buf = new bl.Bl(size);\n      encoder(buf, tokens, options);\n\n      if (buf.chunks.length !== 1) {\n        throw new Error(`Unexpected error: pre-calculated length for ${tokens} was wrong`);\n      }\n\n      return byteUtils.asU8A(buf.chunks[0]);\n    }\n  }\n\n  buf.reset();\n  tokensToEncoded(buf, tokens, encoders, options);\n  return buf.toBytes(true);\n}\n\nfunction encode(data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options);\n  return encodeCustom(data, cborEncoders, options);\n}\n\nexports.Ref = Ref;\nexports.encode = encode;\nexports.encodeCustom = encodeCustom;\nexports.makeCborEncoders = makeCborEncoders;\nexports.objectToTokens = objectToTokens;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/encode.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/is.js":
/*!******************************************!*\
  !*** ./node_modules/cborg/cjs/lib/is.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nconst typeofs = ['string', 'number', 'bigint', 'symbol'];\nconst objectTypeNames = ['Function', 'Generator', 'AsyncGenerator', 'GeneratorFunction', 'AsyncGeneratorFunction', 'AsyncFunction', 'Observable', 'Array', 'Buffer', 'Object', 'RegExp', 'Date', 'Error', 'Map', 'Set', 'WeakMap', 'WeakSet', 'ArrayBuffer', 'SharedArrayBuffer', 'DataView', 'Promise', 'URL', 'HTMLElement', 'Int8Array', 'Uint8Array', 'Uint8ClampedArray', 'Int16Array', 'Uint16Array', 'Int32Array', 'Uint32Array', 'Float32Array', 'Float64Array', 'BigInt64Array', 'BigUint64Array'];\n\nfunction is(value) {\n  if (value === null) {\n    return 'null';\n  }\n\n  if (value === undefined) {\n    return 'undefined';\n  }\n\n  if (value === true || value === false) {\n    return 'boolean';\n  }\n\n  const typeOf = typeof value;\n\n  if (typeofs.includes(typeOf)) {\n    return typeOf;\n  }\n\n  if (typeOf === 'function') {\n    return 'Function';\n  }\n\n  if (Array.isArray(value)) {\n    return 'Array';\n  }\n\n  if (isBuffer(value)) {\n    return 'Buffer';\n  }\n\n  const objectType = getObjectType(value);\n\n  if (objectType) {\n    return objectType;\n  }\n\n  return 'Object';\n}\n\nfunction isBuffer(value) {\n  return value && value.constructor && value.constructor.isBuffer && value.constructor.isBuffer.call(null, value);\n}\n\nfunction getObjectType(value) {\n  const objectTypeName = Object.prototype.toString.call(value).slice(8, -1);\n\n  if (objectTypeNames.includes(objectTypeName)) {\n    return objectTypeName;\n  }\n\n  return undefined;\n}\n\nexports.is = is;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/is.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/jump.js":
/*!********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/jump.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar token = __webpack_require__(/*! ./token.js */ \"./node_modules/cborg/cjs/lib/token.js\");\n\nvar _0uint = __webpack_require__(/*! ./0uint.js */ \"./node_modules/cborg/cjs/lib/0uint.js\");\n\nvar _1negint = __webpack_require__(/*! ./1negint.js */ \"./node_modules/cborg/cjs/lib/1negint.js\");\n\nvar _2bytes = __webpack_require__(/*! ./2bytes.js */ \"./node_modules/cborg/cjs/lib/2bytes.js\");\n\nvar _3string = __webpack_require__(/*! ./3string.js */ \"./node_modules/cborg/cjs/lib/3string.js\");\n\nvar _4array = __webpack_require__(/*! ./4array.js */ \"./node_modules/cborg/cjs/lib/4array.js\");\n\nvar _5map = __webpack_require__(/*! ./5map.js */ \"./node_modules/cborg/cjs/lib/5map.js\");\n\nvar _6tag = __webpack_require__(/*! ./6tag.js */ \"./node_modules/cborg/cjs/lib/6tag.js\");\n\nvar _7float = __webpack_require__(/*! ./7float.js */ \"./node_modules/cborg/cjs/lib/7float.js\");\n\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/cborg/cjs/lib/common.js\");\n\nvar byteUtils = __webpack_require__(/*! ./byte-utils.js */ \"./node_modules/cborg/cjs/lib/byte-utils.js\");\n\nfunction invalidMinor(data, pos, minor) {\n  throw new Error(`${common.decodeErrPrefix} encountered invalid minor (${minor}) for major ${data[pos] >>> 5}`);\n}\n\nfunction errorer(msg) {\n  return () => {\n    throw new Error(`${common.decodeErrPrefix} ${msg}`);\n  };\n}\n\nconst jump = [];\n\nfor (let i = 0; i <= 23; i++) {\n  jump[i] = invalidMinor;\n}\n\njump[24] = _0uint.decodeUint8;\njump[25] = _0uint.decodeUint16;\njump[26] = _0uint.decodeUint32;\njump[27] = _0uint.decodeUint64;\njump[28] = invalidMinor;\njump[29] = invalidMinor;\njump[30] = invalidMinor;\njump[31] = invalidMinor;\n\nfor (let i = 32; i <= 55; i++) {\n  jump[i] = invalidMinor;\n}\n\njump[56] = _1negint.decodeNegint8;\njump[57] = _1negint.decodeNegint16;\njump[58] = _1negint.decodeNegint32;\njump[59] = _1negint.decodeNegint64;\njump[60] = invalidMinor;\njump[61] = invalidMinor;\njump[62] = invalidMinor;\njump[63] = invalidMinor;\n\nfor (let i = 64; i <= 87; i++) {\n  jump[i] = _2bytes.decodeBytesCompact;\n}\n\njump[88] = _2bytes.decodeBytes8;\njump[89] = _2bytes.decodeBytes16;\njump[90] = _2bytes.decodeBytes32;\njump[91] = _2bytes.decodeBytes64;\njump[92] = invalidMinor;\njump[93] = invalidMinor;\njump[94] = invalidMinor;\njump[95] = errorer('indefinite length bytes/strings are not supported');\n\nfor (let i = 96; i <= 119; i++) {\n  jump[i] = _3string.decodeStringCompact;\n}\n\njump[120] = _3string.decodeString8;\njump[121] = _3string.decodeString16;\njump[122] = _3string.decodeString32;\njump[123] = _3string.decodeString64;\njump[124] = invalidMinor;\njump[125] = invalidMinor;\njump[126] = invalidMinor;\njump[127] = errorer('indefinite length bytes/strings are not supported');\n\nfor (let i = 128; i <= 151; i++) {\n  jump[i] = _4array.decodeArrayCompact;\n}\n\njump[152] = _4array.decodeArray8;\njump[153] = _4array.decodeArray16;\njump[154] = _4array.decodeArray32;\njump[155] = _4array.decodeArray64;\njump[156] = invalidMinor;\njump[157] = invalidMinor;\njump[158] = invalidMinor;\njump[159] = _4array.decodeArrayIndefinite;\n\nfor (let i = 160; i <= 183; i++) {\n  jump[i] = _5map.decodeMapCompact;\n}\n\njump[184] = _5map.decodeMap8;\njump[185] = _5map.decodeMap16;\njump[186] = _5map.decodeMap32;\njump[187] = _5map.decodeMap64;\njump[188] = invalidMinor;\njump[189] = invalidMinor;\njump[190] = invalidMinor;\njump[191] = _5map.decodeMapIndefinite;\n\nfor (let i = 192; i <= 215; i++) {\n  jump[i] = _6tag.decodeTagCompact;\n}\n\njump[216] = _6tag.decodeTag8;\njump[217] = _6tag.decodeTag16;\njump[218] = _6tag.decodeTag32;\njump[219] = _6tag.decodeTag64;\njump[220] = invalidMinor;\njump[221] = invalidMinor;\njump[222] = invalidMinor;\njump[223] = invalidMinor;\n\nfor (let i = 224; i <= 243; i++) {\n  jump[i] = errorer('simple values are not supported');\n}\n\njump[244] = invalidMinor;\njump[245] = invalidMinor;\njump[246] = invalidMinor;\njump[247] = _7float.decodeUndefined;\njump[248] = errorer('simple values are not supported');\njump[249] = _7float.decodeFloat16;\njump[250] = _7float.decodeFloat32;\njump[251] = _7float.decodeFloat64;\njump[252] = invalidMinor;\njump[253] = invalidMinor;\njump[254] = invalidMinor;\njump[255] = _7float.decodeBreak;\nconst quick = [];\n\nfor (let i = 0; i < 24; i++) {\n  quick[i] = new token.Token(token.Type.uint, i, 1);\n}\n\nfor (let i = -1; i >= -24; i--) {\n  quick[31 - i] = new token.Token(token.Type.negint, i, 1);\n}\n\nquick[64] = new token.Token(token.Type.bytes, new Uint8Array(0), 1);\nquick[96] = new token.Token(token.Type.string, '', 1);\nquick[128] = new token.Token(token.Type.array, 0, 1);\nquick[160] = new token.Token(token.Type.map, 0, 1);\nquick[244] = new token.Token(token.Type.false, false, 1);\nquick[245] = new token.Token(token.Type.true, true, 1);\nquick[246] = new token.Token(token.Type.null, null, 1);\n\nfunction quickEncodeToken(token$1) {\n  switch (token$1.type) {\n    case token.Type.false:\n      return byteUtils.fromArray([244]);\n\n    case token.Type.true:\n      return byteUtils.fromArray([245]);\n\n    case token.Type.null:\n      return byteUtils.fromArray([246]);\n\n    case token.Type.bytes:\n      if (!token$1.value.length) {\n        return byteUtils.fromArray([64]);\n      }\n\n      return;\n\n    case token.Type.string:\n      if (token$1.value === '') {\n        return byteUtils.fromArray([96]);\n      }\n\n      return;\n\n    case token.Type.array:\n      if (token$1.value === 0) {\n        return byteUtils.fromArray([128]);\n      }\n\n      return;\n\n    case token.Type.map:\n      if (token$1.value === 0) {\n        return byteUtils.fromArray([160]);\n      }\n\n      return;\n\n    case token.Type.uint:\n      if (token$1.value < 24) {\n        return byteUtils.fromArray([Number(token$1.value)]);\n      }\n\n      return;\n\n    case token.Type.negint:\n      if (token$1.value >= -24) {\n        return byteUtils.fromArray([31 - Number(token$1.value)]);\n      }\n\n  }\n}\n\nexports.jump = jump;\nexports.quick = quick;\nexports.quickEncodeToken = quickEncodeToken;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/jump.js?");

/***/ }),

/***/ "./node_modules/cborg/cjs/lib/token.js":
/*!*********************************************!*\
  !*** ./node_modules/cborg/cjs/lib/token.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nclass Type {\n  constructor(major, name, terminal) {\n    this.major = major;\n    this.majorEncoded = major << 5;\n    this.name = name;\n    this.terminal = terminal;\n  }\n\n  toString() {\n    return `Type[${this.major}].${this.name}`;\n  }\n\n  compare(typ) {\n    return this.major < typ.major ? -1 : this.major > typ.major ? 1 : 0;\n  }\n\n}\n\nType.uint = new Type(0, 'uint', true);\nType.negint = new Type(1, 'negint', true);\nType.bytes = new Type(2, 'bytes', true);\nType.string = new Type(3, 'string', true);\nType.array = new Type(4, 'array', false);\nType.map = new Type(5, 'map', false);\nType.tag = new Type(6, 'tag', false);\nType.float = new Type(7, 'float', true);\nType.false = new Type(7, 'false', true);\nType.true = new Type(7, 'true', true);\nType.null = new Type(7, 'null', true);\nType.undefined = new Type(7, 'undefined', true);\nType.break = new Type(7, 'break', true);\n\nclass Token {\n  constructor(type, value, encodedLength) {\n    this.type = type;\n    this.value = value;\n    this.encodedLength = encodedLength;\n    this.encodedBytes = undefined;\n    this.byteValue = undefined;\n  }\n\n  toString() {\n    return `Token[${this.type}].${this.value}`;\n  }\n\n}\n\nexports.Token = Token;\nexports.Type = Type;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/cborg/cjs/lib/token.js?");

/***/ }),

/***/ "./node_modules/concat-map/index.js":
/*!******************************************!*\
  !*** ./node_modules/concat-map/index.js ***!
  \******************************************/
/***/ ((module) => {

eval("module.exports = function (xs, fn) {\n  var res = [];\n\n  for (var i = 0; i < xs.length; i++) {\n    var x = fn(xs[i], i);\n    if (isArray(x)) res.push.apply(res, x);else res.push(x);\n  }\n\n  return res;\n};\n\nvar isArray = Array.isArray || function (xs) {\n  return Object.prototype.toString.call(xs) === '[object Array]';\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/concat-map/index.js?");

/***/ }),

/***/ "./node_modules/data-uri-to-buffer/dist/src/index.js":
/*!***********************************************************!*\
  !*** ./node_modules/data-uri-to-buffer/dist/src/index.js ***!
  \***********************************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Returns a `Buffer` instance from the given data URI `uri`.\n *\n * @param {String} uri Data URI to turn into a Buffer instance\n * @return {Buffer} Buffer instance from Data URI\n * @api public\n */\n\nfunction dataUriToBuffer(uri) {\n  if (!/^data:/i.test(uri)) {\n    throw new TypeError('`uri` does not appear to be a Data URI (must begin with \"data:\")');\n  } // strip newlines\n\n\n  uri = uri.replace(/\\r?\\n/g, ''); // split the URI up into the \"metadata\" and the \"data\" portions\n\n  const firstComma = uri.indexOf(',');\n\n  if (firstComma === -1 || firstComma <= 4) {\n    throw new TypeError('malformed data: URI');\n  } // remove the \"data:\" scheme and parse the metadata\n\n\n  const meta = uri.substring(5, firstComma).split(';');\n  let charset = '';\n  let base64 = false;\n  const type = meta[0] || 'text/plain';\n  let typeFull = type;\n\n  for (let i = 1; i < meta.length; i++) {\n    if (meta[i] === 'base64') {\n      base64 = true;\n    } else {\n      typeFull += `;${meta[i]}`;\n\n      if (meta[i].indexOf('charset=') === 0) {\n        charset = meta[i].substring(8);\n      }\n    }\n  } // defaults to US-ASCII only if type is not provided\n\n\n  if (!meta[0] && !charset.length) {\n    typeFull += ';charset=US-ASCII';\n    charset = 'US-ASCII';\n  } // get the encoded data portion and decode URI-encoded chars\n\n\n  const encoding = base64 ? 'base64' : 'ascii';\n  const data = unescape(uri.substring(firstComma + 1));\n  const buffer = Buffer.from(data, encoding); // set `.type` and `.typeFull` properties to MIME type\n\n  buffer.type = type;\n  buffer.typeFull = typeFull; // set the `.charset` property\n\n  buffer.charset = charset;\n  return buffer;\n}\n\nmodule.exports = dataUriToBuffer;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/data-uri-to-buffer/dist/src/index.js?");

/***/ }),

/***/ "./node_modules/err-code/index.js":
/*!****************************************!*\
  !*** ./node_modules/err-code/index.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\n\nfunction assign(obj, props) {\n  for (const key in props) {\n    Object.defineProperty(obj, key, {\n      value: props[key],\n      enumerable: true,\n      configurable: true\n    });\n  }\n\n  return obj;\n}\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\n\n\nfunction createError(err, code, props) {\n  if (!err || typeof err === 'string') {\n    throw new TypeError('Please pass an Error to err-code');\n  }\n\n  if (!props) {\n    props = {};\n  }\n\n  if (typeof code === 'object') {\n    props = code;\n    code = '';\n  }\n\n  if (code) {\n    props.code = code;\n  }\n\n  try {\n    return assign(err, props);\n  } catch (_) {\n    props.message = err.message;\n    props.stack = err.stack;\n\n    const ErrClass = function () {};\n\n    ErrClass.prototype = Object.create(Object.getPrototypeOf(err)); // @ts-ignore\n\n    const output = assign(new ErrClass(), props);\n    return output;\n  }\n}\n\nmodule.exports = createError;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/err-code/index.js?");

/***/ }),

/***/ "./node_modules/files-from-path/cjs/src/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/files-from-path/cjs/src/index.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar Path = __webpack_require__(/*! path */ \"path\");\n\nvar fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/graceful-fs/graceful-fs.js\");\n\nvar util = __webpack_require__(/*! util */ \"util\");\n\nvar glob = __webpack_require__(/*! it-glob */ \"./node_modules/it-glob/index.js\");\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar Path__default = /*#__PURE__*/_interopDefaultLegacy(Path);\n\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\n\nvar glob__default = /*#__PURE__*/_interopDefaultLegacy(glob);\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nconst fsStat = util.promisify(fs__default[\"default\"].stat);\n\nasync function getFilesFromPath(paths, options) {\n  const files = [];\n\n  for await (const file of filesFromPath(paths, options)) {\n    files.push(file);\n  }\n\n  return files;\n}\n\nasync function* filesFromPath(paths, options) {\n  options = options || {};\n\n  if (typeof paths === 'string') {\n    paths = [paths];\n  }\n\n  const globSourceOptions = {\n    recursive: true,\n    glob: {\n      dot: Boolean(options.hidden),\n      ignore: Array.isArray(options.ignore) ? options.ignore : [],\n      follow: options.followSymlinks != null ? options.followSymlinks : true\n    }\n  };\n\n  for await (const path of paths) {\n    if (typeof path !== 'string') {\n      throw errCode__default[\"default\"](new Error('Path must be a string'), 'ERR_INVALID_PATH', {\n        path\n      });\n    }\n\n    const absolutePath = Path__default[\"default\"].resolve(process.cwd(), path);\n    const stat = await fsStat(absolutePath);\n    const prefix = options.pathPrefix || Path__default[\"default\"].dirname(absolutePath);\n    let mode = options.mode;\n\n    if (options.preserveMode) {\n      mode = stat.mode;\n    }\n\n    let mtime = options.mtime;\n\n    if (options.preserveMtime) {\n      mtime = stat.mtime;\n    }\n\n    yield* toGlobSource({\n      path,\n      type: stat.isDirectory() ? 'dir' : 'file',\n      prefix,\n      mode,\n      mtime,\n      size: stat.size,\n      preserveMode: options.preserveMode,\n      preserveMtime: options.preserveMtime\n    }, globSourceOptions);\n  }\n}\n\nasync function* toGlobSource({\n  path,\n  type,\n  prefix,\n  mode,\n  mtime,\n  size,\n  preserveMode,\n  preserveMtime\n}, options) {\n  options = options || {};\n  const baseName = Path__default[\"default\"].basename(path);\n\n  if (type === 'file') {\n    yield {\n      name: `/${baseName.replace(prefix, '')}`,\n      stream: () => fs__default[\"default\"].createReadStream(Path__default[\"default\"].isAbsolute(path) ? path : Path__default[\"default\"].join(process.cwd(), path)),\n      mode,\n      mtime,\n      size\n    };\n    return;\n  }\n\n  const globOptions = Object.assign({}, options.glob, {\n    cwd: path,\n    nodir: false,\n    realpath: false,\n    absolute: true\n  });\n\n  for await (const p of glob__default[\"default\"](path, '**/*', globOptions)) {\n    const stat = await fsStat(p);\n\n    if (!stat.isFile()) {\n      continue;\n    }\n\n    if (preserveMode || preserveMtime) {\n      if (preserveMode) {\n        mode = stat.mode;\n      }\n\n      if (preserveMtime) {\n        mtime = stat.mtime;\n      }\n    }\n\n    yield {\n      name: toPosix(p.replace(prefix, '')),\n      stream: () => fs__default[\"default\"].createReadStream(p),\n      mode,\n      mtime,\n      size: stat.size\n    };\n  }\n}\n\nconst toPosix = path => path.replace(/\\\\/g, '/');\n\nexports.filesFromPath = filesFromPath;\nexports.getFilesFromPath = getFilesFromPath;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/files-from-path/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/clone.js":
/*!*******************************************!*\
  !*** ./node_modules/graceful-fs/clone.js ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = clone;\n\nvar getPrototypeOf = Object.getPrototypeOf || function (obj) {\n  return obj.__proto__;\n};\n\nfunction clone(obj) {\n  if (obj === null || typeof obj !== 'object') return obj;\n  if (obj instanceof Object) var copy = {\n    __proto__: getPrototypeOf(obj)\n  };else var copy = Object.create(null);\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key));\n  });\n  return copy;\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/graceful-fs/clone.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/graceful-fs.js":
/*!*************************************************!*\
  !*** ./node_modules/graceful-fs/graceful-fs.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var fs = __webpack_require__(/*! fs */ \"fs\");\n\nvar polyfills = __webpack_require__(/*! ./polyfills.js */ \"./node_modules/graceful-fs/polyfills.js\");\n\nvar legacy = __webpack_require__(/*! ./legacy-streams.js */ \"./node_modules/graceful-fs/legacy-streams.js\");\n\nvar clone = __webpack_require__(/*! ./clone.js */ \"./node_modules/graceful-fs/clone.js\");\n\nvar util = __webpack_require__(/*! util */ \"util\");\n/* istanbul ignore next - node 0.x polyfill */\n\n\nvar gracefulQueue;\nvar previousSymbol;\n/* istanbul ignore else - node 0.x polyfill */\n\nif (typeof Symbol === 'function' && typeof Symbol.for === 'function') {\n  gracefulQueue = Symbol.for('graceful-fs.queue'); // This is used in testing by future versions\n\n  previousSymbol = Symbol.for('graceful-fs.previous');\n} else {\n  gracefulQueue = '___graceful-fs.queue';\n  previousSymbol = '___graceful-fs.previous';\n}\n\nfunction noop() {}\n\nfunction publishQueue(context, queue) {\n  Object.defineProperty(context, gracefulQueue, {\n    get: function () {\n      return queue;\n    }\n  });\n}\n\nvar debug = noop;\nif (util.debuglog) debug = util.debuglog('gfs4');else if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) debug = function () {\n  var m = util.format.apply(util, arguments);\n  m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ');\n  console.error(m);\n}; // Once time initialization\n\nif (!fs[gracefulQueue]) {\n  // This queue can be shared by multiple loaded instances\n  var queue = global[gracefulQueue] || [];\n  publishQueue(fs, queue); // Patch fs.close/closeSync to shared queue version, because we need\n  // to retry() whenever a close happens *anywhere* in the program.\n  // This is essential when multiple graceful-fs instances are\n  // in play at the same time.\n\n  fs.close = function (fs$close) {\n    function close(fd, cb) {\n      return fs$close.call(fs, fd, function (err) {\n        // This function uses the graceful-fs shared queue\n        if (!err) {\n          resetQueue();\n        }\n\n        if (typeof cb === 'function') cb.apply(this, arguments);\n      });\n    }\n\n    Object.defineProperty(close, previousSymbol, {\n      value: fs$close\n    });\n    return close;\n  }(fs.close);\n\n  fs.closeSync = function (fs$closeSync) {\n    function closeSync(fd) {\n      // This function uses the graceful-fs shared queue\n      fs$closeSync.apply(fs, arguments);\n      resetQueue();\n    }\n\n    Object.defineProperty(closeSync, previousSymbol, {\n      value: fs$closeSync\n    });\n    return closeSync;\n  }(fs.closeSync);\n\n  if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n    process.on('exit', function () {\n      debug(fs[gracefulQueue]);\n\n      (__webpack_require__(/*! assert */ \"assert\").equal)(fs[gracefulQueue].length, 0);\n    });\n  }\n}\n\nif (!global[gracefulQueue]) {\n  publishQueue(global, fs[gracefulQueue]);\n}\n\nmodule.exports = patch(clone(fs));\n\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {\n  module.exports = patch(fs);\n  fs.__patched = true;\n}\n\nfunction patch(fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs);\n  fs.gracefulify = patch;\n  fs.createReadStream = createReadStream;\n  fs.createWriteStream = createWriteStream;\n  var fs$readFile = fs.readFile;\n  fs.readFile = readFile;\n\n  function readFile(path, options, cb) {\n    if (typeof options === 'function') cb = options, options = null;\n    return go$readFile(path, options, cb);\n\n    function go$readFile(path, options, cb, startTime) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) enqueue([go$readFile, [path, options, cb], err, startTime || Date.now(), Date.now()]);else {\n          if (typeof cb === 'function') cb.apply(this, arguments);\n        }\n      });\n    }\n  }\n\n  var fs$writeFile = fs.writeFile;\n  fs.writeFile = writeFile;\n\n  function writeFile(path, data, options, cb) {\n    if (typeof options === 'function') cb = options, options = null;\n    return go$writeFile(path, data, options, cb);\n\n    function go$writeFile(path, data, options, cb, startTime) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) enqueue([go$writeFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()]);else {\n          if (typeof cb === 'function') cb.apply(this, arguments);\n        }\n      });\n    }\n  }\n\n  var fs$appendFile = fs.appendFile;\n  if (fs$appendFile) fs.appendFile = appendFile;\n\n  function appendFile(path, data, options, cb) {\n    if (typeof options === 'function') cb = options, options = null;\n    return go$appendFile(path, data, options, cb);\n\n    function go$appendFile(path, data, options, cb, startTime) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) enqueue([go$appendFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()]);else {\n          if (typeof cb === 'function') cb.apply(this, arguments);\n        }\n      });\n    }\n  }\n\n  var fs$copyFile = fs.copyFile;\n  if (fs$copyFile) fs.copyFile = copyFile;\n\n  function copyFile(src, dest, flags, cb) {\n    if (typeof flags === 'function') {\n      cb = flags;\n      flags = 0;\n    }\n\n    return go$copyFile(src, dest, flags, cb);\n\n    function go$copyFile(src, dest, flags, cb, startTime) {\n      return fs$copyFile(src, dest, flags, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) enqueue([go$copyFile, [src, dest, flags, cb], err, startTime || Date.now(), Date.now()]);else {\n          if (typeof cb === 'function') cb.apply(this, arguments);\n        }\n      });\n    }\n  }\n\n  var fs$readdir = fs.readdir;\n  fs.readdir = readdir;\n  var noReaddirOptionVersions = /^v[0-5]\\./;\n\n  function readdir(path, options, cb) {\n    if (typeof options === 'function') cb = options, options = null;\n    var go$readdir = noReaddirOptionVersions.test(process.version) ? function go$readdir(path, options, cb, startTime) {\n      return fs$readdir(path, fs$readdirCallback(path, options, cb, startTime));\n    } : function go$readdir(path, options, cb, startTime) {\n      return fs$readdir(path, options, fs$readdirCallback(path, options, cb, startTime));\n    };\n    return go$readdir(path, options, cb);\n\n    function fs$readdirCallback(path, options, cb, startTime) {\n      return function (err, files) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) enqueue([go$readdir, [path, options, cb], err, startTime || Date.now(), Date.now()]);else {\n          if (files && files.sort) files.sort();\n          if (typeof cb === 'function') cb.call(this, err, files);\n        }\n      };\n    }\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs);\n    ReadStream = legStreams.ReadStream;\n    WriteStream = legStreams.WriteStream;\n  }\n\n  var fs$ReadStream = fs.ReadStream;\n\n  if (fs$ReadStream) {\n    ReadStream.prototype = Object.create(fs$ReadStream.prototype);\n    ReadStream.prototype.open = ReadStream$open;\n  }\n\n  var fs$WriteStream = fs.WriteStream;\n\n  if (fs$WriteStream) {\n    WriteStream.prototype = Object.create(fs$WriteStream.prototype);\n    WriteStream.prototype.open = WriteStream$open;\n  }\n\n  Object.defineProperty(fs, 'ReadStream', {\n    get: function () {\n      return ReadStream;\n    },\n    set: function (val) {\n      ReadStream = val;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(fs, 'WriteStream', {\n    get: function () {\n      return WriteStream;\n    },\n    set: function (val) {\n      WriteStream = val;\n    },\n    enumerable: true,\n    configurable: true\n  }); // legacy names\n\n  var FileReadStream = ReadStream;\n  Object.defineProperty(fs, 'FileReadStream', {\n    get: function () {\n      return FileReadStream;\n    },\n    set: function (val) {\n      FileReadStream = val;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  var FileWriteStream = WriteStream;\n  Object.defineProperty(fs, 'FileWriteStream', {\n    get: function () {\n      return FileWriteStream;\n    },\n    set: function (val) {\n      FileWriteStream = val;\n    },\n    enumerable: true,\n    configurable: true\n  });\n\n  function ReadStream(path, options) {\n    if (this instanceof ReadStream) return fs$ReadStream.apply(this, arguments), this;else return ReadStream.apply(Object.create(ReadStream.prototype), arguments);\n  }\n\n  function ReadStream$open() {\n    var that = this;\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose) that.destroy();\n        that.emit('error', err);\n      } else {\n        that.fd = fd;\n        that.emit('open', fd);\n        that.read();\n      }\n    });\n  }\n\n  function WriteStream(path, options) {\n    if (this instanceof WriteStream) return fs$WriteStream.apply(this, arguments), this;else return WriteStream.apply(Object.create(WriteStream.prototype), arguments);\n  }\n\n  function WriteStream$open() {\n    var that = this;\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy();\n        that.emit('error', err);\n      } else {\n        that.fd = fd;\n        that.emit('open', fd);\n      }\n    });\n  }\n\n  function createReadStream(path, options) {\n    return new fs.ReadStream(path, options);\n  }\n\n  function createWriteStream(path, options) {\n    return new fs.WriteStream(path, options);\n  }\n\n  var fs$open = fs.open;\n  fs.open = open;\n\n  function open(path, flags, mode, cb) {\n    if (typeof mode === 'function') cb = mode, mode = null;\n    return go$open(path, flags, mode, cb);\n\n    function go$open(path, flags, mode, cb, startTime) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE')) enqueue([go$open, [path, flags, mode, cb], err, startTime || Date.now(), Date.now()]);else {\n          if (typeof cb === 'function') cb.apply(this, arguments);\n        }\n      });\n    }\n  }\n\n  return fs;\n}\n\nfunction enqueue(elem) {\n  debug('ENQUEUE', elem[0].name, elem[1]);\n  fs[gracefulQueue].push(elem);\n  retry();\n} // keep track of the timeout between retry() calls\n\n\nvar retryTimer; // reset the startTime and lastTime to now\n// this resets the start of the 60 second overall timeout as well as the\n// delay between attempts so that we'll retry these jobs sooner\n\nfunction resetQueue() {\n  var now = Date.now();\n\n  for (var i = 0; i < fs[gracefulQueue].length; ++i) {\n    // entries that are only a length of 2 are from an older version, don't\n    // bother modifying those since they'll be retried anyway.\n    if (fs[gracefulQueue][i].length > 2) {\n      fs[gracefulQueue][i][3] = now; // startTime\n\n      fs[gracefulQueue][i][4] = now; // lastTime\n    }\n  } // call retry to make sure we're actively processing the queue\n\n\n  retry();\n}\n\nfunction retry() {\n  // clear the timer and remove it to help prevent unintended concurrency\n  clearTimeout(retryTimer);\n  retryTimer = undefined;\n  if (fs[gracefulQueue].length === 0) return;\n  var elem = fs[gracefulQueue].shift();\n  var fn = elem[0];\n  var args = elem[1]; // these items may be unset if they were added by an older graceful-fs\n\n  var err = elem[2];\n  var startTime = elem[3];\n  var lastTime = elem[4]; // if we don't have a startTime we have no way of knowing if we've waited\n  // long enough, so go ahead and retry this item now\n\n  if (startTime === undefined) {\n    debug('RETRY', fn.name, args);\n    fn.apply(null, args);\n  } else if (Date.now() - startTime >= 60000) {\n    // it's been more than 60 seconds total, bail now\n    debug('TIMEOUT', fn.name, args);\n    var cb = args.pop();\n    if (typeof cb === 'function') cb.call(null, err);\n  } else {\n    // the amount of time between the last attempt and right now\n    var sinceAttempt = Date.now() - lastTime; // the amount of time between when we first tried, and when we last tried\n    // rounded up to at least 1\n\n    var sinceStart = Math.max(lastTime - startTime, 1); // backoff. wait longer than the total time we've been retrying, but only\n    // up to a maximum of 100ms\n\n    var desiredDelay = Math.min(sinceStart * 1.2, 100); // it's been long enough since the last retry, do it again\n\n    if (sinceAttempt >= desiredDelay) {\n      debug('RETRY', fn.name, args);\n      fn.apply(null, args.concat([startTime]));\n    } else {\n      // if we can't do this job yet, push it to the end of the queue\n      // and let the next iteration check again\n      fs[gracefulQueue].push(elem);\n    }\n  } // schedule our next run if one isn't already scheduled\n\n\n  if (retryTimer === undefined) {\n    retryTimer = setTimeout(retry, 0);\n  }\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/graceful-fs/graceful-fs.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/legacy-streams.js":
/*!****************************************************!*\
  !*** ./node_modules/graceful-fs/legacy-streams.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Stream = (__webpack_require__(/*! stream */ \"stream\").Stream);\n\nmodule.exports = legacy;\n\nfunction legacy(fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  };\n\n  function ReadStream(path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n    Stream.call(this);\n    var self = this;\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n    this.flags = 'r';\n    this.mode = 438;\n    /*=0666*/\n\n    this.bufferSize = 64 * 1024;\n    options = options || {}; // Mixin options into this\n\n    var keys = Object.keys(options);\n\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function () {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n\n      self._read();\n    });\n  }\n\n  function WriteStream(path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n    Stream.call(this);\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438;\n    /*=0666*/\n\n    this.bytesWritten = 0;\n    options = options || {}; // Mixin options into this\n\n    var keys = Object.keys(options);\n\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n\n      this.flush();\n    }\n  }\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/graceful-fs/legacy-streams.js?");

/***/ }),

/***/ "./node_modules/graceful-fs/polyfills.js":
/*!***********************************************!*\
  !*** ./node_modules/graceful-fs/polyfills.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var constants = __webpack_require__(/*! constants */ \"constants\");\n\nvar origCwd = process.cwd;\nvar cwd = null;\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform;\n\nprocess.cwd = function () {\n  if (!cwd) cwd = origCwd.call(process);\n  return cwd;\n};\n\ntry {\n  process.cwd();\n} catch (er) {} // This check is needed until node.js 12 is required\n\n\nif (typeof process.chdir === 'function') {\n  var chdir = process.chdir;\n\n  process.chdir = function (d) {\n    cwd = null;\n    chdir.call(process, d);\n  };\n\n  if (Object.setPrototypeOf) Object.setPrototypeOf(process.chdir, chdir);\n}\n\nmodule.exports = patch;\n\nfunction patch(fs) {\n  // (re-)implement some things that are known busted or missing.\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') && process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs);\n  } // lutimes implementation, or no-op\n\n\n  if (!fs.lutimes) {\n    patchLutimes(fs);\n  } // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n\n  fs.chown = chownFix(fs.chown);\n  fs.fchown = chownFix(fs.fchown);\n  fs.lchown = chownFix(fs.lchown);\n  fs.chmod = chmodFix(fs.chmod);\n  fs.fchmod = chmodFix(fs.fchmod);\n  fs.lchmod = chmodFix(fs.lchmod);\n  fs.chownSync = chownFixSync(fs.chownSync);\n  fs.fchownSync = chownFixSync(fs.fchownSync);\n  fs.lchownSync = chownFixSync(fs.lchownSync);\n  fs.chmodSync = chmodFixSync(fs.chmodSync);\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync);\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync);\n  fs.stat = statFix(fs.stat);\n  fs.fstat = statFix(fs.fstat);\n  fs.lstat = statFix(fs.lstat);\n  fs.statSync = statFixSync(fs.statSync);\n  fs.fstatSync = statFixSync(fs.fstatSync);\n  fs.lstatSync = statFixSync(fs.lstatSync); // if lchmod/lchown do not exist, then make them no-ops\n\n  if (fs.chmod && !fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb);\n    };\n\n    fs.lchmodSync = function () {};\n  }\n\n  if (fs.chown && !fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb);\n    };\n\n    fs.lchownSync = function () {};\n  } // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n\n\n  if (platform === \"win32\") {\n    fs.rename = typeof fs.rename !== 'function' ? fs.rename : function (fs$rename) {\n      function rename(from, to, cb) {\n        var start = Date.now();\n        var backoff = 0;\n        fs$rename(from, to, function CB(er) {\n          if (er && (er.code === \"EACCES\" || er.code === \"EPERM\") && Date.now() - start < 60000) {\n            setTimeout(function () {\n              fs.stat(to, function (stater, st) {\n                if (stater && stater.code === \"ENOENT\") fs$rename(from, to, CB);else cb(er);\n              });\n            }, backoff);\n            if (backoff < 100) backoff += 10;\n            return;\n          }\n\n          if (cb) cb(er);\n        });\n      }\n\n      if (Object.setPrototypeOf) Object.setPrototypeOf(rename, fs$rename);\n      return rename;\n    }(fs.rename);\n  } // if read() returns EAGAIN, then just try it again.\n\n\n  fs.read = typeof fs.read !== 'function' ? fs.read : function (fs$read) {\n    function read(fd, buffer, offset, length, position, callback_) {\n      var callback;\n\n      if (callback_ && typeof callback_ === 'function') {\n        var eagCounter = 0;\n\n        callback = function (er, _, __) {\n          if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter++;\n            return fs$read.call(fs, fd, buffer, offset, length, position, callback);\n          }\n\n          callback_.apply(this, arguments);\n        };\n      }\n\n      return fs$read.call(fs, fd, buffer, offset, length, position, callback);\n    } // This ensures `util.promisify` works as it does for native `fs.read`.\n\n\n    if (Object.setPrototypeOf) Object.setPrototypeOf(read, fs$read);\n    return read;\n  }(fs.read);\n  fs.readSync = typeof fs.readSync !== 'function' ? fs.readSync : function (fs$readSync) {\n    return function (fd, buffer, offset, length, position) {\n      var eagCounter = 0;\n\n      while (true) {\n        try {\n          return fs$readSync.call(fs, fd, buffer, offset, length, position);\n        } catch (er) {\n          if (er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter++;\n            continue;\n          }\n\n          throw er;\n        }\n      }\n    };\n  }(fs.readSync);\n\n  function patchLchmod(fs) {\n    fs.lchmod = function (path, mode, callback) {\n      fs.open(path, constants.O_WRONLY | constants.O_SYMLINK, mode, function (err, fd) {\n        if (err) {\n          if (callback) callback(err);\n          return;\n        } // prefer to return the chmod error, if one occurs,\n        // but still try to close, and report closing errors if they occur.\n\n\n        fs.fchmod(fd, mode, function (err) {\n          fs.close(fd, function (err2) {\n            if (callback) callback(err || err2);\n          });\n        });\n      });\n    };\n\n    fs.lchmodSync = function (path, mode) {\n      var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode); // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n\n      var threw = true;\n      var ret;\n\n      try {\n        ret = fs.fchmodSync(fd, mode);\n        threw = false;\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd);\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd);\n        }\n      }\n\n      return ret;\n    };\n  }\n\n  function patchLutimes(fs) {\n    if (constants.hasOwnProperty(\"O_SYMLINK\") && fs.futimes) {\n      fs.lutimes = function (path, at, mt, cb) {\n        fs.open(path, constants.O_SYMLINK, function (er, fd) {\n          if (er) {\n            if (cb) cb(er);\n            return;\n          }\n\n          fs.futimes(fd, at, mt, function (er) {\n            fs.close(fd, function (er2) {\n              if (cb) cb(er || er2);\n            });\n          });\n        });\n      };\n\n      fs.lutimesSync = function (path, at, mt) {\n        var fd = fs.openSync(path, constants.O_SYMLINK);\n        var ret;\n        var threw = true;\n\n        try {\n          ret = fs.futimesSync(fd, at, mt);\n          threw = false;\n        } finally {\n          if (threw) {\n            try {\n              fs.closeSync(fd);\n            } catch (er) {}\n          } else {\n            fs.closeSync(fd);\n          }\n        }\n\n        return ret;\n      };\n    } else if (fs.futimes) {\n      fs.lutimes = function (_a, _b, _c, cb) {\n        if (cb) process.nextTick(cb);\n      };\n\n      fs.lutimesSync = function () {};\n    }\n  }\n\n  function chmodFix(orig) {\n    if (!orig) return orig;\n    return function (target, mode, cb) {\n      return orig.call(fs, target, mode, function (er) {\n        if (chownErOk(er)) er = null;\n        if (cb) cb.apply(this, arguments);\n      });\n    };\n  }\n\n  function chmodFixSync(orig) {\n    if (!orig) return orig;\n    return function (target, mode) {\n      try {\n        return orig.call(fs, target, mode);\n      } catch (er) {\n        if (!chownErOk(er)) throw er;\n      }\n    };\n  }\n\n  function chownFix(orig) {\n    if (!orig) return orig;\n    return function (target, uid, gid, cb) {\n      return orig.call(fs, target, uid, gid, function (er) {\n        if (chownErOk(er)) er = null;\n        if (cb) cb.apply(this, arguments);\n      });\n    };\n  }\n\n  function chownFixSync(orig) {\n    if (!orig) return orig;\n    return function (target, uid, gid) {\n      try {\n        return orig.call(fs, target, uid, gid);\n      } catch (er) {\n        if (!chownErOk(er)) throw er;\n      }\n    };\n  }\n\n  function statFix(orig) {\n    if (!orig) return orig; // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n\n    return function (target, options, cb) {\n      if (typeof options === 'function') {\n        cb = options;\n        options = null;\n      }\n\n      function callback(er, stats) {\n        if (stats) {\n          if (stats.uid < 0) stats.uid += 0x100000000;\n          if (stats.gid < 0) stats.gid += 0x100000000;\n        }\n\n        if (cb) cb.apply(this, arguments);\n      }\n\n      return options ? orig.call(fs, target, options, callback) : orig.call(fs, target, callback);\n    };\n  }\n\n  function statFixSync(orig) {\n    if (!orig) return orig; // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n\n    return function (target, options) {\n      var stats = options ? orig.call(fs, target, options) : orig.call(fs, target);\n\n      if (stats) {\n        if (stats.uid < 0) stats.uid += 0x100000000;\n        if (stats.gid < 0) stats.gid += 0x100000000;\n      }\n\n      return stats;\n    };\n  } // ENOSYS means that the fs doesn't support the op. Just ignore\n  // that, because it doesn't matter.\n  //\n  // if there's no getuid, or if getuid() is something other\n  // than 0, and the error is EINVAL or EPERM, then just ignore\n  // it.\n  //\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  //\n  // When running as root, or if other types of errors are\n  // encountered, then it's strict.\n\n\n  function chownErOk(er) {\n    if (!er) return true;\n    if (er.code === \"ENOSYS\") return true;\n    var nonroot = !process.getuid || process.getuid() !== 0;\n\n    if (nonroot) {\n      if (er.code === \"EINVAL\" || er.code === \"EPERM\") return true;\n    }\n\n    return false;\n  }\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/graceful-fs/polyfills.js?");

/***/ }),

/***/ "./node_modules/hamt-sharding/src/bucket.js":
/*!**************************************************!*\
  !*** ./node_modules/hamt-sharding/src/bucket.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval(" // @ts-ignore\n\nconst SparseArray = __webpack_require__(/*! sparse-array */ \"./node_modules/sparse-array/index.js\");\n\nconst {\n  fromString: uint8ArrayFromString\n} = __webpack_require__(/*! uint8arrays/from-string */ \"./node_modules/uint8arrays/cjs/src/from-string.js\");\n/**\n * @typedef {import('./consumable-hash').InfiniteHash} InfiniteHash\n * @typedef {import('../').UserBucketOptions} UserBucketOptions\n */\n\n/**\n * @template V\n * @typedef {object} BucketChild<V>\n * @property {string} key\n * @property {V} value\n * @property {InfiniteHash} hash\n */\n\n/**\n * @template B\n *\n * @typedef {object} SA<B>\n * @property {number} length\n * @property {() => B[]} compactArray\n * @property {(i: number) => B} get\n * @property {(i: number, value: B) => void} set\n * @property {<A> (fn: (acc: A, curr: B, index: number) => A, initial: A) => B} reduce\n * @property {(fn: (item: B) => boolean) => B | undefined} find\n * @property {() => number[]} bitField\n * @property {(i: number) => void} unset\n */\n\n/**\n * @template T\n *\n * @typedef {object} BucketPosition<T>\n * @property {Bucket<T>} bucket\n * @property {number} pos\n * @property {InfiniteHash} hash\n * @property {BucketChild<T>} [existingChild]\n */\n\n/**\n * @typedef {object} BucketOptions\n * @property {number} bits\n * @property {(value: Uint8Array | InfiniteHash) => InfiniteHash} hash\n */\n\n/**\n * @template T\n */\n\n\nclass Bucket {\n  /**\n   * @param {BucketOptions} options\n   * @param {Bucket<T>} [parent]\n   * @param {number} [posAtParent=0]\n   */\n  constructor(options, parent, posAtParent = 0) {\n    this._options = options;\n    this._popCount = 0;\n    this._parent = parent;\n    this._posAtParent = posAtParent;\n    /** @type {SA<Bucket<T> | BucketChild<T>>} */\n\n    this._children = new SparseArray();\n    /** @type {string | null} */\n\n    this.key = null;\n  }\n  /**\n   * @param {string} key\n   * @param {T} value\n   */\n\n\n  async put(key, value) {\n    const place = await this._findNewBucketAndPos(key);\n    await place.bucket._putAt(place, key, value);\n  }\n  /**\n   * @param {string} key\n   */\n\n\n  async get(key) {\n    const child = await this._findChild(key);\n\n    if (child) {\n      return child.value;\n    }\n  }\n  /**\n   * @param {string} key\n   */\n\n\n  async del(key) {\n    const place = await this._findPlace(key);\n\n    const child = place.bucket._at(place.pos);\n\n    if (child && child.key === key) {\n      place.bucket._delAt(place.pos);\n    }\n  }\n  /**\n   * @returns {number}\n   */\n\n\n  leafCount() {\n    const children = this._children.compactArray();\n\n    return children.reduce((acc, child) => {\n      if (child instanceof Bucket) {\n        return acc + child.leafCount();\n      }\n\n      return acc + 1;\n    }, 0);\n  }\n\n  childrenCount() {\n    return this._children.length;\n  }\n\n  onlyChild() {\n    return this._children.get(0);\n  }\n  /**\n   * @returns {Iterable<BucketChild<T>>}\n   */\n\n\n  *eachLeafSeries() {\n    const children = this._children.compactArray();\n\n    for (const child of children) {\n      if (child instanceof Bucket) {\n        yield* child.eachLeafSeries();\n      } else {\n        yield child;\n      }\n    } // this is necessary because tsc requires a @return annotation as it\n    // can't derive a return type due to the recursion, and eslint requires\n    // a return statement when there is a @return annotation\n\n\n    return [];\n  }\n  /**\n   * @param {(value: BucketChild<T>, index: number) => T} map\n   * @param {(reduced: any) => any} reduce\n   */\n\n\n  serialize(map, reduce) {\n    /** @type {T[]} */\n    const acc = []; // serialize to a custom non-sparse representation\n\n    return reduce(this._children.reduce((acc, child, index) => {\n      if (child) {\n        if (child instanceof Bucket) {\n          acc.push(child.serialize(map, reduce));\n        } else {\n          acc.push(map(child, index));\n        }\n      }\n\n      return acc;\n    }, acc));\n  }\n  /**\n   * @param {(value: BucketChild<T>) => Promise<T[]>} asyncMap\n   * @param {(reduced: any) => Promise<any>} asyncReduce\n   */\n\n\n  asyncTransform(asyncMap, asyncReduce) {\n    return asyncTransformBucket(this, asyncMap, asyncReduce);\n  }\n\n  toJSON() {\n    return this.serialize(mapNode, reduceNodes);\n  }\n\n  prettyPrint() {\n    return JSON.stringify(this.toJSON(), null, '  ');\n  }\n\n  tableSize() {\n    return Math.pow(2, this._options.bits);\n  }\n  /**\n   * @param {string} key\n   * @returns {Promise<BucketChild<T> | undefined>}\n   */\n\n\n  async _findChild(key) {\n    const result = await this._findPlace(key);\n\n    const child = result.bucket._at(result.pos);\n\n    if (child instanceof Bucket) {\n      // should not be possible, this._findPlace should always\n      // return a location for a child, not a bucket\n      return undefined;\n    }\n\n    if (child && child.key === key) {\n      return child;\n    }\n  }\n  /**\n   * @param {string | InfiniteHash} key\n   * @returns {Promise<BucketPosition<T>>}\n   */\n\n\n  async _findPlace(key) {\n    const hashValue = this._options.hash(typeof key === 'string' ? uint8ArrayFromString(key) : key);\n\n    const index = await hashValue.take(this._options.bits);\n\n    const child = this._children.get(index);\n\n    if (child instanceof Bucket) {\n      return child._findPlace(hashValue);\n    }\n\n    return {\n      bucket: this,\n      pos: index,\n      hash: hashValue,\n      existingChild: child\n    };\n  }\n  /**\n   * @param {string | InfiniteHash} key\n   * @returns {Promise<BucketPosition<T>>}\n   */\n\n\n  async _findNewBucketAndPos(key) {\n    const place = await this._findPlace(key);\n\n    if (place.existingChild && place.existingChild.key !== key) {\n      // conflict\n      const bucket = new Bucket(this._options, place.bucket, place.pos);\n\n      place.bucket._putObjectAt(place.pos, bucket); // put the previous value\n\n\n      const newPlace = await bucket._findPlace(place.existingChild.hash);\n\n      newPlace.bucket._putAt(newPlace, place.existingChild.key, place.existingChild.value);\n\n      return bucket._findNewBucketAndPos(place.hash);\n    } // no conflict, we found the place\n\n\n    return place;\n  }\n  /**\n   * @param {BucketPosition<T>} place\n   * @param {string} key\n   * @param {T} value\n   */\n\n\n  _putAt(place, key, value) {\n    this._putObjectAt(place.pos, {\n      key: key,\n      value: value,\n      hash: place.hash\n    });\n  }\n  /**\n   * @param {number} pos\n   * @param {Bucket<T> | BucketChild<T>} object\n   */\n\n\n  _putObjectAt(pos, object) {\n    if (!this._children.get(pos)) {\n      this._popCount++;\n    }\n\n    this._children.set(pos, object);\n  }\n  /**\n   * @param {number} pos\n   */\n\n\n  _delAt(pos) {\n    if (pos === -1) {\n      throw new Error('Invalid position');\n    }\n\n    if (this._children.get(pos)) {\n      this._popCount--;\n    }\n\n    this._children.unset(pos);\n\n    this._level();\n  }\n\n  _level() {\n    if (this._parent && this._popCount <= 1) {\n      if (this._popCount === 1) {\n        // remove myself from parent, replacing me with my only child\n        const onlyChild = this._children.find(exists);\n\n        if (onlyChild && !(onlyChild instanceof Bucket)) {\n          const hash = onlyChild.hash;\n          hash.untake(this._options.bits);\n          const place = {\n            pos: this._posAtParent,\n            hash: hash,\n            bucket: this._parent\n          };\n\n          this._parent._putAt(place, onlyChild.key, onlyChild.value);\n        }\n      } else {\n        this._parent._delAt(this._posAtParent);\n      }\n    }\n  }\n  /**\n   * @param {number} index\n   * @returns {BucketChild<T> | Bucket<T> | undefined}\n   */\n\n\n  _at(index) {\n    return this._children.get(index);\n  }\n\n}\n/**\n * @param {any} o\n */\n\n\nfunction exists(o) {\n  return Boolean(o);\n}\n/**\n *\n * @param {*} node\n * @param {number} index\n */\n\n\nfunction mapNode(node, index) {\n  return node.key;\n}\n/**\n * @param {*} nodes\n */\n\n\nfunction reduceNodes(nodes) {\n  return nodes;\n}\n/**\n * @template T\n *\n * @param {Bucket<T>} bucket\n * @param {(value: BucketChild<T>) => Promise<T[]>} asyncMap\n * @param {(reduced: any) => Promise<any>} asyncReduce\n */\n\n\nasync function asyncTransformBucket(bucket, asyncMap, asyncReduce) {\n  const output = [];\n\n  for (const child of bucket._children.compactArray()) {\n    if (child instanceof Bucket) {\n      await asyncTransformBucket(child, asyncMap, asyncReduce);\n    } else {\n      const mappedChildren = await asyncMap(child);\n      output.push({\n        bitField: bucket._children.bitField(),\n        children: mappedChildren\n      });\n    }\n  }\n\n  return asyncReduce(output);\n}\n\nmodule.exports = Bucket;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/hamt-sharding/src/bucket.js?");

/***/ }),

/***/ "./node_modules/hamt-sharding/src/consumable-buffer.js":
/*!*************************************************************!*\
  !*** ./node_modules/hamt-sharding/src/consumable-buffer.js ***!
  \*************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst START_MASKS = [0b11111111, 0b11111110, 0b11111100, 0b11111000, 0b11110000, 0b11100000, 0b11000000, 0b10000000];\nconst STOP_MASKS = [0b00000001, 0b00000011, 0b00000111, 0b00001111, 0b00011111, 0b00111111, 0b01111111, 0b11111111];\nmodule.exports = class ConsumableBuffer {\n  /**\n   * @param {Uint8Array} value\n   */\n  constructor(value) {\n    this._value = value;\n    this._currentBytePos = value.length - 1;\n    this._currentBitPos = 7;\n  }\n\n  availableBits() {\n    return this._currentBitPos + 1 + this._currentBytePos * 8;\n  }\n\n  totalBits() {\n    return this._value.length * 8;\n  }\n  /**\n   * @param {number} bits\n   */\n\n\n  take(bits) {\n    let pendingBits = bits;\n    let result = 0;\n\n    while (pendingBits && this._haveBits()) {\n      const byte = this._value[this._currentBytePos];\n      const availableBits = this._currentBitPos + 1;\n      const taking = Math.min(availableBits, pendingBits);\n      const value = byteBitsToInt(byte, availableBits - taking, taking);\n      result = (result << taking) + value;\n      pendingBits -= taking;\n      this._currentBitPos -= taking;\n\n      if (this._currentBitPos < 0) {\n        this._currentBitPos = 7;\n        this._currentBytePos--;\n      }\n    }\n\n    return result;\n  }\n  /**\n   * @param {number} bits\n   */\n\n\n  untake(bits) {\n    this._currentBitPos += bits;\n\n    while (this._currentBitPos > 7) {\n      this._currentBitPos -= 8;\n      this._currentBytePos += 1;\n    }\n  }\n\n  _haveBits() {\n    return this._currentBytePos >= 0;\n  }\n\n};\n/**\n * @param {number} byte\n * @param {number} start\n * @param {number} length\n */\n\nfunction byteBitsToInt(byte, start, length) {\n  const mask = maskFor(start, length);\n  return (byte & mask) >>> start;\n}\n/**\n * @param {number} start\n * @param {number} length\n */\n\n\nfunction maskFor(start, length) {\n  return START_MASKS[start] & STOP_MASKS[Math.min(length + start - 1, 7)];\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/hamt-sharding/src/consumable-buffer.js?");

/***/ }),

/***/ "./node_modules/hamt-sharding/src/consumable-hash.js":
/*!***********************************************************!*\
  !*** ./node_modules/hamt-sharding/src/consumable-hash.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst ConsumableBuffer = __webpack_require__(/*! ./consumable-buffer */ \"./node_modules/hamt-sharding/src/consumable-buffer.js\");\n\nconst {\n  concat: uint8ArrayConcat\n} = __webpack_require__(/*! uint8arrays/concat */ \"./node_modules/uint8arrays/cjs/src/concat.js\");\n/**\n * @param {(value: Uint8Array) => Promise<Uint8Array>} hashFn\n */\n\n\nfunction wrapHash(hashFn) {\n  /**\n   * @param {InfiniteHash | Uint8Array} value\n   */\n  function hashing(value) {\n    if (value instanceof InfiniteHash) {\n      // already a hash. return it\n      return value;\n    } else {\n      return new InfiniteHash(value, hashFn);\n    }\n  }\n\n  return hashing;\n}\n\nclass InfiniteHash {\n  /**\n   *\n   * @param {Uint8Array} value\n   * @param {(value: Uint8Array) => Promise<Uint8Array>} hashFn\n   */\n  constructor(value, hashFn) {\n    if (!(value instanceof Uint8Array)) {\n      throw new Error('can only hash Uint8Arrays');\n    }\n\n    this._value = value;\n    this._hashFn = hashFn;\n    this._depth = -1;\n    this._availableBits = 0;\n    this._currentBufferIndex = 0;\n    /** @type {ConsumableBuffer[]} */\n\n    this._buffers = [];\n  }\n  /**\n   * @param {number} bits\n   */\n\n\n  async take(bits) {\n    let pendingBits = bits;\n\n    while (this._availableBits < pendingBits) {\n      await this._produceMoreBits();\n    }\n\n    let result = 0;\n\n    while (pendingBits > 0) {\n      const hash = this._buffers[this._currentBufferIndex];\n      const available = Math.min(hash.availableBits(), pendingBits);\n      const took = hash.take(available);\n      result = (result << available) + took;\n      pendingBits -= available;\n      this._availableBits -= available;\n\n      if (hash.availableBits() === 0) {\n        this._currentBufferIndex++;\n      }\n    }\n\n    return result;\n  }\n  /**\n   * @param {number} bits\n   */\n\n\n  untake(bits) {\n    let pendingBits = bits;\n\n    while (pendingBits > 0) {\n      const hash = this._buffers[this._currentBufferIndex];\n      const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits);\n      hash.untake(availableForUntake);\n      pendingBits -= availableForUntake;\n      this._availableBits += availableForUntake;\n\n      if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {\n        this._depth--;\n        this._currentBufferIndex--;\n      }\n    }\n  }\n\n  async _produceMoreBits() {\n    this._depth++;\n    const value = this._depth ? uint8ArrayConcat([this._value, Uint8Array.from([this._depth])]) : this._value;\n    const hashValue = await this._hashFn(value);\n    const buffer = new ConsumableBuffer(hashValue);\n\n    this._buffers.push(buffer);\n\n    this._availableBits += buffer.availableBits();\n  }\n\n}\n\nmodule.exports = wrapHash;\nmodule.exports.InfiniteHash = InfiniteHash;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/hamt-sharding/src/consumable-hash.js?");

/***/ }),

/***/ "./node_modules/hamt-sharding/src/index.js":
/*!*************************************************!*\
  !*** ./node_modules/hamt-sharding/src/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Bucket = __webpack_require__(/*! ./bucket */ \"./node_modules/hamt-sharding/src/bucket.js\");\n\nconst wrapHash = __webpack_require__(/*! ./consumable-hash */ \"./node_modules/hamt-sharding/src/consumable-hash.js\");\n/**\n * @typedef {object} UserBucketOptions\n * @property {(value: Uint8Array) => Promise<Uint8Array>} hashFn\n * @property {number} [bits=8]\n */\n\n/**\n * @param {UserBucketOptions} options\n */\n\n\nfunction createHAMT(options) {\n  if (!options || !options.hashFn) {\n    throw new Error('please define an options.hashFn');\n  }\n\n  const bucketOptions = {\n    bits: options.bits || 8,\n    hash: wrapHash(options.hashFn)\n  };\n  return new Bucket(bucketOptions);\n}\n\nmodule.exports = {\n  createHAMT,\n  Bucket\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/hamt-sharding/src/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-car/dist/cjs/blockstore/fs.js":
/*!*********************************************************!*\
  !*** ./node_modules/ipfs-car/dist/cjs/blockstore/fs.js ***!
  \*********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.FsBlockStore = void 0;\n\nconst fs_1 = __importDefault(__webpack_require__(/*! fs */ \"fs\"));\n\nconst os_1 = __importDefault(__webpack_require__(/*! os */ \"os\"));\n\nconst multiformats_1 = __webpack_require__(/*! multiformats */ \"./node_modules/multiformats/cjs/src/index.js\");\n\nconst blockstore_core_1 = __webpack_require__(/*! blockstore-core */ \"./node_modules/blockstore-core/cjs/src/index.js\");\n\nclass FsBlockStore extends blockstore_core_1.BaseBlockstore {\n  constructor() {\n    super();\n    this.path = `${os_1.default.tmpdir()}/${parseInt(String(Math.random() * 1e9), 10).toString() + Date.now()}`;\n    this._opened = false;\n  }\n\n  async _open() {\n    if (this._opening) {\n      await this._opening;\n    } else {\n      this._opening = fs_1.default.promises.mkdir(this.path);\n      await this._opening;\n      this._opened = true;\n    }\n  }\n\n  async put(cid, bytes) {\n    if (!this._opened) {\n      await this._open();\n    }\n\n    const cidStr = cid.toString();\n    const location = `${this.path}/${cidStr}`;\n    await fs_1.default.promises.writeFile(location, bytes);\n  }\n\n  async get(cid) {\n    if (!this._opened) {\n      await this._open();\n    }\n\n    const cidStr = cid.toString();\n    const location = `${this.path}/${cidStr}`;\n    const bytes = await fs_1.default.promises.readFile(location);\n    return bytes;\n  }\n\n  async has(cid) {\n    if (!this._opened) {\n      await this._open();\n    }\n\n    const cidStr = cid.toString();\n    const location = `${this.path}/${cidStr}`;\n\n    try {\n      await fs_1.default.promises.access(location);\n      return true;\n    } catch (err) {\n      return false;\n    }\n  }\n\n  async *blocks() {\n    if (!this._opened) {\n      await this._open();\n    }\n\n    const cids = await fs_1.default.promises.readdir(this.path);\n\n    for (const cidStr of cids) {\n      const location = `${this.path}/${cidStr}`;\n      const bytes = await fs_1.default.promises.readFile(location);\n      yield {\n        cid: multiformats_1.CID.parse(cidStr),\n        bytes\n      };\n    }\n  }\n\n  async close() {\n    if (this._opened) {\n      await fs_1.default.promises.rm(this.path, {\n        recursive: true\n      });\n    }\n\n    this._opened = false;\n  }\n\n}\n\nexports.FsBlockStore = FsBlockStore;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-car/dist/cjs/blockstore/fs.js?");

/***/ }),

/***/ "./node_modules/ipfs-car/dist/cjs/blockstore/memory.js":
/*!*************************************************************!*\
  !*** ./node_modules/ipfs-car/dist/cjs/blockstore/memory.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.MemoryBlockStore = void 0;\n\nconst multiformats_1 = __webpack_require__(/*! multiformats */ \"./node_modules/multiformats/cjs/src/index.js\");\n\nconst blockstore_core_1 = __webpack_require__(/*! blockstore-core */ \"./node_modules/blockstore-core/cjs/src/index.js\");\n\nclass MemoryBlockStore extends blockstore_core_1.BaseBlockstore {\n  constructor() {\n    super();\n    this.store = new Map();\n  }\n\n  async *blocks() {\n    for (const [cidStr, bytes] of this.store.entries()) {\n      yield {\n        cid: multiformats_1.CID.parse(cidStr),\n        bytes\n      };\n    }\n  }\n\n  put(cid, bytes) {\n    this.store.set(cid.toString(), bytes);\n    return Promise.resolve();\n  }\n\n  get(cid) {\n    const bytes = this.store.get(cid.toString());\n\n    if (!bytes) {\n      throw new Error(`block with cid ${cid.toString()} no found`);\n    }\n\n    return Promise.resolve(bytes);\n  }\n\n  has(cid) {\n    return Promise.resolve(this.store.has(cid.toString()));\n  }\n\n  close() {\n    this.store.clear();\n    return Promise.resolve();\n  }\n\n}\n\nexports.MemoryBlockStore = MemoryBlockStore;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-car/dist/cjs/blockstore/memory.js?");

/***/ }),

/***/ "./node_modules/ipfs-car/dist/cjs/pack/constants.js":
/*!**********************************************************!*\
  !*** ./node_modules/ipfs-car/dist/cjs/pack/constants.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.unixfsImporterOptionsDefault = void 0;\n\nconst sha2_1 = __webpack_require__(/*! multiformats/hashes/sha2 */ \"./node_modules/multiformats/cjs/src/hashes/sha2.js\");\n\nexports.unixfsImporterOptionsDefault = {\n  cidVersion: 1,\n  chunker: 'fixed',\n  maxChunkSize: 262144,\n  hasher: sha2_1.sha256,\n  rawLeaves: true,\n  wrapWithDirectory: true,\n  maxChildrenPerNode: 174\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-car/dist/cjs/pack/constants.js?");

/***/ }),

/***/ "./node_modules/ipfs-car/dist/cjs/pack/index.js":
/*!******************************************************!*\
  !*** ./node_modules/ipfs-car/dist/cjs/pack/index.js ***!
  \******************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.pack = void 0;\n\nconst it_last_1 = __importDefault(__webpack_require__(/*! it-last */ \"./node_modules/it-last/index.js\"));\n\nconst it_pipe_1 = __importDefault(__webpack_require__(/*! it-pipe */ \"./node_modules/it-pipe/index.js\"));\n\nconst car_1 = __webpack_require__(/*! @ipld/car */ \"./node_modules/@ipld/car/cjs/car.js\");\n\nconst ipfs_unixfs_importer_1 = __webpack_require__(/*! ipfs-unixfs-importer */ \"./node_modules/ipfs-unixfs-importer/cjs/src/index.js\");\n\nconst normalise_input_1 = __webpack_require__(/*! ./utils/normalise-input */ \"./node_modules/ipfs-car/dist/cjs/pack/utils/normalise-input.js\");\n\nconst memory_1 = __webpack_require__(/*! ../blockstore/memory */ \"./node_modules/ipfs-car/dist/cjs/blockstore/memory.js\");\n\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/ipfs-car/dist/cjs/pack/constants.js\");\n\nasync function pack({\n  input,\n  blockstore: userBlockstore,\n  hasher,\n  maxChunkSize,\n  maxChildrenPerNode,\n  wrapWithDirectory,\n  rawLeaves\n}) {\n  if (!input || Array.isArray(input) && !input.length) {\n    throw new Error('missing input file(s)');\n  }\n\n  const blockstore = userBlockstore ? userBlockstore : new memory_1.MemoryBlockStore(); // Consume the source\n\n  const rootEntry = await (0, it_last_1.default)((0, it_pipe_1.default)((0, normalise_input_1.getNormaliser)(input), source => (0, ipfs_unixfs_importer_1.importer)(source, blockstore, { ...constants_1.unixfsImporterOptionsDefault,\n    hasher: hasher || constants_1.unixfsImporterOptionsDefault.hasher,\n    maxChunkSize: maxChunkSize || constants_1.unixfsImporterOptionsDefault.maxChunkSize,\n    maxChildrenPerNode: maxChildrenPerNode || constants_1.unixfsImporterOptionsDefault.maxChildrenPerNode,\n    wrapWithDirectory: wrapWithDirectory === false ? false : constants_1.unixfsImporterOptionsDefault.wrapWithDirectory,\n    rawLeaves: rawLeaves == null ? constants_1.unixfsImporterOptionsDefault.rawLeaves : rawLeaves\n  })));\n\n  if (!rootEntry || !rootEntry.cid) {\n    throw new Error('given input could not be parsed correctly');\n  }\n\n  const root = rootEntry.cid;\n  const {\n    writer,\n    out: carOut\n  } = await car_1.CarWriter.create([root]);\n  const carOutIter = carOut[Symbol.asyncIterator]();\n  let writingPromise;\n\n  const writeAll = async () => {\n    for await (const block of blockstore.blocks()) {\n      // `await` will block until all bytes in `carOut` are consumed by the user\n      // so we have backpressure here\n      await writer.put(block);\n    }\n\n    await writer.close();\n\n    if (!userBlockstore) {\n      await blockstore.close();\n    }\n  };\n\n  const out = {\n    [Symbol.asyncIterator]() {\n      if (writingPromise != null) {\n        throw new Error('Multiple iterator not supported');\n      } // don't start writing until the user starts consuming the iterator\n\n\n      writingPromise = writeAll();\n      return {\n        async next() {\n          const result = await carOutIter.next();\n\n          if (result.done) {\n            await writingPromise; // any errors will propagate from here\n          }\n\n          return result;\n        }\n\n      };\n    }\n\n  };\n  return {\n    root,\n    out\n  };\n}\n\nexports.pack = pack;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-car/dist/cjs/pack/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-car/dist/cjs/pack/utils/normalise-input.js":
/*!**********************************************************************!*\
  !*** ./node_modules/ipfs-car/dist/cjs/pack/utils/normalise-input.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.getNormaliser = void 0;\n\nconst normalise_input_single_1 = __webpack_require__(/*! ipfs-core-utils/files/normalise-input-single */ \"./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-single.js\");\n\nconst normalise_input_multiple_1 = __webpack_require__(/*! ipfs-core-utils/files/normalise-input-multiple */ \"./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-multiple.js\");\n\nfunction isBytes(obj) {\n  return ArrayBuffer.isView(obj) || obj instanceof ArrayBuffer;\n}\n\nfunction isBlob(obj) {\n  return Boolean(obj.constructor) && (obj.constructor.name === 'Blob' || obj.constructor.name === 'File') && typeof obj.stream === 'function';\n}\n\nfunction isSingle(input) {\n  return typeof input === 'string' || input instanceof String || isBytes(input) || isBlob(input) || '_readableState' in input;\n}\n/**\n * Get a single or multiple normaliser depending on the input.\n */\n\n\nfunction getNormaliser(input) {\n  if (isSingle(input)) {\n    return (0, normalise_input_single_1.normaliseInput)(input);\n  } else {\n    return (0, normalise_input_multiple_1.normaliseInput)(input);\n  }\n}\n\nexports.getNormaliser = getNormaliser;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-car/dist/cjs/pack/utils/normalise-input.js?");

/***/ }),

/***/ "./node_modules/ipfs-car/dist/cjs/unpack/index.js":
/*!********************************************************!*\
  !*** ./node_modules/ipfs-car/dist/cjs/unpack/index.js ***!
  \********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.unpackStream = exports.unpack = void 0;\n\nconst browser_readablestream_to_it_1 = __importDefault(__webpack_require__(/*! browser-readablestream-to-it */ \"./node_modules/browser-readablestream-to-it/index.js\"));\n\nconst iterator_1 = __webpack_require__(/*! @ipld/car/iterator */ \"./node_modules/@ipld/car/cjs/lib/iterator.js\");\n\nconst ipfs_unixfs_exporter_1 = __webpack_require__(/*! ipfs-unixfs-exporter */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/index.js\");\n\nconst verifying_get_only_blockstore_1 = __webpack_require__(/*! ./utils/verifying-get-only-blockstore */ \"./node_modules/ipfs-car/dist/cjs/unpack/utils/verifying-get-only-blockstore.js\");\n\nconst memory_1 = __webpack_require__(/*! ../blockstore/memory */ \"./node_modules/ipfs-car/dist/cjs/blockstore/memory.js\"); // Export unixfs entries from car file\n\n\nasync function* unpack(carReader, roots) {\n  const verifyingBlockService = verifying_get_only_blockstore_1.VerifyingGetOnlyBlockStore.fromCarReader(carReader);\n\n  if (!roots || roots.length === 0) {\n    roots = await carReader.getRoots();\n  }\n\n  for (const root of roots) {\n    yield* (0, ipfs_unixfs_exporter_1.recursive)(root, verifyingBlockService, {\n      /* options */\n    });\n  }\n}\n\nexports.unpack = unpack;\n\nasync function* unpackStream(readable, {\n  roots,\n  blockstore: userBlockstore\n} = {}) {\n  const carIterator = await iterator_1.CarBlockIterator.fromIterable(asAsyncIterable(readable));\n  const blockstore = userBlockstore || new memory_1.MemoryBlockStore();\n\n  for await (const block of carIterator) {\n    await blockstore.put(block.cid, block.bytes);\n  }\n\n  const verifyingBlockStore = verifying_get_only_blockstore_1.VerifyingGetOnlyBlockStore.fromBlockstore(blockstore);\n\n  if (!roots || roots.length === 0) {\n    roots = await carIterator.getRoots();\n  }\n\n  for (const root of roots) {\n    yield* (0, ipfs_unixfs_exporter_1.recursive)(root, verifyingBlockStore);\n  }\n}\n\nexports.unpackStream = unpackStream;\n/**\n * Upgrade a ReadableStream to an AsyncIterable if it isn't already\n *\n * ReadableStream (e.g res.body) is asyncIterable in node, but not in chrome, yet.\n * see: https://bugs.chromium.org/p/chromium/issues/detail?id=929585\n */\n\nfunction asAsyncIterable(readable) {\n  // @ts-ignore how to convince tsc that we are checking the type here?\n  return Symbol.asyncIterator in readable ? readable : (0, browser_readablestream_to_it_1.default)(readable);\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-car/dist/cjs/unpack/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-car/dist/cjs/unpack/utils/verifying-get-only-blockstore.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/ipfs-car/dist/cjs/unpack/utils/verifying-get-only-blockstore.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.VerifyingGetOnlyBlockStore = void 0;\n\nconst equals_1 = __webpack_require__(/*! uint8arrays/equals */ \"./node_modules/uint8arrays/cjs/src/equals.js\");\n\nconst sha2_1 = __webpack_require__(/*! multiformats/hashes/sha2 */ \"./node_modules/multiformats/cjs/src/hashes/sha2.js\");\n\nconst blockstore_core_1 = __webpack_require__(/*! blockstore-core */ \"./node_modules/blockstore-core/cjs/src/index.js\");\n\nclass VerifyingGetOnlyBlockStore extends blockstore_core_1.BaseBlockstore {\n  constructor(blockstore) {\n    super();\n    this.store = blockstore;\n  }\n\n  async get(cid) {\n    const res = await this.store.get(cid);\n\n    if (!res) {\n      throw new Error(`Incomplete CAR. Block missing for CID ${cid}`);\n    }\n\n    if (!isValid({\n      cid,\n      bytes: res\n    })) {\n      throw new Error(`Invalid CAR. Hash of block data does not match CID ${cid}`);\n    }\n\n    return res;\n  }\n\n  static fromBlockstore(b) {\n    return new VerifyingGetOnlyBlockStore(b);\n  }\n\n  static fromCarReader(cr) {\n    return new VerifyingGetOnlyBlockStore({\n      // Return bytes in the same fashion as a Blockstore implementation\n      get: async cid => {\n        const block = await cr.get(cid);\n        return block === null || block === void 0 ? void 0 : block.bytes;\n      }\n    });\n  }\n\n}\n\nexports.VerifyingGetOnlyBlockStore = VerifyingGetOnlyBlockStore;\n\nasync function isValid({\n  cid,\n  bytes\n}) {\n  const hash = await sha2_1.sha256.digest(bytes);\n  return (0, equals_1.equals)(hash.digest, cid.multihash.digest);\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-car/dist/cjs/unpack/utils/verifying-get-only-blockstore.js?");

/***/ }),

/***/ "./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-multiple.js":
/*!************************************************************************************!*\
  !*** ./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-multiple.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar browserStreamToIt = __webpack_require__(/*! browser-readablestream-to-it */ \"./node_modules/browser-readablestream-to-it/index.js\");\n\nvar itPeekable = __webpack_require__(/*! it-peekable */ \"./node_modules/it-peekable/index.js\");\n\nvar map = __webpack_require__(/*! it-map */ \"./node_modules/it-map/index.js\");\n\nvar utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/ipfs-core-utils/cjs/src/files/utils.js\");\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar browserStreamToIt__default = /*#__PURE__*/_interopDefaultLegacy(browserStreamToIt);\n\nvar itPeekable__default = /*#__PURE__*/_interopDefaultLegacy(itPeekable);\n\nvar map__default = /*#__PURE__*/_interopDefaultLegacy(map);\n\nasync function* normaliseCandidateMultiple(input, normaliseContent) {\n  if (typeof input === 'string' || input instanceof String || utils.isBytes(input) || utils.isBlob(input) || input._readableState) {\n    throw errCode__default[\"default\"](new Error('Unexpected input: single item passed - if you are using ipfs.addAll, please use ipfs.add instead'), 'ERR_UNEXPECTED_INPUT');\n  }\n\n  if (utils.isReadableStream(input)) {\n    input = browserStreamToIt__default[\"default\"](input);\n  }\n\n  if (Symbol.iterator in input || Symbol.asyncIterator in input) {\n    const peekable = itPeekable__default[\"default\"](input);\n    const {\n      value,\n      done\n    } = await peekable.peek();\n\n    if (done) {\n      yield* [];\n      return;\n    }\n\n    peekable.push(value);\n\n    if (Number.isInteger(value)) {\n      throw errCode__default[\"default\"](new Error('Unexpected input: single item passed - if you are using ipfs.addAll, please use ipfs.add instead'), 'ERR_UNEXPECTED_INPUT');\n    }\n\n    if (value._readableState) {\n      yield* map__default[\"default\"](peekable, value => toFileObject({\n        content: value\n      }, normaliseContent));\n      return;\n    }\n\n    if (utils.isBytes(value)) {\n      yield toFileObject({\n        content: peekable\n      }, normaliseContent);\n      return;\n    }\n\n    if (utils.isFileObject(value) || value[Symbol.iterator] || value[Symbol.asyncIterator] || utils.isReadableStream(value) || utils.isBlob(value)) {\n      yield* map__default[\"default\"](peekable, value => toFileObject(value, normaliseContent));\n      return;\n    }\n  }\n\n  if (utils.isFileObject(input)) {\n    throw errCode__default[\"default\"](new Error('Unexpected input: single item passed - if you are using ipfs.addAll, please use ipfs.add instead'), 'ERR_UNEXPECTED_INPUT');\n  }\n\n  throw errCode__default[\"default\"](new Error('Unexpected input: ' + typeof input), 'ERR_UNEXPECTED_INPUT');\n}\n\nasync function toFileObject(input, normaliseContent) {\n  const {\n    path,\n    mode,\n    mtime,\n    content\n  } = input;\n  const file = {\n    path: path || '',\n    mode: ipfsUnixfs.parseMode(mode),\n    mtime: ipfsUnixfs.parseMtime(mtime)\n  };\n\n  if (content) {\n    file.content = await normaliseContent(content);\n  } else if (!path) {\n    file.content = await normaliseContent(input);\n  }\n\n  return file;\n}\n\nexports.normaliseCandidateMultiple = normaliseCandidateMultiple;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-multiple.js?");

/***/ }),

/***/ "./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-single.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-single.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar browserStreamToIt = __webpack_require__(/*! browser-readablestream-to-it */ \"./node_modules/browser-readablestream-to-it/index.js\");\n\nvar itPeekable = __webpack_require__(/*! it-peekable */ \"./node_modules/it-peekable/index.js\");\n\nvar utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/ipfs-core-utils/cjs/src/files/utils.js\");\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar browserStreamToIt__default = /*#__PURE__*/_interopDefaultLegacy(browserStreamToIt);\n\nvar itPeekable__default = /*#__PURE__*/_interopDefaultLegacy(itPeekable);\n\nasync function* normaliseCandidateSingle(input, normaliseContent) {\n  if (input === null || input === undefined) {\n    throw errCode__default[\"default\"](new Error(`Unexpected input: ${input}`), 'ERR_UNEXPECTED_INPUT');\n  }\n\n  if (typeof input === 'string' || input instanceof String) {\n    yield toFileObject(input.toString(), normaliseContent);\n    return;\n  }\n\n  if (utils.isBytes(input) || utils.isBlob(input)) {\n    yield toFileObject(input, normaliseContent);\n    return;\n  }\n\n  if (utils.isReadableStream(input)) {\n    input = browserStreamToIt__default[\"default\"](input);\n  }\n\n  if (Symbol.iterator in input || Symbol.asyncIterator in input) {\n    const peekable = itPeekable__default[\"default\"](input);\n    const {\n      value,\n      done\n    } = await peekable.peek();\n\n    if (done) {\n      yield {\n        content: []\n      };\n      return;\n    }\n\n    peekable.push(value);\n\n    if (Number.isInteger(value) || utils.isBytes(value) || typeof value === 'string' || value instanceof String) {\n      yield toFileObject(peekable, normaliseContent);\n      return;\n    }\n\n    throw errCode__default[\"default\"](new Error('Unexpected input: multiple items passed - if you are using ipfs.add, please use ipfs.addAll instead'), 'ERR_UNEXPECTED_INPUT');\n  }\n\n  if (utils.isFileObject(input)) {\n    yield toFileObject(input, normaliseContent);\n    return;\n  }\n\n  throw errCode__default[\"default\"](new Error('Unexpected input: cannot convert \"' + typeof input + '\" into ImportCandidate'), 'ERR_UNEXPECTED_INPUT');\n}\n\nasync function toFileObject(input, normaliseContent) {\n  const {\n    path,\n    mode,\n    mtime,\n    content\n  } = input;\n  const file = {\n    path: path || '',\n    mode: ipfsUnixfs.parseMode(mode),\n    mtime: ipfsUnixfs.parseMtime(mtime)\n  };\n\n  if (content) {\n    file.content = await normaliseContent(content);\n  } else if (!path) {\n    file.content = await normaliseContent(input);\n  }\n\n  return file;\n}\n\nexports.normaliseCandidateSingle = normaliseCandidateSingle;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-single.js?");

/***/ }),

/***/ "./node_modules/ipfs-core-utils/cjs/src/files/normalise-content.js":
/*!*************************************************************************!*\
  !*** ./node_modules/ipfs-core-utils/cjs/src/files/normalise-content.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar fromString = __webpack_require__(/*! uint8arrays/from-string */ \"./node_modules/uint8arrays/cjs/src/from-string.js\");\n\nvar browserStreamToIt = __webpack_require__(/*! browser-readablestream-to-it */ \"./node_modules/browser-readablestream-to-it/index.js\");\n\nvar blobToIt = __webpack_require__(/*! blob-to-it */ \"./node_modules/blob-to-it/index.js\");\n\nvar itPeekable = __webpack_require__(/*! it-peekable */ \"./node_modules/it-peekable/index.js\");\n\nvar all = __webpack_require__(/*! it-all */ \"./node_modules/it-all/index.js\");\n\nvar map = __webpack_require__(/*! it-map */ \"./node_modules/it-map/index.js\");\n\nvar utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/ipfs-core-utils/cjs/src/files/utils.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar browserStreamToIt__default = /*#__PURE__*/_interopDefaultLegacy(browserStreamToIt);\n\nvar blobToIt__default = /*#__PURE__*/_interopDefaultLegacy(blobToIt);\n\nvar itPeekable__default = /*#__PURE__*/_interopDefaultLegacy(itPeekable);\n\nvar all__default = /*#__PURE__*/_interopDefaultLegacy(all);\n\nvar map__default = /*#__PURE__*/_interopDefaultLegacy(map);\n\nasync function* toAsyncIterable(thing) {\n  yield thing;\n}\n\nasync function normaliseContent(input) {\n  if (utils.isBytes(input)) {\n    return toAsyncIterable(toBytes(input));\n  }\n\n  if (typeof input === 'string' || input instanceof String) {\n    return toAsyncIterable(toBytes(input.toString()));\n  }\n\n  if (utils.isBlob(input)) {\n    return blobToIt__default[\"default\"](input);\n  }\n\n  if (utils.isReadableStream(input)) {\n    input = browserStreamToIt__default[\"default\"](input);\n  }\n\n  if (Symbol.iterator in input || Symbol.asyncIterator in input) {\n    const peekable = itPeekable__default[\"default\"](input);\n    const {\n      value,\n      done\n    } = await peekable.peek();\n\n    if (done) {\n      return toAsyncIterable(new Uint8Array(0));\n    }\n\n    peekable.push(value);\n\n    if (Number.isInteger(value)) {\n      return toAsyncIterable(Uint8Array.from(await all__default[\"default\"](peekable)));\n    }\n\n    if (utils.isBytes(value) || typeof value === 'string' || value instanceof String) {\n      return map__default[\"default\"](peekable, toBytes);\n    }\n  }\n\n  throw errCode__default[\"default\"](new Error(`Unexpected input: ${input}`), 'ERR_UNEXPECTED_INPUT');\n}\n\nfunction toBytes(chunk) {\n  if (chunk instanceof Uint8Array) {\n    return chunk;\n  }\n\n  if (ArrayBuffer.isView(chunk)) {\n    return new Uint8Array(chunk.buffer, chunk.byteOffset, chunk.byteLength);\n  }\n\n  if (chunk instanceof ArrayBuffer) {\n    return new Uint8Array(chunk);\n  }\n\n  if (Array.isArray(chunk)) {\n    return Uint8Array.from(chunk);\n  }\n\n  return fromString.fromString(chunk.toString());\n}\n\nexports.normaliseContent = normaliseContent;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-core-utils/cjs/src/files/normalise-content.js?");

/***/ }),

/***/ "./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-multiple.js":
/*!********************************************************************************!*\
  !*** ./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-multiple.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar normaliseContent = __webpack_require__(/*! ./normalise-content.js */ \"./node_modules/ipfs-core-utils/cjs/src/files/normalise-content.js\");\n\nvar normaliseCandidateMultiple = __webpack_require__(/*! ./normalise-candidate-multiple.js */ \"./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-multiple.js\");\n\nfunction normaliseInput(input) {\n  return normaliseCandidateMultiple.normaliseCandidateMultiple(input, normaliseContent.normaliseContent);\n}\n\nexports.normaliseInput = normaliseInput;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-multiple.js?");

/***/ }),

/***/ "./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-single.js":
/*!******************************************************************************!*\
  !*** ./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-single.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar normaliseContent = __webpack_require__(/*! ./normalise-content.js */ \"./node_modules/ipfs-core-utils/cjs/src/files/normalise-content.js\");\n\nvar normaliseCandidateSingle = __webpack_require__(/*! ./normalise-candidate-single.js */ \"./node_modules/ipfs-core-utils/cjs/src/files/normalise-candidate-single.js\");\n\nfunction normaliseInput(input) {\n  return normaliseCandidateSingle.normaliseCandidateSingle(input, normaliseContent.normaliseContent);\n}\n\nexports.normaliseInput = normaliseInput;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-core-utils/cjs/src/files/normalise-input-single.js?");

/***/ }),

/***/ "./node_modules/ipfs-core-utils/cjs/src/files/utils.js":
/*!*************************************************************!*\
  !*** ./node_modules/ipfs-core-utils/cjs/src/files/utils.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nfunction isBytes(obj) {\n  return ArrayBuffer.isView(obj) || obj instanceof ArrayBuffer;\n}\n\nfunction isBlob(obj) {\n  return obj.constructor && (obj.constructor.name === 'Blob' || obj.constructor.name === 'File') && typeof obj.stream === 'function';\n}\n\nfunction isFileObject(obj) {\n  return typeof obj === 'object' && (obj.path || obj.content);\n}\n\nconst isReadableStream = value => value && typeof value.getReader === 'function';\n\nexports.isBlob = isBlob;\nexports.isBytes = isBytes;\nexports.isFileObject = isFileObject;\nexports.isReadableStream = isReadableStream;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-core-utils/cjs/src/files/utils.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/index.js":
/*!************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/index.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar index = __webpack_require__(/*! ./resolvers/index.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/index.js\");\n\nvar last = __webpack_require__(/*! it-last */ \"./node_modules/it-last/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar last__default = /*#__PURE__*/_interopDefaultLegacy(last);\n\nconst toPathComponents = (path = '') => {\n  return (path.trim().match(/([^\\\\^/]|\\\\\\/)+/g) || []).filter(Boolean);\n};\n\nconst cidAndRest = path => {\n  if (path instanceof Uint8Array) {\n    return {\n      cid: cid.CID.decode(path),\n      toResolve: []\n    };\n  }\n\n  const cid$1 = cid.CID.asCID(path);\n\n  if (cid$1) {\n    return {\n      cid: cid$1,\n      toResolve: []\n    };\n  }\n\n  if (typeof path === 'string') {\n    if (path.indexOf('/ipfs/') === 0) {\n      path = path.substring(6);\n    }\n\n    const output = toPathComponents(path);\n    return {\n      cid: cid.CID.parse(output[0]),\n      toResolve: output.slice(1)\n    };\n  }\n\n  throw errCode__default[\"default\"](new Error(`Unknown path type ${path}`), 'ERR_BAD_PATH');\n};\n\nasync function* walkPath(path, blockstore, options = {}) {\n  let {\n    cid,\n    toResolve\n  } = cidAndRest(path);\n  let name = cid.toString();\n  let entryPath = name;\n  const startingDepth = toResolve.length;\n\n  while (true) {\n    const result = await index(cid, name, entryPath, toResolve, startingDepth, blockstore, options);\n\n    if (!result.entry && !result.next) {\n      throw errCode__default[\"default\"](new Error(`Could not resolve ${path}`), 'ERR_NOT_FOUND');\n    }\n\n    if (result.entry) {\n      yield result.entry;\n    }\n\n    if (!result.next) {\n      return;\n    }\n\n    toResolve = result.next.toResolve;\n    cid = result.next.cid;\n    name = result.next.name;\n    entryPath = result.next.path;\n  }\n}\n\nasync function exporter(path, blockstore, options = {}) {\n  const result = await last__default[\"default\"](walkPath(path, blockstore, options));\n\n  if (!result) {\n    throw errCode__default[\"default\"](new Error(`Could not resolve ${path}`), 'ERR_NOT_FOUND');\n  }\n\n  return result;\n}\n\nasync function* recursive(path, blockstore, options = {}) {\n  const node = await exporter(path, blockstore, options);\n\n  if (!node) {\n    return;\n  }\n\n  yield node;\n\n  if (node.type === 'directory') {\n    for await (const child of recurse(node, options)) {\n      yield child;\n    }\n  }\n\n  async function* recurse(node, options) {\n    for await (const file of node.content(options)) {\n      yield file;\n\n      if (file instanceof Uint8Array) {\n        continue;\n      }\n\n      if (file.type === 'directory') {\n        yield* recurse(file, options);\n      }\n    }\n  }\n}\n\nexports.exporter = exporter;\nexports.recursive = recursive;\nexports.walkPath = walkPath;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/dag-cbor.js":
/*!*************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/dag-cbor.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar dagCbor = __webpack_require__(/*! @ipld/dag-cbor */ \"./node_modules/@ipld/dag-cbor/cjs/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar dagCbor__namespace = /*#__PURE__*/_interopNamespace(dagCbor);\n\nconst resolve = async (cid$1, name, path, toResolve, resolve, depth, blockstore, options) => {\n  const block = await blockstore.get(cid$1);\n  const object = dagCbor__namespace.decode(block);\n  let subObject = object;\n  let subPath = path;\n\n  while (toResolve.length) {\n    const prop = toResolve[0];\n\n    if (prop in subObject) {\n      toResolve.shift();\n      subPath = `${subPath}/${prop}`;\n      const subObjectCid = cid.CID.asCID(subObject[prop]);\n\n      if (subObjectCid) {\n        return {\n          entry: {\n            type: 'object',\n            name,\n            path,\n            cid: cid$1,\n            node: block,\n            depth,\n            size: block.length,\n            content: async function* () {\n              yield object;\n            }\n          },\n          next: {\n            cid: subObjectCid,\n            name: prop,\n            path: subPath,\n            toResolve\n          }\n        };\n      }\n\n      subObject = subObject[prop];\n    } else {\n      throw errCode__default[\"default\"](new Error(`No property named ${prop} found in cbor node ${cid$1}`), 'ERR_NO_PROP');\n    }\n  }\n\n  return {\n    entry: {\n      type: 'object',\n      name,\n      path,\n      cid: cid$1,\n      node: block,\n      depth,\n      size: block.length,\n      content: async function* () {\n        yield object;\n      }\n    }\n  };\n};\n\nmodule.exports = resolve;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/dag-cbor.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/identity.js":
/*!*************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/identity.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar extractDataFromBlock = __webpack_require__(/*! ../utils/extract-data-from-block.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/utils/extract-data-from-block.js\");\n\nvar validateOffsetAndLength = __webpack_require__(/*! ../utils/validate-offset-and-length.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/utils/validate-offset-and-length.js\");\n\nvar mh = __webpack_require__(/*! multiformats/hashes/digest */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar mh__namespace = /*#__PURE__*/_interopNamespace(mh);\n\nconst rawContent = node => {\n  async function* contentGenerator(options = {}) {\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(node.length, options.offset, options.length);\n    yield extractDataFromBlock(node, 0, offset, offset + length);\n  }\n\n  return contentGenerator;\n};\n\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n  if (toResolve.length) {\n    throw errCode__default[\"default\"](new Error(`No link named ${path} found in raw node ${cid}`), 'ERR_NOT_FOUND');\n  }\n\n  const buf = await mh__namespace.decode(cid.multihash.bytes);\n  return {\n    entry: {\n      type: 'identity',\n      name,\n      path,\n      cid,\n      content: rawContent(buf.digest),\n      depth,\n      size: buf.digest.length,\n      node: buf.digest\n    }\n  };\n};\n\nmodule.exports = resolve;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/identity.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/index.js":
/*!**********************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/index.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar dagCbor = __webpack_require__(/*! @ipld/dag-cbor */ \"./node_modules/@ipld/dag-cbor/cjs/index.js\");\n\nvar raw = __webpack_require__(/*! multiformats/codecs/raw */ \"./node_modules/multiformats/cjs/src/codecs/raw.js\");\n\nvar identity = __webpack_require__(/*! multiformats/hashes/identity */ \"./node_modules/multiformats/cjs/src/hashes/identity.js\");\n\nvar index = __webpack_require__(/*! ./unixfs-v1/index.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/index.js\");\n\nvar raw$1 = __webpack_require__(/*! ./raw.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/raw.js\");\n\nvar dagCbor$1 = __webpack_require__(/*! ./dag-cbor.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/dag-cbor.js\");\n\nvar identity$1 = __webpack_require__(/*! ./identity.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/identity.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar dagPb__namespace = /*#__PURE__*/_interopNamespace(dagPb);\n\nvar dagCbor__namespace = /*#__PURE__*/_interopNamespace(dagCbor);\n\nvar raw__namespace = /*#__PURE__*/_interopNamespace(raw);\n\nconst resolvers = {\n  [dagPb__namespace.code]: index,\n  [raw__namespace.code]: raw$1,\n  [dagCbor__namespace.code]: dagCbor$1,\n  [identity.identity.code]: identity$1\n};\n\nfunction resolve(cid, name, path, toResolve, depth, blockstore, options) {\n  const resolver = resolvers[cid.code];\n\n  if (!resolver) {\n    throw errCode__default[\"default\"](new Error(`No resolver for code ${cid.code}`), 'ERR_NO_RESOLVER');\n  }\n\n  return resolver(cid, name, path, toResolve, resolve, depth, blockstore, options);\n}\n\nmodule.exports = resolve;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/raw.js":
/*!********************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/raw.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar extractDataFromBlock = __webpack_require__(/*! ../utils/extract-data-from-block.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/utils/extract-data-from-block.js\");\n\nvar validateOffsetAndLength = __webpack_require__(/*! ../utils/validate-offset-and-length.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/utils/validate-offset-and-length.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nconst rawContent = node => {\n  async function* contentGenerator(options = {}) {\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(node.length, options.offset, options.length);\n    yield extractDataFromBlock(node, 0, offset, offset + length);\n  }\n\n  return contentGenerator;\n};\n\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n  if (toResolve.length) {\n    throw errCode__default[\"default\"](new Error(`No link named ${path} found in raw node ${cid}`), 'ERR_NOT_FOUND');\n  }\n\n  const block = await blockstore.get(cid, options);\n  return {\n    entry: {\n      type: 'raw',\n      name,\n      path,\n      cid,\n      content: rawContent(block),\n      depth,\n      size: block.length,\n      node: block\n    }\n  };\n};\n\nmodule.exports = resolve;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/raw.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/directory.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/directory.js ***!
  \********************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst directoryContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  async function* yieldDirectoryContent(options = {}) {\n    const offset = options.offset || 0;\n    const length = options.length || node.Links.length;\n    const links = node.Links.slice(offset, length);\n\n    for (const link of links) {\n      const result = await resolve(link.Hash, link.Name || '', `${path}/${link.Name || ''}`, [], depth + 1, blockstore, options);\n\n      if (result.entry) {\n        yield result.entry;\n      }\n    }\n  }\n\n  return yieldDirectoryContent;\n};\n\nmodule.exports = directoryContent;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/directory.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/file.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/file.js ***!
  \***************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar extractDataFromBlock = __webpack_require__(/*! ../../../utils/extract-data-from-block.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/utils/extract-data-from-block.js\");\n\nvar validateOffsetAndLength = __webpack_require__(/*! ../../../utils/validate-offset-and-length.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/utils/validate-offset-and-length.js\");\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar dagCbor = __webpack_require__(/*! @ipld/dag-cbor */ \"./node_modules/@ipld/dag-cbor/cjs/index.js\");\n\nvar raw = __webpack_require__(/*! multiformats/codecs/raw */ \"./node_modules/multiformats/cjs/src/codecs/raw.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar dagPb__namespace = /*#__PURE__*/_interopNamespace(dagPb);\n\nvar dagCbor__namespace = /*#__PURE__*/_interopNamespace(dagCbor);\n\nvar raw__namespace = /*#__PURE__*/_interopNamespace(raw);\n\nasync function* emitBytes(blockstore, node, start, end, streamPosition = 0, options) {\n  if (node instanceof Uint8Array) {\n    const buf = extractDataFromBlock(node, streamPosition, start, end);\n\n    if (buf.length) {\n      yield buf;\n    }\n\n    streamPosition += buf.length;\n    return streamPosition;\n  }\n\n  if (node.Data == null) {\n    throw errCode__default[\"default\"](new Error('no data in PBNode'), 'ERR_NOT_UNIXFS');\n  }\n\n  let file;\n\n  try {\n    file = ipfsUnixfs.UnixFS.unmarshal(node.Data);\n  } catch (err) {\n    throw errCode__default[\"default\"](err, 'ERR_NOT_UNIXFS');\n  }\n\n  if (file.data && file.data.length) {\n    const buf = extractDataFromBlock(file.data, streamPosition, start, end);\n\n    if (buf.length) {\n      yield buf;\n    }\n\n    streamPosition += file.data.length;\n  }\n\n  let childStart = streamPosition;\n\n  for (let i = 0; i < node.Links.length; i++) {\n    const childLink = node.Links[i];\n    const childEnd = streamPosition + file.blockSizes[i];\n\n    if (start >= childStart && start < childEnd || end > childStart && end <= childEnd || start < childStart && end > childEnd) {\n      const block = await blockstore.get(childLink.Hash, {\n        signal: options.signal\n      });\n      let child;\n\n      switch (childLink.Hash.code) {\n        case dagPb__namespace.code:\n          child = await dagPb__namespace.decode(block);\n          break;\n\n        case raw__namespace.code:\n          child = block;\n          break;\n\n        case dagCbor__namespace.code:\n          child = await dagCbor__namespace.decode(block);\n          break;\n\n        default:\n          throw Error(`Unsupported codec: ${childLink.Hash.code}`);\n      }\n\n      for await (const buf of emitBytes(blockstore, child, start, end, streamPosition, options)) {\n        streamPosition += buf.length;\n        yield buf;\n      }\n    }\n\n    streamPosition = childEnd;\n    childStart = childEnd + 1;\n  }\n}\n\nconst fileContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  function yieldFileContent(options = {}) {\n    const fileSize = unixfs.fileSize();\n\n    if (fileSize === undefined) {\n      throw new Error('File was a directory');\n    }\n\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(fileSize, options.offset, options.length);\n    const start = offset;\n    const end = offset + length;\n    return emitBytes(blockstore, node, start, end, 0, options);\n  }\n\n  return yieldFileContent;\n};\n\nmodule.exports = fileContent;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/file.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js ***!
  \*********************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nconst hamtShardedDirectoryContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  function yieldHamtDirectoryContent(options = {}) {\n    return listDirectory(node, path, resolve, depth, blockstore, options);\n  }\n\n  return yieldHamtDirectoryContent;\n};\n\nasync function* listDirectory(node, path, resolve, depth, blockstore, options) {\n  const links = node.Links;\n\n  for (const link of links) {\n    const name = link.Name != null ? link.Name.substring(2) : null;\n\n    if (name) {\n      const result = await resolve(link.Hash, name, `${path}/${name}`, [], depth + 1, blockstore, options);\n      yield result.entry;\n    } else {\n      const block = await blockstore.get(link.Hash);\n      node = dagPb.decode(block);\n\n      for await (const file of listDirectory(node, path, resolve, depth, blockstore, options)) {\n        yield file;\n      }\n    }\n  }\n}\n\nmodule.exports = hamtShardedDirectoryContent;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/index.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nvar findCidInShard = __webpack_require__(/*! ../../utils/find-cid-in-shard.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/utils/find-cid-in-shard.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar file = __webpack_require__(/*! ./content/file.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/file.js\");\n\nvar directory = __webpack_require__(/*! ./content/directory.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/directory.js\");\n\nvar hamtShardedDirectory = __webpack_require__(/*! ./content/hamt-sharded-directory.js */ \"./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nconst findLinkCid = (node, name) => {\n  const link = node.Links.find(link => link.Name === name);\n  return link && link.Hash;\n};\n\nconst contentExporters = {\n  raw: file,\n  file: file,\n  directory: directory,\n  'hamt-sharded-directory': hamtShardedDirectory,\n  metadata: (cid, node, unixfs, path, resolve, depth, blockstore) => {\n    return () => [];\n  },\n  symlink: (cid, node, unixfs, path, resolve, depth, blockstore) => {\n    return () => [];\n  }\n};\n\nconst unixFsResolver = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n  const block = await blockstore.get(cid, options);\n  const node = dagPb.decode(block);\n  let unixfs;\n  let next;\n\n  if (!name) {\n    name = cid.toString();\n  }\n\n  if (node.Data == null) {\n    throw errCode__default[\"default\"](new Error('no data in PBNode'), 'ERR_NOT_UNIXFS');\n  }\n\n  try {\n    unixfs = ipfsUnixfs.UnixFS.unmarshal(node.Data);\n  } catch (err) {\n    throw errCode__default[\"default\"](err, 'ERR_NOT_UNIXFS');\n  }\n\n  if (!path) {\n    path = name;\n  }\n\n  if (toResolve.length) {\n    let linkCid;\n\n    if (unixfs && unixfs.type === 'hamt-sharded-directory') {\n      linkCid = await findCidInShard(node, toResolve[0], blockstore);\n    } else {\n      linkCid = findLinkCid(node, toResolve[0]);\n    }\n\n    if (!linkCid) {\n      throw errCode__default[\"default\"](new Error('file does not exist'), 'ERR_NOT_FOUND');\n    }\n\n    const nextName = toResolve.shift();\n    const nextPath = `${path}/${nextName}`;\n    next = {\n      cid: linkCid,\n      toResolve,\n      name: nextName || '',\n      path: nextPath\n    };\n  }\n\n  return {\n    entry: {\n      type: unixfs.isDirectory() ? 'directory' : 'file',\n      name,\n      path,\n      cid,\n      content: contentExporters[unixfs.type](cid, node, unixfs, path, resolve, depth, blockstore),\n      unixfs,\n      depth,\n      node,\n      size: unixfs.fileSize()\n    },\n    next\n  };\n};\n\nmodule.exports = unixFsResolver;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/resolvers/unixfs-v1/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/utils/extract-data-from-block.js":
/*!************************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/utils/extract-data-from-block.js ***!
  \************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction extractDataFromBlock(block, blockStart, requestedStart, requestedEnd) {\n  const blockLength = block.length;\n  const blockEnd = blockStart + blockLength;\n\n  if (requestedStart >= blockEnd || requestedEnd < blockStart) {\n    return new Uint8Array(0);\n  }\n\n  if (requestedEnd >= blockStart && requestedEnd < blockEnd) {\n    block = block.slice(0, requestedEnd - blockStart);\n  }\n\n  if (requestedStart >= blockStart && requestedStart < blockEnd) {\n    block = block.slice(requestedStart - blockStart);\n  }\n\n  return block;\n}\n\nmodule.exports = extractDataFromBlock;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/utils/extract-data-from-block.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/utils/find-cid-in-shard.js":
/*!******************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/utils/find-cid-in-shard.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar hamtSharding = __webpack_require__(/*! hamt-sharding */ \"./node_modules/hamt-sharding/src/index.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar murmur3 = __webpack_require__(/*! @multiformats/murmur3 */ \"./node_modules/@multiformats/murmur3/cjs/index.js\");\n\nconst hashFn = async function (buf) {\n  return (await murmur3.murmur3128.encode(buf)).slice(0, 8).reverse();\n};\n\nconst addLinksToHamtBucket = (links, bucket, rootBucket) => {\n  return Promise.all(links.map(link => {\n    if (link.Name == null) {\n      throw new Error('Unexpected Link without a Name');\n    }\n\n    if (link.Name.length === 2) {\n      const pos = parseInt(link.Name, 16);\n      return bucket._putObjectAt(pos, new hamtSharding.Bucket({\n        hash: rootBucket._options.hash,\n        bits: rootBucket._options.bits\n      }, bucket, pos));\n    }\n\n    return rootBucket.put(link.Name.substring(2), true);\n  }));\n};\n\nconst toPrefix = position => {\n  return position.toString(16).toUpperCase().padStart(2, '0').substring(0, 2);\n};\n\nconst toBucketPath = position => {\n  let bucket = position.bucket;\n  const path = [];\n\n  while (bucket._parent) {\n    path.push(bucket);\n    bucket = bucket._parent;\n  }\n\n  path.push(bucket);\n  return path.reverse();\n};\n\nconst findShardCid = async (node, name, blockstore, context, options) => {\n  if (!context) {\n    const rootBucket = hamtSharding.createHAMT({\n      hashFn\n    });\n    context = {\n      rootBucket,\n      hamtDepth: 1,\n      lastBucket: rootBucket\n    };\n  }\n\n  await addLinksToHamtBucket(node.Links, context.lastBucket, context.rootBucket);\n  const position = await context.rootBucket._findNewBucketAndPos(name);\n  let prefix = toPrefix(position.pos);\n  const bucketPath = toBucketPath(position);\n\n  if (bucketPath.length > context.hamtDepth) {\n    context.lastBucket = bucketPath[context.hamtDepth];\n    prefix = toPrefix(context.lastBucket._posAtParent);\n  }\n\n  const link = node.Links.find(link => {\n    if (link.Name == null) {\n      return false;\n    }\n\n    const entryPrefix = link.Name.substring(0, 2);\n    const entryName = link.Name.substring(2);\n\n    if (entryPrefix !== prefix) {\n      return false;\n    }\n\n    if (entryName && entryName !== name) {\n      return false;\n    }\n\n    return true;\n  });\n\n  if (!link) {\n    return null;\n  }\n\n  if (link.Name != null && link.Name.substring(2) === name) {\n    return link.Hash;\n  }\n\n  context.hamtDepth++;\n  const block = await blockstore.get(link.Hash, options);\n  node = dagPb.decode(block);\n  return findShardCid(node, name, blockstore, context, options);\n};\n\nmodule.exports = findShardCid;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/utils/find-cid-in-shard.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-exporter/cjs/src/utils/validate-offset-and-length.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-exporter/cjs/src/utils/validate-offset-and-length.js ***!
  \***************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nconst validateOffsetAndLength = (size, offset, length) => {\n  if (!offset) {\n    offset = 0;\n  }\n\n  if (offset < 0) {\n    throw errCode__default[\"default\"](new Error('Offset must be greater than or equal to 0'), 'ERR_INVALID_PARAMS');\n  }\n\n  if (offset > size) {\n    throw errCode__default[\"default\"](new Error('Offset must be less than the file size'), 'ERR_INVALID_PARAMS');\n  }\n\n  if (!length && length !== 0) {\n    length = size - offset;\n  }\n\n  if (length < 0) {\n    throw errCode__default[\"default\"](new Error('Length must be greater than or equal to 0'), 'ERR_INVALID_PARAMS');\n  }\n\n  if (offset + length > size) {\n    length = size - offset;\n  }\n\n  return {\n    offset,\n    length\n  };\n};\n\nmodule.exports = validateOffsetAndLength;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-exporter/cjs/src/utils/validate-offset-and-length.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/chunker/fixed-size.js":
/*!*************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/chunker/fixed-size.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar BufferList = __webpack_require__(/*! bl/BufferList.js */ \"./node_modules/ipfs-unixfs-importer/node_modules/bl/BufferList.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar BufferList__default = /*#__PURE__*/_interopDefaultLegacy(BufferList);\n\nasync function* fixedSizeChunker(source, options) {\n  let bl = new BufferList__default[\"default\"]();\n  let currentLength = 0;\n  let emitted = false;\n  const maxChunkSize = options.maxChunkSize;\n\n  for await (const buffer of source) {\n    bl.append(buffer);\n    currentLength += buffer.length;\n\n    while (currentLength >= maxChunkSize) {\n      yield bl.slice(0, maxChunkSize);\n      emitted = true;\n\n      if (maxChunkSize === bl.length) {\n        bl = new BufferList__default[\"default\"]();\n        currentLength = 0;\n      } else {\n        const newBl = new BufferList__default[\"default\"]();\n        newBl.append(bl.shallowSlice(maxChunkSize));\n        bl = newBl;\n        currentLength -= maxChunkSize;\n      }\n    }\n  }\n\n  if (!emitted || currentLength) {\n    yield bl.slice(0, currentLength);\n  }\n}\n\nmodule.exports = fixedSizeChunker;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/chunker/fixed-size.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/chunker/rabin.js":
/*!********************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/chunker/rabin.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar BufferList = __webpack_require__(/*! bl/BufferList.js */ \"./node_modules/ipfs-unixfs-importer/node_modules/bl/BufferList.js\");\n\nvar rabinWasm = __webpack_require__(/*! rabin-wasm */ \"./node_modules/rabin-wasm/src/index.js\");\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar BufferList__default = /*#__PURE__*/_interopDefaultLegacy(BufferList);\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nasync function* rabinChunker(source, options) {\n  let min, max, avg;\n\n  if (options.minChunkSize && options.maxChunkSize && options.avgChunkSize) {\n    avg = options.avgChunkSize;\n    min = options.minChunkSize;\n    max = options.maxChunkSize;\n  } else if (!options.avgChunkSize) {\n    throw errCode__default[\"default\"](new Error('please specify an average chunk size'), 'ERR_INVALID_AVG_CHUNK_SIZE');\n  } else {\n    avg = options.avgChunkSize;\n    min = avg / 3;\n    max = avg + avg / 2;\n  }\n\n  if (min < 16) {\n    throw errCode__default[\"default\"](new Error('rabin min must be greater than 16'), 'ERR_INVALID_MIN_CHUNK_SIZE');\n  }\n\n  if (max < min) {\n    max = min;\n  }\n\n  if (avg < min) {\n    avg = min;\n  }\n\n  const sizepow = Math.floor(Math.log2(avg));\n\n  for await (const chunk of rabin(source, {\n    min: min,\n    max: max,\n    bits: sizepow,\n    window: options.window,\n    polynomial: options.polynomial\n  })) {\n    yield chunk;\n  }\n}\n\nasync function* rabin(source, options) {\n  const r = await rabinWasm.create(options.bits, options.min, options.max, options.window);\n  const buffers = new BufferList__default[\"default\"]();\n\n  for await (const chunk of source) {\n    buffers.append(chunk);\n    const sizes = r.fingerprint(chunk);\n\n    for (let i = 0; i < sizes.length; i++) {\n      const size = sizes[i];\n      const buf = buffers.slice(0, size);\n      buffers.consume(size);\n      yield buf;\n    }\n  }\n\n  if (buffers.length) {\n    yield buffers.slice(0);\n  }\n}\n\nmodule.exports = rabinChunker;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/chunker/rabin.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/dir.js":
/*!**********************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/dir.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nvar persist = __webpack_require__(/*! ../utils/persist.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nconst dirBuilder = async (item, blockstore, options) => {\n  const unixfs = new ipfsUnixfs.UnixFS({\n    type: 'directory',\n    mtime: item.mtime,\n    mode: item.mode\n  });\n  const buffer = dagPb.encode(dagPb.prepare({\n    Data: unixfs.marshal()\n  }));\n  const cid = await persist(buffer, blockstore, options);\n  const path = item.path;\n  return {\n    cid,\n    path,\n    unixfs,\n    size: buffer.length\n  };\n};\n\nmodule.exports = dirBuilder;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/dir.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/balanced.js":
/*!********************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/balanced.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar batch = __webpack_require__(/*! it-batch */ \"./node_modules/it-batch/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar batch__default = /*#__PURE__*/_interopDefaultLegacy(batch);\n\nfunction balanced(source, reduce, options) {\n  return reduceToParents(source, reduce, options);\n}\n\nasync function reduceToParents(source, reduce, options) {\n  const roots = [];\n\n  for await (const chunked of batch__default[\"default\"](source, options.maxChildrenPerNode)) {\n    roots.push(await reduce(chunked));\n  }\n\n  if (roots.length > 1) {\n    return reduceToParents(roots, reduce, options);\n  }\n\n  return roots[0];\n}\n\nmodule.exports = balanced;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/balanced.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/buffer-importer.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/buffer-importer.js ***!
  \***************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nvar persist = __webpack_require__(/*! ../../utils/persist.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar rawCodec = __webpack_require__(/*! multiformats/codecs/raw */ \"./node_modules/multiformats/cjs/src/codecs/raw.js\");\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar dagPb__namespace = /*#__PURE__*/_interopNamespace(dagPb);\n\nvar rawCodec__namespace = /*#__PURE__*/_interopNamespace(rawCodec);\n\nasync function* bufferImporter(file, block, options) {\n  for await (let buffer of file.content) {\n    yield async () => {\n      options.progress(buffer.length, file.path);\n      let unixfs;\n      const opts = {\n        codec: dagPb__namespace,\n        cidVersion: options.cidVersion,\n        hasher: options.hasher,\n        onlyHash: options.onlyHash\n      };\n\n      if (options.rawLeaves) {\n        opts.codec = rawCodec__namespace;\n        opts.cidVersion = 1;\n      } else {\n        unixfs = new ipfsUnixfs.UnixFS({\n          type: options.leafType,\n          data: buffer\n        });\n        buffer = dagPb__namespace.encode({\n          Data: unixfs.marshal(),\n          Links: []\n        });\n      }\n\n      return {\n        cid: await persist(buffer, block, opts),\n        unixfs,\n        size: buffer.length\n      };\n    };\n  }\n}\n\nmodule.exports = bufferImporter;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/buffer-importer.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/flat.js":
/*!****************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/flat.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar all = __webpack_require__(/*! it-all */ \"./node_modules/it-all/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar all__default = /*#__PURE__*/_interopDefaultLegacy(all);\n\nasync function flat(source, reduce) {\n  return reduce(await all__default[\"default\"](source));\n}\n\nmodule.exports = flat;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/flat.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/index.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/index.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nvar persist = __webpack_require__(/*! ../../utils/persist.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar parallelBatch = __webpack_require__(/*! it-parallel-batch */ \"./node_modules/it-parallel-batch/index.js\");\n\nvar rawCodec = __webpack_require__(/*! multiformats/codecs/raw */ \"./node_modules/multiformats/cjs/src/codecs/raw.js\");\n\nvar flat = __webpack_require__(/*! ./flat.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/flat.js\");\n\nvar balanced = __webpack_require__(/*! ./balanced.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/balanced.js\");\n\nvar trickle = __webpack_require__(/*! ./trickle.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/trickle.js\");\n\nvar bufferImporter = __webpack_require__(/*! ./buffer-importer.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/buffer-importer.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nvar dagPb__namespace = /*#__PURE__*/_interopNamespace(dagPb);\n\nvar parallelBatch__default = /*#__PURE__*/_interopDefaultLegacy(parallelBatch);\n\nvar rawCodec__namespace = /*#__PURE__*/_interopNamespace(rawCodec);\n\nconst dagBuilders = {\n  flat: flat,\n  balanced: balanced,\n  trickle: trickle\n};\n\nasync function* buildFileBatch(file, blockstore, options) {\n  let count = -1;\n  let previous;\n  let bufferImporter$1;\n\n  if (typeof options.bufferImporter === 'function') {\n    bufferImporter$1 = options.bufferImporter;\n  } else {\n    bufferImporter$1 = bufferImporter;\n  }\n\n  for await (const entry of parallelBatch__default[\"default\"](bufferImporter$1(file, blockstore, options), options.blockWriteConcurrency)) {\n    count++;\n\n    if (count === 0) {\n      previous = entry;\n      continue;\n    } else if (count === 1 && previous) {\n      yield previous;\n      previous = null;\n    }\n\n    yield entry;\n  }\n\n  if (previous) {\n    previous.single = true;\n    yield previous;\n  }\n}\n\nconst reduce = (file, blockstore, options) => {\n  async function reducer(leaves) {\n    if (leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf) {\n      const leaf = leaves[0];\n\n      if (file.mtime !== undefined || file.mode !== undefined) {\n        let buffer = await blockstore.get(leaf.cid);\n        leaf.unixfs = new ipfsUnixfs.UnixFS({\n          type: 'file',\n          mtime: file.mtime,\n          mode: file.mode,\n          data: buffer\n        });\n        buffer = dagPb.encode(dagPb.prepare({\n          Data: leaf.unixfs.marshal()\n        }));\n        leaf.cid = await persist(buffer, blockstore, { ...options,\n          codec: dagPb__namespace,\n          hasher: options.hasher,\n          cidVersion: options.cidVersion\n        });\n        leaf.size = buffer.length;\n      }\n\n      return {\n        cid: leaf.cid,\n        path: file.path,\n        unixfs: leaf.unixfs,\n        size: leaf.size\n      };\n    }\n\n    const f = new ipfsUnixfs.UnixFS({\n      type: 'file',\n      mtime: file.mtime,\n      mode: file.mode\n    });\n    const links = leaves.filter(leaf => {\n      if (leaf.cid.code === rawCodec__namespace.code && leaf.size) {\n        return true;\n      }\n\n      if (leaf.unixfs && !leaf.unixfs.data && leaf.unixfs.fileSize()) {\n        return true;\n      }\n\n      return Boolean(leaf.unixfs && leaf.unixfs.data && leaf.unixfs.data.length);\n    }).map(leaf => {\n      if (leaf.cid.code === rawCodec__namespace.code) {\n        f.addBlockSize(leaf.size);\n        return {\n          Name: '',\n          Tsize: leaf.size,\n          Hash: leaf.cid\n        };\n      }\n\n      if (!leaf.unixfs || !leaf.unixfs.data) {\n        f.addBlockSize(leaf.unixfs && leaf.unixfs.fileSize() || 0);\n      } else {\n        f.addBlockSize(leaf.unixfs.data.length);\n      }\n\n      return {\n        Name: '',\n        Tsize: leaf.size,\n        Hash: leaf.cid\n      };\n    });\n    const node = {\n      Data: f.marshal(),\n      Links: links\n    };\n    const buffer = dagPb.encode(dagPb.prepare(node));\n    const cid = await persist(buffer, blockstore, options);\n    return {\n      cid,\n      path: file.path,\n      unixfs: f,\n      size: buffer.length + node.Links.reduce((acc, curr) => acc + curr.Tsize, 0)\n    };\n  }\n\n  return reducer;\n};\n\nfunction fileBuilder(file, block, options) {\n  const dagBuilder = dagBuilders[options.strategy];\n\n  if (!dagBuilder) {\n    throw errCode__default[\"default\"](new Error(`Unknown importer build strategy name: ${options.strategy}`), 'ERR_BAD_STRATEGY');\n  }\n\n  return dagBuilder(buildFileBatch(file, block, options), reduce(file, block, options), options);\n}\n\nmodule.exports = fileBuilder;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/trickle.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/trickle.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar batch = __webpack_require__(/*! it-batch */ \"./node_modules/it-batch/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar batch__default = /*#__PURE__*/_interopDefaultLegacy(batch);\n\nasync function trickleStream(source, reduce, options) {\n  const root = new Root(options.layerRepeat);\n  let iteration = 0;\n  let maxDepth = 1;\n  let subTree = root;\n\n  for await (const layer of batch__default[\"default\"](source, options.maxChildrenPerNode)) {\n    if (subTree.isFull()) {\n      if (subTree !== root) {\n        root.addChild(await subTree.reduce(reduce));\n      }\n\n      if (iteration && iteration % options.layerRepeat === 0) {\n        maxDepth++;\n      }\n\n      subTree = new SubTree(maxDepth, options.layerRepeat, iteration);\n      iteration++;\n    }\n\n    subTree.append(layer);\n  }\n\n  if (subTree && subTree !== root) {\n    root.addChild(await subTree.reduce(reduce));\n  }\n\n  return root.reduce(reduce);\n}\n\nclass SubTree {\n  constructor(maxDepth, layerRepeat, iteration = 0) {\n    this.maxDepth = maxDepth;\n    this.layerRepeat = layerRepeat;\n    this.currentDepth = 1;\n    this.iteration = iteration;\n    this.root = this.node = this.parent = {\n      children: [],\n      depth: this.currentDepth,\n      maxDepth,\n      maxChildren: (this.maxDepth - this.currentDepth) * this.layerRepeat\n    };\n  }\n\n  isFull() {\n    if (!this.root.data) {\n      return false;\n    }\n\n    if (this.currentDepth < this.maxDepth && this.node.maxChildren) {\n      this._addNextNodeToParent(this.node);\n\n      return false;\n    }\n\n    const distantRelative = this._findParent(this.node, this.currentDepth);\n\n    if (distantRelative) {\n      this._addNextNodeToParent(distantRelative);\n\n      return false;\n    }\n\n    return true;\n  }\n\n  _addNextNodeToParent(parent) {\n    this.parent = parent;\n    const nextNode = {\n      children: [],\n      depth: parent.depth + 1,\n      parent,\n      maxDepth: this.maxDepth,\n      maxChildren: Math.floor(parent.children.length / this.layerRepeat) * this.layerRepeat\n    };\n    parent.children.push(nextNode);\n    this.currentDepth = nextNode.depth;\n    this.node = nextNode;\n  }\n\n  append(layer) {\n    this.node.data = layer;\n  }\n\n  reduce(reduce) {\n    return this._reduce(this.root, reduce);\n  }\n\n  async _reduce(node, reduce) {\n    let children = [];\n\n    if (node.children.length) {\n      children = await Promise.all(node.children.filter(child => child.data).map(child => this._reduce(child, reduce)));\n    }\n\n    return reduce((node.data || []).concat(children));\n  }\n\n  _findParent(node, depth) {\n    const parent = node.parent;\n\n    if (!parent || parent.depth === 0) {\n      return;\n    }\n\n    if (parent.children.length === parent.maxChildren || !parent.maxChildren) {\n      return this._findParent(parent, depth);\n    }\n\n    return parent;\n  }\n\n}\n\nclass Root extends SubTree {\n  constructor(layerRepeat) {\n    super(0, layerRepeat);\n    this.root.depth = 0;\n    this.currentDepth = 1;\n  }\n\n  addChild(child) {\n    this.root.children.push(child);\n  }\n\n  reduce(reduce) {\n    return reduce((this.root.data || []).concat(this.root.children));\n  }\n\n}\n\nmodule.exports = trickleStream;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/trickle.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/index.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar dir = __webpack_require__(/*! ./dir.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/dir.js\");\n\nvar index = __webpack_require__(/*! ./file/index.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/file/index.js\");\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar rabin = __webpack_require__(/*! ../chunker/rabin.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/chunker/rabin.js\");\n\nvar fixedSize = __webpack_require__(/*! ../chunker/fixed-size.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/chunker/fixed-size.js\");\n\nvar validateChunks = __webpack_require__(/*! ./validate-chunks.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/validate-chunks.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nfunction isIterable(thing) {\n  return Symbol.iterator in thing;\n}\n\nfunction isAsyncIterable(thing) {\n  return Symbol.asyncIterator in thing;\n}\n\nfunction contentAsAsyncIterable(content) {\n  try {\n    if (content instanceof Uint8Array) {\n      return async function* () {\n        yield content;\n      }();\n    } else if (isIterable(content)) {\n      return async function* () {\n        yield* content;\n      }();\n    } else if (isAsyncIterable(content)) {\n      return content;\n    }\n  } catch {\n    throw errCode__default[\"default\"](new Error('Content was invalid'), 'ERR_INVALID_CONTENT');\n  }\n\n  throw errCode__default[\"default\"](new Error('Content was invalid'), 'ERR_INVALID_CONTENT');\n}\n\nasync function* dagBuilder(source, blockstore, options) {\n  for await (const entry of source) {\n    if (entry.path) {\n      if (entry.path.substring(0, 2) === './') {\n        options.wrapWithDirectory = true;\n      }\n\n      entry.path = entry.path.split('/').filter(path => path && path !== '.').join('/');\n    }\n\n    if (entry.content) {\n      let chunker;\n\n      if (typeof options.chunker === 'function') {\n        chunker = options.chunker;\n      } else if (options.chunker === 'rabin') {\n        chunker = rabin;\n      } else {\n        chunker = fixedSize;\n      }\n\n      let chunkValidator;\n\n      if (typeof options.chunkValidator === 'function') {\n        chunkValidator = options.chunkValidator;\n      } else {\n        chunkValidator = validateChunks;\n      }\n\n      const file = {\n        path: entry.path,\n        mtime: entry.mtime,\n        mode: entry.mode,\n        content: chunker(chunkValidator(contentAsAsyncIterable(entry.content), options), options)\n      };\n      yield () => index(file, blockstore, options);\n    } else if (entry.path) {\n      const dir$1 = {\n        path: entry.path,\n        mtime: entry.mtime,\n        mode: entry.mode\n      };\n      yield () => dir(dir$1, blockstore, options);\n    } else {\n      throw new Error('Import candidate must have content or path or both');\n    }\n  }\n}\n\nmodule.exports = dagBuilder;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/validate-chunks.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/validate-chunks.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar errCode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar fromString = __webpack_require__(/*! uint8arrays/from-string */ \"./node_modules/uint8arrays/cjs/src/from-string.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nasync function* validateChunks(source) {\n  for await (const content of source) {\n    if (content.length === undefined) {\n      throw errCode__default[\"default\"](new Error('Content was invalid'), 'ERR_INVALID_CONTENT');\n    }\n\n    if (typeof content === 'string' || content instanceof String) {\n      yield fromString.fromString(content.toString());\n    } else if (Array.isArray(content)) {\n      yield Uint8Array.from(content);\n    } else if (content instanceof Uint8Array) {\n      yield content;\n    } else {\n      throw errCode__default[\"default\"](new Error('Content was invalid'), 'ERR_INVALID_CONTENT');\n    }\n  }\n}\n\nmodule.exports = validateChunks;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/validate-chunks.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dir-flat.js":
/*!***************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dir-flat.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nvar dir = __webpack_require__(/*! ./dir.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dir.js\");\n\nvar persist = __webpack_require__(/*! ./utils/persist.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js\");\n\nclass DirFlat extends dir {\n  constructor(props, options) {\n    super(props, options);\n    this._children = {};\n  }\n\n  async put(name, value) {\n    this.cid = undefined;\n    this.size = undefined;\n    this._children[name] = value;\n  }\n\n  get(name) {\n    return Promise.resolve(this._children[name]);\n  }\n\n  childCount() {\n    return Object.keys(this._children).length;\n  }\n\n  directChildrenCount() {\n    return this.childCount();\n  }\n\n  onlyChild() {\n    return this._children[Object.keys(this._children)[0]];\n  }\n\n  async *eachChildSeries() {\n    const keys = Object.keys(this._children);\n\n    for (let i = 0; i < keys.length; i++) {\n      const key = keys[i];\n      yield {\n        key: key,\n        child: this._children[key]\n      };\n    }\n  }\n\n  async *flush(block) {\n    const children = Object.keys(this._children);\n    const links = [];\n\n    for (let i = 0; i < children.length; i++) {\n      let child = this._children[children[i]];\n\n      if (child instanceof dir) {\n        for await (const entry of child.flush(block)) {\n          child = entry;\n          yield child;\n        }\n      }\n\n      if (child.size != null && child.cid) {\n        links.push({\n          Name: children[i],\n          Tsize: child.size,\n          Hash: child.cid\n        });\n      }\n    }\n\n    const unixfs = new ipfsUnixfs.UnixFS({\n      type: 'directory',\n      mtime: this.mtime,\n      mode: this.mode\n    });\n    const node = {\n      Data: unixfs.marshal(),\n      Links: links\n    };\n    const buffer = dagPb.encode(dagPb.prepare(node));\n    const cid = await persist(buffer, block, this.options);\n    const size = buffer.length + node.Links.reduce((acc, curr) => acc + (curr.Tsize == null ? 0 : curr.Tsize), 0);\n    this.cid = cid;\n    this.size = size;\n    yield {\n      cid,\n      unixfs,\n      path: this.path,\n      size\n    };\n  }\n\n}\n\nmodule.exports = DirFlat;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dir-flat.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dir-sharded.js":
/*!******************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dir-sharded.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar ipfsUnixfs = __webpack_require__(/*! ipfs-unixfs */ \"./node_modules/ipfs-unixfs/cjs/src/index.js\");\n\nvar dir = __webpack_require__(/*! ./dir.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dir.js\");\n\nvar persist = __webpack_require__(/*! ./utils/persist.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js\");\n\nvar hamtSharding = __webpack_require__(/*! hamt-sharding */ \"./node_modules/hamt-sharding/src/index.js\");\n\nclass DirSharded extends dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = hamtSharding.createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  async *eachChildSeries() {\n    for await (const {\n      key,\n      value\n    } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield { ...entry,\n        path: this.path\n      };\n    }\n  }\n\n}\n\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n\n    if (!child) {\n      continue;\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n    if (child instanceof hamtSharding.Bucket) {\n      let shard;\n\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n\n      if (!value.cid) {\n        continue;\n      }\n\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  }\n\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new ipfsUnixfs.UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = dagPb.encode(dagPb.prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}\n\nmodule.exports = DirSharded;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dir-sharded.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/dir.js":
/*!**********************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/dir.js ***!
  \**********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nclass Dir {\n  constructor(props, options) {\n    this.options = options || {};\n    this.root = props.root;\n    this.dir = props.dir;\n    this.path = props.path;\n    this.dirty = props.dirty;\n    this.flat = props.flat;\n    this.parent = props.parent;\n    this.parentKey = props.parentKey;\n    this.unixfs = props.unixfs;\n    this.mode = props.mode;\n    this.mtime = props.mtime;\n    this.cid = undefined;\n    this.size = undefined;\n  }\n\n  async put(name, value) {}\n\n  get(name) {\n    return Promise.resolve(this);\n  }\n\n  async *eachChildSeries() {}\n\n  async *flush(blockstore) {}\n\n}\n\nmodule.exports = Dir;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/dir.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/flat-to-shard.js":
/*!********************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/flat-to-shard.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar dirSharded = __webpack_require__(/*! ./dir-sharded.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dir-sharded.js\");\n\nvar dirFlat = __webpack_require__(/*! ./dir-flat.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dir-flat.js\");\n\nasync function flatToShard(child, dir, threshold, options) {\n  let newDir = dir;\n\n  if (dir instanceof dirFlat && dir.directChildrenCount() >= threshold) {\n    newDir = await convertToShard(dir, options);\n  }\n\n  const parent = newDir.parent;\n\n  if (parent) {\n    if (newDir !== dir) {\n      if (child) {\n        child.parent = newDir;\n      }\n\n      if (!newDir.parentKey) {\n        throw new Error('No parent key found');\n      }\n\n      await parent.put(newDir.parentKey, newDir);\n    }\n\n    return flatToShard(newDir, parent, threshold, options);\n  }\n\n  return newDir;\n}\n\nasync function convertToShard(oldDir, options) {\n  const newDir = new dirSharded({\n    root: oldDir.root,\n    dir: true,\n    parent: oldDir.parent,\n    parentKey: oldDir.parentKey,\n    path: oldDir.path,\n    dirty: oldDir.dirty,\n    flat: false,\n    mtime: oldDir.mtime,\n    mode: oldDir.mode\n  }, options);\n\n  for await (const {\n    key,\n    child\n  } of oldDir.eachChildSeries()) {\n    await newDir.put(key, child);\n  }\n\n  return newDir;\n}\n\nmodule.exports = flatToShard;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/flat-to-shard.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/index.js":
/*!************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/index.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar parallelBatch = __webpack_require__(/*! it-parallel-batch */ \"./node_modules/it-parallel-batch/index.js\");\n\nvar options = __webpack_require__(/*! ./options.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/options.js\");\n\nvar index = __webpack_require__(/*! ./dag-builder/index.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dag-builder/index.js\");\n\nvar treeBuilder = __webpack_require__(/*! ./tree-builder.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/tree-builder.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar parallelBatch__default = /*#__PURE__*/_interopDefaultLegacy(parallelBatch);\n\nasync function* importer(source, blockstore, options$1 = {}) {\n  const opts = options(options$1);\n  let dagBuilder;\n\n  if (typeof options$1.dagBuilder === 'function') {\n    dagBuilder = options$1.dagBuilder;\n  } else {\n    dagBuilder = index;\n  }\n\n  let treeBuilder$1;\n\n  if (typeof options$1.treeBuilder === 'function') {\n    treeBuilder$1 = options$1.treeBuilder;\n  } else {\n    treeBuilder$1 = treeBuilder;\n  }\n\n  let candidates;\n\n  if (Symbol.asyncIterator in source || Symbol.iterator in source) {\n    candidates = source;\n  } else {\n    candidates = [source];\n  }\n\n  for await (const entry of treeBuilder$1(parallelBatch__default[\"default\"](dagBuilder(candidates, blockstore, opts), opts.fileImportConcurrency), blockstore, opts)) {\n    yield {\n      cid: entry.cid,\n      path: entry.path,\n      unixfs: entry.unixfs,\n      size: entry.size\n    };\n  }\n}\n\nexports.importer = importer;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/options.js":
/*!**************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/options.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar mergeOptions = __webpack_require__(/*! merge-options */ \"./node_modules/merge-options/index.js\");\n\nvar sha2 = __webpack_require__(/*! multiformats/hashes/sha2 */ \"./node_modules/multiformats/cjs/src/hashes/sha2.js\");\n\nvar murmur3 = __webpack_require__(/*! @multiformats/murmur3 */ \"./node_modules/@multiformats/murmur3/cjs/index.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar mergeOptions__default = /*#__PURE__*/_interopDefaultLegacy(mergeOptions);\n\nasync function hamtHashFn(buf) {\n  return (await murmur3.murmur3128.encode(buf)).slice(0, 8).reverse();\n}\n\nconst defaultOptions = {\n  chunker: 'fixed',\n  strategy: 'balanced',\n  rawLeaves: false,\n  onlyHash: false,\n  reduceSingleLeafToSelf: true,\n  hasher: sha2.sha256,\n  leafType: 'file',\n  cidVersion: 0,\n  progress: () => () => {},\n  shardSplitThreshold: 1000,\n  fileImportConcurrency: 50,\n  blockWriteConcurrency: 10,\n  minChunkSize: 262144,\n  maxChunkSize: 262144,\n  avgChunkSize: 262144,\n  window: 16,\n  polynomial: 17437180132763652,\n  maxChildrenPerNode: 174,\n  layerRepeat: 4,\n  wrapWithDirectory: false,\n  recursive: false,\n  hidden: false,\n  timeout: undefined,\n  hamtHashFn,\n  hamtHashCode: 34,\n  hamtBucketBits: 8\n};\n\nvar defaultOptions$1 = (options = {}) => {\n  const defaults = mergeOptions__default[\"default\"].bind({\n    ignoreUndefined: true\n  });\n  return defaults(defaultOptions, options);\n};\n\nmodule.exports = defaultOptions$1;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/options.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/tree-builder.js":
/*!*******************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/tree-builder.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar dirFlat = __webpack_require__(/*! ./dir-flat.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dir-flat.js\");\n\nvar flatToShard = __webpack_require__(/*! ./flat-to-shard.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/flat-to-shard.js\");\n\nvar dir = __webpack_require__(/*! ./dir.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/dir.js\");\n\nvar toPathComponents = __webpack_require__(/*! ./utils/to-path-components.js */ \"./node_modules/ipfs-unixfs-importer/cjs/src/utils/to-path-components.js\");\n\nasync function addToTree(elem, tree, options) {\n  const pathElems = toPathComponents(elem.path || '');\n  const lastIndex = pathElems.length - 1;\n  let parent = tree;\n  let currentPath = '';\n\n  for (let i = 0; i < pathElems.length; i++) {\n    const pathElem = pathElems[i];\n    currentPath += `${currentPath ? '/' : ''}${pathElem}`;\n    const last = i === lastIndex;\n    parent.dirty = true;\n    parent.cid = undefined;\n    parent.size = undefined;\n\n    if (last) {\n      await parent.put(pathElem, elem);\n      tree = await flatToShard(null, parent, options.shardSplitThreshold, options);\n    } else {\n      let dir$1 = await parent.get(pathElem);\n\n      if (!dir$1 || !(dir$1 instanceof dir)) {\n        dir$1 = new dirFlat({\n          root: false,\n          dir: true,\n          parent: parent,\n          parentKey: pathElem,\n          path: currentPath,\n          dirty: true,\n          flat: true,\n          mtime: dir$1 && dir$1.unixfs && dir$1.unixfs.mtime,\n          mode: dir$1 && dir$1.unixfs && dir$1.unixfs.mode\n        }, options);\n      }\n\n      await parent.put(pathElem, dir$1);\n      parent = dir$1;\n    }\n  }\n\n  return tree;\n}\n\nasync function* flushAndYield(tree, blockstore) {\n  if (!(tree instanceof dir)) {\n    if (tree && tree.unixfs && tree.unixfs.isDirectory()) {\n      yield tree;\n    }\n\n    return;\n  }\n\n  yield* tree.flush(blockstore);\n}\n\nasync function* treeBuilder(source, block, options) {\n  let tree = new dirFlat({\n    root: true,\n    dir: true,\n    path: '',\n    dirty: true,\n    flat: true\n  }, options);\n\n  for await (const entry of source) {\n    if (!entry) {\n      continue;\n    }\n\n    tree = await addToTree(entry, tree, options);\n\n    if (!entry.unixfs || !entry.unixfs.isDirectory()) {\n      yield entry;\n    }\n  }\n\n  if (options.wrapWithDirectory) {\n    yield* flushAndYield(tree, block);\n  } else {\n    for await (const unwrapped of tree.eachChildSeries()) {\n      if (!unwrapped) {\n        continue;\n      }\n\n      yield* flushAndYield(unwrapped.child, block);\n    }\n  }\n}\n\nmodule.exports = treeBuilder;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/tree-builder.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js":
/*!********************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar cid = __webpack_require__(/*! multiformats/cid */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar dagPb = __webpack_require__(/*! @ipld/dag-pb */ \"./node_modules/@ipld/dag-pb/cjs/src/index.js\");\n\nvar sha2 = __webpack_require__(/*! multiformats/hashes/sha2 */ \"./node_modules/multiformats/cjs/src/hashes/sha2.js\");\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n\n  n[\"default\"] = e;\n  return Object.freeze(n);\n}\n\nvar dagPb__namespace = /*#__PURE__*/_interopNamespace(dagPb);\n\nconst persist = async (buffer, blockstore, options) => {\n  if (!options.codec) {\n    options.codec = dagPb__namespace;\n  }\n\n  if (!options.hasher) {\n    options.hasher = sha2.sha256;\n  }\n\n  if (options.cidVersion === undefined) {\n    options.cidVersion = 1;\n  }\n\n  if (options.codec === dagPb__namespace && options.hasher !== sha2.sha256) {\n    options.cidVersion = 1;\n  }\n\n  const multihash = await options.hasher.digest(buffer);\n  const cid$1 = cid.CID.create(options.cidVersion, options.codec.code, multihash);\n\n  if (!options.onlyHash) {\n    await blockstore.put(cid$1, buffer, {\n      signal: options.signal\n    });\n  }\n\n  return cid$1;\n};\n\nmodule.exports = persist;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/utils/persist.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/cjs/src/utils/to-path-components.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/cjs/src/utils/to-path-components.js ***!
  \*******************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst toPathComponents = (path = '') => {\n  return (path.trim().match(/([^\\\\/]|\\\\\\/)+/g) || []).filter(Boolean);\n};\n\nmodule.exports = toPathComponents;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/cjs/src/utils/to-path-components.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs-importer/node_modules/bl/BufferList.js":
/*!*************************************************************************!*\
  !*** ./node_modules/ipfs-unixfs-importer/node_modules/bl/BufferList.js ***!
  \*************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst {\n  Buffer\n} = __webpack_require__(/*! buffer */ \"buffer\");\n\nconst symbol = Symbol.for('BufferList');\n\nfunction BufferList(buf) {\n  if (!(this instanceof BufferList)) {\n    return new BufferList(buf);\n  }\n\n  BufferList._init.call(this, buf);\n}\n\nBufferList._init = function _init(buf) {\n  Object.defineProperty(this, symbol, {\n    value: true\n  });\n  this._bufs = [];\n  this.length = 0;\n\n  if (buf) {\n    this.append(buf);\n  }\n};\n\nBufferList.prototype._new = function _new(buf) {\n  return new BufferList(buf);\n};\n\nBufferList.prototype._offset = function _offset(offset) {\n  if (offset === 0) {\n    return [0, 0];\n  }\n\n  let tot = 0;\n\n  for (let i = 0; i < this._bufs.length; i++) {\n    const _t = tot + this._bufs[i].length;\n\n    if (offset < _t || i === this._bufs.length - 1) {\n      return [i, offset - tot];\n    }\n\n    tot = _t;\n  }\n};\n\nBufferList.prototype._reverseOffset = function (blOffset) {\n  const bufferId = blOffset[0];\n  let offset = blOffset[1];\n\n  for (let i = 0; i < bufferId; i++) {\n    offset += this._bufs[i].length;\n  }\n\n  return offset;\n};\n\nBufferList.prototype.get = function get(index) {\n  if (index > this.length || index < 0) {\n    return undefined;\n  }\n\n  const offset = this._offset(index);\n\n  return this._bufs[offset[0]][offset[1]];\n};\n\nBufferList.prototype.slice = function slice(start, end) {\n  if (typeof start === 'number' && start < 0) {\n    start += this.length;\n  }\n\n  if (typeof end === 'number' && end < 0) {\n    end += this.length;\n  }\n\n  return this.copy(null, 0, start, end);\n};\n\nBufferList.prototype.copy = function copy(dst, dstStart, srcStart, srcEnd) {\n  if (typeof srcStart !== 'number' || srcStart < 0) {\n    srcStart = 0;\n  }\n\n  if (typeof srcEnd !== 'number' || srcEnd > this.length) {\n    srcEnd = this.length;\n  }\n\n  if (srcStart >= this.length) {\n    return dst || Buffer.alloc(0);\n  }\n\n  if (srcEnd <= 0) {\n    return dst || Buffer.alloc(0);\n  }\n\n  const copy = !!dst;\n\n  const off = this._offset(srcStart);\n\n  const len = srcEnd - srcStart;\n  let bytes = len;\n  let bufoff = copy && dstStart || 0;\n  let start = off[1]; // copy/slice everything\n\n  if (srcStart === 0 && srcEnd === this.length) {\n    if (!copy) {\n      // slice, but full concat if multiple buffers\n      return this._bufs.length === 1 ? this._bufs[0] : Buffer.concat(this._bufs, this.length);\n    } // copy, need to copy individual buffers\n\n\n    for (let i = 0; i < this._bufs.length; i++) {\n      this._bufs[i].copy(dst, bufoff);\n\n      bufoff += this._bufs[i].length;\n    }\n\n    return dst;\n  } // easy, cheap case where it's a subset of one of the buffers\n\n\n  if (bytes <= this._bufs[off[0]].length - start) {\n    return copy ? this._bufs[off[0]].copy(dst, dstStart, start, start + bytes) : this._bufs[off[0]].slice(start, start + bytes);\n  }\n\n  if (!copy) {\n    // a slice, we need something to copy in to\n    dst = Buffer.allocUnsafe(len);\n  }\n\n  for (let i = off[0]; i < this._bufs.length; i++) {\n    const l = this._bufs[i].length - start;\n\n    if (bytes > l) {\n      this._bufs[i].copy(dst, bufoff, start);\n\n      bufoff += l;\n    } else {\n      this._bufs[i].copy(dst, bufoff, start, start + bytes);\n\n      bufoff += l;\n      break;\n    }\n\n    bytes -= l;\n\n    if (start) {\n      start = 0;\n    }\n  } // safeguard so that we don't return uninitialized memory\n\n\n  if (dst.length > bufoff) return dst.slice(0, bufoff);\n  return dst;\n};\n\nBufferList.prototype.shallowSlice = function shallowSlice(start, end) {\n  start = start || 0;\n  end = typeof end !== 'number' ? this.length : end;\n\n  if (start < 0) {\n    start += this.length;\n  }\n\n  if (end < 0) {\n    end += this.length;\n  }\n\n  if (start === end) {\n    return this._new();\n  }\n\n  const startOffset = this._offset(start);\n\n  const endOffset = this._offset(end);\n\n  const buffers = this._bufs.slice(startOffset[0], endOffset[0] + 1);\n\n  if (endOffset[1] === 0) {\n    buffers.pop();\n  } else {\n    buffers[buffers.length - 1] = buffers[buffers.length - 1].slice(0, endOffset[1]);\n  }\n\n  if (startOffset[1] !== 0) {\n    buffers[0] = buffers[0].slice(startOffset[1]);\n  }\n\n  return this._new(buffers);\n};\n\nBufferList.prototype.toString = function toString(encoding, start, end) {\n  return this.slice(start, end).toString(encoding);\n};\n\nBufferList.prototype.consume = function consume(bytes) {\n  // first, normalize the argument, in accordance with how Buffer does it\n  bytes = Math.trunc(bytes); // do nothing if not a positive number\n\n  if (Number.isNaN(bytes) || bytes <= 0) return this;\n\n  while (this._bufs.length) {\n    if (bytes >= this._bufs[0].length) {\n      bytes -= this._bufs[0].length;\n      this.length -= this._bufs[0].length;\n\n      this._bufs.shift();\n    } else {\n      this._bufs[0] = this._bufs[0].slice(bytes);\n      this.length -= bytes;\n      break;\n    }\n  }\n\n  return this;\n};\n\nBufferList.prototype.duplicate = function duplicate() {\n  const copy = this._new();\n\n  for (let i = 0; i < this._bufs.length; i++) {\n    copy.append(this._bufs[i]);\n  }\n\n  return copy;\n};\n\nBufferList.prototype.append = function append(buf) {\n  if (buf == null) {\n    return this;\n  }\n\n  if (buf.buffer) {\n    // append a view of the underlying ArrayBuffer\n    this._appendBuffer(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength));\n  } else if (Array.isArray(buf)) {\n    for (let i = 0; i < buf.length; i++) {\n      this.append(buf[i]);\n    }\n  } else if (this._isBufferList(buf)) {\n    // unwrap argument into individual BufferLists\n    for (let i = 0; i < buf._bufs.length; i++) {\n      this.append(buf._bufs[i]);\n    }\n  } else {\n    // coerce number arguments to strings, since Buffer(number) does\n    // uninitialized memory allocation\n    if (typeof buf === 'number') {\n      buf = buf.toString();\n    }\n\n    this._appendBuffer(Buffer.from(buf));\n  }\n\n  return this;\n};\n\nBufferList.prototype._appendBuffer = function appendBuffer(buf) {\n  this._bufs.push(buf);\n\n  this.length += buf.length;\n};\n\nBufferList.prototype.indexOf = function (search, offset, encoding) {\n  if (encoding === undefined && typeof offset === 'string') {\n    encoding = offset;\n    offset = undefined;\n  }\n\n  if (typeof search === 'function' || Array.isArray(search)) {\n    throw new TypeError('The \"value\" argument must be one of type string, Buffer, BufferList, or Uint8Array.');\n  } else if (typeof search === 'number') {\n    search = Buffer.from([search]);\n  } else if (typeof search === 'string') {\n    search = Buffer.from(search, encoding);\n  } else if (this._isBufferList(search)) {\n    search = search.slice();\n  } else if (Array.isArray(search.buffer)) {\n    search = Buffer.from(search.buffer, search.byteOffset, search.byteLength);\n  } else if (!Buffer.isBuffer(search)) {\n    search = Buffer.from(search);\n  }\n\n  offset = Number(offset || 0);\n\n  if (isNaN(offset)) {\n    offset = 0;\n  }\n\n  if (offset < 0) {\n    offset = this.length + offset;\n  }\n\n  if (offset < 0) {\n    offset = 0;\n  }\n\n  if (search.length === 0) {\n    return offset > this.length ? this.length : offset;\n  }\n\n  const blOffset = this._offset(offset);\n\n  let blIndex = blOffset[0]; // index of which internal buffer we're working on\n\n  let buffOffset = blOffset[1]; // offset of the internal buffer we're working on\n  // scan over each buffer\n\n  for (; blIndex < this._bufs.length; blIndex++) {\n    const buff = this._bufs[blIndex];\n\n    while (buffOffset < buff.length) {\n      const availableWindow = buff.length - buffOffset;\n\n      if (availableWindow >= search.length) {\n        const nativeSearchResult = buff.indexOf(search, buffOffset);\n\n        if (nativeSearchResult !== -1) {\n          return this._reverseOffset([blIndex, nativeSearchResult]);\n        }\n\n        buffOffset = buff.length - search.length + 1; // end of native search window\n      } else {\n        const revOffset = this._reverseOffset([blIndex, buffOffset]);\n\n        if (this._match(revOffset, search)) {\n          return revOffset;\n        }\n\n        buffOffset++;\n      }\n    }\n\n    buffOffset = 0;\n  }\n\n  return -1;\n};\n\nBufferList.prototype._match = function (offset, search) {\n  if (this.length - offset < search.length) {\n    return false;\n  }\n\n  for (let searchOffset = 0; searchOffset < search.length; searchOffset++) {\n    if (this.get(offset + searchOffset) !== search[searchOffset]) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\n(function () {\n  const methods = {\n    readDoubleBE: 8,\n    readDoubleLE: 8,\n    readFloatBE: 4,\n    readFloatLE: 4,\n    readInt32BE: 4,\n    readInt32LE: 4,\n    readUInt32BE: 4,\n    readUInt32LE: 4,\n    readInt16BE: 2,\n    readInt16LE: 2,\n    readUInt16BE: 2,\n    readUInt16LE: 2,\n    readInt8: 1,\n    readUInt8: 1,\n    readIntBE: null,\n    readIntLE: null,\n    readUIntBE: null,\n    readUIntLE: null\n  };\n\n  for (const m in methods) {\n    (function (m) {\n      if (methods[m] === null) {\n        BufferList.prototype[m] = function (offset, byteLength) {\n          return this.slice(offset, offset + byteLength)[m](0, byteLength);\n        };\n      } else {\n        BufferList.prototype[m] = function (offset = 0) {\n          return this.slice(offset, offset + methods[m])[m](0);\n        };\n      }\n    })(m);\n  }\n})(); // Used internally by the class and also as an indicator of this object being\n// a `BufferList`. It's not possible to use `instanceof BufferList` in a browser\n// environment because there could be multiple different copies of the\n// BufferList class and some `BufferList`s might be `BufferList`s.\n\n\nBufferList.prototype._isBufferList = function _isBufferList(b) {\n  return b instanceof BufferList || BufferList.isBufferList(b);\n};\n\nBufferList.isBufferList = function isBufferList(b) {\n  return b != null && b[symbol];\n};\n\nmodule.exports = BufferList;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs-importer/node_modules/bl/BufferList.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs/cjs/src/index.js":
/*!***************************************************!*\
  !*** ./node_modules/ipfs-unixfs/cjs/src/index.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar errcode = __webpack_require__(/*! err-code */ \"./node_modules/err-code/index.js\");\n\nvar unixfs = __webpack_require__(/*! ./unixfs.js */ \"./node_modules/ipfs-unixfs/cjs/src/unixfs.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar errcode__default = /*#__PURE__*/_interopDefaultLegacy(errcode);\n\nconst PBData = unixfs.Data;\nconst types = ['raw', 'directory', 'file', 'metadata', 'symlink', 'hamt-sharded-directory'];\nconst dirTypes = ['directory', 'hamt-sharded-directory'];\nconst DEFAULT_FILE_MODE = parseInt('0644', 8);\nconst DEFAULT_DIRECTORY_MODE = parseInt('0755', 8);\n\nfunction parseMode(mode) {\n  if (mode == null) {\n    return undefined;\n  }\n\n  if (typeof mode === 'number') {\n    return mode & 4095;\n  }\n\n  mode = mode.toString();\n\n  if (mode.substring(0, 1) === '0') {\n    return parseInt(mode, 8) & 4095;\n  }\n\n  return parseInt(mode, 10) & 4095;\n}\n\nfunction parseMtime(input) {\n  if (input == null) {\n    return undefined;\n  }\n\n  let mtime;\n\n  if (input.secs != null) {\n    mtime = {\n      secs: input.secs,\n      nsecs: input.nsecs\n    };\n  }\n\n  if (input.Seconds != null) {\n    mtime = {\n      secs: input.Seconds,\n      nsecs: input.FractionalNanoseconds\n    };\n  }\n\n  if (Array.isArray(input)) {\n    mtime = {\n      secs: input[0],\n      nsecs: input[1]\n    };\n  }\n\n  if (input instanceof Date) {\n    const ms = input.getTime();\n    const secs = Math.floor(ms / 1000);\n    mtime = {\n      secs: secs,\n      nsecs: (ms - secs * 1000) * 1000\n    };\n  }\n\n  if (!Object.prototype.hasOwnProperty.call(mtime, 'secs')) {\n    return undefined;\n  }\n\n  if (mtime != null && mtime.nsecs != null && (mtime.nsecs < 0 || mtime.nsecs > 999999999)) {\n    throw errcode__default[\"default\"](new Error('mtime-nsecs must be within the range [0,999999999]'), 'ERR_INVALID_MTIME_NSECS');\n  }\n\n  return mtime;\n}\n\nclass UnixFS {\n  static unmarshal(marshaled) {\n    const message = PBData.decode(marshaled);\n    const decoded = PBData.toObject(message, {\n      defaults: false,\n      arrays: true,\n      longs: Number,\n      objects: false\n    });\n    const data = new UnixFS({\n      type: types[decoded.Type],\n      data: decoded.Data,\n      blockSizes: decoded.blocksizes,\n      mode: decoded.mode,\n      mtime: decoded.mtime ? {\n        secs: decoded.mtime.Seconds,\n        nsecs: decoded.mtime.FractionalNanoseconds\n      } : undefined\n    });\n    data._originalMode = decoded.mode || 0;\n    return data;\n  }\n\n  constructor(options = {\n    type: 'file'\n  }) {\n    const {\n      type,\n      data,\n      blockSizes,\n      hashType,\n      fanout,\n      mtime,\n      mode\n    } = options;\n\n    if (type && !types.includes(type)) {\n      throw errcode__default[\"default\"](new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE');\n    }\n\n    this.type = type || 'file';\n    this.data = data;\n    this.hashType = hashType;\n    this.fanout = fanout;\n    this.blockSizes = blockSizes || [];\n    this._originalMode = 0;\n    this.mode = parseMode(mode);\n\n    if (mtime) {\n      this.mtime = parseMtime(mtime);\n\n      if (this.mtime && !this.mtime.nsecs) {\n        this.mtime.nsecs = 0;\n      }\n    }\n  }\n\n  set mode(mode) {\n    this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE;\n    const parsedMode = parseMode(mode);\n\n    if (parsedMode !== undefined) {\n      this._mode = parsedMode;\n    }\n  }\n\n  get mode() {\n    return this._mode;\n  }\n\n  isDirectory() {\n    return Boolean(this.type && dirTypes.includes(this.type));\n  }\n\n  addBlockSize(size) {\n    this.blockSizes.push(size);\n  }\n\n  removeBlockSize(index) {\n    this.blockSizes.splice(index, 1);\n  }\n\n  fileSize() {\n    if (this.isDirectory()) {\n      return 0;\n    }\n\n    let sum = 0;\n    this.blockSizes.forEach(size => {\n      sum += size;\n    });\n\n    if (this.data) {\n      sum += this.data.length;\n    }\n\n    return sum;\n  }\n\n  marshal() {\n    let type;\n\n    switch (this.type) {\n      case 'raw':\n        type = PBData.DataType.Raw;\n        break;\n\n      case 'directory':\n        type = PBData.DataType.Directory;\n        break;\n\n      case 'file':\n        type = PBData.DataType.File;\n        break;\n\n      case 'metadata':\n        type = PBData.DataType.Metadata;\n        break;\n\n      case 'symlink':\n        type = PBData.DataType.Symlink;\n        break;\n\n      case 'hamt-sharded-directory':\n        type = PBData.DataType.HAMTShard;\n        break;\n\n      default:\n        throw errcode__default[\"default\"](new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE');\n    }\n\n    let data = this.data;\n\n    if (!this.data || !this.data.length) {\n      data = undefined;\n    }\n\n    let mode;\n\n    if (this.mode != null) {\n      mode = this._originalMode & 4294963200 | (parseMode(this.mode) || 0);\n\n      if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {\n        mode = undefined;\n      }\n\n      if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {\n        mode = undefined;\n      }\n    }\n\n    let mtime;\n\n    if (this.mtime != null) {\n      const parsed = parseMtime(this.mtime);\n\n      if (parsed) {\n        mtime = {\n          Seconds: parsed.secs,\n          FractionalNanoseconds: parsed.nsecs\n        };\n\n        if (mtime.FractionalNanoseconds === 0) {\n          delete mtime.FractionalNanoseconds;\n        }\n      }\n    }\n\n    const pbData = {\n      Type: type,\n      Data: data,\n      filesize: this.isDirectory() ? undefined : this.fileSize(),\n      blocksizes: this.blockSizes,\n      hashType: this.hashType,\n      fanout: this.fanout,\n      mode,\n      mtime\n    };\n    return PBData.encode(pbData).finish();\n  }\n\n}\n\nexports.UnixFS = UnixFS;\nexports.parseMode = parseMode;\nexports.parseMtime = parseMtime;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/ipfs-unixfs/cjs/src/unixfs.js":
/*!****************************************************!*\
  !*** ./node_modules/ipfs-unixfs/cjs/src/unixfs.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar $protobuf = __webpack_require__(/*! protobufjs/minimal.js */ \"./node_modules/protobufjs/minimal.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar $protobuf__default = /*#__PURE__*/_interopDefaultLegacy($protobuf);\n\nconst $Reader = $protobuf__default[\"default\"].Reader,\n      $Writer = $protobuf__default[\"default\"].Writer,\n      $util = $protobuf__default[\"default\"].util;\nconst $root = $protobuf__default[\"default\"].roots['ipfs-unixfs'] || ($protobuf__default[\"default\"].roots['ipfs-unixfs'] = {});\n\nconst Data = $root.Data = (() => {\n  function Data(p) {\n    this.blocksizes = [];\n    if (p) for (var ks = Object.keys(p), i = 0; i < ks.length; ++i) if (p[ks[i]] != null) this[ks[i]] = p[ks[i]];\n  }\n\n  Data.prototype.Type = 0;\n  Data.prototype.Data = $util.newBuffer([]);\n  Data.prototype.filesize = $util.Long ? $util.Long.fromBits(0, 0, true) : 0;\n  Data.prototype.blocksizes = $util.emptyArray;\n  Data.prototype.hashType = $util.Long ? $util.Long.fromBits(0, 0, true) : 0;\n  Data.prototype.fanout = $util.Long ? $util.Long.fromBits(0, 0, true) : 0;\n  Data.prototype.mode = 0;\n  Data.prototype.mtime = null;\n\n  Data.encode = function encode(m, w) {\n    if (!w) w = $Writer.create();\n    w.uint32(8).int32(m.Type);\n    if (m.Data != null && Object.hasOwnProperty.call(m, 'Data')) w.uint32(18).bytes(m.Data);\n    if (m.filesize != null && Object.hasOwnProperty.call(m, 'filesize')) w.uint32(24).uint64(m.filesize);\n\n    if (m.blocksizes != null && m.blocksizes.length) {\n      for (var i = 0; i < m.blocksizes.length; ++i) w.uint32(32).uint64(m.blocksizes[i]);\n    }\n\n    if (m.hashType != null && Object.hasOwnProperty.call(m, 'hashType')) w.uint32(40).uint64(m.hashType);\n    if (m.fanout != null && Object.hasOwnProperty.call(m, 'fanout')) w.uint32(48).uint64(m.fanout);\n    if (m.mode != null && Object.hasOwnProperty.call(m, 'mode')) w.uint32(56).uint32(m.mode);\n    if (m.mtime != null && Object.hasOwnProperty.call(m, 'mtime')) $root.UnixTime.encode(m.mtime, w.uint32(66).fork()).ldelim();\n    return w;\n  };\n\n  Data.decode = function decode(r, l) {\n    if (!(r instanceof $Reader)) r = $Reader.create(r);\n    var c = l === undefined ? r.len : r.pos + l,\n        m = new $root.Data();\n\n    while (r.pos < c) {\n      var t = r.uint32();\n\n      switch (t >>> 3) {\n        case 1:\n          m.Type = r.int32();\n          break;\n\n        case 2:\n          m.Data = r.bytes();\n          break;\n\n        case 3:\n          m.filesize = r.uint64();\n          break;\n\n        case 4:\n          if (!(m.blocksizes && m.blocksizes.length)) m.blocksizes = [];\n\n          if ((t & 7) === 2) {\n            var c2 = r.uint32() + r.pos;\n\n            while (r.pos < c2) m.blocksizes.push(r.uint64());\n          } else m.blocksizes.push(r.uint64());\n\n          break;\n\n        case 5:\n          m.hashType = r.uint64();\n          break;\n\n        case 6:\n          m.fanout = r.uint64();\n          break;\n\n        case 7:\n          m.mode = r.uint32();\n          break;\n\n        case 8:\n          m.mtime = $root.UnixTime.decode(r, r.uint32());\n          break;\n\n        default:\n          r.skipType(t & 7);\n          break;\n      }\n    }\n\n    if (!m.hasOwnProperty('Type')) throw $util.ProtocolError('missing required \\'Type\\'', {\n      instance: m\n    });\n    return m;\n  };\n\n  Data.fromObject = function fromObject(d) {\n    if (d instanceof $root.Data) return d;\n    var m = new $root.Data();\n\n    switch (d.Type) {\n      case 'Raw':\n      case 0:\n        m.Type = 0;\n        break;\n\n      case 'Directory':\n      case 1:\n        m.Type = 1;\n        break;\n\n      case 'File':\n      case 2:\n        m.Type = 2;\n        break;\n\n      case 'Metadata':\n      case 3:\n        m.Type = 3;\n        break;\n\n      case 'Symlink':\n      case 4:\n        m.Type = 4;\n        break;\n\n      case 'HAMTShard':\n      case 5:\n        m.Type = 5;\n        break;\n    }\n\n    if (d.Data != null) {\n      if (typeof d.Data === 'string') $util.base64.decode(d.Data, m.Data = $util.newBuffer($util.base64.length(d.Data)), 0);else if (d.Data.length) m.Data = d.Data;\n    }\n\n    if (d.filesize != null) {\n      if ($util.Long) (m.filesize = $util.Long.fromValue(d.filesize)).unsigned = true;else if (typeof d.filesize === 'string') m.filesize = parseInt(d.filesize, 10);else if (typeof d.filesize === 'number') m.filesize = d.filesize;else if (typeof d.filesize === 'object') m.filesize = new $util.LongBits(d.filesize.low >>> 0, d.filesize.high >>> 0).toNumber(true);\n    }\n\n    if (d.blocksizes) {\n      if (!Array.isArray(d.blocksizes)) throw TypeError('.Data.blocksizes: array expected');\n      m.blocksizes = [];\n\n      for (var i = 0; i < d.blocksizes.length; ++i) {\n        if ($util.Long) (m.blocksizes[i] = $util.Long.fromValue(d.blocksizes[i])).unsigned = true;else if (typeof d.blocksizes[i] === 'string') m.blocksizes[i] = parseInt(d.blocksizes[i], 10);else if (typeof d.blocksizes[i] === 'number') m.blocksizes[i] = d.blocksizes[i];else if (typeof d.blocksizes[i] === 'object') m.blocksizes[i] = new $util.LongBits(d.blocksizes[i].low >>> 0, d.blocksizes[i].high >>> 0).toNumber(true);\n      }\n    }\n\n    if (d.hashType != null) {\n      if ($util.Long) (m.hashType = $util.Long.fromValue(d.hashType)).unsigned = true;else if (typeof d.hashType === 'string') m.hashType = parseInt(d.hashType, 10);else if (typeof d.hashType === 'number') m.hashType = d.hashType;else if (typeof d.hashType === 'object') m.hashType = new $util.LongBits(d.hashType.low >>> 0, d.hashType.high >>> 0).toNumber(true);\n    }\n\n    if (d.fanout != null) {\n      if ($util.Long) (m.fanout = $util.Long.fromValue(d.fanout)).unsigned = true;else if (typeof d.fanout === 'string') m.fanout = parseInt(d.fanout, 10);else if (typeof d.fanout === 'number') m.fanout = d.fanout;else if (typeof d.fanout === 'object') m.fanout = new $util.LongBits(d.fanout.low >>> 0, d.fanout.high >>> 0).toNumber(true);\n    }\n\n    if (d.mode != null) {\n      m.mode = d.mode >>> 0;\n    }\n\n    if (d.mtime != null) {\n      if (typeof d.mtime !== 'object') throw TypeError('.Data.mtime: object expected');\n      m.mtime = $root.UnixTime.fromObject(d.mtime);\n    }\n\n    return m;\n  };\n\n  Data.toObject = function toObject(m, o) {\n    if (!o) o = {};\n    var d = {};\n\n    if (o.arrays || o.defaults) {\n      d.blocksizes = [];\n    }\n\n    if (o.defaults) {\n      d.Type = o.enums === String ? 'Raw' : 0;\n      if (o.bytes === String) d.Data = '';else {\n        d.Data = [];\n        if (o.bytes !== Array) d.Data = $util.newBuffer(d.Data);\n      }\n\n      if ($util.Long) {\n        var n = new $util.Long(0, 0, true);\n        d.filesize = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n      } else d.filesize = o.longs === String ? '0' : 0;\n\n      if ($util.Long) {\n        var n = new $util.Long(0, 0, true);\n        d.hashType = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n      } else d.hashType = o.longs === String ? '0' : 0;\n\n      if ($util.Long) {\n        var n = new $util.Long(0, 0, true);\n        d.fanout = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n      } else d.fanout = o.longs === String ? '0' : 0;\n\n      d.mode = 0;\n      d.mtime = null;\n    }\n\n    if (m.Type != null && m.hasOwnProperty('Type')) {\n      d.Type = o.enums === String ? $root.Data.DataType[m.Type] : m.Type;\n    }\n\n    if (m.Data != null && m.hasOwnProperty('Data')) {\n      d.Data = o.bytes === String ? $util.base64.encode(m.Data, 0, m.Data.length) : o.bytes === Array ? Array.prototype.slice.call(m.Data) : m.Data;\n    }\n\n    if (m.filesize != null && m.hasOwnProperty('filesize')) {\n      if (typeof m.filesize === 'number') d.filesize = o.longs === String ? String(m.filesize) : m.filesize;else d.filesize = o.longs === String ? $util.Long.prototype.toString.call(m.filesize) : o.longs === Number ? new $util.LongBits(m.filesize.low >>> 0, m.filesize.high >>> 0).toNumber(true) : m.filesize;\n    }\n\n    if (m.blocksizes && m.blocksizes.length) {\n      d.blocksizes = [];\n\n      for (var j = 0; j < m.blocksizes.length; ++j) {\n        if (typeof m.blocksizes[j] === 'number') d.blocksizes[j] = o.longs === String ? String(m.blocksizes[j]) : m.blocksizes[j];else d.blocksizes[j] = o.longs === String ? $util.Long.prototype.toString.call(m.blocksizes[j]) : o.longs === Number ? new $util.LongBits(m.blocksizes[j].low >>> 0, m.blocksizes[j].high >>> 0).toNumber(true) : m.blocksizes[j];\n      }\n    }\n\n    if (m.hashType != null && m.hasOwnProperty('hashType')) {\n      if (typeof m.hashType === 'number') d.hashType = o.longs === String ? String(m.hashType) : m.hashType;else d.hashType = o.longs === String ? $util.Long.prototype.toString.call(m.hashType) : o.longs === Number ? new $util.LongBits(m.hashType.low >>> 0, m.hashType.high >>> 0).toNumber(true) : m.hashType;\n    }\n\n    if (m.fanout != null && m.hasOwnProperty('fanout')) {\n      if (typeof m.fanout === 'number') d.fanout = o.longs === String ? String(m.fanout) : m.fanout;else d.fanout = o.longs === String ? $util.Long.prototype.toString.call(m.fanout) : o.longs === Number ? new $util.LongBits(m.fanout.low >>> 0, m.fanout.high >>> 0).toNumber(true) : m.fanout;\n    }\n\n    if (m.mode != null && m.hasOwnProperty('mode')) {\n      d.mode = m.mode;\n    }\n\n    if (m.mtime != null && m.hasOwnProperty('mtime')) {\n      d.mtime = $root.UnixTime.toObject(m.mtime, o);\n    }\n\n    return d;\n  };\n\n  Data.prototype.toJSON = function toJSON() {\n    return this.constructor.toObject(this, $protobuf__default[\"default\"].util.toJSONOptions);\n  };\n\n  Data.DataType = function () {\n    const valuesById = {},\n          values = Object.create(valuesById);\n    values[valuesById[0] = 'Raw'] = 0;\n    values[valuesById[1] = 'Directory'] = 1;\n    values[valuesById[2] = 'File'] = 2;\n    values[valuesById[3] = 'Metadata'] = 3;\n    values[valuesById[4] = 'Symlink'] = 4;\n    values[valuesById[5] = 'HAMTShard'] = 5;\n    return values;\n  }();\n\n  return Data;\n})();\n\nconst UnixTime = $root.UnixTime = (() => {\n  function UnixTime(p) {\n    if (p) for (var ks = Object.keys(p), i = 0; i < ks.length; ++i) if (p[ks[i]] != null) this[ks[i]] = p[ks[i]];\n  }\n\n  UnixTime.prototype.Seconds = $util.Long ? $util.Long.fromBits(0, 0, false) : 0;\n  UnixTime.prototype.FractionalNanoseconds = 0;\n\n  UnixTime.encode = function encode(m, w) {\n    if (!w) w = $Writer.create();\n    w.uint32(8).int64(m.Seconds);\n    if (m.FractionalNanoseconds != null && Object.hasOwnProperty.call(m, 'FractionalNanoseconds')) w.uint32(21).fixed32(m.FractionalNanoseconds);\n    return w;\n  };\n\n  UnixTime.decode = function decode(r, l) {\n    if (!(r instanceof $Reader)) r = $Reader.create(r);\n    var c = l === undefined ? r.len : r.pos + l,\n        m = new $root.UnixTime();\n\n    while (r.pos < c) {\n      var t = r.uint32();\n\n      switch (t >>> 3) {\n        case 1:\n          m.Seconds = r.int64();\n          break;\n\n        case 2:\n          m.FractionalNanoseconds = r.fixed32();\n          break;\n\n        default:\n          r.skipType(t & 7);\n          break;\n      }\n    }\n\n    if (!m.hasOwnProperty('Seconds')) throw $util.ProtocolError('missing required \\'Seconds\\'', {\n      instance: m\n    });\n    return m;\n  };\n\n  UnixTime.fromObject = function fromObject(d) {\n    if (d instanceof $root.UnixTime) return d;\n    var m = new $root.UnixTime();\n\n    if (d.Seconds != null) {\n      if ($util.Long) (m.Seconds = $util.Long.fromValue(d.Seconds)).unsigned = false;else if (typeof d.Seconds === 'string') m.Seconds = parseInt(d.Seconds, 10);else if (typeof d.Seconds === 'number') m.Seconds = d.Seconds;else if (typeof d.Seconds === 'object') m.Seconds = new $util.LongBits(d.Seconds.low >>> 0, d.Seconds.high >>> 0).toNumber();\n    }\n\n    if (d.FractionalNanoseconds != null) {\n      m.FractionalNanoseconds = d.FractionalNanoseconds >>> 0;\n    }\n\n    return m;\n  };\n\n  UnixTime.toObject = function toObject(m, o) {\n    if (!o) o = {};\n    var d = {};\n\n    if (o.defaults) {\n      if ($util.Long) {\n        var n = new $util.Long(0, 0, false);\n        d.Seconds = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n      } else d.Seconds = o.longs === String ? '0' : 0;\n\n      d.FractionalNanoseconds = 0;\n    }\n\n    if (m.Seconds != null && m.hasOwnProperty('Seconds')) {\n      if (typeof m.Seconds === 'number') d.Seconds = o.longs === String ? String(m.Seconds) : m.Seconds;else d.Seconds = o.longs === String ? $util.Long.prototype.toString.call(m.Seconds) : o.longs === Number ? new $util.LongBits(m.Seconds.low >>> 0, m.Seconds.high >>> 0).toNumber() : m.Seconds;\n    }\n\n    if (m.FractionalNanoseconds != null && m.hasOwnProperty('FractionalNanoseconds')) {\n      d.FractionalNanoseconds = m.FractionalNanoseconds;\n    }\n\n    return d;\n  };\n\n  UnixTime.prototype.toJSON = function toJSON() {\n    return this.constructor.toObject(this, $protobuf__default[\"default\"].util.toJSONOptions);\n  };\n\n  return UnixTime;\n})();\n\nconst Metadata = $root.Metadata = (() => {\n  function Metadata(p) {\n    if (p) for (var ks = Object.keys(p), i = 0; i < ks.length; ++i) if (p[ks[i]] != null) this[ks[i]] = p[ks[i]];\n  }\n\n  Metadata.prototype.MimeType = '';\n\n  Metadata.encode = function encode(m, w) {\n    if (!w) w = $Writer.create();\n    if (m.MimeType != null && Object.hasOwnProperty.call(m, 'MimeType')) w.uint32(10).string(m.MimeType);\n    return w;\n  };\n\n  Metadata.decode = function decode(r, l) {\n    if (!(r instanceof $Reader)) r = $Reader.create(r);\n    var c = l === undefined ? r.len : r.pos + l,\n        m = new $root.Metadata();\n\n    while (r.pos < c) {\n      var t = r.uint32();\n\n      switch (t >>> 3) {\n        case 1:\n          m.MimeType = r.string();\n          break;\n\n        default:\n          r.skipType(t & 7);\n          break;\n      }\n    }\n\n    return m;\n  };\n\n  Metadata.fromObject = function fromObject(d) {\n    if (d instanceof $root.Metadata) return d;\n    var m = new $root.Metadata();\n\n    if (d.MimeType != null) {\n      m.MimeType = String(d.MimeType);\n    }\n\n    return m;\n  };\n\n  Metadata.toObject = function toObject(m, o) {\n    if (!o) o = {};\n    var d = {};\n\n    if (o.defaults) {\n      d.MimeType = '';\n    }\n\n    if (m.MimeType != null && m.hasOwnProperty('MimeType')) {\n      d.MimeType = m.MimeType;\n    }\n\n    return d;\n  };\n\n  Metadata.prototype.toJSON = function toJSON() {\n    return this.constructor.toObject(this, $protobuf__default[\"default\"].util.toJSONOptions);\n  };\n\n  return Metadata;\n})();\n\nexports.Data = Data;\nexports.Metadata = Metadata;\nexports.UnixTime = UnixTime;\nexports[\"default\"] = $root;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/ipfs-unixfs/cjs/src/unixfs.js?");

/***/ }),

/***/ "./node_modules/is-plain-obj/index.js":
/*!********************************************!*\
  !*** ./node_modules/is-plain-obj/index.js ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = value => {\n  if (Object.prototype.toString.call(value) !== '[object Object]') {\n    return false;\n  }\n\n  const prototype = Object.getPrototypeOf(value);\n  return prototype === null || prototype === Object.prototype;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/is-plain-obj/index.js?");

/***/ }),

/***/ "./node_modules/it-all/index.js":
/*!**************************************!*\
  !*** ./node_modules/it-all/index.js ***!
  \**************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Collects all values from an (async) iterable into an array and returns it.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n */\n\nconst all = async source => {\n  const arr = [];\n\n  for await (const entry of source) {\n    arr.push(entry);\n  }\n\n  return arr;\n};\n\nmodule.exports = all;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-all/index.js?");

/***/ }),

/***/ "./node_modules/it-batch/index.js":
/*!****************************************!*\
  !*** ./node_modules/it-batch/index.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Takes an (async) iterable that emits things and returns an async iterable that\n * emits those things in fixed-sized batches.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @param {number} [size=1]\n * @returns {AsyncIterable<T[]>}\n */\n\nasync function* batch(source, size = 1) {\n  /** @type {T[]} */\n  let things = [];\n\n  if (size < 1) {\n    size = 1;\n  }\n\n  for await (const thing of source) {\n    things.push(thing);\n\n    while (things.length >= size) {\n      yield things.slice(0, size);\n      things = things.slice(size);\n    }\n  }\n\n  while (things.length) {\n    yield things.slice(0, size);\n    things = things.slice(size);\n  }\n}\n\nmodule.exports = batch;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-batch/index.js?");

/***/ }),

/***/ "./node_modules/it-drain/index.js":
/*!****************************************!*\
  !*** ./node_modules/it-drain/index.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Drains an (async) iterable discarding its' content and does not return\n * anything.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @returns {Promise<void>}\n */\n\nconst drain = async source => {\n  for await (const _ of source) {} // eslint-disable-line no-unused-vars,no-empty\n\n};\n\nmodule.exports = drain;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-drain/index.js?");

/***/ }),

/***/ "./node_modules/it-filter/index.js":
/*!*****************************************!*\
  !*** ./node_modules/it-filter/index.js ***!
  \*****************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Filters the passed (async) iterable by using the filter function\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @param {function(T):boolean|Promise<boolean>} fn\n */\n\nconst filter = async function* (source, fn) {\n  for await (const entry of source) {\n    if (await fn(entry)) {\n      yield entry;\n    }\n  }\n};\n\nmodule.exports = filter;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-filter/index.js?");

/***/ }),

/***/ "./node_modules/it-glob/index.js":
/*!***************************************!*\
  !*** ./node_modules/it-glob/index.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = (__webpack_require__(/*! fs */ \"fs\").promises);\n\nconst path = __webpack_require__(/*! path */ \"path\");\n\nconst minimatch = __webpack_require__(/*! minimatch */ \"./node_modules/minimatch/minimatch.js\");\n/**\n * @typedef {string} Glob\n * @typedef {Object} OptionsExt\n * @property {Glob[]} [ignore] - Glob patterns to ignore\n * @property {string} [cwd=process.cwd()]\n * @property {boolean} [absolute=false] - If true produces absolute paths\n * @property {boolean} [nodir] - If true yields file paths and skip directories\n *\n * @typedef {OptionsExt & minimatch.IOptions} Options\n */\n\n/**\n * Async iterable filename pattern matcher\n *\n * @param {string} dir\n * @param {string} pattern\n * @param {Options} [options]\n * @returns {AsyncIterable<string>}\n */\n\n\nasync function* glob(dir, pattern, options = {}) {\n  const absoluteDir = path.resolve(dir);\n  const relativeDir = path.relative(options.cwd || process.cwd(), dir);\n  const stats = await fs.stat(absoluteDir);\n\n  if (stats.isDirectory()) {\n    for await (const entry of _glob(absoluteDir, '', pattern, options)) {\n      yield entry;\n    }\n\n    return;\n  }\n\n  if (minimatch(relativeDir, pattern, options)) {\n    yield options.absolute ? absoluteDir : relativeDir;\n  }\n}\n/**\n * @param {string} base\n * @param {string} dir\n * @param {Glob} pattern\n * @param {Options} options\n * @returns {AsyncIterable<string>}\n */\n\n\nasync function* _glob(base, dir, pattern, options) {\n  for await (const entry of await fs.readdir(path.join(base, dir))) {\n    const relativeEntryPath = path.join(dir, entry);\n    const absoluteEntryPath = path.join(base, dir, entry);\n    const stats = await fs.stat(absoluteEntryPath);\n    let match = minimatch(relativeEntryPath, pattern, options);\n\n    if (options.ignore && match && options.ignore.reduce((acc, curr) => {\n      return acc || minimatch(relativeEntryPath, curr, options);\n    }, false)) {\n      match = false;\n    }\n\n    if (match && !(stats.isDirectory() && options.nodir)) {\n      yield options.absolute ? absoluteEntryPath : relativeEntryPath;\n    }\n\n    if (stats.isDirectory()) {\n      yield* _glob(base, relativeEntryPath, pattern, options);\n    }\n  }\n}\n\nmodule.exports = glob;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-glob/index.js?");

/***/ }),

/***/ "./node_modules/it-last/index.js":
/*!***************************************!*\
  !*** ./node_modules/it-last/index.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Returns the last item of an (async) iterable, unless empty, in which case\n * return `undefined`.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n */\n\nconst last = async source => {\n  let res;\n\n  for await (const entry of source) {\n    res = entry;\n  }\n\n  return res;\n};\n\nmodule.exports = last;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-last/index.js?");

/***/ }),

/***/ "./node_modules/it-map/index.js":
/*!**************************************!*\
  !*** ./node_modules/it-map/index.js ***!
  \**************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Takes an (async) iterable and returns one with each item mapped by the passed\n * function.\n *\n * @template I,O\n * @param {AsyncIterable<I>|Iterable<I>} source\n * @param {function(I):O|Promise<O>} func\n * @returns {AsyncIterable<O>}\n */\n\nconst map = async function* (source, func) {\n  for await (const val of source) {\n    yield func(val);\n  }\n};\n\nmodule.exports = map;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-map/index.js?");

/***/ }),

/***/ "./node_modules/it-parallel-batch/index.js":
/*!*************************************************!*\
  !*** ./node_modules/it-parallel-batch/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst batch = __webpack_require__(/*! it-batch */ \"./node_modules/it-batch/index.js\");\n/**\n * @template T\n * @typedef {{ok:true, value:T}} Success\n */\n\n/**\n * @typedef {{ok:false, err:Error}} Failure\n */\n\n/**\n * Takes an (async) iterator that emits promise-returning functions,\n * invokes them in parallel and emits the results as they become available but\n * in the same order as the input\n *\n * @template T\n * @param {AsyncIterable<() => Promise<T>>} source\n * @param {number} [size=1]\n * @returns {AsyncIterable<T>}\n */\n\n\nasync function* parallelBatch(source, size = 1) {\n  for await (const tasks of batch(source, size)) {\n    /** @type {Promise<Success<T>|Failure>[]} */\n    const things = tasks.map(\n    /**\n     * @param {() => Promise<T>} p\n     */\n    p => {\n      return p().then(value => ({\n        ok: true,\n        value\n      }), err => ({\n        ok: false,\n        err\n      }));\n    });\n\n    for (let i = 0; i < things.length; i++) {\n      const result = await things[i];\n\n      if (result.ok) {\n        yield result.value;\n      } else {\n        throw result.err;\n      }\n    }\n  }\n}\n\nmodule.exports = parallelBatch;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-parallel-batch/index.js?");

/***/ }),

/***/ "./node_modules/it-peekable/index.js":
/*!*******************************************!*\
  !*** ./node_modules/it-peekable/index.js ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * @template T\n * @typedef {Object} Peek\n * @property {() => IteratorResult<T, void>} peek\n */\n\n/**\n * @template T\n * @typedef {Object} AsyncPeek\n * @property {() => Promise<IteratorResult<T, void>>} peek\n */\n\n/**\n * @template T\n * @typedef {Object} Push\n * @property {(value:T) => void} push\n */\n\n/**\n * @template T\n * @typedef {Iterable<T> & Peek<T> & Push<T> & Iterator<T>} Peekable<T>\n */\n\n/**\n * @template T\n * @typedef {AsyncIterable<T> & AsyncPeek<T> & Push<T> & AsyncIterator<T>} AsyncPeekable<T>\n */\n\n/**\n * @template {Iterable<any> | AsyncIterable<any>} I\n * @param {I} iterable\n * @returns {I extends Iterable<infer T>\n *  ? Peekable<T>\n *  : I extends AsyncIterable<infer T>\n *  ? AsyncPeekable<T>\n *  : never\n * }\n */\n\nfunction peekableIterator(iterable) {\n  // @ts-ignore\n  const [iterator, symbol] = iterable[Symbol.asyncIterator] // @ts-ignore\n  ? [iterable[Symbol.asyncIterator](), Symbol.asyncIterator] // @ts-ignore\n  : [iterable[Symbol.iterator](), Symbol.iterator];\n  /** @type {any[]} */\n\n  const queue = []; // @ts-ignore\n\n  return {\n    peek: () => {\n      return iterator.next();\n    },\n    push: value => {\n      queue.push(value);\n    },\n    next: () => {\n      if (queue.length) {\n        return {\n          done: false,\n          value: queue.shift()\n        };\n      }\n\n      return iterator.next();\n    },\n\n    [symbol]() {\n      return this;\n    }\n\n  };\n}\n\nmodule.exports = peekableIterator;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-peekable/index.js?");

/***/ }),

/***/ "./node_modules/it-pipe/index.js":
/*!***************************************!*\
  !*** ./node_modules/it-pipe/index.js ***!
  \***************************************/
/***/ ((module) => {

eval("const rawPipe = (...fns) => {\n  let res;\n\n  while (fns.length) {\n    res = fns.shift()(res);\n  }\n\n  return res;\n};\n\nconst isIterable = obj => obj && (typeof obj[Symbol.asyncIterator] === 'function' || typeof obj[Symbol.iterator] === 'function' || typeof obj.next === 'function' // Probably, right?\n);\n\nconst isDuplex = obj => obj && typeof obj.sink === 'function' && isIterable(obj.source);\n\nconst duplexPipelineFn = duplex => source => {\n  duplex.sink(source); // TODO: error on sink side is unhandled rejection - this is the same as pull streams\n\n  return duplex.source;\n};\n\nconst pipe = (...fns) => {\n  // Duplex at start: wrap in function and return duplex source\n  if (isDuplex(fns[0])) {\n    const duplex = fns[0];\n\n    fns[0] = () => duplex.source; // Iterable at start: wrap in function\n\n  } else if (isIterable(fns[0])) {\n    const source = fns[0];\n\n    fns[0] = () => source;\n  }\n\n  if (fns.length > 1) {\n    // Duplex at end: use duplex sink\n    if (isDuplex(fns[fns.length - 1])) {\n      fns[fns.length - 1] = fns[fns.length - 1].sink;\n    }\n  }\n\n  if (fns.length > 2) {\n    // Duplex in the middle, consume source with duplex sink and return duplex source\n    for (let i = 1; i < fns.length - 1; i++) {\n      if (isDuplex(fns[i])) {\n        fns[i] = duplexPipelineFn(fns[i]);\n      }\n    }\n  }\n\n  return rawPipe(...fns);\n};\n\nmodule.exports = pipe;\nmodule.exports.pipe = pipe;\nmodule.exports.rawPipe = rawPipe;\nmodule.exports.isIterable = isIterable;\nmodule.exports.isDuplex = isDuplex;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-pipe/index.js?");

/***/ }),

/***/ "./node_modules/it-take/index.js":
/*!***************************************!*\
  !*** ./node_modules/it-take/index.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("\n/**\n * Stop iteration after n items have been received.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @param {number} limit\n * @returns {AsyncIterable<T>}\n */\n\nconst take = async function* (source, limit) {\n  let items = 0;\n\n  if (limit < 1) {\n    return;\n  }\n\n  for await (const entry of source) {\n    yield entry;\n    items++;\n\n    if (items === limit) {\n      return;\n    }\n  }\n};\n\nmodule.exports = take;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/it-take/index.js?");

/***/ }),

/***/ "./node_modules/merge-options/index.js":
/*!*********************************************!*\
  !*** ./node_modules/merge-options/index.js ***!
  \*********************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
eval("\n\nconst isOptionObject = __webpack_require__(/*! is-plain-obj */ \"./node_modules/is-plain-obj/index.js\");\n\nconst {\n  hasOwnProperty\n} = Object.prototype;\nconst {\n  propertyIsEnumerable\n} = Object;\n\nconst defineProperty = (object, name, value) => Object.defineProperty(object, name, {\n  value,\n  writable: true,\n  enumerable: true,\n  configurable: true\n});\n\nconst globalThis = this;\nconst defaultMergeOptions = {\n  concatArrays: false,\n  ignoreUndefined: false\n};\n\nconst getEnumerableOwnPropertyKeys = value => {\n  const keys = [];\n\n  for (const key in value) {\n    if (hasOwnProperty.call(value, key)) {\n      keys.push(key);\n    }\n  }\n  /* istanbul ignore else  */\n\n\n  if (Object.getOwnPropertySymbols) {\n    const symbols = Object.getOwnPropertySymbols(value);\n\n    for (const symbol of symbols) {\n      if (propertyIsEnumerable.call(value, symbol)) {\n        keys.push(symbol);\n      }\n    }\n  }\n\n  return keys;\n};\n\nfunction clone(value) {\n  if (Array.isArray(value)) {\n    return cloneArray(value);\n  }\n\n  if (isOptionObject(value)) {\n    return cloneOptionObject(value);\n  }\n\n  return value;\n}\n\nfunction cloneArray(array) {\n  const result = array.slice(0, 0);\n  getEnumerableOwnPropertyKeys(array).forEach(key => {\n    defineProperty(result, key, clone(array[key]));\n  });\n  return result;\n}\n\nfunction cloneOptionObject(object) {\n  const result = Object.getPrototypeOf(object) === null ? Object.create(null) : {};\n  getEnumerableOwnPropertyKeys(object).forEach(key => {\n    defineProperty(result, key, clone(object[key]));\n  });\n  return result;\n}\n/**\n * @param {*} merged already cloned\n * @param {*} source something to merge\n * @param {string[]} keys keys to merge\n * @param {Object} config Config Object\n * @returns {*} cloned Object\n */\n\n\nconst mergeKeys = (merged, source, keys, config) => {\n  keys.forEach(key => {\n    if (typeof source[key] === 'undefined' && config.ignoreUndefined) {\n      return;\n    } // Do not recurse into prototype chain of merged\n\n\n    if (key in merged && merged[key] !== Object.getPrototypeOf(merged)) {\n      defineProperty(merged, key, merge(merged[key], source[key], config));\n    } else {\n      defineProperty(merged, key, clone(source[key]));\n    }\n  });\n  return merged;\n};\n/**\n * @param {*} merged already cloned\n * @param {*} source something to merge\n * @param {Object} config Config Object\n * @returns {*} cloned Object\n *\n * see [Array.prototype.concat ( ...arguments )](http://www.ecma-international.org/ecma-262/6.0/#sec-array.prototype.concat)\n */\n\n\nconst concatArrays = (merged, source, config) => {\n  let result = merged.slice(0, 0);\n  let resultIndex = 0;\n  [merged, source].forEach(array => {\n    const indices = []; // `result.concat(array)` with cloning\n\n    for (let k = 0; k < array.length; k++) {\n      if (!hasOwnProperty.call(array, k)) {\n        continue;\n      }\n\n      indices.push(String(k));\n\n      if (array === merged) {\n        // Already cloned\n        defineProperty(result, resultIndex++, array[k]);\n      } else {\n        defineProperty(result, resultIndex++, clone(array[k]));\n      }\n    } // Merge non-index keys\n\n\n    result = mergeKeys(result, array, getEnumerableOwnPropertyKeys(array).filter(key => !indices.includes(key)), config);\n  });\n  return result;\n};\n/**\n * @param {*} merged already cloned\n * @param {*} source something to merge\n * @param {Object} config Config Object\n * @returns {*} cloned Object\n */\n\n\nfunction merge(merged, source, config) {\n  if (config.concatArrays && Array.isArray(merged) && Array.isArray(source)) {\n    return concatArrays(merged, source, config);\n  }\n\n  if (!isOptionObject(source) || !isOptionObject(merged)) {\n    return clone(source);\n  }\n\n  return mergeKeys(merged, source, getEnumerableOwnPropertyKeys(source), config);\n}\n\nmodule.exports = function (...options) {\n  const config = merge(clone(defaultMergeOptions), this !== globalThis && this || {}, defaultMergeOptions);\n  let merged = {\n    _: {}\n  };\n\n  for (const option of options) {\n    if (option === undefined) {\n      continue;\n    }\n\n    if (!isOptionObject(option)) {\n      throw new TypeError('`' + option + '` is not an Option Object');\n    }\n\n    merged = merge(merged, {\n      _: option\n    }, config);\n  }\n\n  return merged._;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/merge-options/index.js?");

/***/ }),

/***/ "./node_modules/minimatch/minimatch.js":
/*!*********************************************!*\
  !*** ./node_modules/minimatch/minimatch.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = minimatch;\nminimatch.Minimatch = Minimatch;\n\nvar path = function () {\n  try {\n    return __webpack_require__(/*! path */ \"path\");\n  } catch (e) {}\n}() || {\n  sep: '/'\n};\n\nminimatch.sep = path.sep;\nvar GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {};\n\nvar expand = __webpack_require__(/*! brace-expansion */ \"./node_modules/brace-expansion/index.js\");\n\nvar plTypes = {\n  '!': {\n    open: '(?:(?!(?:',\n    close: '))[^/]*?)'\n  },\n  '?': {\n    open: '(?:',\n    close: ')?'\n  },\n  '+': {\n    open: '(?:',\n    close: ')+'\n  },\n  '*': {\n    open: '(?:',\n    close: ')*'\n  },\n  '@': {\n    open: '(?:',\n    close: ')'\n  }\n}; // any single thing other than /\n// don't need to escape / when using new RegExp()\n\nvar qmark = '[^/]'; // * => any number of characters\n\nvar star = qmark + '*?'; // ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\n\nvar twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'; // not a ^ or / followed by a dot,\n// followed by anything, any number of times.\n\nvar twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'; // characters that need to be escaped in RegExp.\n\nvar reSpecials = charSet('().*{}+?[]^$\\\\!'); // \"abc\" -> { a:true, b:true, c:true }\n\nfunction charSet(s) {\n  return s.split('').reduce(function (set, c) {\n    set[c] = true;\n    return set;\n  }, {});\n} // normalizes slashes.\n\n\nvar slashSplit = /\\/+/;\nminimatch.filter = filter;\n\nfunction filter(pattern, options) {\n  options = options || {};\n  return function (p, i, list) {\n    return minimatch(p, pattern, options);\n  };\n}\n\nfunction ext(a, b) {\n  b = b || {};\n  var t = {};\n  Object.keys(a).forEach(function (k) {\n    t[k] = a[k];\n  });\n  Object.keys(b).forEach(function (k) {\n    t[k] = b[k];\n  });\n  return t;\n}\n\nminimatch.defaults = function (def) {\n  if (!def || typeof def !== 'object' || !Object.keys(def).length) {\n    return minimatch;\n  }\n\n  var orig = minimatch;\n\n  var m = function minimatch(p, pattern, options) {\n    return orig(p, pattern, ext(def, options));\n  };\n\n  m.Minimatch = function Minimatch(pattern, options) {\n    return new orig.Minimatch(pattern, ext(def, options));\n  };\n\n  m.Minimatch.defaults = function defaults(options) {\n    return orig.defaults(ext(def, options)).Minimatch;\n  };\n\n  m.filter = function filter(pattern, options) {\n    return orig.filter(pattern, ext(def, options));\n  };\n\n  m.defaults = function defaults(options) {\n    return orig.defaults(ext(def, options));\n  };\n\n  m.makeRe = function makeRe(pattern, options) {\n    return orig.makeRe(pattern, ext(def, options));\n  };\n\n  m.braceExpand = function braceExpand(pattern, options) {\n    return orig.braceExpand(pattern, ext(def, options));\n  };\n\n  m.match = function (list, pattern, options) {\n    return orig.match(list, pattern, ext(def, options));\n  };\n\n  return m;\n};\n\nMinimatch.defaults = function (def) {\n  return minimatch.defaults(def).Minimatch;\n};\n\nfunction minimatch(p, pattern, options) {\n  assertValidPattern(pattern);\n  if (!options) options = {}; // shortcut: comments match nothing.\n\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false;\n  }\n\n  return new Minimatch(pattern, options).match(p);\n}\n\nfunction Minimatch(pattern, options) {\n  if (!(this instanceof Minimatch)) {\n    return new Minimatch(pattern, options);\n  }\n\n  assertValidPattern(pattern);\n  if (!options) options = {};\n  pattern = pattern.trim(); // windows support: need to use /, not \\\n\n  if (!options.allowWindowsEscape && path.sep !== '/') {\n    pattern = pattern.split(path.sep).join('/');\n  }\n\n  this.options = options;\n  this.set = [];\n  this.pattern = pattern;\n  this.regexp = null;\n  this.negate = false;\n  this.comment = false;\n  this.empty = false;\n  this.partial = !!options.partial; // make the set of regexps etc.\n\n  this.make();\n}\n\nMinimatch.prototype.debug = function () {};\n\nMinimatch.prototype.make = make;\n\nfunction make() {\n  var pattern = this.pattern;\n  var options = this.options; // empty patterns and comments match nothing.\n\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    this.comment = true;\n    return;\n  }\n\n  if (!pattern) {\n    this.empty = true;\n    return;\n  } // step 1: figure out negation, etc.\n\n\n  this.parseNegate(); // step 2: expand braces\n\n  var set = this.globSet = this.braceExpand();\n  if (options.debug) this.debug = function debug() {\n    console.error.apply(console, arguments);\n  };\n  this.debug(this.pattern, set); // step 3: now we have a set, so turn each one into a series of path-portion\n  // matching patterns.\n  // These will be regexps, except in the case of \"**\", which is\n  // set to the GLOBSTAR object for globstar behavior,\n  // and will not contain any / characters\n\n  set = this.globParts = set.map(function (s) {\n    return s.split(slashSplit);\n  });\n  this.debug(this.pattern, set); // glob --> regexps\n\n  set = set.map(function (s, si, set) {\n    return s.map(this.parse, this);\n  }, this);\n  this.debug(this.pattern, set); // filter out everything that didn't compile properly.\n\n  set = set.filter(function (s) {\n    return s.indexOf(false) === -1;\n  });\n  this.debug(this.pattern, set);\n  this.set = set;\n}\n\nMinimatch.prototype.parseNegate = parseNegate;\n\nfunction parseNegate() {\n  var pattern = this.pattern;\n  var negate = false;\n  var options = this.options;\n  var negateOffset = 0;\n  if (options.nonegate) return;\n\n  for (var i = 0, l = pattern.length; i < l && pattern.charAt(i) === '!'; i++) {\n    negate = !negate;\n    negateOffset++;\n  }\n\n  if (negateOffset) this.pattern = pattern.substr(negateOffset);\n  this.negate = negate;\n} // Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\n\n\nminimatch.braceExpand = function (pattern, options) {\n  return braceExpand(pattern, options);\n};\n\nMinimatch.prototype.braceExpand = braceExpand;\n\nfunction braceExpand(pattern, options) {\n  if (!options) {\n    if (this instanceof Minimatch) {\n      options = this.options;\n    } else {\n      options = {};\n    }\n  }\n\n  pattern = typeof pattern === 'undefined' ? this.pattern : pattern;\n  assertValidPattern(pattern); // Thanks to Yeting Li <https://github.com/yetingli> for\n  // improving this regexp to avoid a ReDOS vulnerability.\n\n  if (options.nobrace || !/\\{(?:(?!\\{).)*\\}/.test(pattern)) {\n    // shortcut. no need to expand.\n    return [pattern];\n  }\n\n  return expand(pattern);\n}\n\nvar MAX_PATTERN_LENGTH = 1024 * 64;\n\nvar assertValidPattern = function (pattern) {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('invalid pattern');\n  }\n\n  if (pattern.length > MAX_PATTERN_LENGTH) {\n    throw new TypeError('pattern is too long');\n  }\n}; // parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\n\n\nMinimatch.prototype.parse = parse;\nvar SUBPARSE = {};\n\nfunction parse(pattern, isSub) {\n  assertValidPattern(pattern);\n  var options = this.options; // shortcuts\n\n  if (pattern === '**') {\n    if (!options.noglobstar) return GLOBSTAR;else pattern = '*';\n  }\n\n  if (pattern === '') return '';\n  var re = '';\n  var hasMagic = !!options.nocase;\n  var escaping = false; // ? => one single character\n\n  var patternListStack = [];\n  var negativeLists = [];\n  var stateChar;\n  var inClass = false;\n  var reClassStart = -1;\n  var classStart = -1; // . and .. never match anything that doesn't start with .,\n  // even when options.dot is set.\n\n  var patternStart = pattern.charAt(0) === '.' ? '' // anything\n  // not (start or / followed by . or .. followed by / or end)\n  : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))' : '(?!\\\\.)';\n  var self = this;\n\n  function clearStateChar() {\n    if (stateChar) {\n      // we had some state-tracking character\n      // that wasn't consumed by this pass.\n      switch (stateChar) {\n        case '*':\n          re += star;\n          hasMagic = true;\n          break;\n\n        case '?':\n          re += qmark;\n          hasMagic = true;\n          break;\n\n        default:\n          re += '\\\\' + stateChar;\n          break;\n      }\n\n      self.debug('clearStateChar %j %j', stateChar, re);\n      stateChar = false;\n    }\n  }\n\n  for (var i = 0, len = pattern.length, c; i < len && (c = pattern.charAt(i)); i++) {\n    this.debug('%s\\t%s %s %j', pattern, i, re, c); // skip over any that are escaped.\n\n    if (escaping && reSpecials[c]) {\n      re += '\\\\' + c;\n      escaping = false;\n      continue;\n    }\n\n    switch (c) {\n      /* istanbul ignore next */\n      case '/':\n        {\n          // completely not allowed, even escaped.\n          // Should already be path-split by now.\n          return false;\n        }\n\n      case '\\\\':\n        clearStateChar();\n        escaping = true;\n        continue;\n      // the various stateChar values\n      // for the \"extglob\" stuff.\n\n      case '?':\n      case '*':\n      case '+':\n      case '@':\n      case '!':\n        this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c); // all of those are literals inside a class, except that\n        // the glob [!a] means [^a] in regexp\n\n        if (inClass) {\n          this.debug('  in class');\n          if (c === '!' && i === classStart + 1) c = '^';\n          re += c;\n          continue;\n        } // if we already have a stateChar, then it means\n        // that there was something like ** or +? in there.\n        // Handle the stateChar, then proceed with this one.\n\n\n        self.debug('call clearStateChar %j', stateChar);\n        clearStateChar();\n        stateChar = c; // if extglob is disabled, then +(asdf|foo) isn't a thing.\n        // just clear the statechar *now*, rather than even diving into\n        // the patternList stuff.\n\n        if (options.noext) clearStateChar();\n        continue;\n\n      case '(':\n        if (inClass) {\n          re += '(';\n          continue;\n        }\n\n        if (!stateChar) {\n          re += '\\\\(';\n          continue;\n        }\n\n        patternListStack.push({\n          type: stateChar,\n          start: i - 1,\n          reStart: re.length,\n          open: plTypes[stateChar].open,\n          close: plTypes[stateChar].close\n        }); // negation is (?:(?!js)[^/]*)\n\n        re += stateChar === '!' ? '(?:(?!(?:' : '(?:';\n        this.debug('plType %j %j', stateChar, re);\n        stateChar = false;\n        continue;\n\n      case ')':\n        if (inClass || !patternListStack.length) {\n          re += '\\\\)';\n          continue;\n        }\n\n        clearStateChar();\n        hasMagic = true;\n        var pl = patternListStack.pop(); // negation is (?:(?!js)[^/]*)\n        // The others are (?:<pattern>)<type>\n\n        re += pl.close;\n\n        if (pl.type === '!') {\n          negativeLists.push(pl);\n        }\n\n        pl.reEnd = re.length;\n        continue;\n\n      case '|':\n        if (inClass || !patternListStack.length || escaping) {\n          re += '\\\\|';\n          escaping = false;\n          continue;\n        }\n\n        clearStateChar();\n        re += '|';\n        continue;\n      // these are mostly the same in regexp and glob\n\n      case '[':\n        // swallow any state-tracking char before the [\n        clearStateChar();\n\n        if (inClass) {\n          re += '\\\\' + c;\n          continue;\n        }\n\n        inClass = true;\n        classStart = i;\n        reClassStart = re.length;\n        re += c;\n        continue;\n\n      case ']':\n        //  a right bracket shall lose its special\n        //  meaning and represent itself in\n        //  a bracket expression if it occurs\n        //  first in the list.  -- POSIX.2 2.8.3.2\n        if (i === classStart + 1 || !inClass) {\n          re += '\\\\' + c;\n          escaping = false;\n          continue;\n        } // handle the case where we left a class open.\n        // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n        // split where the last [ was, make sure we don't have\n        // an invalid re. if so, re-walk the contents of the\n        // would-be class to re-translate any characters that\n        // were passed through as-is\n        // TODO: It would probably be faster to determine this\n        // without a try/catch and a new RegExp, but it's tricky\n        // to do safely.  For now, this is safe and works.\n\n\n        var cs = pattern.substring(classStart + 1, i);\n\n        try {\n          RegExp('[' + cs + ']');\n        } catch (er) {\n          // not a valid class!\n          var sp = this.parse(cs, SUBPARSE);\n          re = re.substr(0, reClassStart) + '\\\\[' + sp[0] + '\\\\]';\n          hasMagic = hasMagic || sp[1];\n          inClass = false;\n          continue;\n        } // finish up the class.\n\n\n        hasMagic = true;\n        inClass = false;\n        re += c;\n        continue;\n\n      default:\n        // swallow any state char that wasn't consumed\n        clearStateChar();\n\n        if (escaping) {\n          // no need\n          escaping = false;\n        } else if (reSpecials[c] && !(c === '^' && inClass)) {\n          re += '\\\\';\n        }\n\n        re += c;\n    } // switch\n\n  } // for\n  // handle the case where we left a class open.\n  // \"[abc\" is valid, equivalent to \"\\[abc\"\n\n\n  if (inClass) {\n    // split where the last [ was, and escape it\n    // this is a huge pita.  We now have to re-walk\n    // the contents of the would-be class to re-translate\n    // any characters that were passed through as-is\n    cs = pattern.substr(classStart + 1);\n    sp = this.parse(cs, SUBPARSE);\n    re = re.substr(0, reClassStart) + '\\\\[' + sp[0];\n    hasMagic = hasMagic || sp[1];\n  } // handle the case where we had a +( thing at the *end*\n  // of the pattern.\n  // each pattern list stack adds 3 chars, and we need to go through\n  // and escape any | chars that were passed through as-is for the regexp.\n  // Go through and escape them, taking care not to double-escape any\n  // | chars that were already escaped.\n\n\n  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n    var tail = re.slice(pl.reStart + pl.open.length);\n    this.debug('setting tail', re, pl); // maybe some even number of \\, then maybe 1 \\, followed by a |\n\n    tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, function (_, $1, $2) {\n      if (!$2) {\n        // the | isn't already escaped, so escape it.\n        $2 = '\\\\';\n      } // need to escape all those slashes *again*, without escaping the\n      // one that we need for escaping the | character.  As it works out,\n      // escaping an even number of slashes can be done by simply repeating\n      // it exactly after itself.  That's why this trick works.\n      //\n      // I am sorry that you have to see this.\n\n\n      return $1 + $1 + $2 + '|';\n    });\n    this.debug('tail=%j\\n   %s', tail, tail, pl, re);\n    var t = pl.type === '*' ? star : pl.type === '?' ? qmark : '\\\\' + pl.type;\n    hasMagic = true;\n    re = re.slice(0, pl.reStart) + t + '\\\\(' + tail;\n  } // handle trailing things that only matter at the very end.\n\n\n  clearStateChar();\n\n  if (escaping) {\n    // trailing \\\\\n    re += '\\\\\\\\';\n  } // only need to apply the nodot start if the re starts with\n  // something that could conceivably capture a dot\n\n\n  var addPatternStart = false;\n\n  switch (re.charAt(0)) {\n    case '[':\n    case '.':\n    case '(':\n      addPatternStart = true;\n  } // Hack to work around lack of negative lookbehind in JS\n  // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n  // like 'a.xyz.yz' doesn't match.  So, the first negative\n  // lookahead, has to look ALL the way ahead, to the end of\n  // the pattern.\n\n\n  for (var n = negativeLists.length - 1; n > -1; n--) {\n    var nl = negativeLists[n];\n    var nlBefore = re.slice(0, nl.reStart);\n    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8);\n    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd);\n    var nlAfter = re.slice(nl.reEnd);\n    nlLast += nlAfter; // Handle nested stuff like *(*.js|!(*.json)), where open parens\n    // mean that we should *not* include the ) in the bit that is considered\n    // \"after\" the negated section.\n\n    var openParensBefore = nlBefore.split('(').length - 1;\n    var cleanAfter = nlAfter;\n\n    for (i = 0; i < openParensBefore; i++) {\n      cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '');\n    }\n\n    nlAfter = cleanAfter;\n    var dollar = '';\n\n    if (nlAfter === '' && isSub !== SUBPARSE) {\n      dollar = '$';\n    }\n\n    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast;\n    re = newRe;\n  } // if the re is not \"\" at this point, then we need to make sure\n  // it doesn't match against an empty path part.\n  // Otherwise a/* will match a/, which it should not.\n\n\n  if (re !== '' && hasMagic) {\n    re = '(?=.)' + re;\n  }\n\n  if (addPatternStart) {\n    re = patternStart + re;\n  } // parsing just a piece of a larger pattern.\n\n\n  if (isSub === SUBPARSE) {\n    return [re, hasMagic];\n  } // skip the regexp for non-magical patterns\n  // unescape anything in it, though, so that it'll be\n  // an exact match against a file etc.\n\n\n  if (!hasMagic) {\n    return globUnescape(pattern);\n  }\n\n  var flags = options.nocase ? 'i' : '';\n\n  try {\n    var regExp = new RegExp('^' + re + '$', flags);\n  } catch (er)\n  /* istanbul ignore next - should be impossible */\n  {\n    // If it was an invalid regular expression, then it can't match\n    // anything.  This trick looks for a character after the end of\n    // the string, which is of course impossible, except in multi-line\n    // mode, but it's not a /m regex.\n    return new RegExp('$.');\n  }\n\n  regExp._glob = pattern;\n  regExp._src = re;\n  return regExp;\n}\n\nminimatch.makeRe = function (pattern, options) {\n  return new Minimatch(pattern, options || {}).makeRe();\n};\n\nMinimatch.prototype.makeRe = makeRe;\n\nfunction makeRe() {\n  if (this.regexp || this.regexp === false) return this.regexp; // at this point, this.set is a 2d array of partial\n  // pattern strings, or \"**\".\n  //\n  // It's better to use .match().  This function shouldn't\n  // be used, really, but it's pretty convenient sometimes,\n  // when you just want to work with a regex.\n\n  var set = this.set;\n\n  if (!set.length) {\n    this.regexp = false;\n    return this.regexp;\n  }\n\n  var options = this.options;\n  var twoStar = options.noglobstar ? star : options.dot ? twoStarDot : twoStarNoDot;\n  var flags = options.nocase ? 'i' : '';\n  var re = set.map(function (pattern) {\n    return pattern.map(function (p) {\n      return p === GLOBSTAR ? twoStar : typeof p === 'string' ? regExpEscape(p) : p._src;\n    }).join('\\\\\\/');\n  }).join('|'); // must match entire pattern\n  // ending in a * or ** will make it less strict.\n\n  re = '^(?:' + re + ')$'; // can match anything, as long as it's not this.\n\n  if (this.negate) re = '^(?!' + re + ').*$';\n\n  try {\n    this.regexp = new RegExp(re, flags);\n  } catch (ex)\n  /* istanbul ignore next - should be impossible */\n  {\n    this.regexp = false;\n  }\n\n  return this.regexp;\n}\n\nminimatch.match = function (list, pattern, options) {\n  options = options || {};\n  var mm = new Minimatch(pattern, options);\n  list = list.filter(function (f) {\n    return mm.match(f);\n  });\n\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern);\n  }\n\n  return list;\n};\n\nMinimatch.prototype.match = function match(f, partial) {\n  if (typeof partial === 'undefined') partial = this.partial;\n  this.debug('match', f, this.pattern); // short-circuit in the case of busted things.\n  // comments, etc.\n\n  if (this.comment) return false;\n  if (this.empty) return f === '';\n  if (f === '/' && partial) return true;\n  var options = this.options; // windows: need to use /, not \\\n\n  if (path.sep !== '/') {\n    f = f.split(path.sep).join('/');\n  } // treat the test path as a set of pathparts.\n\n\n  f = f.split(slashSplit);\n  this.debug(this.pattern, 'split', f); // just ONE of the pattern sets in this.set needs to match\n  // in order for it to be valid.  If negating, then just one\n  // match means that we have failed.\n  // Either way, return on the first hit.\n\n  var set = this.set;\n  this.debug(this.pattern, 'set', set); // Find the basename of the path by looking for the last non-empty segment\n\n  var filename;\n  var i;\n\n  for (i = f.length - 1; i >= 0; i--) {\n    filename = f[i];\n    if (filename) break;\n  }\n\n  for (i = 0; i < set.length; i++) {\n    var pattern = set[i];\n    var file = f;\n\n    if (options.matchBase && pattern.length === 1) {\n      file = [filename];\n    }\n\n    var hit = this.matchOne(file, pattern, partial);\n\n    if (hit) {\n      if (options.flipNegate) return true;\n      return !this.negate;\n    }\n  } // didn't get any hits.  this is success if it's a negative\n  // pattern, failure otherwise.\n\n\n  if (options.flipNegate) return false;\n  return this.negate;\n}; // set partial to true to test if, for example,\n// \"/a/b\" matches the start of \"/*/b/*/d\"\n// Partial means, if you run out of file before you run\n// out of pattern, then that's fine, as long as all\n// the parts match.\n\n\nMinimatch.prototype.matchOne = function (file, pattern, partial) {\n  var options = this.options;\n  this.debug('matchOne', {\n    'this': this,\n    file: file,\n    pattern: pattern\n  });\n  this.debug('matchOne', file.length, pattern.length);\n\n  for (var fi = 0, pi = 0, fl = file.length, pl = pattern.length; fi < fl && pi < pl; fi++, pi++) {\n    this.debug('matchOne loop');\n    var p = pattern[pi];\n    var f = file[fi];\n    this.debug(pattern, p, f); // should be impossible.\n    // some invalid regexp stuff in the set.\n\n    /* istanbul ignore if */\n\n    if (p === false) return false;\n\n    if (p === GLOBSTAR) {\n      this.debug('GLOBSTAR', [pattern, p, f]); // \"**\"\n      // a/**/b/**/c would match the following:\n      // a/b/x/y/z/c\n      // a/x/y/z/b/c\n      // a/b/x/b/x/c\n      // a/b/c\n      // To do this, take the rest of the pattern after\n      // the **, and see if it would match the file remainder.\n      // If so, return success.\n      // If not, the ** \"swallows\" a segment, and try again.\n      // This is recursively awful.\n      //\n      // a/**/b/**/c matching a/b/x/y/z/c\n      // - a matches a\n      // - doublestar\n      //   - matchOne(b/x/y/z/c, b/**/c)\n      //     - b matches b\n      //     - doublestar\n      //       - matchOne(x/y/z/c, c) -> no\n      //       - matchOne(y/z/c, c) -> no\n      //       - matchOne(z/c, c) -> no\n      //       - matchOne(c, c) yes, hit\n\n      var fr = fi;\n      var pr = pi + 1;\n\n      if (pr === pl) {\n        this.debug('** at the end'); // a ** at the end will just swallow the rest.\n        // We have found a match.\n        // however, it will not swallow /.x, unless\n        // options.dot is set.\n        // . and .. are *never* matched by **, for explosively\n        // exponential reasons.\n\n        for (; fi < fl; fi++) {\n          if (file[fi] === '.' || file[fi] === '..' || !options.dot && file[fi].charAt(0) === '.') return false;\n        }\n\n        return true;\n      } // ok, let's see if we can swallow whatever we can.\n\n\n      while (fr < fl) {\n        var swallowee = file[fr];\n        this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee); // XXX remove this slice.  Just pass the start index.\n\n        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n          this.debug('globstar found match!', fr, fl, swallowee); // found a match.\n\n          return true;\n        } else {\n          // can't swallow \".\" or \"..\" ever.\n          // can only swallow \".foo\" when explicitly asked.\n          if (swallowee === '.' || swallowee === '..' || !options.dot && swallowee.charAt(0) === '.') {\n            this.debug('dot detected!', file, fr, pattern, pr);\n            break;\n          } // ** swallows a segment, and continue.\n\n\n          this.debug('globstar swallow a segment, and continue');\n          fr++;\n        }\n      } // no match was found.\n      // However, in partial mode, we can't say this is necessarily over.\n      // If there's more *pattern* left, then\n\n      /* istanbul ignore if */\n\n\n      if (partial) {\n        // ran out of file\n        this.debug('\\n>>> no match, partial?', file, fr, pattern, pr);\n        if (fr === fl) return true;\n      }\n\n      return false;\n    } // something other than **\n    // non-magic patterns just have to match exactly\n    // patterns with magic have been turned into regexps.\n\n\n    var hit;\n\n    if (typeof p === 'string') {\n      hit = f === p;\n      this.debug('string match', p, f, hit);\n    } else {\n      hit = f.match(p);\n      this.debug('pattern match', p, f, hit);\n    }\n\n    if (!hit) return false;\n  } // Note: ending in / means that we'll get a final \"\"\n  // at the end of the pattern.  This can only match a\n  // corresponding \"\" at the end of the file.\n  // If the file ends in /, then it can only match a\n  // a pattern that ends in /, unless the pattern just\n  // doesn't have any more for it. But, a/b/ should *not*\n  // match \"a/b/*\", even though \"\" matches against the\n  // [^/]*? pattern, except in partial mode, where it might\n  // simply not be reached yet.\n  // However, a/b/ should still satisfy a/*\n  // now either we fell off the end of the pattern, or we're done.\n\n\n  if (fi === fl && pi === pl) {\n    // ran out of pattern and filename at the same time.\n    // an exact hit!\n    return true;\n  } else if (fi === fl) {\n    // ran out of file, but still had pattern left.\n    // this is ok if we're doing the match as part of\n    // a glob fs traversal.\n    return partial;\n  } else\n    /* istanbul ignore else */\n    if (pi === pl) {\n      // ran out of pattern, still have file left.\n      // this is only acceptable if we're on the very last\n      // empty segment of a file with a trailing slash.\n      // a/* should match a/b/\n      return fi === fl - 1 && file[fi] === '';\n    } // should be unreachable.\n\n  /* istanbul ignore next */\n\n\n  throw new Error('wtf?');\n}; // replace stuff like \\* with *\n\n\nfunction globUnescape(s) {\n  return s.replace(/\\\\(.)/g, '$1');\n}\n\nfunction regExpEscape(s) {\n  return s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/minimatch/minimatch.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base.js":
/*!*********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar baseX$1 = __webpack_require__(/*! ../../vendor/base-x.js */ \"./node_modules/multiformats/cjs/vendor/base-x.js\");\n\nvar bytes = __webpack_require__(/*! ../bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nclass Encoder {\n  constructor(name, prefix, baseEncode) {\n    this.name = name;\n    this.prefix = prefix;\n    this.baseEncode = baseEncode;\n  }\n\n  encode(bytes) {\n    if (bytes instanceof Uint8Array) {\n      return `${this.prefix}${this.baseEncode(bytes)}`;\n    } else {\n      throw Error('Unknown type, must be binary type');\n    }\n  }\n\n}\n\nclass Decoder {\n  constructor(name, prefix, baseDecode) {\n    this.name = name;\n    this.prefix = prefix;\n    this.baseDecode = baseDecode;\n  }\n\n  decode(text) {\n    if (typeof text === 'string') {\n      switch (text[0]) {\n        case this.prefix:\n          {\n            return this.baseDecode(text.slice(1));\n          }\n\n        default:\n          {\n            throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);\n          }\n      }\n    } else {\n      throw Error('Can only multibase decode strings');\n    }\n  }\n\n  or(decoder) {\n    return or(this, decoder);\n  }\n\n}\n\nclass ComposedDecoder {\n  constructor(decoders) {\n    this.decoders = decoders;\n  }\n\n  or(decoder) {\n    return or(this, decoder);\n  }\n\n  decode(input) {\n    const prefix = input[0];\n    const decoder = this.decoders[prefix];\n\n    if (decoder) {\n      return decoder.decode(input);\n    } else {\n      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);\n    }\n  }\n\n}\n\nconst or = (left, right) => new ComposedDecoder({ ...(left.decoders || {\n    [left.prefix]: left\n  }),\n  ...(right.decoders || {\n    [right.prefix]: right\n  })\n});\n\nclass Codec {\n  constructor(name, prefix, baseEncode, baseDecode) {\n    this.name = name;\n    this.prefix = prefix;\n    this.baseEncode = baseEncode;\n    this.baseDecode = baseDecode;\n    this.encoder = new Encoder(name, prefix, baseEncode);\n    this.decoder = new Decoder(name, prefix, baseDecode);\n  }\n\n  encode(input) {\n    return this.encoder.encode(input);\n  }\n\n  decode(input) {\n    return this.decoder.decode(input);\n  }\n\n}\n\nconst from = ({\n  name,\n  prefix,\n  encode,\n  decode\n}) => new Codec(name, prefix, encode, decode);\n\nconst baseX = ({\n  prefix,\n  name,\n  alphabet\n}) => {\n  const {\n    encode,\n    decode\n  } = baseX$1(alphabet, name);\n  return from({\n    prefix,\n    name,\n    encode,\n    decode: text => bytes.coerce(decode(text))\n  });\n};\n\nconst decode = (string, alphabet, bitsPerChar, name) => {\n  const codes = {};\n\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i;\n  }\n\n  let end = string.length;\n\n  while (string[end - 1] === '=') {\n    --end;\n  }\n\n  const out = new Uint8Array(end * bitsPerChar / 8 | 0);\n  let bits = 0;\n  let buffer = 0;\n  let written = 0;\n\n  for (let i = 0; i < end; ++i) {\n    const value = codes[string[i]];\n\n    if (value === undefined) {\n      throw new SyntaxError(`Non-${name} character`);\n    }\n\n    buffer = buffer << bitsPerChar | value;\n    bits += bitsPerChar;\n\n    if (bits >= 8) {\n      bits -= 8;\n      out[written++] = 255 & buffer >> bits;\n    }\n  }\n\n  if (bits >= bitsPerChar || 255 & buffer << 8 - bits) {\n    throw new SyntaxError('Unexpected end of data');\n  }\n\n  return out;\n};\n\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '=';\n  const mask = (1 << bitsPerChar) - 1;\n  let out = '';\n  let bits = 0;\n  let buffer = 0;\n\n  for (let i = 0; i < data.length; ++i) {\n    buffer = buffer << 8 | data[i];\n    bits += 8;\n\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar;\n      out += alphabet[mask & buffer >> bits];\n    }\n  }\n\n  if (bits) {\n    out += alphabet[mask & buffer << bitsPerChar - bits];\n  }\n\n  if (pad) {\n    while (out.length * bitsPerChar & 7) {\n      out += '=';\n    }\n  }\n\n  return out;\n};\n\nconst rfc4648 = ({\n  name,\n  prefix,\n  bitsPerChar,\n  alphabet\n}) => {\n  return from({\n    prefix,\n    name,\n\n    encode(input) {\n      return encode(input, alphabet, bitsPerChar);\n    },\n\n    decode(input) {\n      return decode(input, alphabet, bitsPerChar, name);\n    }\n\n  });\n};\n\nexports.Codec = Codec;\nexports.baseX = baseX;\nexports.from = from;\nexports.or = or;\nexports.rfc4648 = rfc4648;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base10.js":
/*!***********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base10.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base10 = base.baseX({\n  prefix: '9',\n  name: 'base10',\n  alphabet: '0123456789'\n});\nexports.base10 = base10;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base10.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base16.js":
/*!***********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base16.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base16 = base.rfc4648({\n  prefix: 'f',\n  name: 'base16',\n  alphabet: '0123456789abcdef',\n  bitsPerChar: 4\n});\nconst base16upper = base.rfc4648({\n  prefix: 'F',\n  name: 'base16upper',\n  alphabet: '0123456789ABCDEF',\n  bitsPerChar: 4\n});\nexports.base16 = base16;\nexports.base16upper = base16upper;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base16.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base2.js":
/*!**********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base2.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base2 = base.rfc4648({\n  prefix: '0',\n  name: 'base2',\n  alphabet: '01',\n  bitsPerChar: 1\n});\nexports.base2 = base2;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base2.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base32.js":
/*!***********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base32.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base32 = base.rfc4648({\n  prefix: 'b',\n  name: 'base32',\n  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',\n  bitsPerChar: 5\n});\nconst base32upper = base.rfc4648({\n  prefix: 'B',\n  name: 'base32upper',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',\n  bitsPerChar: 5\n});\nconst base32pad = base.rfc4648({\n  prefix: 'c',\n  name: 'base32pad',\n  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',\n  bitsPerChar: 5\n});\nconst base32padupper = base.rfc4648({\n  prefix: 'C',\n  name: 'base32padupper',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',\n  bitsPerChar: 5\n});\nconst base32hex = base.rfc4648({\n  prefix: 'v',\n  name: 'base32hex',\n  alphabet: '0123456789abcdefghijklmnopqrstuv',\n  bitsPerChar: 5\n});\nconst base32hexupper = base.rfc4648({\n  prefix: 'V',\n  name: 'base32hexupper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',\n  bitsPerChar: 5\n});\nconst base32hexpad = base.rfc4648({\n  prefix: 't',\n  name: 'base32hexpad',\n  alphabet: '0123456789abcdefghijklmnopqrstuv=',\n  bitsPerChar: 5\n});\nconst base32hexpadupper = base.rfc4648({\n  prefix: 'T',\n  name: 'base32hexpadupper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',\n  bitsPerChar: 5\n});\nconst base32z = base.rfc4648({\n  prefix: 'h',\n  name: 'base32z',\n  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',\n  bitsPerChar: 5\n});\nexports.base32 = base32;\nexports.base32hex = base32hex;\nexports.base32hexpad = base32hexpad;\nexports.base32hexpadupper = base32hexpadupper;\nexports.base32hexupper = base32hexupper;\nexports.base32pad = base32pad;\nexports.base32padupper = base32padupper;\nexports.base32upper = base32upper;\nexports.base32z = base32z;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base32.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base36.js":
/*!***********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base36.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base36 = base.baseX({\n  prefix: 'k',\n  name: 'base36',\n  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'\n});\nconst base36upper = base.baseX({\n  prefix: 'K',\n  name: 'base36upper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n});\nexports.base36 = base36;\nexports.base36upper = base36upper;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base36.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base58.js":
/*!***********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base58.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base58btc = base.baseX({\n  name: 'base58btc',\n  prefix: 'z',\n  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'\n});\nconst base58flickr = base.baseX({\n  name: 'base58flickr',\n  prefix: 'Z',\n  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'\n});\nexports.base58btc = base58btc;\nexports.base58flickr = base58flickr;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base58.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base64.js":
/*!***********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base64.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base64 = base.rfc4648({\n  prefix: 'm',\n  name: 'base64',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',\n  bitsPerChar: 6\n});\nconst base64pad = base.rfc4648({\n  prefix: 'M',\n  name: 'base64pad',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',\n  bitsPerChar: 6\n});\nconst base64url = base.rfc4648({\n  prefix: 'u',\n  name: 'base64url',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',\n  bitsPerChar: 6\n});\nconst base64urlpad = base.rfc4648({\n  prefix: 'U',\n  name: 'base64urlpad',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',\n  bitsPerChar: 6\n});\nexports.base64 = base64;\nexports.base64pad = base64pad;\nexports.base64url = base64url;\nexports.base64urlpad = base64urlpad;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base64.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/base8.js":
/*!**********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/base8.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nconst base8 = base.rfc4648({\n  prefix: '7',\n  name: 'base8',\n  alphabet: '01234567',\n  bitsPerChar: 3\n});\nexports.base8 = base8;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/base8.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bases/identity.js":
/*!*************************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bases/identity.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar base = __webpack_require__(/*! ./base.js */ \"./node_modules/multiformats/cjs/src/bases/base.js\");\n\nvar bytes = __webpack_require__(/*! ../bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nconst identity = base.from({\n  prefix: '\\0',\n  name: 'identity',\n  encode: buf => bytes.toString(buf),\n  decode: str => bytes.fromString(str)\n});\nexports.identity = identity;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bases/identity.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/basics.js":
/*!*****************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/basics.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar identity = __webpack_require__(/*! ./bases/identity.js */ \"./node_modules/multiformats/cjs/src/bases/identity.js\");\n\nvar base2 = __webpack_require__(/*! ./bases/base2.js */ \"./node_modules/multiformats/cjs/src/bases/base2.js\");\n\nvar base8 = __webpack_require__(/*! ./bases/base8.js */ \"./node_modules/multiformats/cjs/src/bases/base8.js\");\n\nvar base10 = __webpack_require__(/*! ./bases/base10.js */ \"./node_modules/multiformats/cjs/src/bases/base10.js\");\n\nvar base16 = __webpack_require__(/*! ./bases/base16.js */ \"./node_modules/multiformats/cjs/src/bases/base16.js\");\n\nvar base32 = __webpack_require__(/*! ./bases/base32.js */ \"./node_modules/multiformats/cjs/src/bases/base32.js\");\n\nvar base36 = __webpack_require__(/*! ./bases/base36.js */ \"./node_modules/multiformats/cjs/src/bases/base36.js\");\n\nvar base58 = __webpack_require__(/*! ./bases/base58.js */ \"./node_modules/multiformats/cjs/src/bases/base58.js\");\n\nvar base64 = __webpack_require__(/*! ./bases/base64.js */ \"./node_modules/multiformats/cjs/src/bases/base64.js\");\n\nvar sha2 = __webpack_require__(/*! ./hashes/sha2.js */ \"./node_modules/multiformats/cjs/src/hashes/sha2.js\");\n\nvar identity$1 = __webpack_require__(/*! ./hashes/identity.js */ \"./node_modules/multiformats/cjs/src/hashes/identity.js\");\n\nvar raw = __webpack_require__(/*! ./codecs/raw.js */ \"./node_modules/multiformats/cjs/src/codecs/raw.js\");\n\nvar json = __webpack_require__(/*! ./codecs/json.js */ \"./node_modules/multiformats/cjs/src/codecs/json.js\");\n\n__webpack_require__(/*! ./index.js */ \"./node_modules/multiformats/cjs/src/index.js\");\n\nvar cid = __webpack_require__(/*! ./cid.js */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar hasher = __webpack_require__(/*! ./hashes/hasher.js */ \"./node_modules/multiformats/cjs/src/hashes/hasher.js\");\n\nvar digest = __webpack_require__(/*! ./hashes/digest.js */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nvar varint = __webpack_require__(/*! ./varint.js */ \"./node_modules/multiformats/cjs/src/varint.js\");\n\nvar bytes = __webpack_require__(/*! ./bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nconst bases = { ...identity,\n  ...base2,\n  ...base8,\n  ...base10,\n  ...base16,\n  ...base32,\n  ...base36,\n  ...base58,\n  ...base64\n};\nconst hashes = { ...sha2,\n  ...identity$1\n};\nconst codecs = {\n  raw,\n  json\n};\nexports.CID = cid.CID;\nexports.hasher = hasher;\nexports.digest = digest;\nexports.varint = varint;\nexports.bytes = bytes;\nexports.bases = bases;\nexports.codecs = codecs;\nexports.hashes = hashes;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/basics.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/block.js":
/*!****************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/block.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\n__webpack_require__(/*! ./index.js */ \"./node_modules/multiformats/cjs/src/index.js\");\n\nvar cid = __webpack_require__(/*! ./cid.js */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar bytes = __webpack_require__(/*! ./bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nconst readonly = ({\n  enumerable = true,\n  configurable = false\n} = {}) => ({\n  enumerable,\n  configurable,\n  writable: false\n});\n\nconst links = function* (source, base) {\n  if (source == null) return;\n  if (source instanceof Uint8Array) return;\n\n  for (const [key, value] of Object.entries(source)) {\n    const path = [...base, key];\n\n    if (value != null && typeof value === 'object') {\n      if (Array.isArray(value)) {\n        for (const [index, element] of value.entries()) {\n          const elementPath = [...path, index];\n          const cid$1 = cid.CID.asCID(element);\n\n          if (cid$1) {\n            yield [elementPath.join('/'), cid$1];\n          } else if (typeof element === 'object') {\n            yield* links(element, elementPath);\n          }\n        }\n      } else {\n        const cid$1 = cid.CID.asCID(value);\n\n        if (cid$1) {\n          yield [path.join('/'), cid$1];\n        } else {\n          yield* links(value, path);\n        }\n      }\n    }\n  }\n};\n\nconst tree = function* (source, base) {\n  if (source == null) return;\n\n  for (const [key, value] of Object.entries(source)) {\n    const path = [...base, key];\n    yield path.join('/');\n\n    if (value != null && !(value instanceof Uint8Array) && typeof value === 'object' && !cid.CID.asCID(value)) {\n      if (Array.isArray(value)) {\n        for (const [index, element] of value.entries()) {\n          const elementPath = [...path, index];\n          yield elementPath.join('/');\n\n          if (typeof element === 'object' && !cid.CID.asCID(element)) {\n            yield* tree(element, elementPath);\n          }\n        }\n      } else {\n        yield* tree(value, path);\n      }\n    }\n  }\n};\n\nconst get = (source, path) => {\n  let node = source;\n\n  for (const [index, key] of path.entries()) {\n    node = node[key];\n\n    if (node == null) {\n      throw new Error(`Object has no property at ${path.slice(0, index + 1).map(part => `[${JSON.stringify(part)}]`).join('')}`);\n    }\n\n    const cid$1 = cid.CID.asCID(node);\n\n    if (cid$1) {\n      return {\n        value: cid$1,\n        remaining: path.slice(index + 1).join('/')\n      };\n    }\n  }\n\n  return {\n    value: node\n  };\n};\n\nclass Block {\n  constructor({\n    cid,\n    bytes,\n    value\n  }) {\n    if (!cid || !bytes || typeof value === 'undefined') throw new Error('Missing required argument');\n    this.cid = cid;\n    this.bytes = bytes;\n    this.value = value;\n    this.asBlock = this;\n    Object.defineProperties(this, {\n      cid: readonly(),\n      bytes: readonly(),\n      value: readonly(),\n      asBlock: readonly()\n    });\n  }\n\n  links() {\n    return links(this.value, []);\n  }\n\n  tree() {\n    return tree(this.value, []);\n  }\n\n  get(path = '/') {\n    return get(this.value, path.split('/').filter(Boolean));\n  }\n\n}\n\nconst encode = async ({\n  value,\n  codec,\n  hasher\n}) => {\n  if (typeof value === 'undefined') throw new Error('Missing required argument \"value\"');\n  if (!codec || !hasher) throw new Error('Missing required argument: codec or hasher');\n  const bytes = codec.encode(value);\n  const hash = await hasher.digest(bytes);\n  const cid$1 = cid.CID.create(1, codec.code, hash);\n  return new Block({\n    value,\n    bytes,\n    cid: cid$1\n  });\n};\n\nconst decode = async ({\n  bytes,\n  codec,\n  hasher\n}) => {\n  if (!bytes) throw new Error('Missing required argument \"bytes\"');\n  if (!codec || !hasher) throw new Error('Missing required argument: codec or hasher');\n  const value = codec.decode(bytes);\n  const hash = await hasher.digest(bytes);\n  const cid$1 = cid.CID.create(1, codec.code, hash);\n  return new Block({\n    value,\n    bytes,\n    cid: cid$1\n  });\n};\n\nconst createUnsafe = ({\n  bytes,\n  cid,\n  value: maybeValue,\n  codec\n}) => {\n  const value = maybeValue !== undefined ? maybeValue : codec && codec.decode(bytes);\n  if (value === undefined) throw new Error('Missing required argument, must either provide \"value\" or \"codec\"');\n  return new Block({\n    cid,\n    bytes,\n    value\n  });\n};\n\nconst create = async ({\n  bytes: bytes$1,\n  cid,\n  hasher,\n  codec\n}) => {\n  if (!bytes$1) throw new Error('Missing required argument \"bytes\"');\n  if (!hasher) throw new Error('Missing required argument \"hasher\"');\n  const value = codec.decode(bytes$1);\n  const hash = await hasher.digest(bytes$1);\n\n  if (!bytes.equals(cid.multihash.bytes, hash.bytes)) {\n    throw new Error('CID hash does not match bytes');\n  }\n\n  return createUnsafe({\n    bytes: bytes$1,\n    cid,\n    value,\n    codec\n  });\n};\n\nexports.Block = Block;\nexports.create = create;\nexports.createUnsafe = createUnsafe;\nexports.decode = decode;\nexports.encode = encode;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/block.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/bytes.js":
/*!****************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/bytes.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nconst empty = new Uint8Array(0);\n\nconst toHex = d => d.reduce((hex, byte) => hex + byte.toString(16).padStart(2, '0'), '');\n\nconst fromHex = hex => {\n  const hexes = hex.match(/../g);\n  return hexes ? new Uint8Array(hexes.map(b => parseInt(b, 16))) : empty;\n};\n\nconst equals = (aa, bb) => {\n  if (aa === bb) return true;\n\n  if (aa.byteLength !== bb.byteLength) {\n    return false;\n  }\n\n  for (let ii = 0; ii < aa.byteLength; ii++) {\n    if (aa[ii] !== bb[ii]) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\nconst coerce = o => {\n  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o;\n  if (o instanceof ArrayBuffer) return new Uint8Array(o);\n\n  if (ArrayBuffer.isView(o)) {\n    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);\n  }\n\n  throw new Error('Unknown type, must be binary type');\n};\n\nconst isBinary = o => o instanceof ArrayBuffer || ArrayBuffer.isView(o);\n\nconst fromString = str => new TextEncoder().encode(str);\n\nconst toString = b => new TextDecoder().decode(b);\n\nexports.coerce = coerce;\nexports.empty = empty;\nexports.equals = equals;\nexports.fromHex = fromHex;\nexports.fromString = fromString;\nexports.isBinary = isBinary;\nexports.toHex = toHex;\nexports.toString = toString;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/bytes.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/cid.js":
/*!**************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/cid.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar varint = __webpack_require__(/*! ./varint.js */ \"./node_modules/multiformats/cjs/src/varint.js\");\n\nvar digest = __webpack_require__(/*! ./hashes/digest.js */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nvar base58 = __webpack_require__(/*! ./bases/base58.js */ \"./node_modules/multiformats/cjs/src/bases/base58.js\");\n\nvar base32 = __webpack_require__(/*! ./bases/base32.js */ \"./node_modules/multiformats/cjs/src/bases/base32.js\");\n\nvar bytes = __webpack_require__(/*! ./bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nclass CID {\n  constructor(version, code, multihash, bytes) {\n    this.code = code;\n    this.version = version;\n    this.multihash = multihash;\n    this.bytes = bytes;\n    this.byteOffset = bytes.byteOffset;\n    this.byteLength = bytes.byteLength;\n    this.asCID = this;\n    this._baseCache = new Map();\n    Object.defineProperties(this, {\n      byteOffset: hidden,\n      byteLength: hidden,\n      code: readonly,\n      version: readonly,\n      multihash: readonly,\n      bytes: readonly,\n      _baseCache: hidden,\n      asCID: hidden\n    });\n  }\n\n  toV0() {\n    switch (this.version) {\n      case 0:\n        {\n          return this;\n        }\n\n      default:\n        {\n          const {\n            code,\n            multihash\n          } = this;\n\n          if (code !== DAG_PB_CODE) {\n            throw new Error('Cannot convert a non dag-pb CID to CIDv0');\n          }\n\n          if (multihash.code !== SHA_256_CODE) {\n            throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0');\n          }\n\n          return CID.createV0(multihash);\n        }\n    }\n  }\n\n  toV1() {\n    switch (this.version) {\n      case 0:\n        {\n          const {\n            code,\n            digest: digest$1\n          } = this.multihash;\n          const multihash = digest.create(code, digest$1);\n          return CID.createV1(this.code, multihash);\n        }\n\n      case 1:\n        {\n          return this;\n        }\n\n      default:\n        {\n          throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);\n        }\n    }\n  }\n\n  equals(other) {\n    return other && this.code === other.code && this.version === other.version && digest.equals(this.multihash, other.multihash);\n  }\n\n  toString(base) {\n    const {\n      bytes,\n      version,\n      _baseCache\n    } = this;\n\n    switch (version) {\n      case 0:\n        return toStringV0(bytes, _baseCache, base || base58.base58btc.encoder);\n\n      default:\n        return toStringV1(bytes, _baseCache, base || base32.base32.encoder);\n    }\n  }\n\n  toJSON() {\n    return {\n      code: this.code,\n      version: this.version,\n      hash: this.multihash.bytes\n    };\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'CID';\n  }\n\n  [Symbol.for('nodejs.util.inspect.custom')]() {\n    return 'CID(' + this.toString() + ')';\n  }\n\n  static isCID(value) {\n    deprecate(/^0\\.0/, IS_CID_DEPRECATION);\n    return !!(value && (value[cidSymbol] || value.asCID === value));\n  }\n\n  get toBaseEncodedString() {\n    throw new Error('Deprecated, use .toString()');\n  }\n\n  get codec() {\n    throw new Error('\"codec\" property is deprecated, use integer \"code\" property instead');\n  }\n\n  get buffer() {\n    throw new Error('Deprecated .buffer property, use .bytes to get Uint8Array instead');\n  }\n\n  get multibaseName() {\n    throw new Error('\"multibaseName\" property is deprecated');\n  }\n\n  get prefix() {\n    throw new Error('\"prefix\" property is deprecated');\n  }\n\n  static asCID(value) {\n    if (value instanceof CID) {\n      return value;\n    } else if (value != null && value.asCID === value) {\n      const {\n        version,\n        code,\n        multihash,\n        bytes\n      } = value;\n      return new CID(version, code, multihash, bytes || encodeCID(version, code, multihash.bytes));\n    } else if (value != null && value[cidSymbol] === true) {\n      const {\n        version,\n        multihash,\n        code\n      } = value;\n      const digest$1 = digest.decode(multihash);\n      return CID.create(version, code, digest$1);\n    } else {\n      return null;\n    }\n  }\n\n  static create(version, code, digest) {\n    if (typeof code !== 'number') {\n      throw new Error('String codecs are no longer supported');\n    }\n\n    switch (version) {\n      case 0:\n        {\n          if (code !== DAG_PB_CODE) {\n            throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`);\n          } else {\n            return new CID(version, code, digest, digest.bytes);\n          }\n        }\n\n      case 1:\n        {\n          const bytes = encodeCID(version, code, digest.bytes);\n          return new CID(version, code, digest, bytes);\n        }\n\n      default:\n        {\n          throw new Error('Invalid version');\n        }\n    }\n  }\n\n  static createV0(digest) {\n    return CID.create(0, DAG_PB_CODE, digest);\n  }\n\n  static createV1(code, digest) {\n    return CID.create(1, code, digest);\n  }\n\n  static decode(bytes) {\n    const [cid, remainder] = CID.decodeFirst(bytes);\n\n    if (remainder.length) {\n      throw new Error('Incorrect length');\n    }\n\n    return cid;\n  }\n\n  static decodeFirst(bytes$1) {\n    const specs = CID.inspectBytes(bytes$1);\n    const prefixSize = specs.size - specs.multihashSize;\n    const multihashBytes = bytes.coerce(bytes$1.subarray(prefixSize, prefixSize + specs.multihashSize));\n\n    if (multihashBytes.byteLength !== specs.multihashSize) {\n      throw new Error('Incorrect length');\n    }\n\n    const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);\n    const digest$1 = new digest.Digest(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);\n    const cid = specs.version === 0 ? CID.createV0(digest$1) : CID.createV1(specs.codec, digest$1);\n    return [cid, bytes$1.subarray(specs.size)];\n  }\n\n  static inspectBytes(initialBytes) {\n    let offset = 0;\n\n    const next = () => {\n      const [i, length] = varint.decode(initialBytes.subarray(offset));\n      offset += length;\n      return i;\n    };\n\n    let version = next();\n    let codec = DAG_PB_CODE;\n\n    if (version === 18) {\n      version = 0;\n      offset = 0;\n    } else if (version === 1) {\n      codec = next();\n    }\n\n    if (version !== 0 && version !== 1) {\n      throw new RangeError(`Invalid CID version ${version}`);\n    }\n\n    const prefixSize = offset;\n    const multihashCode = next();\n    const digestSize = next();\n    const size = offset + digestSize;\n    const multihashSize = size - prefixSize;\n    return {\n      version,\n      codec,\n      multihashCode,\n      digestSize,\n      multihashSize,\n      size\n    };\n  }\n\n  static parse(source, base) {\n    const [prefix, bytes] = parseCIDtoBytes(source, base);\n    const cid = CID.decode(bytes);\n\n    cid._baseCache.set(prefix, source);\n\n    return cid;\n  }\n\n}\n\nconst parseCIDtoBytes = (source, base) => {\n  switch (source[0]) {\n    case 'Q':\n      {\n        const decoder = base || base58.base58btc;\n        return [base58.base58btc.prefix, decoder.decode(`${base58.base58btc.prefix}${source}`)];\n      }\n\n    case base58.base58btc.prefix:\n      {\n        const decoder = base || base58.base58btc;\n        return [base58.base58btc.prefix, decoder.decode(source)];\n      }\n\n    case base32.base32.prefix:\n      {\n        const decoder = base || base32.base32;\n        return [base32.base32.prefix, decoder.decode(source)];\n      }\n\n    default:\n      {\n        if (base == null) {\n          throw Error('To parse non base32 or base58btc encoded CID multibase decoder must be provided');\n        }\n\n        return [source[0], base.decode(source)];\n      }\n  }\n};\n\nconst toStringV0 = (bytes, cache, base) => {\n  const {\n    prefix\n  } = base;\n\n  if (prefix !== base58.base58btc.prefix) {\n    throw Error(`Cannot string encode V0 in ${base.name} encoding`);\n  }\n\n  const cid = cache.get(prefix);\n\n  if (cid == null) {\n    const cid = base.encode(bytes).slice(1);\n    cache.set(prefix, cid);\n    return cid;\n  } else {\n    return cid;\n  }\n};\n\nconst toStringV1 = (bytes, cache, base) => {\n  const {\n    prefix\n  } = base;\n  const cid = cache.get(prefix);\n\n  if (cid == null) {\n    const cid = base.encode(bytes);\n    cache.set(prefix, cid);\n    return cid;\n  } else {\n    return cid;\n  }\n};\n\nconst DAG_PB_CODE = 112;\nconst SHA_256_CODE = 18;\n\nconst encodeCID = (version, code, multihash) => {\n  const codeOffset = varint.encodingLength(version);\n  const hashOffset = codeOffset + varint.encodingLength(code);\n  const bytes = new Uint8Array(hashOffset + multihash.byteLength);\n  varint.encodeTo(version, bytes, 0);\n  varint.encodeTo(code, bytes, codeOffset);\n  bytes.set(multihash, hashOffset);\n  return bytes;\n};\n\nconst cidSymbol = Symbol.for('@ipld/js-cid/CID');\nconst readonly = {\n  writable: false,\n  configurable: false,\n  enumerable: true\n};\nconst hidden = {\n  writable: false,\n  enumerable: false,\n  configurable: false\n};\nconst version = '0.0.0-dev';\n\nconst deprecate = (range, message) => {\n  if (range.test(version)) {\n    console.warn(message);\n  } else {\n    throw new Error(message);\n  }\n};\n\nconst IS_CID_DEPRECATION = `CID.isCID(v) is deprecated and will be removed in the next major release.\nFollowing code pattern:\n\nif (CID.isCID(value)) {\n  doSomethingWithCID(value)\n}\n\nIs replaced with:\n\nconst cid = CID.asCID(value)\nif (cid) {\n  // Make sure to use cid instead of value\n  doSomethingWithCID(cid)\n}\n`;\nexports.CID = CID;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/cid.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/codecs/json.js":
/*!**********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/codecs/json.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nconst textEncoder = new TextEncoder();\nconst textDecoder = new TextDecoder();\nconst name = 'json';\nconst code = 512;\n\nconst encode = node => textEncoder.encode(JSON.stringify(node));\n\nconst decode = data => JSON.parse(textDecoder.decode(data));\n\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/codecs/json.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/codecs/raw.js":
/*!*********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/codecs/raw.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar bytes = __webpack_require__(/*! ../bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nconst name = 'raw';\nconst code = 85;\n\nconst encode = node => bytes.coerce(node);\n\nconst decode = data => bytes.coerce(data);\n\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/codecs/raw.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/hashes/digest.js":
/*!************************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/hashes/digest.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar bytes = __webpack_require__(/*! ../bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nvar varint = __webpack_require__(/*! ../varint.js */ \"./node_modules/multiformats/cjs/src/varint.js\");\n\nconst create = (code, digest) => {\n  const size = digest.byteLength;\n  const sizeOffset = varint.encodingLength(code);\n  const digestOffset = sizeOffset + varint.encodingLength(size);\n  const bytes = new Uint8Array(digestOffset + size);\n  varint.encodeTo(code, bytes, 0);\n  varint.encodeTo(size, bytes, sizeOffset);\n  bytes.set(digest, digestOffset);\n  return new Digest(code, size, digest, bytes);\n};\n\nconst decode = multihash => {\n  const bytes$1 = bytes.coerce(multihash);\n  const [code, sizeOffset] = varint.decode(bytes$1);\n  const [size, digestOffset] = varint.decode(bytes$1.subarray(sizeOffset));\n  const digest = bytes$1.subarray(sizeOffset + digestOffset);\n\n  if (digest.byteLength !== size) {\n    throw new Error('Incorrect length');\n  }\n\n  return new Digest(code, size, digest, bytes$1);\n};\n\nconst equals = (a, b) => {\n  if (a === b) {\n    return true;\n  } else {\n    return a.code === b.code && a.size === b.size && bytes.equals(a.bytes, b.bytes);\n  }\n};\n\nclass Digest {\n  constructor(code, size, digest, bytes) {\n    this.code = code;\n    this.size = size;\n    this.digest = digest;\n    this.bytes = bytes;\n  }\n\n}\n\nexports.Digest = Digest;\nexports.create = create;\nexports.decode = decode;\nexports.equals = equals;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/hashes/digest.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/hashes/hasher.js":
/*!************************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/hashes/hasher.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar digest = __webpack_require__(/*! ./digest.js */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nconst from = ({\n  name,\n  code,\n  encode\n}) => new Hasher(name, code, encode);\n\nclass Hasher {\n  constructor(name, code, encode) {\n    this.name = name;\n    this.code = code;\n    this.encode = encode;\n  }\n\n  digest(input) {\n    if (input instanceof Uint8Array) {\n      const result = this.encode(input);\n      return result instanceof Uint8Array ? digest.create(this.code, result) : result.then(digest$1 => digest.create(this.code, digest$1));\n    } else {\n      throw Error('Unknown type, must be binary type');\n    }\n  }\n\n}\n\nexports.Hasher = Hasher;\nexports.from = from;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/hashes/hasher.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/hashes/identity.js":
/*!**************************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/hashes/identity.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar bytes = __webpack_require__(/*! ../bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nvar digest$1 = __webpack_require__(/*! ./digest.js */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nconst code = 0;\nconst name = 'identity';\nconst encode = bytes.coerce;\n\nconst digest = input => digest$1.create(code, encode(input));\n\nconst identity = {\n  code,\n  name,\n  encode,\n  digest\n};\nexports.identity = identity;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/hashes/identity.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/hashes/sha2.js":
/*!**********************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/hashes/sha2.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar crypto = __webpack_require__(/*! crypto */ \"crypto\");\n\nvar hasher = __webpack_require__(/*! ./hasher.js */ \"./node_modules/multiformats/cjs/src/hashes/hasher.js\");\n\nvar bytes = __webpack_require__(/*! ../bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nfunction _interopDefaultLegacy(e) {\n  return e && typeof e === 'object' && 'default' in e ? e : {\n    'default': e\n  };\n}\n\nvar crypto__default = /*#__PURE__*/_interopDefaultLegacy(crypto);\n\nconst sha256 = hasher.from({\n  name: 'sha2-256',\n  code: 18,\n  encode: input => bytes.coerce(crypto__default[\"default\"].createHash('sha256').update(input).digest())\n});\nconst sha512 = hasher.from({\n  name: 'sha2-512',\n  code: 19,\n  encode: input => bytes.coerce(crypto__default[\"default\"].createHash('sha512').update(input).digest())\n});\nexports.sha256 = sha256;\nexports.sha512 = sha512;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/hashes/sha2.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/index.js":
/*!****************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar cid = __webpack_require__(/*! ./cid.js */ \"./node_modules/multiformats/cjs/src/cid.js\");\n\nvar varint = __webpack_require__(/*! ./varint.js */ \"./node_modules/multiformats/cjs/src/varint.js\");\n\nvar bytes = __webpack_require__(/*! ./bytes.js */ \"./node_modules/multiformats/cjs/src/bytes.js\");\n\nvar hasher = __webpack_require__(/*! ./hashes/hasher.js */ \"./node_modules/multiformats/cjs/src/hashes/hasher.js\");\n\nvar digest = __webpack_require__(/*! ./hashes/digest.js */ \"./node_modules/multiformats/cjs/src/hashes/digest.js\");\n\nexports.CID = cid.CID;\nexports.varint = varint;\nexports.bytes = bytes;\nexports.hasher = hasher;\nexports.digest = digest;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/index.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/src/varint.js":
/*!*****************************************************!*\
  !*** ./node_modules/multiformats/cjs/src/varint.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar varint$1 = __webpack_require__(/*! ../vendor/varint.js */ \"./node_modules/multiformats/cjs/vendor/varint.js\");\n\nconst decode = data => {\n  const code = varint$1.decode(data);\n  return [code, varint$1.decode.bytes];\n};\n\nconst encodeTo = (int, target, offset = 0) => {\n  varint$1.encode(int, target, offset);\n  return target;\n};\n\nconst encodingLength = int => {\n  return varint$1.encodingLength(int);\n};\n\nexports.decode = decode;\nexports.encodeTo = encodeTo;\nexports.encodingLength = encodingLength;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/src/varint.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/vendor/base-x.js":
/*!********************************************************!*\
  !*** ./node_modules/multiformats/cjs/vendor/base-x.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction base(ALPHABET, name) {\n  if (ALPHABET.length >= 255) {\n    throw new TypeError('Alphabet too long');\n  }\n\n  var BASE_MAP = new Uint8Array(256);\n\n  for (var j = 0; j < BASE_MAP.length; j++) {\n    BASE_MAP[j] = 255;\n  }\n\n  for (var i = 0; i < ALPHABET.length; i++) {\n    var x = ALPHABET.charAt(i);\n    var xc = x.charCodeAt(0);\n\n    if (BASE_MAP[xc] !== 255) {\n      throw new TypeError(x + ' is ambiguous');\n    }\n\n    BASE_MAP[xc] = i;\n  }\n\n  var BASE = ALPHABET.length;\n  var LEADER = ALPHABET.charAt(0);\n  var FACTOR = Math.log(BASE) / Math.log(256);\n  var iFACTOR = Math.log(256) / Math.log(BASE);\n\n  function encode(source) {\n    if (source instanceof Uint8Array) ;else if (ArrayBuffer.isView(source)) {\n      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);\n    } else if (Array.isArray(source)) {\n      source = Uint8Array.from(source);\n    }\n\n    if (!(source instanceof Uint8Array)) {\n      throw new TypeError('Expected Uint8Array');\n    }\n\n    if (source.length === 0) {\n      return '';\n    }\n\n    var zeroes = 0;\n    var length = 0;\n    var pbegin = 0;\n    var pend = source.length;\n\n    while (pbegin !== pend && source[pbegin] === 0) {\n      pbegin++;\n      zeroes++;\n    }\n\n    var size = (pend - pbegin) * iFACTOR + 1 >>> 0;\n    var b58 = new Uint8Array(size);\n\n    while (pbegin !== pend) {\n      var carry = source[pbegin];\n      var i = 0;\n\n      for (var it1 = size - 1; (carry !== 0 || i < length) && it1 !== -1; it1--, i++) {\n        carry += 256 * b58[it1] >>> 0;\n        b58[it1] = carry % BASE >>> 0;\n        carry = carry / BASE >>> 0;\n      }\n\n      if (carry !== 0) {\n        throw new Error('Non-zero carry');\n      }\n\n      length = i;\n      pbegin++;\n    }\n\n    var it2 = size - length;\n\n    while (it2 !== size && b58[it2] === 0) {\n      it2++;\n    }\n\n    var str = LEADER.repeat(zeroes);\n\n    for (; it2 < size; ++it2) {\n      str += ALPHABET.charAt(b58[it2]);\n    }\n\n    return str;\n  }\n\n  function decodeUnsafe(source) {\n    if (typeof source !== 'string') {\n      throw new TypeError('Expected String');\n    }\n\n    if (source.length === 0) {\n      return new Uint8Array();\n    }\n\n    var psz = 0;\n\n    if (source[psz] === ' ') {\n      return;\n    }\n\n    var zeroes = 0;\n    var length = 0;\n\n    while (source[psz] === LEADER) {\n      zeroes++;\n      psz++;\n    }\n\n    var size = (source.length - psz) * FACTOR + 1 >>> 0;\n    var b256 = new Uint8Array(size);\n\n    while (source[psz]) {\n      var carry = BASE_MAP[source.charCodeAt(psz)];\n\n      if (carry === 255) {\n        return;\n      }\n\n      var i = 0;\n\n      for (var it3 = size - 1; (carry !== 0 || i < length) && it3 !== -1; it3--, i++) {\n        carry += BASE * b256[it3] >>> 0;\n        b256[it3] = carry % 256 >>> 0;\n        carry = carry / 256 >>> 0;\n      }\n\n      if (carry !== 0) {\n        throw new Error('Non-zero carry');\n      }\n\n      length = i;\n      psz++;\n    }\n\n    if (source[psz] === ' ') {\n      return;\n    }\n\n    var it4 = size - length;\n\n    while (it4 !== size && b256[it4] === 0) {\n      it4++;\n    }\n\n    var vch = new Uint8Array(zeroes + (size - it4));\n    var j = zeroes;\n\n    while (it4 !== size) {\n      vch[j++] = b256[it4++];\n    }\n\n    return vch;\n  }\n\n  function decode(string) {\n    var buffer = decodeUnsafe(string);\n\n    if (buffer) {\n      return buffer;\n    }\n\n    throw new Error(`Non-${name} character`);\n  }\n\n  return {\n    encode: encode,\n    decodeUnsafe: decodeUnsafe,\n    decode: decode\n  };\n}\n\nvar src = base;\nvar _brrp__multiformats_scope_baseX = src;\nmodule.exports = _brrp__multiformats_scope_baseX;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/vendor/base-x.js?");

/***/ }),

/***/ "./node_modules/multiformats/cjs/vendor/varint.js":
/*!********************************************************!*\
  !*** ./node_modules/multiformats/cjs/vendor/varint.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar encode_1 = encode;\nvar MSB = 128,\n    REST = 127,\n    MSBALL = ~REST,\n    INT = Math.pow(2, 31);\n\nfunction encode(num, out, offset) {\n  out = out || [];\n  offset = offset || 0;\n  var oldOffset = offset;\n\n  while (num >= INT) {\n    out[offset++] = num & 255 | MSB;\n    num /= 128;\n  }\n\n  while (num & MSBALL) {\n    out[offset++] = num & 255 | MSB;\n    num >>>= 7;\n  }\n\n  out[offset] = num | 0;\n  encode.bytes = offset - oldOffset + 1;\n  return out;\n}\n\nvar decode = read;\nvar MSB$1 = 128,\n    REST$1 = 127;\n\nfunction read(buf, offset) {\n  var res = 0,\n      offset = offset || 0,\n      shift = 0,\n      counter = offset,\n      b,\n      l = buf.length;\n\n  do {\n    if (counter >= l) {\n      read.bytes = 0;\n      throw new RangeError('Could not decode varint');\n    }\n\n    b = buf[counter++];\n    res += shift < 28 ? (b & REST$1) << shift : (b & REST$1) * Math.pow(2, shift);\n    shift += 7;\n  } while (b >= MSB$1);\n\n  read.bytes = counter - offset;\n  return res;\n}\n\nvar N1 = Math.pow(2, 7);\nvar N2 = Math.pow(2, 14);\nvar N3 = Math.pow(2, 21);\nvar N4 = Math.pow(2, 28);\nvar N5 = Math.pow(2, 35);\nvar N6 = Math.pow(2, 42);\nvar N7 = Math.pow(2, 49);\nvar N8 = Math.pow(2, 56);\nvar N9 = Math.pow(2, 63);\n\nvar length = function (value) {\n  return value < N1 ? 1 : value < N2 ? 2 : value < N3 ? 3 : value < N4 ? 4 : value < N5 ? 5 : value < N6 ? 6 : value < N7 ? 7 : value < N8 ? 8 : value < N9 ? 9 : 10;\n};\n\nvar varint = {\n  encode: encode_1,\n  decode: decode,\n  encodingLength: length\n};\nvar _brrp_varint = varint;\nvar varint$1 = _brrp_varint;\nmodule.exports = varint$1;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/multiformats/cjs/vendor/varint.js?");

/***/ }),

/***/ "./node_modules/murmurhash3js-revisited/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/murmurhash3js-revisited/index.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! ./lib/murmurHash3js */ \"./node_modules/murmurhash3js-revisited/lib/murmurHash3js.js\");\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/murmurhash3js-revisited/index.js?");

/***/ }),

/***/ "./node_modules/murmurhash3js-revisited/lib/murmurHash3js.js":
/*!*******************************************************************!*\
  !*** ./node_modules/murmurhash3js-revisited/lib/murmurHash3js.js ***!
  \*******************************************************************/
/***/ (function(module, exports) {

eval("/* jshint -W086: true */\n// +----------------------------------------------------------------------+\n// | murmurHash3js.js v3.0.1 // https://github.com/pid/murmurHash3js\n// | A javascript implementation of MurmurHash3's x86 hashing algorithms. |\n// |----------------------------------------------------------------------|\n// | Copyright (c) 2012-2015 Karan Lyons                                       |\n// | https://github.com/karanlyons/murmurHash3.js/blob/c1778f75792abef7bdd74bc85d2d4e1a3d25cfe9/murmurHash3.js |\n// | Freely distributable under the MIT license.                          |\n// +----------------------------------------------------------------------+\n;\n\n(function (root, undefined) {\n  'use strict'; // Create a local object that'll be exported or referenced globally.\n\n  var library = {\n    'version': '3.0.0',\n    'x86': {},\n    'x64': {},\n    'inputValidation': true\n  }; // PRIVATE FUNCTIONS\n  // -----------------\n\n  function _validBytes(bytes) {\n    // check the input is an array or a typed array\n    if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {\n      return false;\n    } // check all bytes are actually bytes\n\n\n    for (var i = 0; i < bytes.length; i++) {\n      if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  function _x86Multiply(m, n) {\n    //\n    // Given two 32bit ints, returns the two multiplied together as a\n    // 32bit int.\n    //\n    return (m & 0xffff) * n + (((m >>> 16) * n & 0xffff) << 16);\n  }\n\n  function _x86Rotl(m, n) {\n    //\n    // Given a 32bit int and an int representing a number of bit positions,\n    // returns the 32bit int rotated left by that number of positions.\n    //\n    return m << n | m >>> 32 - n;\n  }\n\n  function _x86Fmix(h) {\n    //\n    // Given a block, returns murmurHash3's final x86 mix of that block.\n    //\n    h ^= h >>> 16;\n    h = _x86Multiply(h, 0x85ebca6b);\n    h ^= h >>> 13;\n    h = _x86Multiply(h, 0xc2b2ae35);\n    h ^= h >>> 16;\n    return h;\n  }\n\n  function _x64Add(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // added together as a 64bit int (as an array of two 32bit ints).\n    //\n    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n    var o = [0, 0, 0, 0];\n    o[3] += m[3] + n[3];\n    o[2] += o[3] >>> 16;\n    o[3] &= 0xffff;\n    o[2] += m[2] + n[2];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[1] += m[1] + n[1];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[0] += m[0] + n[0];\n    o[0] &= 0xffff;\n    return [o[0] << 16 | o[1], o[2] << 16 | o[3]];\n  }\n\n  function _x64Multiply(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // multiplied together as a 64bit int (as an array of two 32bit ints).\n    //\n    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n    var o = [0, 0, 0, 0];\n    o[3] += m[3] * n[3];\n    o[2] += o[3] >>> 16;\n    o[3] &= 0xffff;\n    o[2] += m[2] * n[3];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[2] += m[3] * n[2];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[1] += m[1] * n[3];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[1] += m[2] * n[2];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[1] += m[3] * n[1];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];\n    o[0] &= 0xffff;\n    return [o[0] << 16 | o[1], o[2] << 16 | o[3]];\n  }\n\n  function _x64Rotl(m, n) {\n    //\n    // Given a 64bit int (as an array of two 32bit ints) and an int\n    // representing a number of bit positions, returns the 64bit int (as an\n    // array of two 32bit ints) rotated left by that number of positions.\n    //\n    n %= 64;\n\n    if (n === 32) {\n      return [m[1], m[0]];\n    } else if (n < 32) {\n      return [m[0] << n | m[1] >>> 32 - n, m[1] << n | m[0] >>> 32 - n];\n    } else {\n      n -= 32;\n      return [m[1] << n | m[0] >>> 32 - n, m[0] << n | m[1] >>> 32 - n];\n    }\n  }\n\n  function _x64LeftShift(m, n) {\n    //\n    // Given a 64bit int (as an array of two 32bit ints) and an int\n    // representing a number of bit positions, returns the 64bit int (as an\n    // array of two 32bit ints) shifted left by that number of positions.\n    //\n    n %= 64;\n\n    if (n === 0) {\n      return m;\n    } else if (n < 32) {\n      return [m[0] << n | m[1] >>> 32 - n, m[1] << n];\n    } else {\n      return [m[1] << n - 32, 0];\n    }\n  }\n\n  function _x64Xor(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // xored together as a 64bit int (as an array of two 32bit ints).\n    //\n    return [m[0] ^ n[0], m[1] ^ n[1]];\n  }\n\n  function _x64Fmix(h) {\n    //\n    // Given a block, returns murmurHash3's final x64 mix of that block.\n    // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n    // only place where we need to right shift 64bit ints.)\n    //\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    return h;\n  } // PUBLIC FUNCTIONS\n  // ----------------\n\n\n  library.x86.hash32 = function (bytes, seed) {\n    //\n    // Given a string and an optional seed as an int, returns a 32 bit hash\n    // using the x86 flavor of MurmurHash3, as an unsigned int.\n    //\n    if (library.inputValidation && !_validBytes(bytes)) {\n      return undefined;\n    }\n\n    seed = seed || 0;\n    var remainder = bytes.length % 4;\n    var blocks = bytes.length - remainder;\n    var h1 = seed;\n    var k1 = 0;\n    var c1 = 0xcc9e2d51;\n    var c2 = 0x1b873593;\n\n    for (var i = 0; i < blocks; i = i + 4) {\n      k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;\n      k1 = _x86Multiply(k1, c1);\n      k1 = _x86Rotl(k1, 15);\n      k1 = _x86Multiply(k1, c2);\n      h1 ^= k1;\n      h1 = _x86Rotl(h1, 13);\n      h1 = _x86Multiply(h1, 5) + 0xe6546b64;\n    }\n\n    k1 = 0;\n\n    switch (remainder) {\n      case 3:\n        k1 ^= bytes[i + 2] << 16;\n\n      case 2:\n        k1 ^= bytes[i + 1] << 8;\n\n      case 1:\n        k1 ^= bytes[i];\n        k1 = _x86Multiply(k1, c1);\n        k1 = _x86Rotl(k1, 15);\n        k1 = _x86Multiply(k1, c2);\n        h1 ^= k1;\n    }\n\n    h1 ^= bytes.length;\n    h1 = _x86Fmix(h1);\n    return h1 >>> 0;\n  };\n\n  library.x86.hash128 = function (bytes, seed) {\n    //\n    // Given a string and an optional seed as an int, returns a 128 bit\n    // hash using the x86 flavor of MurmurHash3, as an unsigned hex.\n    //\n    if (library.inputValidation && !_validBytes(bytes)) {\n      return undefined;\n    }\n\n    seed = seed || 0;\n    var remainder = bytes.length % 16;\n    var blocks = bytes.length - remainder;\n    var h1 = seed;\n    var h2 = seed;\n    var h3 = seed;\n    var h4 = seed;\n    var k1 = 0;\n    var k2 = 0;\n    var k3 = 0;\n    var k4 = 0;\n    var c1 = 0x239b961b;\n    var c2 = 0xab0e9789;\n    var c3 = 0x38b34ae5;\n    var c4 = 0xa1e38b93;\n\n    for (var i = 0; i < blocks; i = i + 16) {\n      k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;\n      k2 = bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24;\n      k3 = bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24;\n      k4 = bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24;\n      k1 = _x86Multiply(k1, c1);\n      k1 = _x86Rotl(k1, 15);\n      k1 = _x86Multiply(k1, c2);\n      h1 ^= k1;\n      h1 = _x86Rotl(h1, 19);\n      h1 += h2;\n      h1 = _x86Multiply(h1, 5) + 0x561ccd1b;\n      k2 = _x86Multiply(k2, c2);\n      k2 = _x86Rotl(k2, 16);\n      k2 = _x86Multiply(k2, c3);\n      h2 ^= k2;\n      h2 = _x86Rotl(h2, 17);\n      h2 += h3;\n      h2 = _x86Multiply(h2, 5) + 0x0bcaa747;\n      k3 = _x86Multiply(k3, c3);\n      k3 = _x86Rotl(k3, 17);\n      k3 = _x86Multiply(k3, c4);\n      h3 ^= k3;\n      h3 = _x86Rotl(h3, 15);\n      h3 += h4;\n      h3 = _x86Multiply(h3, 5) + 0x96cd1c35;\n      k4 = _x86Multiply(k4, c4);\n      k4 = _x86Rotl(k4, 18);\n      k4 = _x86Multiply(k4, c1);\n      h4 ^= k4;\n      h4 = _x86Rotl(h4, 13);\n      h4 += h1;\n      h4 = _x86Multiply(h4, 5) + 0x32ac3b17;\n    }\n\n    k1 = 0;\n    k2 = 0;\n    k3 = 0;\n    k4 = 0;\n\n    switch (remainder) {\n      case 15:\n        k4 ^= bytes[i + 14] << 16;\n\n      case 14:\n        k4 ^= bytes[i + 13] << 8;\n\n      case 13:\n        k4 ^= bytes[i + 12];\n        k4 = _x86Multiply(k4, c4);\n        k4 = _x86Rotl(k4, 18);\n        k4 = _x86Multiply(k4, c1);\n        h4 ^= k4;\n\n      case 12:\n        k3 ^= bytes[i + 11] << 24;\n\n      case 11:\n        k3 ^= bytes[i + 10] << 16;\n\n      case 10:\n        k3 ^= bytes[i + 9] << 8;\n\n      case 9:\n        k3 ^= bytes[i + 8];\n        k3 = _x86Multiply(k3, c3);\n        k3 = _x86Rotl(k3, 17);\n        k3 = _x86Multiply(k3, c4);\n        h3 ^= k3;\n\n      case 8:\n        k2 ^= bytes[i + 7] << 24;\n\n      case 7:\n        k2 ^= bytes[i + 6] << 16;\n\n      case 6:\n        k2 ^= bytes[i + 5] << 8;\n\n      case 5:\n        k2 ^= bytes[i + 4];\n        k2 = _x86Multiply(k2, c2);\n        k2 = _x86Rotl(k2, 16);\n        k2 = _x86Multiply(k2, c3);\n        h2 ^= k2;\n\n      case 4:\n        k1 ^= bytes[i + 3] << 24;\n\n      case 3:\n        k1 ^= bytes[i + 2] << 16;\n\n      case 2:\n        k1 ^= bytes[i + 1] << 8;\n\n      case 1:\n        k1 ^= bytes[i];\n        k1 = _x86Multiply(k1, c1);\n        k1 = _x86Rotl(k1, 15);\n        k1 = _x86Multiply(k1, c2);\n        h1 ^= k1;\n    }\n\n    h1 ^= bytes.length;\n    h2 ^= bytes.length;\n    h3 ^= bytes.length;\n    h4 ^= bytes.length;\n    h1 += h2;\n    h1 += h3;\n    h1 += h4;\n    h2 += h1;\n    h3 += h1;\n    h4 += h1;\n    h1 = _x86Fmix(h1);\n    h2 = _x86Fmix(h2);\n    h3 = _x86Fmix(h3);\n    h4 = _x86Fmix(h4);\n    h1 += h2;\n    h1 += h3;\n    h1 += h4;\n    h2 += h1;\n    h3 += h1;\n    h4 += h1;\n    return (\"00000000\" + (h1 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h3 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h4 >>> 0).toString(16)).slice(-8);\n  };\n\n  library.x64.hash128 = function (bytes, seed) {\n    //\n    // Given a string and an optional seed as an int, returns a 128 bit\n    // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n    //\n    if (library.inputValidation && !_validBytes(bytes)) {\n      return undefined;\n    }\n\n    seed = seed || 0;\n    var remainder = bytes.length % 16;\n    var blocks = bytes.length - remainder;\n    var h1 = [0, seed];\n    var h2 = [0, seed];\n    var k1 = [0, 0];\n    var k2 = [0, 0];\n    var c1 = [0x87c37b91, 0x114253d5];\n    var c2 = [0x4cf5ad43, 0x2745937f];\n\n    for (var i = 0; i < blocks; i = i + 16) {\n      k1 = [bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24, bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24];\n      k2 = [bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24, bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24];\n      k1 = _x64Multiply(k1, c1);\n      k1 = _x64Rotl(k1, 31);\n      k1 = _x64Multiply(k1, c2);\n      h1 = _x64Xor(h1, k1);\n      h1 = _x64Rotl(h1, 27);\n      h1 = _x64Add(h1, h2);\n      h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n      k2 = _x64Multiply(k2, c2);\n      k2 = _x64Rotl(k2, 33);\n      k2 = _x64Multiply(k2, c1);\n      h2 = _x64Xor(h2, k2);\n      h2 = _x64Rotl(h2, 31);\n      h2 = _x64Add(h2, h1);\n      h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n    }\n\n    k1 = [0, 0];\n    k2 = [0, 0];\n\n    switch (remainder) {\n      case 15:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));\n\n      case 14:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));\n\n      case 13:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));\n\n      case 12:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));\n\n      case 11:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));\n\n      case 10:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));\n\n      case 9:\n        k2 = _x64Xor(k2, [0, bytes[i + 8]]);\n        k2 = _x64Multiply(k2, c2);\n        k2 = _x64Rotl(k2, 33);\n        k2 = _x64Multiply(k2, c1);\n        h2 = _x64Xor(h2, k2);\n\n      case 8:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));\n\n      case 7:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));\n\n      case 6:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));\n\n      case 5:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));\n\n      case 4:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));\n\n      case 3:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));\n\n      case 2:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));\n\n      case 1:\n        k1 = _x64Xor(k1, [0, bytes[i]]);\n        k1 = _x64Multiply(k1, c1);\n        k1 = _x64Rotl(k1, 31);\n        k1 = _x64Multiply(k1, c2);\n        h1 = _x64Xor(h1, k1);\n    }\n\n    h1 = _x64Xor(h1, [0, bytes.length]);\n    h2 = _x64Xor(h2, [0, bytes.length]);\n    h1 = _x64Add(h1, h2);\n    h2 = _x64Add(h2, h1);\n    h1 = _x64Fmix(h1);\n    h2 = _x64Fmix(h2);\n    h1 = _x64Add(h1, h2);\n    h2 = _x64Add(h2, h1);\n    return (\"00000000\" + (h1[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h1[1] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[1] >>> 0).toString(16)).slice(-8);\n  }; // INITIALIZATION\n  // --------------\n  // Export murmurHash3 for CommonJS, either as an AMD module or just as part\n  // of the global object.\n\n\n  if (true) {\n    if ( true && module.exports) {\n      exports = module.exports = library;\n    }\n\n    exports.murmurHash3 = library;\n  } else {}\n})(this);\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/murmurhash3js-revisited/lib/murmurHash3js.js?");

/***/ }),

/***/ "./node_modules/p-retry/index.js":
/*!***************************************!*\
  !*** ./node_modules/p-retry/index.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst retry = __webpack_require__(/*! retry */ \"./node_modules/retry/index.js\");\n\nconst networkErrorMsgs = ['Failed to fetch', // Chrome\n'NetworkError when attempting to fetch resource.', // Firefox\n'The Internet connection appears to be offline.', // Safari\n'Network request failed' // `cross-fetch`\n];\n\nclass AbortError extends Error {\n  constructor(message) {\n    super();\n\n    if (message instanceof Error) {\n      this.originalError = message;\n      ({\n        message\n      } = message);\n    } else {\n      this.originalError = new Error(message);\n      this.originalError.stack = this.stack;\n    }\n\n    this.name = 'AbortError';\n    this.message = message;\n  }\n\n}\n\nconst decorateErrorWithCounts = (error, attemptNumber, options) => {\n  // Minus 1 from attemptNumber because the first attempt does not count as a retry\n  const retriesLeft = options.retries - (attemptNumber - 1);\n  error.attemptNumber = attemptNumber;\n  error.retriesLeft = retriesLeft;\n  return error;\n};\n\nconst isNetworkError = errorMessage => networkErrorMsgs.includes(errorMessage);\n\nconst pRetry = (input, options) => new Promise((resolve, reject) => {\n  options = {\n    onFailedAttempt: () => {},\n    retries: 10,\n    ...options\n  };\n  const operation = retry.operation(options);\n  operation.attempt(async attemptNumber => {\n    try {\n      resolve(await input(attemptNumber));\n    } catch (error) {\n      if (!(error instanceof Error)) {\n        reject(new TypeError(`Non-error was thrown: \"${error}\". You should only throw errors.`));\n        return;\n      }\n\n      if (error instanceof AbortError) {\n        operation.stop();\n        reject(error.originalError);\n      } else if (error instanceof TypeError && !isNetworkError(error.message)) {\n        operation.stop();\n        reject(error);\n      } else {\n        decorateErrorWithCounts(error, attemptNumber, options);\n\n        try {\n          await options.onFailedAttempt(error);\n        } catch (error) {\n          reject(error);\n          return;\n        }\n\n        if (!operation.retry(error)) {\n          reject(operation.mainError());\n        }\n      }\n    }\n  });\n});\n\nmodule.exports = pRetry; // TODO: remove this in the next major version\n\nmodule.exports[\"default\"] = pRetry;\nmodule.exports.AbortError = AbortError;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/p-retry/index.js?");

/***/ }),

/***/ "./node_modules/protobufjs/minimal.js":
/*!********************************************!*\
  !*** ./node_modules/protobufjs/minimal.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// minimal library entry point.\n\n\nmodule.exports = __webpack_require__(/*! ./src/index-minimal */ \"./node_modules/protobufjs/src/index-minimal.js\");\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/minimal.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/index-minimal.js":
/*!******************************************************!*\
  !*** ./node_modules/protobufjs/src/index-minimal.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nvar protobuf = exports;\n/**\n * Build type, one of `\"full\"`, `\"light\"` or `\"minimal\"`.\n * @name build\n * @type {string}\n * @const\n */\n\nprotobuf.build = \"minimal\"; // Serialization\n\nprotobuf.Writer = __webpack_require__(/*! ./writer */ \"./node_modules/protobufjs/src/writer.js\");\nprotobuf.BufferWriter = __webpack_require__(/*! ./writer_buffer */ \"./node_modules/protobufjs/src/writer_buffer.js\");\nprotobuf.Reader = __webpack_require__(/*! ./reader */ \"./node_modules/protobufjs/src/reader.js\");\nprotobuf.BufferReader = __webpack_require__(/*! ./reader_buffer */ \"./node_modules/protobufjs/src/reader_buffer.js\"); // Utility\n\nprotobuf.util = __webpack_require__(/*! ./util/minimal */ \"./node_modules/protobufjs/src/util/minimal.js\");\nprotobuf.rpc = __webpack_require__(/*! ./rpc */ \"./node_modules/protobufjs/src/rpc.js\");\nprotobuf.roots = __webpack_require__(/*! ./roots */ \"./node_modules/protobufjs/src/roots.js\");\nprotobuf.configure = configure;\n/* istanbul ignore next */\n\n/**\n * Reconfigures the library according to the environment.\n * @returns {undefined}\n */\n\nfunction configure() {\n  protobuf.util._configure();\n\n  protobuf.Writer._configure(protobuf.BufferWriter);\n\n  protobuf.Reader._configure(protobuf.BufferReader);\n} // Set up buffer utility according to the environment\n\n\nconfigure();\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/index-minimal.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/reader.js":
/*!***********************************************!*\
  !*** ./node_modules/protobufjs/src/reader.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = Reader;\n\nvar util = __webpack_require__(/*! ./util/minimal */ \"./node_modules/protobufjs/src/util/minimal.js\");\n\nvar BufferReader; // cyclic\n\nvar LongBits = util.LongBits,\n    utf8 = util.utf8;\n/* istanbul ignore next */\n\nfunction indexOutOfRange(reader, writeLength) {\n  return RangeError(\"index out of range: \" + reader.pos + \" + \" + (writeLength || 1) + \" > \" + reader.len);\n}\n/**\n * Constructs a new reader instance using the specified buffer.\n * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.\n * @constructor\n * @param {Uint8Array} buffer Buffer to read from\n */\n\n\nfunction Reader(buffer) {\n  /**\n   * Read buffer.\n   * @type {Uint8Array}\n   */\n  this.buf = buffer;\n  /**\n   * Read buffer position.\n   * @type {number}\n   */\n\n  this.pos = 0;\n  /**\n   * Read buffer length.\n   * @type {number}\n   */\n\n  this.len = buffer.length;\n}\n\nvar create_array = typeof Uint8Array !== \"undefined\" ? function create_typed_array(buffer) {\n  if (buffer instanceof Uint8Array || Array.isArray(buffer)) return new Reader(buffer);\n  throw Error(\"illegal buffer\");\n}\n/* istanbul ignore next */\n: function create_array(buffer) {\n  if (Array.isArray(buffer)) return new Reader(buffer);\n  throw Error(\"illegal buffer\");\n};\n\nvar create = function create() {\n  return util.Buffer ? function create_buffer_setup(buffer) {\n    return (Reader.create = function create_buffer(buffer) {\n      return util.Buffer.isBuffer(buffer) ? new BufferReader(buffer)\n      /* istanbul ignore next */\n      : create_array(buffer);\n    })(buffer);\n  }\n  /* istanbul ignore next */\n  : create_array;\n};\n/**\n * Creates a new reader using the specified buffer.\n * @function\n * @param {Uint8Array|Buffer} buffer Buffer to read from\n * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}\n * @throws {Error} If `buffer` is not a valid buffer\n */\n\n\nReader.create = create();\nReader.prototype._slice = util.Array.prototype.subarray ||\n/* istanbul ignore next */\nutil.Array.prototype.slice;\n/**\n * Reads a varint as an unsigned 32 bit value.\n * @function\n * @returns {number} Value read\n */\n\nReader.prototype.uint32 = function read_uint32_setup() {\n  var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)\n\n  return function read_uint32() {\n    value = (this.buf[this.pos] & 127) >>> 0;\n    if (this.buf[this.pos++] < 128) return value;\n    value = (value | (this.buf[this.pos] & 127) << 7) >>> 0;\n    if (this.buf[this.pos++] < 128) return value;\n    value = (value | (this.buf[this.pos] & 127) << 14) >>> 0;\n    if (this.buf[this.pos++] < 128) return value;\n    value = (value | (this.buf[this.pos] & 127) << 21) >>> 0;\n    if (this.buf[this.pos++] < 128) return value;\n    value = (value | (this.buf[this.pos] & 15) << 28) >>> 0;\n    if (this.buf[this.pos++] < 128) return value;\n    /* istanbul ignore if */\n\n    if ((this.pos += 5) > this.len) {\n      this.pos = this.len;\n      throw indexOutOfRange(this, 10);\n    }\n\n    return value;\n  };\n}();\n/**\n * Reads a varint as a signed 32 bit value.\n * @returns {number} Value read\n */\n\n\nReader.prototype.int32 = function read_int32() {\n  return this.uint32() | 0;\n};\n/**\n * Reads a zig-zag encoded varint as a signed 32 bit value.\n * @returns {number} Value read\n */\n\n\nReader.prototype.sint32 = function read_sint32() {\n  var value = this.uint32();\n  return value >>> 1 ^ -(value & 1) | 0;\n};\n/* eslint-disable no-invalid-this */\n\n\nfunction readLongVarint() {\n  // tends to deopt with local vars for octet etc.\n  var bits = new LongBits(0, 0);\n  var i = 0;\n\n  if (this.len - this.pos > 4) {\n    // fast route (lo)\n    for (; i < 4; ++i) {\n      // 1st..4th\n      bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n      if (this.buf[this.pos++] < 128) return bits;\n    } // 5th\n\n\n    bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;\n    bits.hi = (bits.hi | (this.buf[this.pos] & 127) >> 4) >>> 0;\n    if (this.buf[this.pos++] < 128) return bits;\n    i = 0;\n  } else {\n    for (; i < 3; ++i) {\n      /* istanbul ignore if */\n      if (this.pos >= this.len) throw indexOutOfRange(this); // 1st..3th\n\n      bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n      if (this.buf[this.pos++] < 128) return bits;\n    } // 4th\n\n\n    bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;\n    return bits;\n  }\n\n  if (this.len - this.pos > 4) {\n    // fast route (hi)\n    for (; i < 5; ++i) {\n      // 6th..10th\n      bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n      if (this.buf[this.pos++] < 128) return bits;\n    }\n  } else {\n    for (; i < 5; ++i) {\n      /* istanbul ignore if */\n      if (this.pos >= this.len) throw indexOutOfRange(this); // 6th..10th\n\n      bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n      if (this.buf[this.pos++] < 128) return bits;\n    }\n  }\n  /* istanbul ignore next */\n\n\n  throw Error(\"invalid varint encoding\");\n}\n/* eslint-enable no-invalid-this */\n\n/**\n * Reads a varint as a signed 64 bit value.\n * @name Reader#int64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a varint as an unsigned 64 bit value.\n * @name Reader#uint64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a zig-zag encoded varint as a signed 64 bit value.\n * @name Reader#sint64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a varint as a boolean.\n * @returns {boolean} Value read\n */\n\n\nReader.prototype.bool = function read_bool() {\n  return this.uint32() !== 0;\n};\n\nfunction readFixed32_end(buf, end) {\n  // note that this uses `end`, not `pos`\n  return (buf[end - 4] | buf[end - 3] << 8 | buf[end - 2] << 16 | buf[end - 1] << 24) >>> 0;\n}\n/**\n * Reads fixed 32 bits as an unsigned 32 bit integer.\n * @returns {number} Value read\n */\n\n\nReader.prototype.fixed32 = function read_fixed32() {\n  /* istanbul ignore if */\n  if (this.pos + 4 > this.len) throw indexOutOfRange(this, 4);\n  return readFixed32_end(this.buf, this.pos += 4);\n};\n/**\n * Reads fixed 32 bits as a signed 32 bit integer.\n * @returns {number} Value read\n */\n\n\nReader.prototype.sfixed32 = function read_sfixed32() {\n  /* istanbul ignore if */\n  if (this.pos + 4 > this.len) throw indexOutOfRange(this, 4);\n  return readFixed32_end(this.buf, this.pos += 4) | 0;\n};\n/* eslint-disable no-invalid-this */\n\n\nfunction\n  /* this: Reader */\nreadFixed64() {\n  /* istanbul ignore if */\n  if (this.pos + 8 > this.len) throw indexOutOfRange(this, 8);\n  return new LongBits(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));\n}\n/* eslint-enable no-invalid-this */\n\n/**\n * Reads fixed 64 bits.\n * @name Reader#fixed64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads zig-zag encoded fixed 64 bits.\n * @name Reader#sfixed64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a float (32 bit) as a number.\n * @function\n * @returns {number} Value read\n */\n\n\nReader.prototype.float = function read_float() {\n  /* istanbul ignore if */\n  if (this.pos + 4 > this.len) throw indexOutOfRange(this, 4);\n  var value = util.float.readFloatLE(this.buf, this.pos);\n  this.pos += 4;\n  return value;\n};\n/**\n * Reads a double (64 bit float) as a number.\n * @function\n * @returns {number} Value read\n */\n\n\nReader.prototype.double = function read_double() {\n  /* istanbul ignore if */\n  if (this.pos + 8 > this.len) throw indexOutOfRange(this, 4);\n  var value = util.float.readDoubleLE(this.buf, this.pos);\n  this.pos += 8;\n  return value;\n};\n/**\n * Reads a sequence of bytes preceeded by its length as a varint.\n * @returns {Uint8Array} Value read\n */\n\n\nReader.prototype.bytes = function read_bytes() {\n  var length = this.uint32(),\n      start = this.pos,\n      end = this.pos + length;\n  /* istanbul ignore if */\n\n  if (end > this.len) throw indexOutOfRange(this, length);\n  this.pos += length;\n  if (Array.isArray(this.buf)) // plain array\n    return this.buf.slice(start, end);\n  return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1\n  ? new this.buf.constructor(0) : this._slice.call(this.buf, start, end);\n};\n/**\n * Reads a string preceeded by its byte length as a varint.\n * @returns {string} Value read\n */\n\n\nReader.prototype.string = function read_string() {\n  var bytes = this.bytes();\n  return utf8.read(bytes, 0, bytes.length);\n};\n/**\n * Skips the specified number of bytes if specified, otherwise skips a varint.\n * @param {number} [length] Length if known, otherwise a varint is assumed\n * @returns {Reader} `this`\n */\n\n\nReader.prototype.skip = function skip(length) {\n  if (typeof length === \"number\") {\n    /* istanbul ignore if */\n    if (this.pos + length > this.len) throw indexOutOfRange(this, length);\n    this.pos += length;\n  } else {\n    do {\n      /* istanbul ignore if */\n      if (this.pos >= this.len) throw indexOutOfRange(this);\n    } while (this.buf[this.pos++] & 128);\n  }\n\n  return this;\n};\n/**\n * Skips the next element of the specified wire type.\n * @param {number} wireType Wire type received\n * @returns {Reader} `this`\n */\n\n\nReader.prototype.skipType = function (wireType) {\n  switch (wireType) {\n    case 0:\n      this.skip();\n      break;\n\n    case 1:\n      this.skip(8);\n      break;\n\n    case 2:\n      this.skip(this.uint32());\n      break;\n\n    case 3:\n      while ((wireType = this.uint32() & 7) !== 4) {\n        this.skipType(wireType);\n      }\n\n      break;\n\n    case 5:\n      this.skip(4);\n      break;\n\n    /* istanbul ignore next */\n\n    default:\n      throw Error(\"invalid wire type \" + wireType + \" at offset \" + this.pos);\n  }\n\n  return this;\n};\n\nReader._configure = function (BufferReader_) {\n  BufferReader = BufferReader_;\n  Reader.create = create();\n\n  BufferReader._configure();\n\n  var fn = util.Long ? \"toLong\" :\n  /* istanbul ignore next */\n  \"toNumber\";\n  util.merge(Reader.prototype, {\n    int64: function read_int64() {\n      return readLongVarint.call(this)[fn](false);\n    },\n    uint64: function read_uint64() {\n      return readLongVarint.call(this)[fn](true);\n    },\n    sint64: function read_sint64() {\n      return readLongVarint.call(this).zzDecode()[fn](false);\n    },\n    fixed64: function read_fixed64() {\n      return readFixed64.call(this)[fn](true);\n    },\n    sfixed64: function read_sfixed64() {\n      return readFixed64.call(this)[fn](false);\n    }\n  });\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/reader.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/reader_buffer.js":
/*!******************************************************!*\
  !*** ./node_modules/protobufjs/src/reader_buffer.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = BufferReader; // extends Reader\n\nvar Reader = __webpack_require__(/*! ./reader */ \"./node_modules/protobufjs/src/reader.js\");\n\n(BufferReader.prototype = Object.create(Reader.prototype)).constructor = BufferReader;\n\nvar util = __webpack_require__(/*! ./util/minimal */ \"./node_modules/protobufjs/src/util/minimal.js\");\n/**\n * Constructs a new buffer reader instance.\n * @classdesc Wire format reader using node buffers.\n * @extends Reader\n * @constructor\n * @param {Buffer} buffer Buffer to read from\n */\n\n\nfunction BufferReader(buffer) {\n  Reader.call(this, buffer);\n  /**\n   * Read buffer.\n   * @name BufferReader#buf\n   * @type {Buffer}\n   */\n}\n\nBufferReader._configure = function () {\n  /* istanbul ignore else */\n  if (util.Buffer) BufferReader.prototype._slice = util.Buffer.prototype.slice;\n};\n/**\n * @override\n */\n\n\nBufferReader.prototype.string = function read_string_buffer() {\n  var len = this.uint32(); // modifies pos\n\n  return this.buf.utf8Slice ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len)) : this.buf.toString(\"utf-8\", this.pos, this.pos = Math.min(this.pos + len, this.len));\n};\n/**\n * Reads a sequence of bytes preceeded by its length as a varint.\n * @name BufferReader#bytes\n * @function\n * @returns {Buffer} Value read\n */\n\n\nBufferReader._configure();\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/reader_buffer.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/roots.js":
/*!**********************************************!*\
  !*** ./node_modules/protobufjs/src/roots.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = {};\n/**\n * Named roots.\n * This is where pbjs stores generated structures (the option `-r, --root` specifies a name).\n * Can also be used manually to make roots available accross modules.\n * @name roots\n * @type {Object.<string,Root>}\n * @example\n * // pbjs -r myroot -o compiled.js ...\n *\n * // in another module:\n * require(\"./compiled.js\");\n *\n * // in any subsequent module:\n * var root = protobuf.roots[\"myroot\"];\n */\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/roots.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/rpc.js":
/*!********************************************!*\
  !*** ./node_modules/protobufjs/src/rpc.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n/**\n * Streaming RPC helpers.\n * @namespace\n */\n\nvar rpc = exports;\n/**\n * RPC implementation passed to {@link Service#create} performing a service request on network level, i.e. by utilizing http requests or websockets.\n * @typedef RPCImpl\n * @type {function}\n * @param {Method|rpc.ServiceMethod<Message<{}>,Message<{}>>} method Reflected or static method being called\n * @param {Uint8Array} requestData Request data\n * @param {RPCImplCallback} callback Callback function\n * @returns {undefined}\n * @example\n * function rpcImpl(method, requestData, callback) {\n *     if (protobuf.util.lcFirst(method.name) !== \"myMethod\") // compatible with static code\n *         throw Error(\"no such method\");\n *     asynchronouslyObtainAResponse(requestData, function(err, responseData) {\n *         callback(err, responseData);\n *     });\n * }\n */\n\n/**\n * Node-style callback as used by {@link RPCImpl}.\n * @typedef RPCImplCallback\n * @type {function}\n * @param {Error|null} error Error, if any, otherwise `null`\n * @param {Uint8Array|null} [response] Response data or `null` to signal end of stream, if there hasn't been an error\n * @returns {undefined}\n */\n\nrpc.Service = __webpack_require__(/*! ./rpc/service */ \"./node_modules/protobufjs/src/rpc/service.js\");\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/rpc.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/rpc/service.js":
/*!****************************************************!*\
  !*** ./node_modules/protobufjs/src/rpc/service.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = Service;\n\nvar util = __webpack_require__(/*! ../util/minimal */ \"./node_modules/protobufjs/src/util/minimal.js\"); // Extends EventEmitter\n\n\n(Service.prototype = Object.create(util.EventEmitter.prototype)).constructor = Service;\n/**\n * A service method callback as used by {@link rpc.ServiceMethod|ServiceMethod}.\n *\n * Differs from {@link RPCImplCallback} in that it is an actual callback of a service method which may not return `response = null`.\n * @typedef rpc.ServiceMethodCallback\n * @template TRes extends Message<TRes>\n * @type {function}\n * @param {Error|null} error Error, if any\n * @param {TRes} [response] Response message\n * @returns {undefined}\n */\n\n/**\n * A service method part of a {@link rpc.Service} as created by {@link Service.create}.\n * @typedef rpc.ServiceMethod\n * @template TReq extends Message<TReq>\n * @template TRes extends Message<TRes>\n * @type {function}\n * @param {TReq|Properties<TReq>} request Request message or plain object\n * @param {rpc.ServiceMethodCallback<TRes>} [callback] Node-style callback called with the error, if any, and the response message\n * @returns {Promise<Message<TRes>>} Promise if `callback` has been omitted, otherwise `undefined`\n */\n\n/**\n * Constructs a new RPC service instance.\n * @classdesc An RPC service as returned by {@link Service#create}.\n * @exports rpc.Service\n * @extends util.EventEmitter\n * @constructor\n * @param {RPCImpl} rpcImpl RPC implementation\n * @param {boolean} [requestDelimited=false] Whether requests are length-delimited\n * @param {boolean} [responseDelimited=false] Whether responses are length-delimited\n */\n\nfunction Service(rpcImpl, requestDelimited, responseDelimited) {\n  if (typeof rpcImpl !== \"function\") throw TypeError(\"rpcImpl must be a function\");\n  util.EventEmitter.call(this);\n  /**\n   * RPC implementation. Becomes `null` once the service is ended.\n   * @type {RPCImpl|null}\n   */\n\n  this.rpcImpl = rpcImpl;\n  /**\n   * Whether requests are length-delimited.\n   * @type {boolean}\n   */\n\n  this.requestDelimited = Boolean(requestDelimited);\n  /**\n   * Whether responses are length-delimited.\n   * @type {boolean}\n   */\n\n  this.responseDelimited = Boolean(responseDelimited);\n}\n/**\n * Calls a service method through {@link rpc.Service#rpcImpl|rpcImpl}.\n * @param {Method|rpc.ServiceMethod<TReq,TRes>} method Reflected or static method\n * @param {Constructor<TReq>} requestCtor Request constructor\n * @param {Constructor<TRes>} responseCtor Response constructor\n * @param {TReq|Properties<TReq>} request Request message or plain object\n * @param {rpc.ServiceMethodCallback<TRes>} callback Service callback\n * @returns {undefined}\n * @template TReq extends Message<TReq>\n * @template TRes extends Message<TRes>\n */\n\n\nService.prototype.rpcCall = function rpcCall(method, requestCtor, responseCtor, request, callback) {\n  if (!request) throw TypeError(\"request must be specified\");\n  var self = this;\n  if (!callback) return util.asPromise(rpcCall, self, method, requestCtor, responseCtor, request);\n\n  if (!self.rpcImpl) {\n    setTimeout(function () {\n      callback(Error(\"already ended\"));\n    }, 0);\n    return undefined;\n  }\n\n  try {\n    return self.rpcImpl(method, requestCtor[self.requestDelimited ? \"encodeDelimited\" : \"encode\"](request).finish(), function rpcCallback(err, response) {\n      if (err) {\n        self.emit(\"error\", err, method);\n        return callback(err);\n      }\n\n      if (response === null) {\n        self.end(\n        /* endedByRPC */\n        true);\n        return undefined;\n      }\n\n      if (!(response instanceof responseCtor)) {\n        try {\n          response = responseCtor[self.responseDelimited ? \"decodeDelimited\" : \"decode\"](response);\n        } catch (err) {\n          self.emit(\"error\", err, method);\n          return callback(err);\n        }\n      }\n\n      self.emit(\"data\", response, method);\n      return callback(null, response);\n    });\n  } catch (err) {\n    self.emit(\"error\", err, method);\n    setTimeout(function () {\n      callback(err);\n    }, 0);\n    return undefined;\n  }\n};\n/**\n * Ends this service and emits the `end` event.\n * @param {boolean} [endedByRPC=false] Whether the service has been ended by the RPC implementation.\n * @returns {rpc.Service} `this`\n */\n\n\nService.prototype.end = function end(endedByRPC) {\n  if (this.rpcImpl) {\n    if (!endedByRPC) // signal end to rpcImpl\n      this.rpcImpl(null, null, null);\n    this.rpcImpl = null;\n    this.emit(\"end\").off();\n  }\n\n  return this;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/rpc/service.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/util/longbits.js":
/*!******************************************************!*\
  !*** ./node_modules/protobufjs/src/util/longbits.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = LongBits;\n\nvar util = __webpack_require__(/*! ../util/minimal */ \"./node_modules/protobufjs/src/util/minimal.js\");\n/**\n * Constructs new long bits.\n * @classdesc Helper class for working with the low and high bits of a 64 bit value.\n * @memberof util\n * @constructor\n * @param {number} lo Low 32 bits, unsigned\n * @param {number} hi High 32 bits, unsigned\n */\n\n\nfunction LongBits(lo, hi) {\n  // note that the casts below are theoretically unnecessary as of today, but older statically\n  // generated converter code might still call the ctor with signed 32bits. kept for compat.\n\n  /**\n   * Low bits.\n   * @type {number}\n   */\n  this.lo = lo >>> 0;\n  /**\n   * High bits.\n   * @type {number}\n   */\n\n  this.hi = hi >>> 0;\n}\n/**\n * Zero bits.\n * @memberof util.LongBits\n * @type {util.LongBits}\n */\n\n\nvar zero = LongBits.zero = new LongBits(0, 0);\n\nzero.toNumber = function () {\n  return 0;\n};\n\nzero.zzEncode = zero.zzDecode = function () {\n  return this;\n};\n\nzero.length = function () {\n  return 1;\n};\n/**\n * Zero hash.\n * @memberof util.LongBits\n * @type {string}\n */\n\n\nvar zeroHash = LongBits.zeroHash = \"\\0\\0\\0\\0\\0\\0\\0\\0\";\n/**\n * Constructs new long bits from the specified number.\n * @param {number} value Value\n * @returns {util.LongBits} Instance\n */\n\nLongBits.fromNumber = function fromNumber(value) {\n  if (value === 0) return zero;\n  var sign = value < 0;\n  if (sign) value = -value;\n  var lo = value >>> 0,\n      hi = (value - lo) / 4294967296 >>> 0;\n\n  if (sign) {\n    hi = ~hi >>> 0;\n    lo = ~lo >>> 0;\n\n    if (++lo > 4294967295) {\n      lo = 0;\n      if (++hi > 4294967295) hi = 0;\n    }\n  }\n\n  return new LongBits(lo, hi);\n};\n/**\n * Constructs new long bits from a number, long or string.\n * @param {Long|number|string} value Value\n * @returns {util.LongBits} Instance\n */\n\n\nLongBits.from = function from(value) {\n  if (typeof value === \"number\") return LongBits.fromNumber(value);\n\n  if (util.isString(value)) {\n    /* istanbul ignore else */\n    if (util.Long) value = util.Long.fromString(value);else return LongBits.fromNumber(parseInt(value, 10));\n  }\n\n  return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;\n};\n/**\n * Converts this long bits to a possibly unsafe JavaScript number.\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {number} Possibly unsafe number\n */\n\n\nLongBits.prototype.toNumber = function toNumber(unsigned) {\n  if (!unsigned && this.hi >>> 31) {\n    var lo = ~this.lo + 1 >>> 0,\n        hi = ~this.hi >>> 0;\n    if (!lo) hi = hi + 1 >>> 0;\n    return -(lo + hi * 4294967296);\n  }\n\n  return this.lo + this.hi * 4294967296;\n};\n/**\n * Converts this long bits to a long.\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {Long} Long\n */\n\n\nLongBits.prototype.toLong = function toLong(unsigned) {\n  return util.Long ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))\n  /* istanbul ignore next */\n  : {\n    low: this.lo | 0,\n    high: this.hi | 0,\n    unsigned: Boolean(unsigned)\n  };\n};\n\nvar charCodeAt = String.prototype.charCodeAt;\n/**\n * Constructs new long bits from the specified 8 characters long hash.\n * @param {string} hash Hash\n * @returns {util.LongBits} Bits\n */\n\nLongBits.fromHash = function fromHash(hash) {\n  if (hash === zeroHash) return zero;\n  return new LongBits((charCodeAt.call(hash, 0) | charCodeAt.call(hash, 1) << 8 | charCodeAt.call(hash, 2) << 16 | charCodeAt.call(hash, 3) << 24) >>> 0, (charCodeAt.call(hash, 4) | charCodeAt.call(hash, 5) << 8 | charCodeAt.call(hash, 6) << 16 | charCodeAt.call(hash, 7) << 24) >>> 0);\n};\n/**\n * Converts this long bits to a 8 characters long hash.\n * @returns {string} Hash\n */\n\n\nLongBits.prototype.toHash = function toHash() {\n  return String.fromCharCode(this.lo & 255, this.lo >>> 8 & 255, this.lo >>> 16 & 255, this.lo >>> 24, this.hi & 255, this.hi >>> 8 & 255, this.hi >>> 16 & 255, this.hi >>> 24);\n};\n/**\n * Zig-zag encodes this long bits.\n * @returns {util.LongBits} `this`\n */\n\n\nLongBits.prototype.zzEncode = function zzEncode() {\n  var mask = this.hi >> 31;\n  this.hi = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;\n  this.lo = (this.lo << 1 ^ mask) >>> 0;\n  return this;\n};\n/**\n * Zig-zag decodes this long bits.\n * @returns {util.LongBits} `this`\n */\n\n\nLongBits.prototype.zzDecode = function zzDecode() {\n  var mask = -(this.lo & 1);\n  this.lo = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;\n  this.hi = (this.hi >>> 1 ^ mask) >>> 0;\n  return this;\n};\n/**\n * Calculates the length of this longbits when encoded as a varint.\n * @returns {number} Length\n */\n\n\nLongBits.prototype.length = function length() {\n  var part0 = this.lo,\n      part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,\n      part2 = this.hi >>> 24;\n  return part2 === 0 ? part1 === 0 ? part0 < 16384 ? part0 < 128 ? 1 : 2 : part0 < 2097152 ? 3 : 4 : part1 < 16384 ? part1 < 128 ? 5 : 6 : part1 < 2097152 ? 7 : 8 : part2 < 128 ? 9 : 10;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/util/longbits.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/util/minimal.js":
/*!*****************************************************!*\
  !*** ./node_modules/protobufjs/src/util/minimal.js ***!
  \*****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar util = exports; // used to return a Promise where callback is omitted\n\nutil.asPromise = __webpack_require__(/*! @protobufjs/aspromise */ \"./node_modules/@protobufjs/aspromise/index.js\"); // converts to / from base64 encoded strings\n\nutil.base64 = __webpack_require__(/*! @protobufjs/base64 */ \"./node_modules/@protobufjs/base64/index.js\"); // base class of rpc.Service\n\nutil.EventEmitter = __webpack_require__(/*! @protobufjs/eventemitter */ \"./node_modules/@protobufjs/eventemitter/index.js\"); // float handling accross browsers\n\nutil.float = __webpack_require__(/*! @protobufjs/float */ \"./node_modules/@protobufjs/float/index.js\"); // requires modules optionally and hides the call from bundlers\n\nutil.inquire = __webpack_require__(/*! @protobufjs/inquire */ \"./node_modules/@protobufjs/inquire/index.js\"); // converts to / from utf8 encoded strings\n\nutil.utf8 = __webpack_require__(/*! @protobufjs/utf8 */ \"./node_modules/@protobufjs/utf8/index.js\"); // provides a node-like buffer pool in the browser\n\nutil.pool = __webpack_require__(/*! @protobufjs/pool */ \"./node_modules/@protobufjs/pool/index.js\"); // utility to work with the low and high bits of a 64 bit value\n\nutil.LongBits = __webpack_require__(/*! ./longbits */ \"./node_modules/protobufjs/src/util/longbits.js\");\n/**\n * Whether running within node or not.\n * @memberof util\n * @type {boolean}\n */\n\nutil.isNode = Boolean(typeof global !== \"undefined\" && global && global.process && global.process.versions && global.process.versions.node);\n/**\n * Global object reference.\n * @memberof util\n * @type {Object}\n */\n\nutil.global = util.isNode && global || typeof window !== \"undefined\" && window || typeof self !== \"undefined\" && self || this; // eslint-disable-line no-invalid-this\n\n/**\n * An immuable empty array.\n * @memberof util\n * @type {Array.<*>}\n * @const\n */\n\nutil.emptyArray = Object.freeze ? Object.freeze([]) :\n/* istanbul ignore next */\n[]; // used on prototypes\n\n/**\n * An immutable empty object.\n * @type {Object}\n * @const\n */\n\nutil.emptyObject = Object.freeze ? Object.freeze({}) :\n/* istanbul ignore next */\n{}; // used on prototypes\n\n/**\n * Tests if the specified value is an integer.\n * @function\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is an integer\n */\n\nutil.isInteger = Number.isInteger ||\n/* istanbul ignore next */\nfunction isInteger(value) {\n  return typeof value === \"number\" && isFinite(value) && Math.floor(value) === value;\n};\n/**\n * Tests if the specified value is a string.\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is a string\n */\n\n\nutil.isString = function isString(value) {\n  return typeof value === \"string\" || value instanceof String;\n};\n/**\n * Tests if the specified value is a non-null object.\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is a non-null object\n */\n\n\nutil.isObject = function isObject(value) {\n  return value && typeof value === \"object\";\n};\n/**\n * Checks if a property on a message is considered to be present.\n * This is an alias of {@link util.isSet}.\n * @function\n * @param {Object} obj Plain object or message instance\n * @param {string} prop Property name\n * @returns {boolean} `true` if considered to be present, otherwise `false`\n */\n\n\nutil.isset =\n/**\n * Checks if a property on a message is considered to be present.\n * @param {Object} obj Plain object or message instance\n * @param {string} prop Property name\n * @returns {boolean} `true` if considered to be present, otherwise `false`\n */\nutil.isSet = function isSet(obj, prop) {\n  var value = obj[prop];\n  if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins\n    return typeof value !== \"object\" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;\n  return false;\n};\n/**\n * Any compatible Buffer instance.\n * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.\n * @interface Buffer\n * @extends Uint8Array\n */\n\n/**\n * Node's Buffer class if available.\n * @type {Constructor<Buffer>}\n */\n\n\nutil.Buffer = function () {\n  try {\n    var Buffer = util.inquire(\"buffer\").Buffer; // refuse to use non-node buffers if not explicitly assigned (perf reasons):\n\n    return Buffer.prototype.utf8Write ? Buffer :\n    /* istanbul ignore next */\n    null;\n  } catch (e) {\n    /* istanbul ignore next */\n    return null;\n  }\n}(); // Internal alias of or polyfull for Buffer.from.\n\n\nutil._Buffer_from = null; // Internal alias of or polyfill for Buffer.allocUnsafe.\n\nutil._Buffer_allocUnsafe = null;\n/**\n * Creates a new buffer of whatever type supported by the environment.\n * @param {number|number[]} [sizeOrArray=0] Buffer size or number array\n * @returns {Uint8Array|Buffer} Buffer\n */\n\nutil.newBuffer = function newBuffer(sizeOrArray) {\n  /* istanbul ignore next */\n  return typeof sizeOrArray === \"number\" ? util.Buffer ? util._Buffer_allocUnsafe(sizeOrArray) : new util.Array(sizeOrArray) : util.Buffer ? util._Buffer_from(sizeOrArray) : typeof Uint8Array === \"undefined\" ? sizeOrArray : new Uint8Array(sizeOrArray);\n};\n/**\n * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.\n * @type {Constructor<Uint8Array>}\n */\n\n\nutil.Array = typeof Uint8Array !== \"undefined\" ? Uint8Array\n/* istanbul ignore next */\n: Array;\n/**\n * Any compatible Long instance.\n * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.\n * @interface Long\n * @property {number} low Low bits\n * @property {number} high High bits\n * @property {boolean} unsigned Whether unsigned or not\n */\n\n/**\n * Long.js's Long class if available.\n * @type {Constructor<Long>}\n */\n\nutil.Long =\n/* istanbul ignore next */\nutil.global.dcodeIO &&\n/* istanbul ignore next */\nutil.global.dcodeIO.Long ||\n/* istanbul ignore next */\nutil.global.Long || util.inquire(\"long\");\n/**\n * Regular expression used to verify 2 bit (`bool`) map keys.\n * @type {RegExp}\n * @const\n */\n\nutil.key2Re = /^true|false|0|1$/;\n/**\n * Regular expression used to verify 32 bit (`int32` etc.) map keys.\n * @type {RegExp}\n * @const\n */\n\nutil.key32Re = /^-?(?:0|[1-9][0-9]*)$/;\n/**\n * Regular expression used to verify 64 bit (`int64` etc.) map keys.\n * @type {RegExp}\n * @const\n */\n\nutil.key64Re = /^(?:[\\\\x00-\\\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;\n/**\n * Converts a number or long to an 8 characters long hash string.\n * @param {Long|number} value Value to convert\n * @returns {string} Hash\n */\n\nutil.longToHash = function longToHash(value) {\n  return value ? util.LongBits.from(value).toHash() : util.LongBits.zeroHash;\n};\n/**\n * Converts an 8 characters long hash string to a long or number.\n * @param {string} hash Hash\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {Long|number} Original value\n */\n\n\nutil.longFromHash = function longFromHash(hash, unsigned) {\n  var bits = util.LongBits.fromHash(hash);\n  if (util.Long) return util.Long.fromBits(bits.lo, bits.hi, unsigned);\n  return bits.toNumber(Boolean(unsigned));\n};\n/**\n * Merges the properties of the source object into the destination object.\n * @memberof util\n * @param {Object.<string,*>} dst Destination object\n * @param {Object.<string,*>} src Source object\n * @param {boolean} [ifNotSet=false] Merges only if the key is not already set\n * @returns {Object.<string,*>} Destination object\n */\n\n\nfunction merge(dst, src, ifNotSet) {\n  // used by converters\n  for (var keys = Object.keys(src), i = 0; i < keys.length; ++i) if (dst[keys[i]] === undefined || !ifNotSet) dst[keys[i]] = src[keys[i]];\n\n  return dst;\n}\n\nutil.merge = merge;\n/**\n * Converts the first character of a string to lower case.\n * @param {string} str String to convert\n * @returns {string} Converted string\n */\n\nutil.lcFirst = function lcFirst(str) {\n  return str.charAt(0).toLowerCase() + str.substring(1);\n};\n/**\n * Creates a custom error constructor.\n * @memberof util\n * @param {string} name Error name\n * @returns {Constructor<Error>} Custom error constructor\n */\n\n\nfunction newError(name) {\n  function CustomError(message, properties) {\n    if (!(this instanceof CustomError)) return new CustomError(message, properties); // Error.call(this, message);\n    // ^ just returns a new error instance because the ctor can be called as a function\n\n    Object.defineProperty(this, \"message\", {\n      get: function () {\n        return message;\n      }\n    });\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) // node\n      Error.captureStackTrace(this, CustomError);else Object.defineProperty(this, \"stack\", {\n      value: new Error().stack || \"\"\n    });\n    if (properties) merge(this, properties);\n  }\n\n  (CustomError.prototype = Object.create(Error.prototype)).constructor = CustomError;\n  Object.defineProperty(CustomError.prototype, \"name\", {\n    get: function () {\n      return name;\n    }\n  });\n\n  CustomError.prototype.toString = function toString() {\n    return this.name + \": \" + this.message;\n  };\n\n  return CustomError;\n}\n\nutil.newError = newError;\n/**\n * Constructs a new protocol error.\n * @classdesc Error subclass indicating a protocol specifc error.\n * @memberof util\n * @extends Error\n * @template T extends Message<T>\n * @constructor\n * @param {string} message Error message\n * @param {Object.<string,*>} [properties] Additional properties\n * @example\n * try {\n *     MyMessage.decode(someBuffer); // throws if required fields are missing\n * } catch (e) {\n *     if (e instanceof ProtocolError && e.instance)\n *         console.log(\"decoded so far: \" + JSON.stringify(e.instance));\n * }\n */\n\nutil.ProtocolError = newError(\"ProtocolError\");\n/**\n * So far decoded message instance.\n * @name util.ProtocolError#instance\n * @type {Message<T>}\n */\n\n/**\n * A OneOf getter as returned by {@link util.oneOfGetter}.\n * @typedef OneOfGetter\n * @type {function}\n * @returns {string|undefined} Set field name, if any\n */\n\n/**\n * Builds a getter for a oneof's present field name.\n * @param {string[]} fieldNames Field names\n * @returns {OneOfGetter} Unbound getter\n */\n\nutil.oneOfGetter = function getOneOf(fieldNames) {\n  var fieldMap = {};\n\n  for (var i = 0; i < fieldNames.length; ++i) fieldMap[fieldNames[i]] = 1;\n  /**\n   * @returns {string|undefined} Set field name, if any\n   * @this Object\n   * @ignore\n   */\n\n\n  return function () {\n    // eslint-disable-line consistent-return\n    for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i) if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null) return keys[i];\n  };\n};\n/**\n * A OneOf setter as returned by {@link util.oneOfSetter}.\n * @typedef OneOfSetter\n * @type {function}\n * @param {string|undefined} value Field name\n * @returns {undefined}\n */\n\n/**\n * Builds a setter for a oneof's present field name.\n * @param {string[]} fieldNames Field names\n * @returns {OneOfSetter} Unbound setter\n */\n\n\nutil.oneOfSetter = function setOneOf(fieldNames) {\n  /**\n   * @param {string} name Field name\n   * @returns {undefined}\n   * @this Object\n   * @ignore\n   */\n  return function (name) {\n    for (var i = 0; i < fieldNames.length; ++i) if (fieldNames[i] !== name) delete this[fieldNames[i]];\n  };\n};\n/**\n * Default conversion options used for {@link Message#toJSON} implementations.\n *\n * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:\n *\n * - Longs become strings\n * - Enums become string keys\n * - Bytes become base64 encoded strings\n * - (Sub-)Messages become plain objects\n * - Maps become plain objects with all string keys\n * - Repeated fields become arrays\n * - NaN and Infinity for float and double fields become strings\n *\n * @type {IConversionOptions}\n * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json\n */\n\n\nutil.toJSONOptions = {\n  longs: String,\n  enums: String,\n  bytes: String,\n  json: true\n}; // Sets up buffer utility according to the environment (called in index-minimal)\n\nutil._configure = function () {\n  var Buffer = util.Buffer;\n  /* istanbul ignore if */\n\n  if (!Buffer) {\n    util._Buffer_from = util._Buffer_allocUnsafe = null;\n    return;\n  } // because node 4.x buffers are incompatible & immutable\n  // see: https://github.com/dcodeIO/protobuf.js/pull/665\n\n\n  util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||\n  /* istanbul ignore next */\n  function Buffer_from(value, encoding) {\n    return new Buffer(value, encoding);\n  };\n\n  util._Buffer_allocUnsafe = Buffer.allocUnsafe ||\n  /* istanbul ignore next */\n  function Buffer_allocUnsafe(size) {\n    return new Buffer(size);\n  };\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/util/minimal.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/writer.js":
/*!***********************************************!*\
  !*** ./node_modules/protobufjs/src/writer.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = Writer;\n\nvar util = __webpack_require__(/*! ./util/minimal */ \"./node_modules/protobufjs/src/util/minimal.js\");\n\nvar BufferWriter; // cyclic\n\nvar LongBits = util.LongBits,\n    base64 = util.base64,\n    utf8 = util.utf8;\n/**\n * Constructs a new writer operation instance.\n * @classdesc Scheduled writer operation.\n * @constructor\n * @param {function(*, Uint8Array, number)} fn Function to call\n * @param {number} len Value byte length\n * @param {*} val Value to write\n * @ignore\n */\n\nfunction Op(fn, len, val) {\n  /**\n   * Function to call.\n   * @type {function(Uint8Array, number, *)}\n   */\n  this.fn = fn;\n  /**\n   * Value byte length.\n   * @type {number}\n   */\n\n  this.len = len;\n  /**\n   * Next operation.\n   * @type {Writer.Op|undefined}\n   */\n\n  this.next = undefined;\n  /**\n   * Value to write.\n   * @type {*}\n   */\n\n  this.val = val; // type varies\n}\n/* istanbul ignore next */\n\n\nfunction noop() {} // eslint-disable-line no-empty-function\n\n/**\n * Constructs a new writer state instance.\n * @classdesc Copied writer state.\n * @memberof Writer\n * @constructor\n * @param {Writer} writer Writer to copy state from\n * @ignore\n */\n\n\nfunction State(writer) {\n  /**\n   * Current head.\n   * @type {Writer.Op}\n   */\n  this.head = writer.head;\n  /**\n   * Current tail.\n   * @type {Writer.Op}\n   */\n\n  this.tail = writer.tail;\n  /**\n   * Current buffer length.\n   * @type {number}\n   */\n\n  this.len = writer.len;\n  /**\n   * Next state.\n   * @type {State|null}\n   */\n\n  this.next = writer.states;\n}\n/**\n * Constructs a new writer instance.\n * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.\n * @constructor\n */\n\n\nfunction Writer() {\n  /**\n   * Current length.\n   * @type {number}\n   */\n  this.len = 0;\n  /**\n   * Operations head.\n   * @type {Object}\n   */\n\n  this.head = new Op(noop, 0, 0);\n  /**\n   * Operations tail\n   * @type {Object}\n   */\n\n  this.tail = this.head;\n  /**\n   * Linked forked states.\n   * @type {Object|null}\n   */\n\n  this.states = null; // When a value is written, the writer calculates its byte length and puts it into a linked\n  // list of operations to perform when finish() is called. This both allows us to allocate\n  // buffers of the exact required size and reduces the amount of work we have to do compared\n  // to first calculating over objects and then encoding over objects. In our case, the encoding\n  // part is just a linked list walk calling operations with already prepared values.\n}\n\nvar create = function create() {\n  return util.Buffer ? function create_buffer_setup() {\n    return (Writer.create = function create_buffer() {\n      return new BufferWriter();\n    })();\n  }\n  /* istanbul ignore next */\n  : function create_array() {\n    return new Writer();\n  };\n};\n/**\n * Creates a new writer.\n * @function\n * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}\n */\n\n\nWriter.create = create();\n/**\n * Allocates a buffer of the specified size.\n * @param {number} size Buffer size\n * @returns {Uint8Array} Buffer\n */\n\nWriter.alloc = function alloc(size) {\n  return new util.Array(size);\n}; // Use Uint8Array buffer pool in the browser, just like node does with buffers\n\n/* istanbul ignore else */\n\n\nif (util.Array !== Array) Writer.alloc = util.pool(Writer.alloc, util.Array.prototype.subarray);\n/**\n * Pushes a new operation to the queue.\n * @param {function(Uint8Array, number, *)} fn Function to call\n * @param {number} len Value byte length\n * @param {number} val Value to write\n * @returns {Writer} `this`\n * @private\n */\n\nWriter.prototype._push = function push(fn, len, val) {\n  this.tail = this.tail.next = new Op(fn, len, val);\n  this.len += len;\n  return this;\n};\n\nfunction writeByte(val, buf, pos) {\n  buf[pos] = val & 255;\n}\n\nfunction writeVarint32(val, buf, pos) {\n  while (val > 127) {\n    buf[pos++] = val & 127 | 128;\n    val >>>= 7;\n  }\n\n  buf[pos] = val;\n}\n/**\n * Constructs a new varint writer operation instance.\n * @classdesc Scheduled varint writer operation.\n * @extends Op\n * @constructor\n * @param {number} len Value byte length\n * @param {number} val Value to write\n * @ignore\n */\n\n\nfunction VarintOp(len, val) {\n  this.len = len;\n  this.next = undefined;\n  this.val = val;\n}\n\nVarintOp.prototype = Object.create(Op.prototype);\nVarintOp.prototype.fn = writeVarint32;\n/**\n * Writes an unsigned 32 bit value as a varint.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\n\nWriter.prototype.uint32 = function write_uint32(value) {\n  // here, the call to this.push has been inlined and a varint specific Op subclass is used.\n  // uint32 is by far the most frequently used operation and benefits significantly from this.\n  this.len += (this.tail = this.tail.next = new VarintOp((value = value >>> 0) < 128 ? 1 : value < 16384 ? 2 : value < 2097152 ? 3 : value < 268435456 ? 4 : 5, value)).len;\n  return this;\n};\n/**\n * Writes a signed 32 bit value as a varint.\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.int32 = function write_int32(value) {\n  return value < 0 ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec\n  : this.uint32(value);\n};\n/**\n * Writes a 32 bit value as a varint, zig-zag encoded.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.sint32 = function write_sint32(value) {\n  return this.uint32((value << 1 ^ value >> 31) >>> 0);\n};\n\nfunction writeVarint64(val, buf, pos) {\n  while (val.hi) {\n    buf[pos++] = val.lo & 127 | 128;\n    val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;\n    val.hi >>>= 7;\n  }\n\n  while (val.lo > 127) {\n    buf[pos++] = val.lo & 127 | 128;\n    val.lo = val.lo >>> 7;\n  }\n\n  buf[pos++] = val.lo;\n}\n/**\n * Writes an unsigned 64 bit value as a varint.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\n\n\nWriter.prototype.uint64 = function write_uint64(value) {\n  var bits = LongBits.from(value);\n  return this._push(writeVarint64, bits.length(), bits);\n};\n/**\n * Writes a signed 64 bit value as a varint.\n * @function\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\n\n\nWriter.prototype.int64 = Writer.prototype.uint64;\n/**\n * Writes a signed 64 bit value as a varint, zig-zag encoded.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\n\nWriter.prototype.sint64 = function write_sint64(value) {\n  var bits = LongBits.from(value).zzEncode();\n  return this._push(writeVarint64, bits.length(), bits);\n};\n/**\n * Writes a boolish value as a varint.\n * @param {boolean} value Value to write\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.bool = function write_bool(value) {\n  return this._push(writeByte, 1, value ? 1 : 0);\n};\n\nfunction writeFixed32(val, buf, pos) {\n  buf[pos] = val & 255;\n  buf[pos + 1] = val >>> 8 & 255;\n  buf[pos + 2] = val >>> 16 & 255;\n  buf[pos + 3] = val >>> 24;\n}\n/**\n * Writes an unsigned 32 bit value as fixed 32 bits.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.fixed32 = function write_fixed32(value) {\n  return this._push(writeFixed32, 4, value >>> 0);\n};\n/**\n * Writes a signed 32 bit value as fixed 32 bits.\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.sfixed32 = Writer.prototype.fixed32;\n/**\n * Writes an unsigned 64 bit value as fixed 64 bits.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\n\nWriter.prototype.fixed64 = function write_fixed64(value) {\n  var bits = LongBits.from(value);\n  return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);\n};\n/**\n * Writes a signed 64 bit value as fixed 64 bits.\n * @function\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\n\n\nWriter.prototype.sfixed64 = Writer.prototype.fixed64;\n/**\n * Writes a float (32 bit).\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\n\nWriter.prototype.float = function write_float(value) {\n  return this._push(util.float.writeFloatLE, 4, value);\n};\n/**\n * Writes a double (64 bit float).\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.double = function write_double(value) {\n  return this._push(util.float.writeDoubleLE, 8, value);\n};\n\nvar writeBytes = util.Array.prototype.set ? function writeBytes_set(val, buf, pos) {\n  buf.set(val, pos); // also works for plain array values\n}\n/* istanbul ignore next */\n: function writeBytes_for(val, buf, pos) {\n  for (var i = 0; i < val.length; ++i) buf[pos + i] = val[i];\n};\n/**\n * Writes a sequence of bytes.\n * @param {Uint8Array|string} value Buffer or base64 encoded string to write\n * @returns {Writer} `this`\n */\n\nWriter.prototype.bytes = function write_bytes(value) {\n  var len = value.length >>> 0;\n  if (!len) return this._push(writeByte, 1, 0);\n\n  if (util.isString(value)) {\n    var buf = Writer.alloc(len = base64.length(value));\n    base64.decode(value, buf, 0);\n    value = buf;\n  }\n\n  return this.uint32(len)._push(writeBytes, len, value);\n};\n/**\n * Writes a string.\n * @param {string} value Value to write\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.string = function write_string(value) {\n  var len = utf8.length(value);\n  return len ? this.uint32(len)._push(utf8.write, len, value) : this._push(writeByte, 1, 0);\n};\n/**\n * Forks this writer's state by pushing it to a stack.\n * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.fork = function fork() {\n  this.states = new State(this);\n  this.head = this.tail = new Op(noop, 0, 0);\n  this.len = 0;\n  return this;\n};\n/**\n * Resets this instance to the last state.\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.reset = function reset() {\n  if (this.states) {\n    this.head = this.states.head;\n    this.tail = this.states.tail;\n    this.len = this.states.len;\n    this.states = this.states.next;\n  } else {\n    this.head = this.tail = new Op(noop, 0, 0);\n    this.len = 0;\n  }\n\n  return this;\n};\n/**\n * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.\n * @returns {Writer} `this`\n */\n\n\nWriter.prototype.ldelim = function ldelim() {\n  var head = this.head,\n      tail = this.tail,\n      len = this.len;\n  this.reset().uint32(len);\n\n  if (len) {\n    this.tail.next = head.next; // skip noop\n\n    this.tail = tail;\n    this.len += len;\n  }\n\n  return this;\n};\n/**\n * Finishes the write operation.\n * @returns {Uint8Array} Finished buffer\n */\n\n\nWriter.prototype.finish = function finish() {\n  var head = this.head.next,\n      // skip noop\n  buf = this.constructor.alloc(this.len),\n      pos = 0;\n\n  while (head) {\n    head.fn(head.val, buf, pos);\n    pos += head.len;\n    head = head.next;\n  } // this.head = this.tail = null;\n\n\n  return buf;\n};\n\nWriter._configure = function (BufferWriter_) {\n  BufferWriter = BufferWriter_;\n  Writer.create = create();\n\n  BufferWriter._configure();\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/writer.js?");

/***/ }),

/***/ "./node_modules/protobufjs/src/writer_buffer.js":
/*!******************************************************!*\
  !*** ./node_modules/protobufjs/src/writer_buffer.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = BufferWriter; // extends Writer\n\nvar Writer = __webpack_require__(/*! ./writer */ \"./node_modules/protobufjs/src/writer.js\");\n\n(BufferWriter.prototype = Object.create(Writer.prototype)).constructor = BufferWriter;\n\nvar util = __webpack_require__(/*! ./util/minimal */ \"./node_modules/protobufjs/src/util/minimal.js\");\n/**\n * Constructs a new buffer writer instance.\n * @classdesc Wire format writer using node buffers.\n * @extends Writer\n * @constructor\n */\n\n\nfunction BufferWriter() {\n  Writer.call(this);\n}\n\nBufferWriter._configure = function () {\n  /**\n   * Allocates a buffer of the specified size.\n   * @function\n   * @param {number} size Buffer size\n   * @returns {Buffer} Buffer\n   */\n  BufferWriter.alloc = util._Buffer_allocUnsafe;\n  BufferWriter.writeBytesBuffer = util.Buffer && util.Buffer.prototype instanceof Uint8Array && util.Buffer.prototype.set.name === \"set\" ? function writeBytesBuffer_set(val, buf, pos) {\n    buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)\n    // also works for plain array values\n  }\n  /* istanbul ignore next */\n  : function writeBytesBuffer_copy(val, buf, pos) {\n    if (val.copy) // Buffer values\n      val.copy(buf, pos, 0, val.length);else for (var i = 0; i < val.length;) // plain array values\n    buf[pos++] = val[i++];\n  };\n};\n/**\n * @override\n */\n\n\nBufferWriter.prototype.bytes = function write_bytes_buffer(value) {\n  if (util.isString(value)) value = util._Buffer_from(value, \"base64\");\n  var len = value.length >>> 0;\n  this.uint32(len);\n  if (len) this._push(BufferWriter.writeBytesBuffer, len, value);\n  return this;\n};\n\nfunction writeStringBuffer(val, buf, pos) {\n  if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)\n    util.utf8.write(val, buf, pos);else if (buf.utf8Write) buf.utf8Write(val, pos);else buf.write(val, pos);\n}\n/**\n * @override\n */\n\n\nBufferWriter.prototype.string = function write_string_buffer(value) {\n  var len = util.Buffer.byteLength(value);\n  this.uint32(len);\n  if (len) this._push(writeStringBuffer, len, value);\n  return this;\n};\n/**\n * Finishes the write operation.\n * @name BufferWriter#finish\n * @function\n * @returns {Buffer} Finished buffer\n */\n\n\nBufferWriter._configure();\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/protobufjs/src/writer_buffer.js?");

/***/ }),

/***/ "./node_modules/rabin-wasm/dist/rabin-wasm.node.js":
/*!*********************************************************!*\
  !*** ./node_modules/rabin-wasm/dist/rabin-wasm.node.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const {\n  instantiateSync\n} = __webpack_require__(/*! @assemblyscript/loader */ \"./node_modules/@assemblyscript/loader/index.js\");\n\nconst fs = __webpack_require__(/*! fs */ \"fs\");\n\nloadWebAssembly.supported = typeof WebAssembly !== 'undefined';\n\nasync function loadWebAssembly(imp = {}) {\n  if (!loadWebAssembly.supported) return null;\n  return instantiateSync(fs.readFileSync(__dirname + \"/../dist/rabin.wasm\"), imp);\n}\n\nmodule.exports = loadWebAssembly;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/rabin-wasm/dist/rabin-wasm.node.js?");

/***/ }),

/***/ "./node_modules/rabin-wasm/src/index.js":
/*!**********************************************!*\
  !*** ./node_modules/rabin-wasm/src/index.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Rabin = __webpack_require__(/*! ./rabin */ \"./node_modules/rabin-wasm/src/rabin.js\");\n\nconst getRabin = __webpack_require__(/*! ../dist/rabin-wasm.node.js */ \"./node_modules/rabin-wasm/dist/rabin-wasm.node.js\");\n\nconst create = async (avg, min, max, windowSize, polynomial) => {\n  const compiled = await getRabin();\n  return new Rabin(compiled, avg, min, max, windowSize, polynomial);\n};\n\nmodule.exports = {\n  Rabin,\n  create\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/rabin-wasm/src/index.js?");

/***/ }),

/***/ "./node_modules/rabin-wasm/src/rabin.js":
/*!**********************************************!*\
  !*** ./node_modules/rabin-wasm/src/rabin.js ***!
  \**********************************************/
/***/ ((module) => {

eval("/**\n * Rabin fingerprinting\n *\n * @class Rabin\n */\nclass Rabin {\n  /**\n   * Creates an instance of Rabin.\n   * @param { import(\"./../dist/rabin-wasm\") } asModule\n   * @param {number} [bits=12]\n   * @param {number} [min=8 * 1024]\n   * @param {number} [max=32 * 1024]\n   * @param {number} polynomial\n   * @memberof Rabin\n   */\n  constructor(asModule, bits = 12, min = 8 * 1024, max = 32 * 1024, windowSize = 64, polynomial) {\n    this.bits = bits;\n    this.min = min;\n    this.max = max;\n    this.asModule = asModule;\n    this.rabin = new asModule.Rabin(bits, min, max, windowSize, polynomial);\n    this.polynomial = polynomial;\n  }\n  /**\n   * Fingerprints the buffer\n   *\n   * @param {Uint8Array} buf\n   * @returns {Array<number>}\n   * @memberof Rabin\n   */\n\n\n  fingerprint(buf) {\n    const {\n      __retain,\n      __release,\n      __allocArray,\n      __getInt32Array,\n      Int32Array_ID,\n      Uint8Array_ID\n    } = this.asModule;\n    const lengths = new Int32Array(Math.ceil(buf.length / this.min));\n\n    const lengthsPtr = __retain(__allocArray(Int32Array_ID, lengths));\n\n    const pointer = __retain(__allocArray(Uint8Array_ID, buf));\n\n    const out = this.rabin.fingerprint(pointer, lengthsPtr);\n\n    const processed = __getInt32Array(out);\n\n    __release(pointer);\n\n    __release(lengthsPtr);\n\n    const end = processed.indexOf(0);\n    return end >= 0 ? processed.subarray(0, end) : processed;\n  }\n\n}\n\nmodule.exports = Rabin;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/rabin-wasm/src/rabin.js?");

/***/ }),

/***/ "./node_modules/retry/index.js":
/*!*************************************!*\
  !*** ./node_modules/retry/index.js ***!
  \*************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! ./lib/retry */ \"./node_modules/retry/lib/retry.js\");\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/retry/index.js?");

/***/ }),

/***/ "./node_modules/retry/lib/retry.js":
/*!*****************************************!*\
  !*** ./node_modules/retry/lib/retry.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("var RetryOperation = __webpack_require__(/*! ./retry_operation */ \"./node_modules/retry/lib/retry_operation.js\");\n\nexports.operation = function (options) {\n  var timeouts = exports.timeouts(options);\n  return new RetryOperation(timeouts, {\n    forever: options && (options.forever || options.retries === Infinity),\n    unref: options && options.unref,\n    maxRetryTime: options && options.maxRetryTime\n  });\n};\n\nexports.timeouts = function (options) {\n  if (options instanceof Array) {\n    return [].concat(options);\n  }\n\n  var opts = {\n    retries: 10,\n    factor: 2,\n    minTimeout: 1 * 1000,\n    maxTimeout: Infinity,\n    randomize: false\n  };\n\n  for (var key in options) {\n    opts[key] = options[key];\n  }\n\n  if (opts.minTimeout > opts.maxTimeout) {\n    throw new Error('minTimeout is greater than maxTimeout');\n  }\n\n  var timeouts = [];\n\n  for (var i = 0; i < opts.retries; i++) {\n    timeouts.push(this.createTimeout(i, opts));\n  }\n\n  if (options && options.forever && !timeouts.length) {\n    timeouts.push(this.createTimeout(i, opts));\n  } // sort the array numerically ascending\n\n\n  timeouts.sort(function (a, b) {\n    return a - b;\n  });\n  return timeouts;\n};\n\nexports.createTimeout = function (attempt, opts) {\n  var random = opts.randomize ? Math.random() + 1 : 1;\n  var timeout = Math.round(random * Math.max(opts.minTimeout, 1) * Math.pow(opts.factor, attempt));\n  timeout = Math.min(timeout, opts.maxTimeout);\n  return timeout;\n};\n\nexports.wrap = function (obj, options, methods) {\n  if (options instanceof Array) {\n    methods = options;\n    options = null;\n  }\n\n  if (!methods) {\n    methods = [];\n\n    for (var key in obj) {\n      if (typeof obj[key] === 'function') {\n        methods.push(key);\n      }\n    }\n  }\n\n  for (var i = 0; i < methods.length; i++) {\n    var method = methods[i];\n    var original = obj[method];\n\n    obj[method] = function retryWrapper(original) {\n      var op = exports.operation(options);\n      var args = Array.prototype.slice.call(arguments, 1);\n      var callback = args.pop();\n      args.push(function (err) {\n        if (op.retry(err)) {\n          return;\n        }\n\n        if (err) {\n          arguments[0] = op.mainError();\n        }\n\n        callback.apply(this, arguments);\n      });\n      op.attempt(function () {\n        original.apply(obj, args);\n      });\n    }.bind(obj, original);\n\n    obj[method].options = options;\n  }\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/retry/lib/retry.js?");

/***/ }),

/***/ "./node_modules/retry/lib/retry_operation.js":
/*!***************************************************!*\
  !*** ./node_modules/retry/lib/retry_operation.js ***!
  \***************************************************/
/***/ ((module) => {

eval("function RetryOperation(timeouts, options) {\n  // Compatibility for the old (timeouts, retryForever) signature\n  if (typeof options === 'boolean') {\n    options = {\n      forever: options\n    };\n  }\n\n  this._originalTimeouts = JSON.parse(JSON.stringify(timeouts));\n  this._timeouts = timeouts;\n  this._options = options || {};\n  this._maxRetryTime = options && options.maxRetryTime || Infinity;\n  this._fn = null;\n  this._errors = [];\n  this._attempts = 1;\n  this._operationTimeout = null;\n  this._operationTimeoutCb = null;\n  this._timeout = null;\n  this._operationStart = null;\n  this._timer = null;\n\n  if (this._options.forever) {\n    this._cachedTimeouts = this._timeouts.slice(0);\n  }\n}\n\nmodule.exports = RetryOperation;\n\nRetryOperation.prototype.reset = function () {\n  this._attempts = 1;\n  this._timeouts = this._originalTimeouts.slice(0);\n};\n\nRetryOperation.prototype.stop = function () {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n\n  if (this._timer) {\n    clearTimeout(this._timer);\n  }\n\n  this._timeouts = [];\n  this._cachedTimeouts = null;\n};\n\nRetryOperation.prototype.retry = function (err) {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n\n  if (!err) {\n    return false;\n  }\n\n  var currentTime = new Date().getTime();\n\n  if (err && currentTime - this._operationStart >= this._maxRetryTime) {\n    this._errors.push(err);\n\n    this._errors.unshift(new Error('RetryOperation timeout occurred'));\n\n    return false;\n  }\n\n  this._errors.push(err);\n\n  var timeout = this._timeouts.shift();\n\n  if (timeout === undefined) {\n    if (this._cachedTimeouts) {\n      // retry forever, only keep last error\n      this._errors.splice(0, this._errors.length - 1);\n\n      timeout = this._cachedTimeouts.slice(-1);\n    } else {\n      return false;\n    }\n  }\n\n  var self = this;\n  this._timer = setTimeout(function () {\n    self._attempts++;\n\n    if (self._operationTimeoutCb) {\n      self._timeout = setTimeout(function () {\n        self._operationTimeoutCb(self._attempts);\n      }, self._operationTimeout);\n\n      if (self._options.unref) {\n        self._timeout.unref();\n      }\n    }\n\n    self._fn(self._attempts);\n  }, timeout);\n\n  if (this._options.unref) {\n    this._timer.unref();\n  }\n\n  return true;\n};\n\nRetryOperation.prototype.attempt = function (fn, timeoutOps) {\n  this._fn = fn;\n\n  if (timeoutOps) {\n    if (timeoutOps.timeout) {\n      this._operationTimeout = timeoutOps.timeout;\n    }\n\n    if (timeoutOps.cb) {\n      this._operationTimeoutCb = timeoutOps.cb;\n    }\n  }\n\n  var self = this;\n\n  if (this._operationTimeoutCb) {\n    this._timeout = setTimeout(function () {\n      self._operationTimeoutCb();\n    }, self._operationTimeout);\n  }\n\n  this._operationStart = new Date().getTime();\n\n  this._fn(this._attempts);\n};\n\nRetryOperation.prototype.try = function (fn) {\n  console.log('Using RetryOperation.try() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = function (fn) {\n  console.log('Using RetryOperation.start() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = RetryOperation.prototype.try;\n\nRetryOperation.prototype.errors = function () {\n  return this._errors;\n};\n\nRetryOperation.prototype.attempts = function () {\n  return this._attempts;\n};\n\nRetryOperation.prototype.mainError = function () {\n  if (this._errors.length === 0) {\n    return null;\n  }\n\n  var counts = {};\n  var mainError = null;\n  var mainErrorCount = 0;\n\n  for (var i = 0; i < this._errors.length; i++) {\n    var error = this._errors[i];\n    var message = error.message;\n    var count = (counts[message] || 0) + 1;\n    counts[message] = count;\n\n    if (count >= mainErrorCount) {\n      mainError = error;\n      mainErrorCount = count;\n    }\n  }\n\n  return mainError;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/retry/lib/retry_operation.js?");

/***/ }),

/***/ "./node_modules/sparse-array/index.js":
/*!********************************************!*\
  !*** ./node_modules/sparse-array/index.js ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval(" // JS treats subjects of bitwise operators as SIGNED 32 bit numbers,\n// which means the maximum amount of bits we can store inside each byte\n// is 7..\n\nconst BITS_PER_BYTE = 7;\nmodule.exports = class SparseArray {\n  constructor() {\n    this._bitArrays = [];\n    this._data = [];\n    this._length = 0;\n    this._changedLength = false;\n    this._changedData = false;\n  }\n\n  set(index, value) {\n    let pos = this._internalPositionFor(index, false);\n\n    if (value === undefined) {\n      // unsetting\n      if (pos !== -1) {\n        // remove item from bit array and array itself\n        this._unsetInternalPos(pos);\n\n        this._unsetBit(index);\n\n        this._changedLength = true;\n        this._changedData = true;\n      }\n    } else {\n      let needsSort = false;\n\n      if (pos === -1) {\n        pos = this._data.length;\n\n        this._setBit(index);\n\n        this._changedData = true;\n      } else {\n        needsSort = true;\n      }\n\n      this._setInternalPos(pos, index, value, needsSort);\n\n      this._changedLength = true;\n    }\n  }\n\n  unset(index) {\n    this.set(index, undefined);\n  }\n\n  get(index) {\n    this._sortData();\n\n    const pos = this._internalPositionFor(index, true);\n\n    if (pos === -1) {\n      return undefined;\n    }\n\n    return this._data[pos][1];\n  }\n\n  push(value) {\n    this.set(this.length, value);\n    return this.length;\n  }\n\n  get length() {\n    this._sortData();\n\n    if (this._changedLength) {\n      const last = this._data[this._data.length - 1];\n      this._length = last ? last[0] + 1 : 0;\n      this._changedLength = false;\n    }\n\n    return this._length;\n  }\n\n  forEach(iterator) {\n    let i = 0;\n\n    while (i < this.length) {\n      iterator(this.get(i), i, this);\n      i++;\n    }\n  }\n\n  map(iterator) {\n    let i = 0;\n    let mapped = new Array(this.length);\n\n    while (i < this.length) {\n      mapped[i] = iterator(this.get(i), i, this);\n      i++;\n    }\n\n    return mapped;\n  }\n\n  reduce(reducer, initialValue) {\n    let i = 0;\n    let acc = initialValue;\n\n    while (i < this.length) {\n      const value = this.get(i);\n      acc = reducer(acc, value, i);\n      i++;\n    }\n\n    return acc;\n  }\n\n  find(finder) {\n    let i = 0,\n        found,\n        last;\n\n    while (i < this.length && !found) {\n      last = this.get(i);\n      found = finder(last);\n      i++;\n    }\n\n    return found ? last : undefined;\n  }\n\n  _internalPositionFor(index, noCreate) {\n    const bytePos = this._bytePosFor(index, noCreate);\n\n    if (bytePos >= this._bitArrays.length) {\n      return -1;\n    }\n\n    const byte = this._bitArrays[bytePos];\n    const bitPos = index - bytePos * BITS_PER_BYTE;\n    const exists = (byte & 1 << bitPos) > 0;\n\n    if (!exists) {\n      return -1;\n    }\n\n    const previousPopCount = this._bitArrays.slice(0, bytePos).reduce(popCountReduce, 0);\n\n    const mask = ~(0xffffffff << bitPos + 1);\n    const bytePopCount = popCount(byte & mask);\n    const arrayPos = previousPopCount + bytePopCount - 1;\n    return arrayPos;\n  }\n\n  _bytePosFor(index, noCreate) {\n    const bytePos = Math.floor(index / BITS_PER_BYTE);\n    const targetLength = bytePos + 1;\n\n    while (!noCreate && this._bitArrays.length < targetLength) {\n      this._bitArrays.push(0);\n    }\n\n    return bytePos;\n  }\n\n  _setBit(index) {\n    const bytePos = this._bytePosFor(index, false);\n\n    this._bitArrays[bytePos] |= 1 << index - bytePos * BITS_PER_BYTE;\n  }\n\n  _unsetBit(index) {\n    const bytePos = this._bytePosFor(index, false);\n\n    this._bitArrays[bytePos] &= ~(1 << index - bytePos * BITS_PER_BYTE);\n  }\n\n  _setInternalPos(pos, index, value, needsSort) {\n    const data = this._data;\n    const elem = [index, value];\n\n    if (needsSort) {\n      this._sortData();\n\n      data[pos] = elem;\n    } else {\n      // new element. just shove it into the array\n      // but be nice about where we shove it\n      // in order to make sorting it later easier\n      if (data.length) {\n        if (data[data.length - 1][0] >= index) {\n          data.push(elem);\n        } else if (data[0][0] <= index) {\n          data.unshift(elem);\n        } else {\n          const randomIndex = Math.round(data.length / 2);\n          this._data = data.slice(0, randomIndex).concat(elem).concat(data.slice(randomIndex));\n        }\n      } else {\n        this._data.push(elem);\n      }\n\n      this._changedData = true;\n      this._changedLength = true;\n    }\n  }\n\n  _unsetInternalPos(pos) {\n    this._data.splice(pos, 1);\n  }\n\n  _sortData() {\n    if (this._changedData) {\n      this._data.sort(sortInternal);\n    }\n\n    this._changedData = false;\n  }\n\n  bitField() {\n    const bytes = [];\n    let pendingBitsForResultingByte = 8;\n    let pendingBitsForNewByte = 0;\n    let resultingByte = 0;\n    let newByte;\n\n    const pending = this._bitArrays.slice();\n\n    while (pending.length || pendingBitsForNewByte) {\n      if (pendingBitsForNewByte === 0) {\n        newByte = pending.shift();\n        pendingBitsForNewByte = 7;\n      }\n\n      const usingBits = Math.min(pendingBitsForNewByte, pendingBitsForResultingByte);\n      const mask = ~(0b11111111 << usingBits);\n      const masked = newByte & mask;\n      resultingByte |= masked << 8 - pendingBitsForResultingByte;\n      newByte = newByte >>> usingBits;\n      pendingBitsForNewByte -= usingBits;\n      pendingBitsForResultingByte -= usingBits;\n\n      if (!pendingBitsForResultingByte || !pendingBitsForNewByte && !pending.length) {\n        bytes.push(resultingByte);\n        resultingByte = 0;\n        pendingBitsForResultingByte = 8;\n      }\n    } // remove trailing zeroes\n\n\n    for (var i = bytes.length - 1; i > 0; i--) {\n      const value = bytes[i];\n\n      if (value === 0) {\n        bytes.pop();\n      } else {\n        break;\n      }\n    }\n\n    return bytes;\n  }\n\n  compactArray() {\n    this._sortData();\n\n    return this._data.map(valueOnly);\n  }\n\n};\n\nfunction popCountReduce(count, byte) {\n  return count + popCount(byte);\n}\n\nfunction popCount(_v) {\n  let v = _v;\n  v = v - (v >> 1 & 0x55555555); // reuse input as temporary\n\n  v = (v & 0x33333333) + (v >> 2 & 0x33333333); // temp\n\n  return (v + (v >> 4) & 0xF0F0F0F) * 0x1010101 >> 24;\n}\n\nfunction sortInternal(a, b) {\n  return a[0] - b[0];\n}\n\nfunction valueOnly(elem) {\n  return elem[1];\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/sparse-array/index.js?");

/***/ }),

/***/ "./node_modules/streaming-iterables/dist/index.js":
/*!********************************************************!*\
  !*** ./node_modules/streaming-iterables/dist/index.js ***!
  \********************************************************/
/***/ (function(__unused_webpack_module, exports) {

eval("(function (global, factory) {\n   true ? factory(exports) : 0;\n})(this, function (exports) {\n  'use strict';\n\n  async function* _batch(size, iterable) {\n    let dataBatch = [];\n\n    for await (const data of iterable) {\n      dataBatch.push(data);\n\n      if (dataBatch.length === size) {\n        yield dataBatch;\n        dataBatch = [];\n      }\n    }\n\n    if (dataBatch.length > 0) {\n      yield dataBatch;\n    }\n  }\n\n  function* _syncBatch(size, iterable) {\n    let dataBatch = [];\n\n    for (const data of iterable) {\n      dataBatch.push(data);\n\n      if (dataBatch.length === size) {\n        yield dataBatch;\n        dataBatch = [];\n      }\n    }\n\n    if (dataBatch.length > 0) {\n      yield dataBatch;\n    }\n  }\n\n  function batch(size, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => batch(size, curriedIterable);\n    }\n\n    if (iterable[Symbol.asyncIterator]) {\n      return _batch(size, iterable);\n    }\n\n    return _syncBatch(size, iterable);\n  }\n\n  const TIMEOUT = Symbol('TIMEOUT');\n\n  const createTimer = duration => {\n    let timeoutId;\n    return [new Promise(resolve => {\n      timeoutId = setTimeout(() => resolve(TIMEOUT), duration);\n    }), () => {\n      clearTimeout(timeoutId);\n    }];\n  }; // Like `batch` but flushes early if the `timeout` is reached\n  // NOTE: The strategy is to only hold onto a single item for a maximum of `timeout` ms.\n\n\n  async function* _batchWithTimeout(size, timeout, iterable) {\n    const iterator = iterable[Symbol.asyncIterator]();\n    let pendingData;\n    let batchData = [];\n    let timer;\n    let clearTimer;\n\n    const startTimer = () => {\n      deleteTimer();\n      [timer, clearTimer] = createTimer(timeout);\n    };\n\n    const deleteTimer = () => {\n      if (clearTimer) {\n        clearTimer();\n      }\n\n      timer = undefined;\n    };\n\n    pendingData = iterator.next();\n\n    while (true) {\n      const res = await (timer ? Promise.race([pendingData, timer]) : pendingData);\n\n      if (res === TIMEOUT || res.done) {\n        // Flush early (before we reach the batch size)\n        if (batchData.length) {\n          yield batchData;\n          batchData = [];\n        }\n\n        deleteTimer(); // And exit appropriately\n\n        if (res !== TIMEOUT) {\n          // done\n          break;\n        }\n\n        continue;\n      } // Fetch next item early doors (before we potentially yield)\n\n\n      pendingData = iterator.next(); // Then handle the value\n\n      batchData.push(res.value);\n\n      if (batchData.length === 1) {\n        // Start timer once we have at least 1 item ready to go\n        startTimer();\n      }\n\n      if (batchData.length === size) {\n        yield batchData;\n        batchData = [];\n        deleteTimer();\n        continue;\n      }\n    }\n  }\n\n  function batchWithTimeout(size, timeout, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => batchWithTimeout(size, timeout, curriedIterable);\n    }\n\n    if (iterable[Symbol.asyncIterator] && timeout !== Infinity) {\n      return _batchWithTimeout(size, timeout, iterable);\n    } // For sync iterables or an infinite timeout, the timeout is irrelevant so just fallback to regular `batch`.\n\n\n    return batch(size, iterable);\n  }\n\n  function getIterator(iterable) {\n    if (typeof iterable.next === 'function') {\n      return iterable;\n    }\n\n    if (typeof iterable[Symbol.iterator] === 'function') {\n      return iterable[Symbol.iterator]();\n    }\n\n    if (typeof iterable[Symbol.asyncIterator] === 'function') {\n      return iterable[Symbol.asyncIterator]();\n    }\n\n    throw new TypeError('\"values\" does not to conform to any of the iterator or iterable protocols');\n  }\n\n  function defer() {\n    let reject;\n    let resolve;\n    const promise = new Promise((resolveFunc, rejectFunc) => {\n      resolve = resolveFunc;\n      reject = rejectFunc;\n    });\n    return {\n      promise,\n      reject,\n      resolve\n    };\n  }\n\n  function _buffer(size, iterable) {\n    const iterator = getIterator(iterable);\n    const resultQueue = [];\n    const readQueue = [];\n    let reading = false;\n    let ended = false;\n\n    function fulfillReadQueue() {\n      while (readQueue.length > 0 && resultQueue.length > 0) {\n        const readDeferred = readQueue.shift();\n        const {\n          error,\n          value\n        } = resultQueue.shift();\n\n        if (error) {\n          readDeferred.reject(error);\n        } else {\n          readDeferred.resolve({\n            done: false,\n            value\n          });\n        }\n      }\n\n      while (readQueue.length > 0 && ended) {\n        const {\n          resolve\n        } = readQueue.shift();\n        resolve({\n          done: true,\n          value: undefined\n        });\n      }\n    }\n\n    async function fillQueue() {\n      if (ended) {\n        return;\n      }\n\n      if (reading) {\n        return;\n      }\n\n      if (resultQueue.length >= size) {\n        return;\n      }\n\n      reading = true;\n\n      try {\n        const {\n          done,\n          value\n        } = await iterator.next();\n\n        if (done) {\n          ended = true;\n        } else {\n          resultQueue.push({\n            value\n          });\n        }\n      } catch (error) {\n        ended = true;\n        resultQueue.push({\n          error\n        });\n      }\n\n      fulfillReadQueue();\n      reading = false;\n      fillQueue();\n    }\n\n    async function next() {\n      if (resultQueue.length > 0) {\n        const {\n          error,\n          value\n        } = resultQueue.shift();\n\n        if (error) {\n          throw error;\n        }\n\n        fillQueue();\n        return {\n          done: false,\n          value\n        };\n      }\n\n      if (ended) {\n        return {\n          done: true,\n          value: undefined\n        }; // stupid ts\n      }\n\n      const deferred = defer();\n      readQueue.push(deferred);\n      fillQueue();\n      return deferred.promise;\n    }\n\n    const asyncIterableIterator = {\n      next,\n      [Symbol.asyncIterator]: () => asyncIterableIterator\n    };\n    return asyncIterableIterator;\n  }\n\n  function* syncBuffer(size, iterable) {\n    const valueQueue = [];\n    let e;\n\n    try {\n      for (const value of iterable) {\n        valueQueue.push(value);\n\n        if (valueQueue.length <= size) {\n          continue;\n        }\n\n        yield valueQueue.shift();\n      }\n    } catch (error) {\n      e = error;\n    }\n\n    for (const value of valueQueue) {\n      yield value;\n    }\n\n    if (e) {\n      throw e;\n    }\n  }\n\n  function buffer(size, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => buffer(size, curriedIterable);\n    }\n\n    if (size === 0) {\n      return iterable;\n    }\n\n    if (iterable[Symbol.asyncIterator]) {\n      return _buffer(size, iterable);\n    }\n\n    return syncBuffer(size, iterable);\n  }\n\n  async function _collect(iterable) {\n    const values = [];\n\n    for await (const value of iterable) {\n      values.push(value);\n    }\n\n    return values;\n  }\n\n  function collect(iterable) {\n    if (iterable[Symbol.asyncIterator]) {\n      return _collect(iterable);\n    }\n\n    return Array.from(iterable);\n  }\n\n  async function* _concat(iterables) {\n    for await (const iterable of iterables) {\n      yield* iterable;\n    }\n  }\n\n  function* _syncConcat(iterables) {\n    for (const iterable of iterables) {\n      yield* iterable;\n    }\n  }\n\n  function concat(...iterables) {\n    const hasAnyAsync = iterables.find(itr => itr[Symbol.asyncIterator] !== undefined);\n\n    if (hasAnyAsync) {\n      return _concat(iterables);\n    } else {\n      return _syncConcat(iterables);\n    }\n  }\n\n  async function _consume(iterable) {\n    for await (const val of iterable) {// do nothing\n    }\n  }\n\n  function consume(iterable) {\n    if (iterable[Symbol.asyncIterator]) {\n      return _consume(iterable);\n    }\n\n    for (const val of iterable) {// do nothing\n    }\n  }\n\n  async function* _filter(filterFunc, iterable) {\n    for await (const data of iterable) {\n      if (await filterFunc(data)) {\n        yield data;\n      }\n    }\n  }\n\n  function filter(filterFunc, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => _filter(filterFunc, curriedIterable);\n    }\n\n    return _filter(filterFunc, iterable);\n  }\n\n  async function* flatten(iterable) {\n    for await (const maybeItr of iterable) {\n      if (maybeItr && typeof maybeItr !== 'string' && (maybeItr[Symbol.iterator] || maybeItr[Symbol.asyncIterator])) {\n        yield* flatten(maybeItr);\n      } else {\n        yield maybeItr;\n      }\n    }\n  }\n\n  async function* _map(func, iterable) {\n    for await (const val of iterable) {\n      yield await func(val);\n    }\n  }\n\n  function map(func, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => _map(func, curriedIterable);\n    }\n\n    return _map(func, iterable);\n  }\n\n  function flatMap(func, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => flatMap(func, curriedIterable);\n    }\n\n    return filter(i => i !== undefined && i !== null, flatten(map(func, iterable)));\n  }\n\n  function _flatTransform(concurrency, func, iterable) {\n    const iterator = getIterator(iterable);\n    const resultQueue = [];\n    const readQueue = [];\n    let ended = false;\n    let reading = false;\n    let inflightCount = 0;\n    let lastError = null;\n\n    function fulfillReadQueue() {\n      while (readQueue.length > 0 && resultQueue.length > 0) {\n        const {\n          resolve\n        } = readQueue.shift();\n        const value = resultQueue.shift();\n        resolve({\n          done: false,\n          value\n        });\n      }\n\n      while (readQueue.length > 0 && inflightCount === 0 && ended) {\n        const {\n          resolve,\n          reject\n        } = readQueue.shift();\n\n        if (lastError) {\n          reject(lastError);\n          lastError = null;\n        } else {\n          resolve({\n            done: true,\n            value: undefined\n          });\n        }\n      }\n    }\n\n    async function fillQueue() {\n      if (ended) {\n        fulfillReadQueue();\n        return;\n      }\n\n      if (reading) {\n        return;\n      }\n\n      if (inflightCount + resultQueue.length >= concurrency) {\n        return;\n      }\n\n      reading = true;\n      inflightCount++;\n\n      try {\n        const {\n          done,\n          value\n        } = await iterator.next();\n\n        if (done) {\n          ended = true;\n          inflightCount--;\n          fulfillReadQueue();\n        } else {\n          mapAndQueue(value);\n        }\n      } catch (error) {\n        ended = true;\n        inflightCount--;\n        lastError = error;\n        fulfillReadQueue();\n      }\n\n      reading = false;\n      fillQueue();\n    }\n\n    async function mapAndQueue(itrValue) {\n      try {\n        const value = await func(itrValue);\n\n        if (value && value[Symbol.asyncIterator]) {\n          for await (const asyncVal of value) {\n            resultQueue.push(asyncVal);\n          }\n        } else {\n          resultQueue.push(value);\n        }\n      } catch (error) {\n        ended = true;\n        lastError = error;\n      }\n\n      inflightCount--;\n      fulfillReadQueue();\n      fillQueue();\n    }\n\n    async function next() {\n      if (resultQueue.length === 0) {\n        const deferred = defer();\n        readQueue.push(deferred);\n        fillQueue();\n        return deferred.promise;\n      }\n\n      const value = resultQueue.shift();\n      fillQueue();\n      return {\n        done: false,\n        value\n      };\n    }\n\n    const asyncIterableIterator = {\n      next,\n      [Symbol.asyncIterator]: () => asyncIterableIterator\n    };\n    return asyncIterableIterator;\n  }\n\n  function flatTransform(concurrency, func, iterable) {\n    if (func === undefined) {\n      return (curriedFunc, curriedIterable) => curriedIterable ? flatTransform(concurrency, curriedFunc, curriedIterable) : flatTransform(concurrency, curriedFunc);\n    }\n\n    if (iterable === undefined) {\n      return curriedIterable => flatTransform(concurrency, func, curriedIterable);\n    }\n\n    return filter(i => i !== undefined && i !== null, flatten(_flatTransform(concurrency, func, iterable)));\n  }\n\n  async function onceReadable(stream) {\n    return new Promise(resolve => {\n      stream.once('readable', () => {\n        resolve();\n      });\n    });\n  }\n\n  async function* _fromStream(stream) {\n    while (true) {\n      const data = stream.read();\n\n      if (data !== null) {\n        yield data;\n        continue;\n      }\n\n      if (stream._readableState.ended) {\n        break;\n      }\n\n      await onceReadable(stream);\n    }\n  }\n\n  function fromStream(stream) {\n    if (typeof stream[Symbol.asyncIterator] === 'function') {\n      return stream;\n    }\n\n    return _fromStream(stream);\n  }\n\n  async function* merge(...iterables) {\n    const sources = new Set(iterables.map(getIterator));\n\n    while (sources.size > 0) {\n      for (const iterator of sources) {\n        const nextVal = await iterator.next();\n\n        if (nextVal.done) {\n          sources.delete(iterator);\n        } else {\n          yield nextVal.value;\n        }\n      }\n    }\n  }\n\n  function pipeline(firstFn, ...fns) {\n    let previousFn = firstFn();\n\n    for (const func of fns) {\n      previousFn = func(previousFn);\n    }\n\n    return previousFn;\n  }\n\n  async function* _parallelMap(concurrency, func, iterable) {\n    let transformError = null;\n\n    const wrapFunc = value => ({\n      value: func(value)\n    });\n\n    const stopOnError = async function* (source) {\n      for await (const value of source) {\n        if (transformError) {\n          return;\n        }\n\n        yield value;\n      }\n    };\n\n    const output = pipeline(() => iterable, buffer(1), stopOnError, map(wrapFunc), buffer(concurrency - 1));\n    const itr = getIterator(output);\n\n    while (true) {\n      const {\n        value,\n        done\n      } = await itr.next();\n\n      if (done) {\n        break;\n      }\n\n      try {\n        const val = await value.value;\n\n        if (!transformError) {\n          yield val;\n        }\n      } catch (error) {\n        transformError = error;\n      }\n    }\n\n    if (transformError) {\n      throw transformError;\n    }\n  }\n\n  function parallelMap(concurrency, func, iterable) {\n    if (func === undefined) {\n      return (curriedFunc, curriedIterable) => parallelMap(concurrency, curriedFunc, curriedIterable);\n    }\n\n    if (iterable === undefined) {\n      return curriedIterable => parallelMap(concurrency, func, curriedIterable);\n    }\n\n    if (concurrency === 1) {\n      return map(func, iterable);\n    }\n\n    return _parallelMap(concurrency, func, iterable);\n  }\n\n  function parallelFlatMap(concurrency, func, iterable) {\n    if (func === undefined) {\n      return (curriedFunc, curriedIterable) => curriedIterable ? parallelFlatMap(concurrency, curriedFunc, curriedIterable) : parallelFlatMap(concurrency, curriedFunc);\n    }\n\n    if (iterable === undefined) {\n      return curriedIterable => parallelFlatMap(concurrency, func, curriedIterable);\n    }\n\n    return filter(i => i !== undefined && i !== null, flatten(parallelMap(concurrency, func, iterable)));\n  }\n\n  async function* parallelMerge(...iterables) {\n    const inputs = iterables.map(getIterator);\n    const concurrentWork = new Set();\n    const values = new Map();\n    let lastError = null;\n    let errCb = null;\n    let valueCb = null;\n\n    const notifyError = err => {\n      lastError = err;\n\n      if (errCb) {\n        errCb(err);\n      }\n    };\n\n    const notifyDone = value => {\n      if (valueCb) {\n        valueCb(value);\n      }\n    };\n\n    const waitForQueue = () => new Promise((resolve, reject) => {\n      if (lastError) {\n        reject(lastError);\n      }\n\n      if (values.size > 0) {\n        return resolve();\n      }\n\n      valueCb = resolve;\n      errCb = reject;\n    });\n\n    const queueNext = input => {\n      const nextVal = Promise.resolve(input.next()).then(async ({\n        done,\n        value\n      }) => {\n        if (!done) {\n          values.set(input, value);\n        }\n\n        concurrentWork.delete(nextVal);\n      });\n      concurrentWork.add(nextVal);\n      nextVal.then(notifyDone, notifyError);\n    };\n\n    for (const input of inputs) {\n      queueNext(input);\n    }\n\n    while (true) {\n      // We technically don't have to check `values.size` as the for loop should have emptied it\n      // However I haven't yet found specs verifying that behavior, only tests\n      // the guard in waitForQueue() checking for values is in place for the same reason\n      if (concurrentWork.size === 0 && values.size === 0) {\n        return;\n      }\n\n      await waitForQueue();\n\n      for (const [input, value] of values) {\n        values.delete(input);\n        yield value;\n        queueNext(input);\n      }\n    }\n  }\n\n  async function _reduce(func, start, iterable) {\n    let value = start;\n\n    for await (const nextItem of iterable) {\n      value = await func(value, nextItem);\n    }\n\n    return value;\n  }\n\n  function reduce(func, start, iterable) {\n    if (start === undefined) {\n      return (curriedStart, curriedIterable) => curriedIterable ? _reduce(func, curriedStart, curriedIterable) : reduce(func, curriedStart);\n    }\n\n    if (iterable === undefined) {\n      return curriedIterable => reduce(func, start, curriedIterable);\n    }\n\n    return _reduce(func, start, iterable);\n  }\n\n  async function* _take(count, iterable) {\n    let taken = 0;\n\n    for await (const val of iterable) {\n      yield await val;\n      taken++;\n\n      if (taken >= count) {\n        break;\n      }\n    }\n  }\n\n  function* _syncTake(count, iterable) {\n    let taken = 0;\n\n    for (const val of iterable) {\n      yield val;\n      taken++;\n\n      if (taken >= count) {\n        break;\n      }\n    }\n  }\n\n  function take(count, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => take(count, curriedIterable);\n    }\n\n    if (iterable[Symbol.asyncIterator]) {\n      return _take(count, iterable);\n    }\n\n    return _syncTake(count, iterable);\n  }\n\n  async function* _asyncTap(func, iterable) {\n    for await (const val of iterable) {\n      await func(val);\n      yield val;\n    }\n  }\n\n  function tap(func, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => _asyncTap(func, curriedIterable);\n    }\n\n    return _asyncTap(func, iterable);\n  }\n\n  const sleep = ms => new Promise(resolve => setTimeout(resolve, ms));\n\n  function _throttle(limit, interval, iterable) {\n    if (!Number.isFinite(limit)) {\n      throw new TypeError('Expected `limit` to be a finite number');\n    }\n\n    if (limit <= 0) {\n      throw new TypeError('Expected `limit` to be greater than 0');\n    }\n\n    if (!Number.isFinite(interval)) {\n      throw new TypeError('Expected `interval` to be a finite number');\n    }\n\n    return async function* __throttle() {\n      let sent = 0;\n      let time;\n\n      for await (const val of iterable) {\n        if (sent < limit) {\n          if (typeof time === 'undefined') {\n            time = Date.now();\n          }\n\n          sent++;\n          yield val;\n          continue;\n        } // Only wait if the interval hasn't already passed while we were\n        // yielding the previous values.\n\n\n        const elapsedMs = Date.now() - time;\n        const waitFor = interval - elapsedMs;\n\n        if (waitFor > 0) {\n          await sleep(waitFor);\n        }\n\n        time = Date.now();\n        sent = 1;\n        yield val;\n      }\n    }();\n  }\n\n  function throttle(limit, interval, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => _throttle(limit, interval, curriedIterable);\n    }\n\n    return _throttle(limit, interval, iterable);\n  }\n\n  function addTime(a, b) {\n    let seconds = a[0] + b[0];\n    let nanoseconds = a[1] + b[1];\n\n    if (nanoseconds >= 1000000000) {\n      const remainder = nanoseconds % 1000000000;\n      seconds += (nanoseconds - remainder) / 1000000000;\n      nanoseconds = remainder;\n    }\n\n    return [seconds, nanoseconds];\n  }\n\n  async function* _asyncTime(config, iterable) {\n    const itr = iterable[Symbol.asyncIterator]();\n    let total = [0, 0];\n\n    while (true) {\n      const start = process.hrtime();\n      const {\n        value,\n        done\n      } = await itr.next();\n      const delta = process.hrtime(start);\n      total = addTime(total, delta);\n\n      if (config.progress) {\n        config.progress(delta, total);\n      }\n\n      if (done) {\n        if (config.total) {\n          config.total(total);\n        }\n\n        return value;\n      }\n\n      yield value;\n    }\n  }\n\n  function* _syncTime(config, iterable) {\n    const itr = iterable[Symbol.iterator]();\n    let total = [0, 0];\n\n    while (true) {\n      const start = process.hrtime();\n      const {\n        value,\n        done\n      } = itr.next();\n      const delta = process.hrtime(start);\n      total = addTime(total, delta);\n\n      if (config.progress) {\n        config.progress(delta, total);\n      }\n\n      if (done) {\n        if (config.total) {\n          config.total(total);\n        }\n\n        return value;\n      }\n\n      yield value;\n    }\n  }\n\n  function time(config = {}, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => time(config, curriedIterable);\n    }\n\n    if (iterable[Symbol.asyncIterator] !== undefined) {\n      return _asyncTime(config, iterable);\n    } else {\n      return _syncTime(config, iterable);\n    }\n  }\n\n  function _transform(concurrency, func, iterable) {\n    const iterator = getIterator(iterable);\n    const resultQueue = [];\n    const readQueue = [];\n    let ended = false;\n    let reading = false;\n    let inflightCount = 0;\n    let lastError = null;\n\n    function fulfillReadQueue() {\n      while (readQueue.length > 0 && resultQueue.length > 0) {\n        const {\n          resolve\n        } = readQueue.shift();\n        const value = resultQueue.shift();\n        resolve({\n          done: false,\n          value\n        });\n      }\n\n      while (readQueue.length > 0 && inflightCount === 0 && ended) {\n        const {\n          resolve,\n          reject\n        } = readQueue.shift();\n\n        if (lastError) {\n          reject(lastError);\n          lastError = null;\n        } else {\n          resolve({\n            done: true,\n            value: undefined\n          });\n        }\n      }\n    }\n\n    async function fillQueue() {\n      if (ended) {\n        fulfillReadQueue();\n        return;\n      }\n\n      if (reading) {\n        return;\n      }\n\n      if (inflightCount + resultQueue.length >= concurrency) {\n        return;\n      }\n\n      reading = true;\n      inflightCount++;\n\n      try {\n        const {\n          done,\n          value\n        } = await iterator.next();\n\n        if (done) {\n          ended = true;\n          inflightCount--;\n          fulfillReadQueue();\n        } else {\n          mapAndQueue(value);\n        }\n      } catch (error) {\n        ended = true;\n        inflightCount--;\n        lastError = error;\n        fulfillReadQueue();\n      }\n\n      reading = false;\n      fillQueue();\n    }\n\n    async function mapAndQueue(itrValue) {\n      try {\n        const value = await func(itrValue);\n        resultQueue.push(value);\n      } catch (error) {\n        ended = true;\n        lastError = error;\n      }\n\n      inflightCount--;\n      fulfillReadQueue();\n      fillQueue();\n    }\n\n    async function next() {\n      if (resultQueue.length === 0) {\n        const deferred = defer();\n        readQueue.push(deferred);\n        fillQueue();\n        return deferred.promise;\n      }\n\n      const value = resultQueue.shift();\n      fillQueue();\n      return {\n        done: false,\n        value\n      };\n    }\n\n    const asyncIterableIterator = {\n      next,\n      [Symbol.asyncIterator]: () => asyncIterableIterator\n    };\n    return asyncIterableIterator;\n  }\n\n  function transform(concurrency, func, iterable) {\n    if (func === undefined) {\n      return (curriedFunc, curriedIterable) => curriedIterable ? transform(concurrency, curriedFunc, curriedIterable) : transform(concurrency, curriedFunc);\n    }\n\n    if (iterable === undefined) {\n      return curriedIterable => transform(concurrency, func, curriedIterable);\n    }\n\n    return _transform(concurrency, func, iterable);\n  }\n\n  async function _writeToStream(stream, iterable) {\n    let lastError = null;\n    let errCb = null;\n    let drainCb = null;\n\n    const notifyError = err => {\n      lastError = err;\n\n      if (errCb) {\n        errCb(err);\n      }\n    };\n\n    const notifyDrain = () => {\n      if (drainCb) {\n        drainCb();\n      }\n    };\n\n    const cleanup = () => {\n      stream.removeListener('error', notifyError);\n      stream.removeListener('drain', notifyDrain);\n    };\n\n    stream.once('error', notifyError);\n\n    const waitForDrain = () => new Promise((resolve, reject) => {\n      if (lastError) {\n        return reject(lastError);\n      }\n\n      stream.once('drain', notifyDrain);\n      drainCb = resolve;\n      errCb = reject;\n    });\n\n    for await (const value of iterable) {\n      if (stream.write(value) === false) {\n        await waitForDrain();\n      }\n\n      if (lastError) {\n        break;\n      }\n    }\n\n    cleanup();\n\n    if (lastError) {\n      throw lastError;\n    }\n  }\n\n  function writeToStream(stream, iterable) {\n    if (iterable === undefined) {\n      return curriedIterable => _writeToStream(stream, curriedIterable);\n    }\n\n    return _writeToStream(stream, iterable);\n  }\n\n  exports.batch = batch;\n  exports.batchWithTimeout = batchWithTimeout;\n  exports.buffer = buffer;\n  exports.collect = collect;\n  exports.concat = concat;\n  exports.consume = consume;\n  exports.filter = filter;\n  exports.flatMap = flatMap;\n  exports.flatTransform = flatTransform;\n  exports.flatten = flatten;\n  exports.fromStream = fromStream;\n  exports.getIterator = getIterator;\n  exports.map = map;\n  exports.merge = merge;\n  exports.parallelFlatMap = parallelFlatMap;\n  exports.parallelMap = parallelMap;\n  exports.parallelMerge = parallelMerge;\n  exports.pipeline = pipeline;\n  exports.reduce = reduce;\n  exports.take = take;\n  exports.tap = tap;\n  exports.throttle = throttle;\n  exports.time = time;\n  exports.transform = transform;\n  exports.writeToStream = writeToStream;\n  Object.defineProperty(exports, '__esModule', {\n    value: true\n  });\n});\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/streaming-iterables/dist/index.js?");

/***/ }),

/***/ "./node_modules/uint8arrays/cjs/src/concat.js":
/*!****************************************************!*\
  !*** ./node_modules/uint8arrays/cjs/src/concat.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nfunction concat(arrays, length) {\n  if (!length) {\n    length = arrays.reduce((acc, curr) => acc + curr.length, 0);\n  }\n\n  const output = new Uint8Array(length);\n  let offset = 0;\n\n  for (const arr of arrays) {\n    output.set(arr, offset);\n    offset += arr.length;\n  }\n\n  return output;\n}\n\nexports.concat = concat;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/uint8arrays/cjs/src/concat.js?");

/***/ }),

/***/ "./node_modules/uint8arrays/cjs/src/equals.js":
/*!****************************************************!*\
  !*** ./node_modules/uint8arrays/cjs/src/equals.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nfunction equals(a, b) {\n  if (a === b) {\n    return true;\n  }\n\n  if (a.byteLength !== b.byteLength) {\n    return false;\n  }\n\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nexports.equals = equals;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/uint8arrays/cjs/src/equals.js?");

/***/ }),

/***/ "./node_modules/uint8arrays/cjs/src/from-string.js":
/*!*********************************************************!*\
  !*** ./node_modules/uint8arrays/cjs/src/from-string.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\n\nvar bases = __webpack_require__(/*! ./util/bases.js */ \"./node_modules/uint8arrays/cjs/src/util/bases.js\");\n\nfunction fromString(string, encoding = 'utf8') {\n  const base = bases[encoding];\n\n  if (!base) {\n    throw new Error(`Unsupported encoding \"${encoding}\"`);\n  }\n\n  return base.decoder.decode(`${base.prefix}${string}`);\n}\n\nexports.fromString = fromString;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/uint8arrays/cjs/src/from-string.js?");

/***/ }),

/***/ "./node_modules/uint8arrays/cjs/src/util/bases.js":
/*!********************************************************!*\
  !*** ./node_modules/uint8arrays/cjs/src/util/bases.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar basics = __webpack_require__(/*! multiformats/basics */ \"./node_modules/multiformats/cjs/src/basics.js\");\n\nfunction createCodec(name, prefix, encode, decode) {\n  return {\n    name,\n    prefix,\n    encoder: {\n      name,\n      prefix,\n      encode\n    },\n    decoder: {\n      decode\n    }\n  };\n}\n\nconst string = createCodec('utf8', 'u', buf => {\n  const decoder = new TextDecoder('utf8');\n  return 'u' + decoder.decode(buf);\n}, str => {\n  const encoder = new TextEncoder();\n  return encoder.encode(str.substring(1));\n});\nconst ascii = createCodec('ascii', 'a', buf => {\n  let string = 'a';\n\n  for (let i = 0; i < buf.length; i++) {\n    string += String.fromCharCode(buf[i]);\n  }\n\n  return string;\n}, str => {\n  str = str.substring(1);\n  const buf = new Uint8Array(str.length);\n\n  for (let i = 0; i < str.length; i++) {\n    buf[i] = str.charCodeAt(i);\n  }\n\n  return buf;\n});\nconst BASES = {\n  utf8: string,\n  'utf-8': string,\n  hex: basics.bases.base16,\n  latin1: ascii,\n  ascii: ascii,\n  binary: ascii,\n  ...basics.bases\n};\nmodule.exports = BASES;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/uint8arrays/cjs/src/util/bases.js?");

/***/ }),

/***/ "./node_modules/varint/decode.js":
/*!***************************************!*\
  !*** ./node_modules/varint/decode.js ***!
  \***************************************/
/***/ ((module) => {

eval("module.exports = read;\nvar MSB = 0x80,\n    REST = 0x7F;\n\nfunction read(buf, offset) {\n  var res = 0,\n      offset = offset || 0,\n      shift = 0,\n      counter = offset,\n      b,\n      l = buf.length;\n\n  do {\n    if (counter >= l || shift > 49) {\n      read.bytes = 0;\n      throw new RangeError('Could not decode varint');\n    }\n\n    b = buf[counter++];\n    res += shift < 28 ? (b & REST) << shift : (b & REST) * Math.pow(2, shift);\n    shift += 7;\n  } while (b >= MSB);\n\n  read.bytes = counter - offset;\n  return res;\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/varint/decode.js?");

/***/ }),

/***/ "./node_modules/varint/encode.js":
/*!***************************************!*\
  !*** ./node_modules/varint/encode.js ***!
  \***************************************/
/***/ ((module) => {

eval("module.exports = encode;\nvar MSB = 0x80,\n    REST = 0x7F,\n    MSBALL = ~REST,\n    INT = Math.pow(2, 31);\n\nfunction encode(num, out, offset) {\n  if (Number.MAX_SAFE_INTEGER && num > Number.MAX_SAFE_INTEGER) {\n    encode.bytes = 0;\n    throw new RangeError('Could not encode varint');\n  }\n\n  out = out || [];\n  offset = offset || 0;\n  var oldOffset = offset;\n\n  while (num >= INT) {\n    out[offset++] = num & 0xFF | MSB;\n    num /= 128;\n  }\n\n  while (num & MSBALL) {\n    out[offset++] = num & 0xFF | MSB;\n    num >>>= 7;\n  }\n\n  out[offset] = num | 0;\n  encode.bytes = offset - oldOffset + 1;\n  return out;\n}\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/varint/encode.js?");

/***/ }),

/***/ "./node_modules/varint/index.js":
/*!**************************************!*\
  !*** ./node_modules/varint/index.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = {\n  encode: __webpack_require__(/*! ./encode.js */ \"./node_modules/varint/encode.js\"),\n  decode: __webpack_require__(/*! ./decode.js */ \"./node_modules/varint/decode.js\"),\n  encodingLength: __webpack_require__(/*! ./length.js */ \"./node_modules/varint/length.js\")\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/varint/index.js?");

/***/ }),

/***/ "./node_modules/varint/length.js":
/*!***************************************!*\
  !*** ./node_modules/varint/length.js ***!
  \***************************************/
/***/ ((module) => {

eval("var N1 = Math.pow(2, 7);\nvar N2 = Math.pow(2, 14);\nvar N3 = Math.pow(2, 21);\nvar N4 = Math.pow(2, 28);\nvar N5 = Math.pow(2, 35);\nvar N6 = Math.pow(2, 42);\nvar N7 = Math.pow(2, 49);\nvar N8 = Math.pow(2, 56);\nvar N9 = Math.pow(2, 63);\n\nmodule.exports = function (value) {\n  return value < N1 ? 1 : value < N2 ? 2 : value < N3 ? 3 : value < N4 ? 4 : value < N5 ? 5 : value < N6 ? 6 : value < N7 ? 7 : value < N8 ? 8 : value < N9 ? 9 : 10;\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/varint/length.js?");

/***/ }),

/***/ "./node_modules/web-encoding/src/lib.js":
/*!**********************************************!*\
  !*** ./node_modules/web-encoding/src/lib.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nexports.TextEncoder = typeof TextEncoder !== \"undefined\" ? TextEncoder : (__webpack_require__(/*! util */ \"util\").TextEncoder);\nexports.TextDecoder = typeof TextDecoder !== \"undefined\" ? TextDecoder : (__webpack_require__(/*! util */ \"util\").TextDecoder);\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/web-encoding/src/lib.js?");

/***/ }),

/***/ "./src/config-related.js":
/*!*******************************!*\
  !*** ./src/config-related.js ***!
  \*******************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! fs */ \"fs\");\n\nconst crypt = __webpack_require__(/*! crypto */ \"crypto\"); //const { configpath, confdirpath, keystorepath, profilespath } = require('./initial-vals')\n\n\nconst initialVals = __webpack_require__(/*! ./initial-vals */ \"./src/initial-vals.js\");\n\nconst {\n  configpath,\n  confdirpath,\n  keystorepath,\n  profilespath\n} = initialVals;\n\nlet setup = () => {\n  // try to read ~/.config/w3proof-dispatch/config.json --> create if doesn't exist\n  if (!fs.existsSync(configpath)) {\n    fs.mkdirSync(confdirpath, {\n      recursive: true\n    }); // it creates any directory in the specified path if it does not exist\n\n    let configObj = {\n      \"my-gateway\": \"http://dweb.link\",\n      \"my-web3.storage-api-token\": \"**insert your token here**\"\n    };\n    fs.writeFileSync(configpath, JSON.stringify(configObj));\n  }\n\n  if (!fs.existsSync(keystorepath)) {\n    fs.writeFileSync(keystorepath, JSON.stringify({}));\n  }\n\n  if (!fs.existsSync(profilespath)) {\n    fs.writeFileSync(profilespath, JSON.stringify({}));\n  }\n};\n\nlet keygen = profileName => {\n  /* const {\n      publicKey,\n      privateKey\n  } = crypto.generateKeyPairSync('rsa', {\n      modulusLength : 4096,\n      publicKeyEncoding: {\n          type : 'spki',\n          format : 'pem'\n      },\n      privateKeyEncoding: {\n          type: 'pkcs8',\n          format: 'pem',\n          cipher: 'aes-256-cbc',\n          passphrase: 'top secret'\n      }\n  }) */\n  const {\n    privateKey,\n    publicKey\n  } = crypt.generateKeyPairSync('ec', {\n    namedCurve: 'sect239k1',\n    publicKeyEncoding: {\n      type: 'spki',\n      format: 'pem'\n    },\n    privateKeyEncoding: {\n      type: 'pkcs8',\n      format: 'pem'\n    }\n  }); //console.log(\"private key : \" + privateKey)\n  //console.log(\"public key : \" + publicKey)\n  // create a profile and add it to the profiles file\n\n  let fingerPrint = crypt.createHash('sha256').update(publicKey).digest('hex');\n  let profiles = JSON.parse(fs.readFileSync(profilespath));\n  let newProfile = {\n    \"name\": profileName,\n    \"public-key\": publicKey,\n    \"private-key\": privateKey,\n    \"fingerprint\": fingerPrint\n  };\n  profiles[profileName] = newProfile;\n\n  try {\n    fs.writeFileSync(profilespath, JSON.stringify(profiles));\n  } catch (err) {\n    console.log(err);\n  }\n};\n\nlet setweb3token = token => {\n  let configFile = fs.readFileSync(configpath);\n  let config = JSON.parse(configFile);\n  config[\"my-web3.storage-api-token\"] = token;\n\n  try {\n    fs.writeFileSync(configpath, JSON.stringify(config));\n  } catch (err) {\n    console.log(err);\n  }\n};\n\nlet setgateway = gateway => {\n  let configFile = fs.readFileSync(configpath);\n  let config = JSON.parse(configFile);\n  config[\"my-gateway\"] = gateway;\n\n  try {\n    fs.writeFileSync(configpath, JSON.stringify(config));\n  } catch (err) {\n    console.log(err);\n  }\n};\n\nlet listconfig = () => {\n  let configFile = fs.readFileSync(configpath);\n  let config = JSON.parse(configFile);\n  console.log(config);\n};\n\nmodule.exports = {\n  setup,\n  keygen,\n  setweb3token,\n  setgateway,\n  listconfig\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./src/config-related.js?");

/***/ }),

/***/ "./src/get.js":
/*!********************!*\
  !*** ./src/get.js ***!
  \********************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
eval("\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nconst fs = __webpack_require__(/*! fs */ \"fs\");\n\nconst {\n  execSync\n} = __webpack_require__(/*! child_process */ \"child_process\");\n\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\"); // cid refers to: formula, sequent, assertion, or sequence\n\n\nlet getCommand = (cid, directoryPath) => __awaiter(void 0, void 0, void 0, function* () {\n  let result = {};\n\n  try {\n    let mainObj = yield ipfsGetObj(cid);\n\n    if (mainObj != {}) {\n      if (!isFormula(mainObj) && !isSequent(mainObj) && !isAssertion(mainObj) && !isSequence(mainObj)) throw new Error(\"Retrieved object has unknown/invalid format.\");\n      let mainObjFormat = mainObj[\"format\"];\n\n      if (mainObjFormat == \"assertion\") {\n        if (verifySignature(mainObj)) {\n          let asset = yield ipfsGetObj(mainObj[\"asset\"][\"/\"]);\n          yield processSequent(asset, result, mainObj[\"principal\"]);\n        } else throw new Error(\"Assertion not verified.\");\n      } else if (mainObjFormat == \"asset\") {\n        let assetType = mainObj[\"assetType\"];\n\n        switch (assetType) {\n          case 'formula':\n            yield processFormula(mainObj);\n\n          case 'sequent':\n            yield processSequent(mainObj, result, \"\");\n\n          case 'sequence':\n            yield processSequence(mainObj, result);\n        }\n      }\n    } else throw new Error(\"Retrieved object is empty.\");\n\n    if (!fs.existsSync(directoryPath)) fs.mkdirSync(directoryPath, {\n      recursive: true\n    });\n    fs.writeFileSync(directoryPath + \"/\" + cid + \".json\", JSON.stringify(result));\n    console.log(\"dag referred to by this cid is in the file named thecid.json to be used by abella\");\n  } catch (err) {\n    console.log(err);\n  }\n});\n\nlet processFormula = obj => __awaiter(void 0, void 0, void 0, function* () {\n  console.log(\"the given cid refers to the formula object:\");\n  console.log(obj);\n  console.log(\"This format is NOT allowed/expected to be imported.\");\n});\n\nlet processSequent = (obj, result, signer) => __awaiter(void 0, void 0, void 0, function* () {\n  let lemmas = obj[\"lemmas\"];\n  let conclusion = yield ipfsGetObj(obj[\"conclusion\"][\"/\"]);\n  let entry = {};\n  let theoremName = conclusion[\"name\"];\n\n  if (result[theoremName]) {\n    // test if different cidformula => error, exit\n    // if same cidformula => entry = outputObj[theoremName]\n    entry = result[theoremName];\n\n    if (entry[\"cidFormula\"] != obj[\"conclusion\"][\"/\"]) {\n      console.error(\"Different formula using same name --> not allowed\");\n      process.exit(0);\n    }\n  } else {\n    entry[\"cidFormula\"] = obj[\"conclusion\"][\"/\"];\n    entry[\"formula\"] = conclusion[\"formula\"];\n    entry[\"sigmaFormula\"] = conclusion[\"sigma\"];\n    entry[\"sequents\"] = [];\n  }\n\n  let sequent = {};\n  sequent[\"lemmas\"] = yield unfoldLemmas(lemmas);\n  if (signer != \"\") sequent[\"signer\"] = signer;\n  entry[\"sequents\"].push(sequent);\n  result[theoremName] = entry; //console.log(outputObj)\n  //console.log(\"sequents\")\n  //console.log(outputObj[theoremName][\"sequents\"])\n});\n\nlet processSequence = (obj, result) => __awaiter(void 0, void 0, void 0, function* () {\n  let sequentsLinks = obj[\"sequents\"]; // sequents or assertions\n\n  for (let link of sequentsLinks) {\n    let entry = yield ipfsGetObj(link[\"/\"]);\n\n    if (isAssertion(entry)) {\n      let asset = yield ipfsGetObj(entry[\"asset\"][\"/\"]);\n      yield processSequent(asset, result, entry[\"principal\"]);\n    } else if (isSequent(entry)) {\n      yield processSequent(entry, result, \"\");\n    }\n  }\n});\n\nlet unfoldLemmas = lemmas => __awaiter(void 0, void 0, void 0, function* () {\n  // fix to add checks\n  let lemmaFormulaObjects = [];\n\n  for (let lemma of lemmas) {\n    let formulaObject = yield ipfsGetObj(lemma[\"/\"]);\n    lemmaFormulaObjects.push({\n      \"name\": formulaObject[\"name\"],\n      \"formula\": formulaObject[\"formula\"],\n      \"sigma\": formulaObject[\"sigma\"]\n    });\n  }\n\n  return lemmaFormulaObjects;\n});\n\nlet ipfsGetObj = cid => __awaiter(void 0, void 0, void 0, function* () {\n  try {\n    let cmd = \"ipfs dag get \" + cid + \" > \" + cid + \".json\";\n    execSync(cmd, {\n      encoding: 'utf-8'\n    });\n    let obj = JSON.parse(fs.readFileSync(cid + \".json\"));\n    fs.unlinkSync(cid + \".json\");\n    return obj;\n  } catch (error) {\n    console.error(\"getting object from ipfs failed\");\n    return {};\n  }\n});\n\nlet isAssertion = obj => {\n  if (Object.keys(obj).length == 4 && \"format\" in obj && obj[\"format\"] == \"assertion\") {\n    return \"principal\" in obj && \"asset\" in obj && \"signature\" in obj;\n  }\n\n  return false;\n};\n\nlet isSequent = obj => {\n  if (Object.keys(obj).length == 4 && \"format\" in obj && obj[\"format\"] == \"asset\") {\n    return \"assetType\" in obj && obj[\"assetType\"] == \"sequent\" && \"lemmas\" in obj && \"conclusion\" in obj;\n  }\n\n  return false;\n};\n\nlet isSequence = obj => {\n  if (Object.keys(obj).length == 4 && \"format\" in obj && obj[\"format\"] == \"asset\") {\n    return \"assetType\" in obj && obj[\"assetType\"] == \"sequence\" && \"name\" in obj && \"sequents\" in obj;\n  }\n\n  return false;\n};\n\nlet isFormula = obj => {\n  if (Object.keys(obj).length == 5 && \"format\" in obj && obj[\"format\"] == \"asset\") {\n    return \"assetType\" in obj && obj[\"assetType\"] == \"formula\" && \"name\" in obj && \"formula\" in obj && \"sigma\" in obj;\n  }\n\n  return false;\n};\n\nlet verifySignature = assertion => {\n  let signature = assertion[\"signature\"];\n  let claimedPublicKey = assertion[\"principal\"]; // the data to verify : here it's the asset's cid in the object\n\n  let dataToVerify = assertion[\"asset\"][\"/\"];\n  const verify = crypto.createVerify('SHA256');\n  verify.write(dataToVerify);\n  verify.end();\n  let signatureVerified = verify.verify(claimedPublicKey, signature, 'hex');\n  return signatureVerified;\n};\n\nmodule.exports = {\n  getCommand\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./src/get.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("//#! /usr/bin/env node\n\n\nconst {\n  program\n} = __webpack_require__(/*! commander */ \"./node_modules/commander/index.js\");\n\nconst {\n  publishCommand\n} = __webpack_require__(/*! ./publish.js */ \"./src/publish.js\");\n\nconst {\n  setup,\n  keygen,\n  setweb3token,\n  setgateway,\n  listconfig\n} = __webpack_require__(/*! ./config-related.js */ \"./src/config-related.js\");\n\nconst {\n  getCommand\n} = __webpack_require__(/*! ./get.js */ \"./src/get.js\");\n\nsetup();\nprogram.command('keygen <profileName>').description('generate a public-private key pair with a profile name to be used when publishing. These will be added to your profiles config file. BE CAREFUL ABOUT KEEPING YOUR PRIVATE KEYS PRIVATE !').action(keygen);\nprogram.command('set-web3token <token>').description('set your own web3.storage api token to be able to publish through web3.storage api').action(setweb3token);\nprogram.command('set-gateway <gateway>').description('set the gateway through which files are retreived. The default is set to http://dweb.link').action(setgateway);\nprogram.command('list-config').description('list the configuration parameters - ex: gateway, web3.storage api token').action(listconfig);\nprogram.command('publish-signed <fileName> <directoryPath> <target>').description('publish the standard format .json file generated from abella (or other) theorem files with signature by the specified profile, and you can specify <target> as either \"local\" or \"cloud\" for publishing through web3.storage service. <directoryPath> takes the path of the directory containing the file starting from the directory of execution, ex \"a/b/c.').action(publishCommand);\nprogram.command('get <CID> <directoryPath>').description('constructs the standard format file to be consumed by abella (or other) with the name theGivenCID.json (in case the given cid refers to a sequent, assertion, or sequence object type). <directoryPath> takes the path of the directory to construct the resulting file in (starting from the directory of execution).').action(getCommand);\nprogram.parse();\nmodule.exports = {};\n\n//# sourceURL=webpack://w3proof-dispatch/./src/index.js?");

/***/ }),

/***/ "./src/initial-vals.js":
/*!*****************************!*\
  !*** ./src/initial-vals.js ***!
  \*****************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst os = __webpack_require__(/*! os */ \"os\");\n\nconst confdirpath = os.homedir() + '/.config/w3proof-dispatch';\nconst configpath = confdirpath + \"/config.json\";\nconst keystorepath = confdirpath + \"/keystore.json\";\nconst profilespath = confdirpath + \"/profiles.json\";\nmodule.exports = {\n  configpath,\n  confdirpath,\n  keystorepath,\n  profilespath\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./src/initial-vals.js?");

/***/ }),

/***/ "./src/publish.js":
/*!************************!*\
  !*** ./src/publish.js ***!
  \************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
eval("\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nconst fs = __webpack_require__(/*! fs */ \"fs\");\n\nconst {\n  execSync\n} = __webpack_require__(/*! child_process */ \"child_process\");\n\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\n\nconst {\n  Web3Storage\n} = __webpack_require__(/*! web3.storage */ \"./node_modules/web3.storage/dist/src/lib.cjs\");\n\nconst {\n  CarReader\n} = __webpack_require__(/*! @ipld/car */ \"./node_modules/@ipld/car/cjs/car.js\");\n\nconst initialVals = __webpack_require__(/*! ./initial-vals */ \"./src/initial-vals.js\");\n\nconst {\n  configpath,\n  profilespath\n} = initialVals;\nlet publishedFormulas = {};\nlet publishedSequents = [];\nlet publishedAssertions = [];\n\nlet publishCommand = (filename, profileName, directoryPath, storage) => __awaiter(void 0, void 0, void 0, function* () {\n  try {\n    let theorems = JSON.parse(fs.readFileSync(directoryPath + \"/\" + filename + \".json\")); // publish all formula objects first (to have all the cids ready before publishing a sequent in case a formula is listed as lemma)\n\n    for (let conclusionName of Object.keys(theorems)) {\n      yield publishFormula(conclusionName, theorems[conclusionName][\"conclusion\"], theorems[conclusionName][\"sigma\"]);\n    }\n\n    for (let conclusionName of Object.keys(theorems)) {\n      let sequentsLemmas = theorems[conclusionName][\"sequentsLemmas\"];\n\n      for (let sequentLemmas of sequentsLemmas) {\n        yield publishSequent(conclusionName, sequentLemmas);\n      }\n    }\n\n    for (let sequentCid of publishedSequents) {\n      yield publishAssertion(sequentCid, profileName);\n    }\n\n    let sequenceCid = yield publishSequence(filename, publishedAssertions); //for now publish sequence as composed of assertions signed by the same profile\n\n    console.log(\"The root cid of the published sequence of assertions by profile: \" + profileName + \" is \" + sequenceCid); // if cloud (global), publish the final sequence cid (dag) through the web3.storage api\n\n    if (storage == \"cloud\") {\n      publishDagToCloud(sequenceCid);\n    }\n  } catch (error) {\n    console.error(error);\n  }\n});\n\nlet publishFormula = (formulaName, formula, sigma) => __awaiter(void 0, void 0, void 0, function* () {\n  let th = {\n    \"format\": \"asset\",\n    \"assetType\": \"formula\",\n    \"name\": formulaName,\n    \"formula\": formula,\n    \"sigma\": sigma\n  };\n  let cid = yield ipfsAddObj(th);\n  publishedFormulas[formulaName] = cid;\n});\n\nlet publishSequent = (conclusionName, lemmas) => __awaiter(void 0, void 0, void 0, function* () {\n  let lemmasIpfs = [];\n\n  for (let lemma of lemmas) {\n    if (lemma.startsWith(\"ipfs:\")) {\n      // assuming the cids in \"lemmas\" should refer to a \"formula\" object\n      //(if we remove the .thc generation and replace it with generation of the output format.json file produced by w3proof-dispatch get)\n      let cidFormula = lemma.split(\":\")[1]; // should we test that the cid refers to a formula object here? (check later where it's best to do the cid objects type checking?)\n\n      lemmasIpfs.push({\n        \"/\": cidFormula\n      }); // allowed cids: sequent/assertion and sequence types\n    } else {\n      lemmasIpfs.push({\n        \"/\": publishedFormulas[lemma]\n      });\n    }\n  }\n\n  let seq = {\n    \"format\": \"asset\",\n    \"assetType\": \"sequent\",\n    \"lemmas\": lemmasIpfs,\n    \"conclusion\": {\n      \"/\": publishedFormulas[conclusionName]\n    }\n  };\n  let cid = yield ipfsAddObj(seq);\n  publishedSequents.push(cid);\n});\n\nlet publishAssertion = (sequentCid, profileName) => __awaiter(void 0, void 0, void 0, function* () {\n  try {\n    let profiles = JSON.parse(fs.readFileSync(profilespath));\n\n    if (profiles[profileName]) {\n      let profile = profiles[profileName];\n      const sign = crypto.createSign('SHA256');\n      sign.write(sequentCid);\n      sign.end();\n      const signature = sign.sign(profile[\"private-key\"], 'hex');\n      let assertion = {\n        \"format\": \"assertion\",\n        \"principal\": profile[\"public-key\"],\n        \"asset\": {\n          \"/\": sequentCid\n        },\n        \"signature\": signature\n      };\n      let assertionCid = yield ipfsAddObj(assertion);\n      publishedAssertions.push(assertionCid);\n    } else throw new Error(\"given profile name does not exist\");\n  } catch (error) {\n    console.error(error);\n    process.exit(0);\n  }\n});\n\nlet publishSequence = (sequenceName, sequentsCids) => __awaiter(void 0, void 0, void 0, function* () {\n  let sequentsLinks = [];\n\n  for (let cid of sequentsCids) {\n    sequentsLinks.push({\n      \"/\": cid\n    });\n  }\n\n  let sequence = {\n    \"format\": \"asset\",\n    \"assetType\": \"sequence\",\n    \"name\": sequenceName,\n    \"sequents\": sequentsLinks\n  };\n  console.log(sequence);\n  let sequenceCid = yield ipfsAddObj(sequence);\n  return sequenceCid;\n});\n\nlet ipfsAddObj = obj => __awaiter(void 0, void 0, void 0, function* () {\n  try {\n    fs.writeFileSync(\"tmpJSON.json\", JSON.stringify(obj));\n    let addcmd = \"ipfs dag put tmpJSON.json --pin\";\n    let output = execSync(addcmd, {\n      encoding: 'utf-8'\n    });\n    fs.unlinkSync('tmpJSON.json');\n    return output.substring(0, output.length - 1);\n  } catch (error) {\n    console.error(\"adding object to ipfs failed\");\n    return \"\";\n  }\n});\n\nlet publishDagToCloud = cid => __awaiter(void 0, void 0, void 0, function* () {\n  let web3Token, web3Client;\n\n  try {\n    let config = JSON.parse(fs.readFileSync(configpath));\n\n    if (config[\"my-web3.storage-api-token\"] && config[\"my-web3.storage-api-token\"] != \"**insert your token here**\") {\n      web3Token = config[\"my-web3.storage-api-token\"];\n      web3Client = new Web3Storage({\n        token: web3Token\n      });\n    } else {\n      throw new Error(\"setting a web3.storage token is required as the chosen mode for publishing is 'cloud' and not 'local'.\");\n    }\n\n    let cmd = \"ipfs dag export \" + cid + \" > tmpcar.car\";\n    execSync(cmd, {\n      encoding: 'utf-8'\n    });\n    const inStream = fs.createReadStream('tmpcar.car'); // read and parse the entire stream in one go, this will cache the contents of\n    // the car in memory so is not suitable for large files.\n\n    const reader = yield CarReader.fromIterable(inStream);\n    const cid1 = yield web3Client.putCar(reader);\n    console.log(\"DAG successfully published to web3.storage!\");\n    fs.unlink('tmpcar.car', err => {\n      if (err) throw err;\n    });\n  } catch (err) {\n    console.log(err);\n  }\n});\n\nmodule.exports = {\n  publishCommand\n};\n\n//# sourceURL=webpack://w3proof-dispatch/./src/publish.js?");

/***/ }),

/***/ "assert":
/*!*************************!*\
  !*** external "assert" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("assert");

/***/ }),

/***/ "buffer":
/*!*************************!*\
  !*** external "buffer" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("buffer");

/***/ }),

/***/ "child_process":
/*!********************************!*\
  !*** external "child_process" ***!
  \********************************/
/***/ ((module) => {

"use strict";
module.exports = require("child_process");

/***/ }),

/***/ "constants":
/*!****************************!*\
  !*** external "constants" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("constants");

/***/ }),

/***/ "crypto":
/*!*************************!*\
  !*** external "crypto" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("crypto");

/***/ }),

/***/ "events":
/*!*************************!*\
  !*** external "events" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("events");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ "http":
/*!***********************!*\
  !*** external "http" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("http");

/***/ }),

/***/ "https":
/*!************************!*\
  !*** external "https" ***!
  \************************/
/***/ ((module) => {

"use strict";
module.exports = require("https");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("os");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("path");

/***/ }),

/***/ "process":
/*!**************************!*\
  !*** external "process" ***!
  \**************************/
/***/ ((module) => {

"use strict";
module.exports = require("process");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("stream");

/***/ }),

/***/ "stream/web":
/*!*****************************!*\
  !*** external "stream/web" ***!
  \*****************************/
/***/ ((module) => {

"use strict";
module.exports = require("stream/web");

/***/ }),

/***/ "url":
/*!**********************!*\
  !*** external "url" ***!
  \**********************/
/***/ ((module) => {

"use strict";
module.exports = require("url");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("util");

/***/ }),

/***/ "zlib":
/*!***********************!*\
  !*** external "zlib" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("zlib");

/***/ }),

/***/ "./node_modules/@web-std/blob/dist/src/blob.cjs":
/*!******************************************************!*\
  !*** ./node_modules/@web-std/blob/dist/src/blob.cjs ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\nvar webEncoding = __webpack_require__(/*! web-encoding */ \"./node_modules/web-encoding/src/lib.js\");\nvar stream = __webpack_require__(/*! @web-std/stream */ \"./node_modules/@web-std/stream/src/stream.cjs\");\n\n/**\n * @implements {globalThis.Blob}\n */\nconst WebBlob = class Blob {\n  /**\n   * @param {BlobPart[]} [init]\n   * @param {BlobPropertyBag} [options]\n   */\n  constructor(init = [], options = {}) {\n    /** @type {Uint8Array[]} */\n    const parts = [];\n\n    let size = 0;\n    for (const part of init) {\n      if (typeof part === \"string\") {\n        const bytes = new webEncoding.TextEncoder().encode(part);\n        parts.push(bytes);\n        size += bytes.byteLength;\n      } else if (part instanceof WebBlob) {\n        size += part.size;\n        // @ts-ignore - `_parts` is marked private so TS will complain about\n        // accessing it.\n        parts.push(...part._parts);\n      } else if (part instanceof ArrayBuffer) {\n        parts.push(new Uint8Array(part));\n        size += part.byteLength;\n      } else if (part instanceof Uint8Array) {\n        parts.push(part);\n        size += part.byteLength;\n      } else if (ArrayBuffer.isView(part)) {\n        const { buffer, byteOffset, byteLength } = part;\n        parts.push(new Uint8Array(buffer, byteOffset, byteLength));\n        size += byteLength;\n      } else {\n        const bytes = new webEncoding.TextEncoder().encode(String(part));\n        parts.push(bytes);\n        size += bytes.byteLength;\n      }\n    }\n\n    /** @private */\n    this._size = size;\n    /** @private */\n    this._type = readType(options.type);\n    /** @private */\n    this._parts = parts;\n\n    Object.defineProperties(this, {\n      _size: { enumerable: false },\n      _type: { enumerable: false },\n      _parts: { enumerable: false },\n    });\n  }\n\n  /**\n   * A string indicating the MIME type of the data contained in the Blob.\n   * If the type is unknown, this string is empty.\n   * @type {string}\n   */\n  get type() {\n    return this._type\n  }\n  /**\n   * The size, in bytes, of the data contained in the Blob object.\n   * @type {number}\n   */\n  get size() {\n    return this._size\n  }\n\n  /**\n   * Returns a new Blob object containing the data in the specified range of\n   * bytes of the blob on which it's called.\n   * @param {number} [start=0] - An index into the Blob indicating the first\n   * byte to include in the new Blob. If you specify a negative value, it's\n   * treated as an offset from the end of the Blob toward the beginning. For\n   * example, `-10` would be the 10th from last byte in the Blob. The default\n   * value is `0`. If you specify a value for start that is larger than the\n   * size of the source Blob, the returned Blob has size 0 and contains no\n   * data.\n   * @param {number} [end] - An index into the `Blob` indicating the first byte\n   *  that will *not* be included in the new `Blob` (i.e. the byte exactly at\n   * this index is not included). If you specify a negative value, it's treated\n   * as an offset from the end of the Blob toward the beginning. For example,\n   * `-10` would be the 10th from last byte in the `Blob`. The default value is\n   * size.\n   * @param {string} [type] - The content type to assign to the new Blob;\n   * this will be the value of its type property. The default value is an empty\n   * string.\n   * @returns {Blob}\n   */\n  slice(start = 0, end = this.size, type = \"\") {\n    const { size, _parts } = this;\n    let offset = start < 0 ? Math.max(size + start, 0) : Math.min(start, size);\n\n    let limit = end < 0 ? Math.max(size + end, 0) : Math.min(end, size);\n    const span = Math.max(limit - offset, 0);\n    const blob = new Blob([], { type });\n\n    if (span === 0) {\n      return blob\n    }\n\n    let blobSize = 0;\n    const blobParts = [];\n    for (const part of _parts) {\n      const { byteLength } = part;\n      if (offset > 0 && byteLength <= offset) {\n        offset -= byteLength;\n        limit -= byteLength;\n      } else {\n        const chunk = part.subarray(offset, Math.min(byteLength, limit));\n        blobParts.push(chunk);\n        blobSize += chunk.byteLength;\n        // no longer need to take that into account\n        offset = 0;\n\n        // don't add the overflow to new blobParts\n        if (blobSize >= span) {\n          break\n        }\n      }\n    }\n\n    blob._parts = blobParts;\n    blob._size = blobSize;\n\n    return blob\n  }\n\n  /**\n   * Returns a promise that resolves with an ArrayBuffer containing the entire\n   * contents of the Blob as binary data.\n   * @returns {Promise<ArrayBuffer>}\n   */\n  // eslint-disable-next-line require-await\n  async arrayBuffer() {\n    const buffer = new ArrayBuffer(this.size);\n    const bytes = new Uint8Array(buffer);\n    let offset = 0;\n    for (const part of this._parts) {\n      bytes.set(part, offset);\n      offset += part.byteLength;\n    }\n    return buffer\n  }\n\n  /**\n   * Returns a promise that resolves with a USVString containing the entire\n   * contents of the Blob interpreted as UTF-8 text.\n   * @returns {Promise<string>}\n   */\n  // eslint-disable-next-line require-await\n  async text() {\n    const decoder = new webEncoding.TextDecoder();\n    let text = \"\";\n    for (const part of this._parts) {\n      text += decoder.decode(part);\n    }\n    return text\n  }\n\n  /**\n   * @returns {BlobStream}\n   */\n  stream() {\n    return new BlobStream(this._parts)\n  }\n\n  /**\n   * @returns {string}\n   */\n  toString() {\n    return \"[object Blob]\"\n  }\n\n  get [Symbol.toStringTag]() {\n    return \"Blob\"\n  }\n};\n\n// Marking export as a DOM File object instead of custom class.\n/** @type {typeof globalThis.Blob} */\nconst Blob = WebBlob;\n\n/**\n * Blob stream is a `ReadableStream` extension optimized to have minimal\n * overhead when consumed as `AsyncIterable<Uint8Array>`.\n * @extends {ReadableStream<Uint8Array>}\n * @implements {AsyncIterable<Uint8Array>}\n */\nclass BlobStream extends stream.ReadableStream {\n  /**\n   * @param {Uint8Array[]} chunks\n   */\n  constructor(chunks) {\n    // @ts-ignore\n    super(new BlobStreamController(chunks.values()), { type: \"bytes\" });\n    /** @private */\n    this._chunks = chunks;\n  }\n\n  /**\n   * @param {Object} [_options]\n   * @property {boolean} [_options.preventCancel]\n   * @returns {AsyncIterator<Uint8Array>}\n   */\n  async *[Symbol.asyncIterator](_options) {\n    const reader = this.getReader();\n    yield* this._chunks;\n    reader.releaseLock();\n  }\n}\n\nclass BlobStreamController {\n  /**\n   * @param {Iterator<Uint8Array>} chunks\n   */\n  constructor(chunks) {\n    this.chunks = chunks;\n  }\n\n  /**\n   * @param {ReadableStreamDefaultController} controller\n   */\n  start(controller) {\n    this.work(controller);\n    this.isWorking = false;\n    this.isCancelled = false;\n  }\n  /**\n   *\n   * @param {ReadableStreamDefaultController} controller\n   */\n  async work(controller) {\n    const { chunks } = this;\n\n    this.isWorking = true;\n    while (!this.isCancelled && (controller.desiredSize || 0) > 0) {\n      let next = null;\n      try {\n        next = chunks.next();\n      } catch (error) {\n        controller.error(error);\n        break\n      }\n\n      if (next) {\n        if (!next.done && !this.isCancelled) {\n          controller.enqueue(next.value);\n        } else {\n          controller.close();\n        }\n      }\n    }\n\n    this.isWorking = false;\n  }\n\n  /**\n   * @param {ReadableStreamDefaultController} controller\n   */\n  pull(controller) {\n    if (!this.isWorking) {\n      this.work(controller);\n    }\n  }\n  cancel() {\n    this.isCancelled = true;\n  }\n}\n\n/**\n * @param {string} [input]\n * @returns {string}\n */\nconst readType = (input = \"\") => {\n  const type = String(input).toLowerCase();\n  return /[^\\u0020-\\u007E]/.test(type) ? \"\" : type\n};\n\nObject.defineProperty(exports, \"TextDecoder\", ({\n  enumerable: true,\n  get: function () {\n    return webEncoding.TextDecoder;\n  }\n}));\nObject.defineProperty(exports, \"TextEncoder\", ({\n  enumerable: true,\n  get: function () {\n    return webEncoding.TextEncoder;\n  }\n}));\nObject.defineProperty(exports, \"ReadableStream\", ({\n  enumerable: true,\n  get: function () {\n    return stream.ReadableStream;\n  }\n}));\nexports.Blob = Blob;\n//# sourceMappingURL=blob.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/blob/dist/src/blob.cjs?");

/***/ }),

/***/ "./node_modules/@web-std/blob/dist/src/lib.node.cjs":
/*!**********************************************************!*\
  !*** ./node_modules/@web-std/blob/dist/src/lib.node.cjs ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\nvar webEncoding = __webpack_require__(/*! web-encoding */ \"./node_modules/web-encoding/src/lib.js\");\nvar stream = __webpack_require__(/*! @web-std/stream */ \"./node_modules/@web-std/stream/src/stream.cjs\");\nvar blob = __webpack_require__(/*! ./blob.cjs */ \"./node_modules/@web-std/blob/dist/src/blob.cjs\");\n\n/** @type {typeof globalThis.Blob} */\n// Our first choise is to use global `Blob` because it may be available e.g. in\n// electron renderrer process. If not available fall back to node native\n// implementation, if also not available use our implementation.\nconst Blob =\n  globalThis.Blob || \n  // Disable node native blob until impractical perf issue is fixed\n  // @see https://github.com/nodejs/node/issues/42108\n  // NodeBlob ||\n  blob.Blob;\n\nObject.defineProperty(exports, \"TextDecoder\", ({\n  enumerable: true,\n  get: function () {\n    return webEncoding.TextDecoder;\n  }\n}));\nObject.defineProperty(exports, \"TextEncoder\", ({\n  enumerable: true,\n  get: function () {\n    return webEncoding.TextEncoder;\n  }\n}));\nObject.defineProperty(exports, \"ReadableStream\", ({\n  enumerable: true,\n  get: function () {\n    return stream.ReadableStream;\n  }\n}));\nexports.Blob = Blob;\n//# sourceMappingURL=lib.node.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/blob/dist/src/lib.node.cjs?");

/***/ }),

/***/ "./node_modules/@web-std/fetch/dist/index.cjs":
/*!****************************************************!*\
  !*** ./node_modules/@web-std/fetch/dist/index.cjs ***!
  \****************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nexports = module.exports = fetch;\n\nconst http = __webpack_require__(/*! http */ \"http\");\nconst https = __webpack_require__(/*! https */ \"https\");\nconst zlib = __webpack_require__(/*! zlib */ \"zlib\");\nconst dataUriToBuffer = __webpack_require__(/*! data-uri-to-buffer */ \"./node_modules/data-uri-to-buffer/dist/src/index.js\");\nconst Stream = __webpack_require__(/*! stream */ \"stream\");\nconst util = __webpack_require__(/*! util */ \"util\");\nconst blob = __webpack_require__(/*! @web-std/blob */ \"./node_modules/@web-std/blob/dist/src/lib.node.cjs\");\nconst formData = __webpack_require__(/*! @web-std/form-data */ \"./node_modules/@web-std/form-data/dist/src/lib.node.cjs\");\nconst crypto = __webpack_require__(/*! crypto */ \"crypto\");\nconst multipartParser = __webpack_require__(/*! @web3-storage/multipart-parser */ \"./node_modules/@web3-storage/multipart-parser/cjs/src/index.js\");\nconst url = __webpack_require__(/*! url */ \"url\");\n\nclass FetchBaseError extends Error {\n\t/**\n\t * @param {string} message \n\t * @param {string} type \n\t */\n\tconstructor(message, type) {\n\t\tsuper(message);\n\t\t// Hide custom error implementation details from end-users\n\t\tError.captureStackTrace(this, this.constructor);\n\n\t\tthis.type = type;\n\t}\n\n\tget name() {\n\t\treturn this.constructor.name;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n}\n\n/**\n * @typedef {{\n * address?: string\n * code: string\n * dest?: string\n * errno: number\n * info?: object\n * message: string\n * path?: string\n * port?: number\n * syscall: string\n * }} SystemError\n*/\n\n/**\n * FetchError interface for operational errors\n */\nclass FetchError extends FetchBaseError {\n\t/**\n\t * @param  {string} message -      Error message for human\n\t * @param  {string} type -        Error type for machine\n\t * @param  {SystemError} [systemError] - For Node.js system error\n\t */\n\tconstructor(message, type, systemError) {\n\t\tsuper(message, type);\n\t\t// When err.type is `system`, err.erroredSysCall contains system error and err.code contains system error code\n\t\tif (systemError) {\n\t\t\t// eslint-disable-next-line no-multi-assign\n\t\t\tthis.code = this.errno = systemError.code;\n\t\t\tthis.erroredSysCall = systemError.syscall;\n\t\t}\n\t}\n}\n\n/**\n * Is.js\n *\n * Object type checks.\n */\n\nconst NAME = Symbol.toStringTag;\n\n/**\n * Check if `obj` is a URLSearchParams object\n * ref: https://github.com/node-fetch/node-fetch/issues/296#issuecomment-307598143\n *\n * @param  {any} object\n * @return {obj is URLSearchParams}\n */\nconst isURLSearchParameters = (object) => {\n\treturn (\n\t\ttypeof object === \"object\" &&\n\t\ttypeof object.append === \"function\" &&\n\t\ttypeof object.delete === \"function\" &&\n\t\ttypeof object.get === \"function\" &&\n\t\ttypeof object.getAll === \"function\" &&\n\t\ttypeof object.has === \"function\" &&\n\t\ttypeof object.set === \"function\" &&\n\t\ttypeof object.sort === \"function\" &&\n\t\tobject[NAME] === \"URLSearchParams\"\n\t);\n};\n\n/**\n * Check if `object` is a W3C `Blob` object (which `File` inherits from)\n *\n * @param  {*} object\n * @return {object is Blob}\n */\nconst isBlob = (object) => {\n\treturn (\n\t\ttypeof object === \"object\" &&\n\t\ttypeof object.arrayBuffer === \"function\" &&\n\t\ttypeof object.type === \"string\" &&\n\t\ttypeof object.stream === \"function\" &&\n\t\ttypeof object.constructor === \"function\" &&\n\t\t/^(Blob|File)$/.test(object[NAME])\n\t);\n};\n\n/**\n * Check if `obj` is a spec-compliant `FormData` object\n *\n * @param {*} object\n * @return {object is FormData}\n */\nfunction isFormData(object) {\n\treturn (\n\t\ttypeof object === \"object\" &&\n\t\ttypeof object.append === \"function\" &&\n\t\ttypeof object.set === \"function\" &&\n\t\ttypeof object.get === \"function\" &&\n\t\ttypeof object.getAll === \"function\" &&\n\t\ttypeof object.delete === \"function\" &&\n\t\ttypeof object.keys === \"function\" &&\n\t\ttypeof object.values === \"function\" &&\n\t\ttypeof object.entries === \"function\" &&\n\t\ttypeof object.constructor === \"function\" &&\n\t\tobject[NAME] === \"FormData\"\n\t);\n}\n\n/**\n * Detect form data input from form-data module\n *\n * @param {any} value\n * @returns {value is Stream & {getBoundary():string, hasKnownLength():boolean, getLengthSync():number|null}}\n */\nconst isMultipartFormDataStream = (value) => {\n\treturn (\n\t\tvalue instanceof Stream === true &&\n\t\ttypeof value.getBoundary === \"function\" &&\n\t\ttypeof value.hasKnownLength === \"function\" &&\n\t\ttypeof value.getLengthSync === \"function\"\n\t);\n};\n\n/**\n * Check if `obj` is an instance of AbortSignal.\n *\n * @param  {any} object\n * @return {obj is AbortSignal}\n */\nconst isAbortSignal = (object) => {\n\treturn (\n\t\ttypeof object === \"object\" &&\n\t\t(object[NAME] === \"AbortSignal\" || object[NAME] === \"EventTarget\")\n\t);\n};\n\n/**\n * Check if `value` is a ReadableStream.\n *\n * @param {*} value\n * @returns {value is ReadableStream}\n */\nconst isReadableStream = (value) => {\n\treturn (\n\t\ttypeof value === \"object\" &&\n\t\ttypeof value.getReader === \"function\" &&\n\t\ttypeof value.cancel === \"function\" &&\n\t\ttypeof value.tee === \"function\"\n\t);\n};\n\n/**\n *\n * @param {any} value\n * @returns {value is Iterable<unknown>}\n */\nconst isIterable = (value) => value && Symbol.iterator in value;\n\nconst carriage = '\\r\\n';\nconst dashes = '-'.repeat(2);\nconst carriageLength = Buffer.byteLength(carriage);\n\n/**\n * @param {string} boundary\n */\nconst getFooter = boundary => `${dashes}${boundary}${dashes}${carriage.repeat(2)}`;\n\n/**\n * @param {string} boundary\n * @param {string} name\n * @param {*} field\n *\n * @return {string}\n */\nfunction getHeader(boundary, name, field) {\n\tlet header = '';\n\n\theader += `${dashes}${boundary}${carriage}`;\n\theader += `Content-Disposition: form-data; name=\"${name}\"`;\n\n\tif (isBlob(field)) {\n\t\tconst { name = 'blob', type } = /** @type {Blob & {name?:string}} */ (field);\n\t\theader += `; filename=\"${name}\"${carriage}`;\n\t\theader += `Content-Type: ${type || 'application/octet-stream'}`;\n\t}\n\n\treturn `${header}${carriage.repeat(2)}`;\n}\n\n/**\n * @return {string}\n */\nconst getBoundary = () => crypto.randomBytes(8).toString('hex');\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nasync function * formDataIterator(form, boundary) {\n\tfor (const [name, value] of form) {\n\t\tyield getHeader(boundary, name, value);\n\n\t\tif (isBlob(value)) {\n\t\t\t// @ts-ignore - we know our streams implement aysnc iteration\n\t\t\tyield * value.stream();\n\t\t} else {\n\t\t\tyield value;\n\t\t}\n\n\t\tyield carriage;\n\t}\n\n\tyield getFooter(boundary);\n}\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nfunction getFormDataLength(form, boundary) {\n\tlet length = 0;\n\n\tfor (const [name, value] of form) {\n\t\tlength += Buffer.byteLength(getHeader(boundary, name, value));\n\n\t\tif (isBlob(value)) {\n\t\t\tlength += value.size;\n\t\t} else {\n\t\t\tlength += Buffer.byteLength(String(value));\n\t\t}\n\n\t\tlength += carriageLength;\n\t}\n\n\tlength += Buffer.byteLength(getFooter(boundary));\n\n\treturn length;\n}\n\n/**\n * @param {Body & {headers?:Headers}} source\n */\nconst toFormData = async ({ body, headers }) => {\n  const contentType = headers?.get('Content-Type') || '';\n  const [type, boundary] = contentType.split(/\\s*;\\s*boundary=/);\n  if (type === 'multipart/form-data' && boundary != null && body != null) {\n    const form = new FormData();\n    const parts = multipartParser.iterateMultipart(body, boundary);\n    for await (const { name, data, filename, contentType } of parts) {\n      if (filename) {\n        form.append(name, new File([data], filename, { type: contentType }));\n      } else {\n        form.append(name, new TextDecoder().decode(data), filename);\n      }\n    }\n    return form\n  } else {\n    throw new TypeError('Could not parse content as FormData.')\n  }\n};\n\nconst encoder = new util.TextEncoder();\nconst decoder = new util.TextDecoder();\n\n/**\n * @param {string} text\n */\nconst encode = text => encoder.encode(text);\n\n/**\n * @param {Uint8Array} bytes\n */\nconst decode = bytes => decoder.decode(bytes);\n\n// @ts-check\nconst {readableHighWaterMark} = new Stream.Readable();\n\nconst INTERNALS$2 = Symbol('Body internals');\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n * @implements {globalThis.Body}\n */\n\nclass Body {\n\t/**\n\t * @param {BodyInit|Stream|null} body\n\t * @param {{size?:number}} options\n\t */\n\tconstructor(body, {\n\t\tsize = 0\n\t} = {}) {\n\t\tconst state = {\n\t\t\t/** @type {null|ReadableStream<Uint8Array>} */\n\t\t\tbody: null,\n\t\t\t/** @type {string|null} */\n\t\t\ttype: null,\n\t\t\t/** @type {number|null} */\n\t\t\tsize: null,\n\t\t\t/** @type {null|string} */\n\t\t\tboundary: null,\n\t\t\tdisturbed: false,\n\t\t\t/** @type {null|Error} */\n\t\t\terror: null\n\t\t};\n\t\t/** @private */\n\t\tthis[INTERNALS$2] = state;\n\n\t\tif (body === null) {\n\t\t\t// Body is undefined or null\n\t\t\tstate.body = null;\n\t\t\tstate.size = 0;\n\t\t} else if (isURLSearchParameters(body)) {\n\t\t// Body is a URLSearchParams\n\t\t\tconst bytes = encode(body.toString());\n\t\t\tstate.body = fromBytes(bytes);\n\t\t\tstate.size = bytes.byteLength;\n\t\t\tstate.type = 'application/x-www-form-urlencoded;charset=UTF-8';\n\t\t} else if (isBlob(body)) {\n\t\t\t// Body is blob\n\t\t\tstate.size = body.size;\n\t\t\tstate.type = body.type || null;\n\t\t\tstate.body = body.stream();\n\t\t} else if (body instanceof Uint8Array) {\n\t\t\t// Body is Buffer\n\t\t\tstate.body = fromBytes(body);\n\t\t\tstate.size = body.byteLength;\n\t\t} else if (util.types.isAnyArrayBuffer(body)) {\n\t\t\t// Body is ArrayBuffer\n\t\t\tconst bytes = new Uint8Array(body);\n\t\t\tstate.body = fromBytes(bytes);\n\t\t\tstate.size = bytes.byteLength;\n\t\t} else if (ArrayBuffer.isView(body)) {\n\t\t\t// Body is ArrayBufferView\n\t\t\tconst bytes = new Uint8Array(body.buffer, body.byteOffset, body.byteLength);\n\t\t\tstate.body = fromBytes(bytes);\n\t\t\tstate.size = bytes.byteLength;\n\t\t} else if (isReadableStream(body)) {\n\t\t\t// Body is stream\n\t\t\tstate.body = body;\n\t\t} else if (isFormData(body)) {\n\t\t\t// Body is an instance of formdata-node\n\t\t\tconst boundary = `NodeFetchFormDataBoundary${getBoundary()}`;\n\t\t\tstate.type = `multipart/form-data; boundary=${boundary}`;\n\t\t\tstate.size = getFormDataLength(body, boundary);\n\t\t\tstate.body = fromAsyncIterable(formDataIterator(body, boundary));\n\t\t} else if (isMultipartFormDataStream(body)) {\n\t\t\tstate.type = `multipart/form-data; boundary=${body.getBoundary()}`;\n\t\t\tstate.size = body.hasKnownLength() ? body.getLengthSync() : null;\n\t\t\tstate.body = fromStream(body);\n\t\t} else if (body instanceof Stream) {\n\t\t\tstate.body = fromStream(body);\n\t\t} else {\n\t\t\t// None of the above\n\t\t\t// coerce to string then buffer\n\t\t\tconst bytes = encode(String(body));\n\t\t\tstate.type = 'text/plain;charset=UTF-8';\n\t\t\tstate.size = bytes.byteLength;\n\t\t\tstate.body = fromBytes(bytes);\n\t\t}\n\n\t\tthis.size = size;\n\n\t\t// if (body instanceof Stream) {\n\t\t// \tbody.on('error', err => {\n\t\t// \t\tconst error = err instanceof FetchBaseError ?\n\t\t// \t\t\terr :\n\t\t// \t\t\tnew FetchError(`Invalid response body while trying to fetch ${this.url}: ${err.message}`, 'system', err);\n\t\t// \t\tthis[INTERNALS].error = error;\n\t\t// \t});\n\t\t// }\n\t}\n\n\t/** @type {Headers} */\n\t/* c8 ignore next 3 */\n\tget headers() {\n\t\tthrow new TypeError(`'get headers' called on an object that does not implements interface.`)\n\t}\n\n\tget body() {\n\t\treturn this[INTERNALS$2].body;\n\t}\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS$2].disturbed;\n\t}\n\n\t/**\n\t * Decode response as ArrayBuffer\n\t *\n\t * @return {Promise<ArrayBuffer>}\n\t */\n\tasync arrayBuffer() {\n\t\tconst {buffer, byteOffset, byteLength} = await consumeBody(this);\n\t\treturn buffer.slice(byteOffset, byteOffset + byteLength);\n\t}\n\n\t/**\n\t * Return raw response as Blob\n\t *\n\t * @return Promise\n\t */\n\tasync blob() {\n\t\tconst ct = (this.headers && this.headers.get('content-type')) || (this[INTERNALS$2].body && this[INTERNALS$2].type) || '';\n\t\tconst buf = await consumeBody(this);\n\n\t\treturn new blob.Blob([buf], {\n\t\t\ttype: ct\n\t\t});\n\t}\n\n\t/**\n\t * Decode response as json\n\t *\n\t * @return  Promise\n\t */\n\tasync json() {\n\t\treturn JSON.parse(await this.text());\n\t}\n\n\t/**\n\t * Decode response as text\n\t *\n\t * @return  Promise\n\t */\n\tasync text() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn decode(buffer);\n\t}\n\n\t/**\n\t * @returns {Promise<FormData>}\n\t */\n\n\tasync formData() {\n\t\treturn toFormData(this)\n\t}\n}\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: {enumerable: true},\n\tbodyUsed: {enumerable: true},\n\tarrayBuffer: {enumerable: true},\n\tblob: {enumerable: true},\n\tjson: {enumerable: true},\n\ttext: {enumerable: true},\n\tformData: {enumerable: true}\n});\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @param {Body & {url?:string}} data\n * @return {Promise<Uint8Array>}\n */\nasync function consumeBody(data) {\n\tconst state = data[INTERNALS$2];\n\tif (state.disturbed) {\n\t\tthrow new TypeError(`body used already for: ${data.url}`);\n\t}\n\n\tstate.disturbed = true;\n\n\tif (state.error) {\n\t\tthrow state.error;\n\t}\n\n\tconst {body} = state;\n\n\t// Body is null\n\tif (body === null) {\n\t\treturn new Uint8Array(0);\n\t}\n\n\t// Body is stream\n\t// get ready to actually consume the body\n\t/** @type {[Uint8Array|null, Uint8Array[], number]} */\n\tconst [buffer, chunks, limit] = data.size > 0 ?\n\t\t[new Uint8Array(data.size), [], data.size] :\n\t\t[null, [], Infinity];\n\tlet offset = 0;\n\n\tconst source = streamIterator(body);\n\ttry {\n\t\tfor await (const chunk of source) {\n\t\t\tconst bytes = chunk instanceof Uint8Array ?\n\t\t\t\tchunk :\n\t\t\t\tBuffer.from(chunk);\n\n\t\t\tif (offset + bytes.byteLength > limit) {\n\t\t\t\tconst error = new FetchError(`content size at ${data.url} over limit: ${limit}`, 'max-size');\n\t\t\t\tsource.throw(error);\n\t\t\t\tthrow error;\n\t\t\t} else if (buffer) {\n\t\t\t\tbuffer.set(bytes, offset);\n\t\t\t} else {\n\t\t\t\tchunks.push(bytes);\n\t\t\t}\n\n\t\t\toffset += bytes.byteLength;\n\t\t}\n\n\t\tif (buffer) {\n\t\t\tif (offset < buffer.byteLength) {\n\t\t\t\tthrow new FetchError(`Premature close of server response while trying to fetch ${data.url}`, 'premature-close');\n\t\t\t} else {\n\t\t\t\treturn buffer;\n\t\t\t}\n\t\t} else {\n\t\t\treturn writeBytes(new Uint8Array(offset), chunks);\n\t\t}\n\t} catch (error) {\n\t\tif (error instanceof FetchBaseError) {\n\t\t\tthrow error;\n\t\t// @ts-expect-error - we know it will have a name\n\t\t} else if (error && error.name === 'AbortError') {\n\t\t\tthrow error;\n\t\t} else {\n\t\t\tconst e = /** @type {import('./errors/fetch-error').SystemError} */(error);\n\t\t\t// Other errors, such as incorrect content-encoding\n\t\t\tthrow new FetchError(`Invalid response body while trying to fetch ${data.url}: ${e.message}`, 'system', e);\n\t\t}\n\t}\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param {Body} instance       Response or Request instance\n * @return {ReadableStream<Uint8Array>}\n */\nconst clone = instance => {\n\tconst {body} = instance;\n\n\t// Don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// @ts-expect-error - could be null\n\tconst [left, right] = body.tee();\n\tinstance[INTERNALS$2].body = left;\n\treturn right;\n};\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param {Body} source Any options.body input\n * @returns {string | null}\n */\nconst extractContentType = source => source[INTERNALS$2].type;\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param {Body} source - Body object from the Body instance.\n * @returns {number | null}\n */\nconst getTotalBytes = source => source[INTERNALS$2].size;\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param {Stream.Writable} dest - The stream to write to.\n * @param {Body} source - Body object from the Body instance.\n * @returns {void}\n */\nconst writeToStream = (dest, {body}) => {\n\tif (body === null) {\n\t\t// Body is null\n\t\tdest.end();\n\t} else {\n\t\tStream.Readable.from(streamIterator(body)).pipe(dest);\n\t}\n};\n\n/**\n * @template T\n * @implements {AsyncGenerator<T, void, void>}\n */\nclass StreamIterableIterator {\n\t/**\n\t * @param {ReadableStream<T>} stream\n\t */\n\tconstructor(stream) {\n\t\tthis.stream = stream;\n\t\tthis.reader = null;\n\t}\n\n\t/**\n\t * @returns {AsyncGenerator<T, void, void>}\n\t */\n\t[Symbol.asyncIterator]() {\n\t\treturn this;\n\t}\n\n\tgetReader() {\n\t\tif (this.reader) {\n\t\t\treturn this.reader;\n\t\t}\n\n\t\tconst reader = this.stream.getReader();\n\t\tthis.reader = reader;\n\t\treturn reader;\n\t}\n\n\t/**\n\t * @returns {Promise<IteratorResult<T, void>>}\n\t */\n\tnext() {\n\t\treturn /** @type {Promise<IteratorResult<T, void>>} */ (this.getReader().read());\n\t}\n\n\t/**\n\t * @returns {Promise<IteratorResult<T, void>>}\n\t */\n\tasync return() {\n\t\tif (this.reader) {\n\t\t\tawait this.reader.cancel();\n\t\t}\n\n\t\treturn {done: true, value: undefined};\n\t}\n\n\t/**\n\t * \n\t * @param {any} error \n\t * @returns {Promise<IteratorResult<T, void>>}\n\t */\n\tasync throw(error) {\n\t\tawait this.getReader().cancel(error);\n\t\treturn {done: true, value: undefined};\n\t}\n}\n\n/**\n * @template T\n * @param {ReadableStream<T>} stream\n */\nconst streamIterator = stream => new StreamIterableIterator(stream);\n\n/**\n * @param {Uint8Array} buffer\n * @param {Uint8Array[]} chunks\n */\nconst writeBytes = (buffer, chunks) => {\n\tlet offset = 0;\n\tfor (const chunk of chunks) {\n\t\tbuffer.set(chunk, offset);\n\t\toffset += chunk.byteLength;\n\t}\n\n\treturn buffer;\n};\n\n/**\n * @param {Uint8Array} bytes\n * @returns {ReadableStream<Uint8Array>}\n */\n// @ts-ignore\nconst fromBytes = bytes => new blob.ReadableStream({\n\tstart(controller) {\n\t\tcontroller.enqueue(bytes);\n\t\tcontroller.close();\n\t}\n});\n\n/**\n * @param {AsyncIterable<Uint8Array>} content\n * @returns {ReadableStream<Uint8Array>}\n */\nconst fromAsyncIterable = content =>\n\t// @ts-ignore\n\tnew blob.ReadableStream(new AsyncIterablePump(content));\n\n/**\n * @implements {UnderlyingSource<Uint8Array>}\n */\nclass AsyncIterablePump {\n\t/**\n\t * @param {AsyncIterable<Uint8Array>} source\n\t */\n\tconstructor(source) {\n\t\tthis.source = source[Symbol.asyncIterator]();\n\t}\n\n\t/**\n\t * @param {ReadableStreamController<Uint8Array>} controller\n\t */\n\tasync pull(controller) {\n\t\ttry {\n\t\t\twhile (controller.desiredSize || 0 > 0) {\n\t\t\t\t// eslint-disable-next-line no-await-in-loop\n\t\t\t\tconst next = await this.source.next();\n\t\t\t\tif (next.done) {\n\t\t\t\t\tcontroller.close();\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\tcontroller.enqueue(next.value);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tcontroller.error(error);\n\t\t}\n\t}\n\n\t/**\n\t * @param {any} [reason]\n\t */\n\tcancel(reason) {\n\t\tif (reason) {\n\t\t\tif (typeof this.source.throw === 'function') {\n\t\t\t\tthis.source.throw(reason);\n\t\t\t} else if (typeof this.source.return === 'function') {\n\t\t\t\tthis.source.return();\n\t\t\t}\n\t\t} else if (typeof this.source.return === 'function') {\n\t\t\tthis.source.return();\n\t\t}\n\t}\n}\n\n/**\n * @param {Stream & {readableHighWaterMark?:number}} source\n * @returns {ReadableStream<Uint8Array>}\n */\nconst fromStream = source => {\n\tconst pump = new StreamPump(source);\n\tconst stream = new blob.ReadableStream(pump, pump);\n\treturn stream;\n};\n\n/**\n * @implements {UnderlyingSource<Uint8Array>}\n * @implements {QueuingStrategy<Uint8Array>}\n */\nclass StreamPump {\n\t/**\n\t * @param {Stream & {\n\t * \treadableHighWaterMark?: number\n\t * \treadable?:boolean,\n\t * \tresume?: () => void,\n\t * \tpause?: () => void\n\t * \tdestroy?: (error?:Error) => void\n\t * }} stream\n\t */\n\tconstructor(stream) {\n\t\tthis.highWaterMark = stream.readableHighWaterMark || readableHighWaterMark;\n\t\tthis.accumalatedSize = 0;\n\t\tthis.stream = stream;\n\t\tthis.enqueue = this.enqueue.bind(this);\n\t\tthis.error = this.error.bind(this);\n\t\tthis.close = this.close.bind(this);\n\t}\n\n\t/**\n\t * @param {Uint8Array} [chunk]\n\t */\n\tsize(chunk) {\n\t\treturn chunk?.byteLength || 0;\n\t}\n\n\t/**\n\t * @param {ReadableStreamController<Uint8Array>} controller\n\t */\n\tstart(controller) {\n\t\tthis.controller = controller;\n\t\tthis.stream.on('data', this.enqueue);\n\t\tthis.stream.once('error', this.error);\n\t\tthis.stream.once('end', this.close);\n\t\tthis.stream.once('close', this.close);\n\t}\n\n\tpull() {\n\t\tthis.resume();\n\t}\n\n\t/**\n\t * @param {any} [reason]\n\t */\n\tcancel(reason) {\n\t\tif (this.stream.destroy) {\n\t\t\tthis.stream.destroy(reason);\n\t\t}\n\n\t\tthis.stream.off('data', this.enqueue);\n\t\tthis.stream.off('error', this.error);\n\t\tthis.stream.off('end', this.close);\n\t\tthis.stream.off('close', this.close);\n\t}\n\n\t/**\n\t * @param {Uint8Array|string} chunk\n\t */\n\tenqueue(chunk) {\n\t\tif (this.controller) {\n\t\t\ttry {\n\t\t\t\tconst bytes = chunk instanceof Uint8Array ?\n\t\t\t\t\tchunk :\n\t\t\t\t\tBuffer.from(chunk);\n\n\t\t\t\tconst available = (this.controller.desiredSize || 0) - bytes.byteLength;\n\t\t\t\tthis.controller.enqueue(bytes);\n\t\t\t\tif (available <= 0) {\n\t\t\t\t\tthis.pause();\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tthis.controller.error(new Error('Could not create Buffer, chunk must be of type string or an instance of Buffer, ArrayBuffer, or Array or an Array-like Object'));\n\t\t\t\tthis.cancel();\n\t\t\t}\n\t\t}\n\t}\n\n\tpause() {\n\t\tif (this.stream.pause) {\n\t\t\tthis.stream.pause();\n\t\t}\n\t}\n\n\tresume() {\n\t\tif (this.stream.readable && this.stream.resume) {\n\t\t\tthis.stream.resume();\n\t\t}\n\t}\n\n\tclose() {\n\t\tif (this.controller) {\n\t\t\tthis.controller.close();\n\t\t\tdelete this.controller;\n\t\t}\n\t}\n\n\t/**\n\t * @param {Error} error \n\t */\n\terror(error) {\n\t\tif (this.controller) {\n\t\t\tthis.controller.error(error);\n\t\t\tdelete this.controller;\n\t\t}\n\t}\n}\n\n/**\n * Headers.js\n *\n * Headers class offers convenient helpers\n */\n\nconst validators = /** @type {{validateHeaderName?:(name:string) => any, validateHeaderValue?:(name:string, value:string) => any}} */\n(http);\n\nconst validateHeaderName = typeof validators.validateHeaderName === 'function' ?\n\tvalidators.validateHeaderName :\n\t/**\n\t * @param {string} name \n\t */\n\tname => {\n\t\tif (!/^[\\^`\\-\\w!#$%&'*+.|~]+$/.test(name)) {\n\t\t\tconst err = new TypeError(`Header name must be a valid HTTP token [${name}]`);\n\t\t\tObject.defineProperty(err, 'code', {value: 'ERR_INVALID_HTTP_TOKEN'});\n\t\t\tthrow err;\n\t\t}\n\t};\n\nconst validateHeaderValue = typeof validators.validateHeaderValue === 'function' ?\n\tvalidators.validateHeaderValue :\n\t/**\n\t * @param {string} name \n\t * @param {string} value \n\t */\n\t(name, value) => {\n\t\tif (/[^\\t\\u0020-\\u007E\\u0080-\\u00FF]/.test(value)) {\n\t\t\tconst err = new TypeError(`Invalid character in header content [\"${name}\"]`);\n\t\t\tObject.defineProperty(err, 'code', {value: 'ERR_INVALID_CHAR'});\n\t\t\tthrow err;\n\t\t}\n\t};\n\n/**\n * @typedef {Headers | Record<string, string> | Iterable<readonly [string, string]> | Iterable<Iterable<string>>} HeadersInit\n */\n\n/**\n * This Fetch API interface allows you to perform various actions on HTTP request and response headers.\n * These actions include retrieving, setting, adding to, and removing.\n * A Headers object has an associated header list, which is initially empty and consists of zero or more name and value pairs.\n * You can add to this using methods like append() (see Examples.)\n * In all methods of this interface, header names are matched by case-insensitive byte sequence.\n *\n * @implements {globalThis.Headers}\n */\nclass Headers extends URLSearchParams {\n\t/**\n\t * Headers class\n\t *\n\t * @constructor\n\t * @param {HeadersInit} [init] - Response headers\n\t */\n\tconstructor(init) {\n\t\t// Validate and normalize init object in [name, value(s)][]\n\t\t/** @type {string[][]} */\n\t\tlet result = [];\n\t\tif (init instanceof Headers) {\n\t\t\tconst raw = init.raw();\n\t\t\tfor (const [name, values] of Object.entries(raw)) {\n\t\t\t\tresult.push(...values.map(value => [name, value]));\n\t\t\t}\n\t\t} else if (init == null) ; else if (isIterable(init)) {\n\t\t\t// Sequence<sequence<ByteString>>\n\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\tresult = [...init]\n\t\t\t\t.map(pair => {\n\t\t\t\t\tif (\n\t\t\t\t\t\ttypeof pair !== 'object' || util.types.isBoxedPrimitive(pair)\n\t\t\t\t\t) {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be an iterable object');\n\t\t\t\t\t}\n\n\t\t\t\t\treturn [...pair];\n\t\t\t\t}).map(pair => {\n\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t}\n\n\t\t\t\t\treturn [...pair];\n\t\t\t\t});\n\t\t} else if (typeof init === \"object\" && init !== null) {\n\t\t\t// Record<ByteString, ByteString>\n\t\t\tresult.push(...Object.entries(init));\n\t\t} else {\n\t\t\tthrow new TypeError('Failed to construct \\'Headers\\': The provided value is not of type \\'(sequence<sequence<ByteString>> or record<ByteString, ByteString>)');\n\t\t}\n\n\t\t// Validate and lowercase\n\t\tresult =\n\t\t\tresult.length > 0 ?\n\t\t\t\tresult.map(([name, value]) => {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn [String(name).toLowerCase(), String(value)];\n\t\t\t\t}) :\n\t\t\t\t[];\n\n\t\tsuper(result);\n\n\t\t// Returning a Proxy that will lowercase key names, validate parameters and sort keys\n\t\t// eslint-disable-next-line no-constructor-return\n\t\treturn new Proxy(this, {\n\t\t\tget(target, p, receiver) {\n\t\t\t\tswitch (p) {\n\t\t\t\t\tcase 'append':\n\t\t\t\t\tcase 'set':\n\t\t\t\t\t\t/**\n\t\t\t\t\t\t * @param {string} name\n\t\t\t\t\t\t * @param {string} value\n\t\t\t\t\t\t */\n\t\t\t\t\t\treturn (name, value) => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\treceiver,\n\t\t\t\t\t\t\t\tString(name).toLowerCase(),\n\t\t\t\t\t\t\t\tString(value)\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'delete':\n\t\t\t\t\tcase 'has':\n\t\t\t\t\tcase 'getAll':\n\t\t\t\t\t\t/**\n\t\t\t\t\t\t * @param {string} name\n\t\t\t\t\t\t */\n\t\t\t\t\t\treturn name => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\t// @ts-ignore\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\treceiver,\n\t\t\t\t\t\t\t\tString(name).toLowerCase()\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'keys':\n\t\t\t\t\t\treturn () => {\n\t\t\t\t\t\t\ttarget.sort();\n\t\t\t\t\t\t\treturn new Set(URLSearchParams.prototype.keys.call(target)).keys();\n\t\t\t\t\t\t};\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn Reflect.get(target, p, receiver);\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* c8 ignore next */\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n\n\ttoString() {\n\t\treturn Object.prototype.toString.call(this);\n\t}\n\n\t/**\n\t * \n\t * @param {string} name \n\t */\n\tget(name) {\n\t\tconst values = this.getAll(name);\n\t\tif (values.length === 0) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet value = values.join(', ');\n\t\tif (/^content-encoding$/i.test(name)) {\n\t\t\tvalue = value.toLowerCase();\n\t\t}\n\n\t\treturn value;\n\t}\n\n\t/**\n\t * @param {(value: string, key: string, parent: this) => void} callback \n\t * @param {any} thisArg \n\t * @returns {void}\n\t */\n\tforEach(callback, thisArg = undefined) {\n\t\tfor (const name of this.keys()) {\n\t\t\tReflect.apply(callback, thisArg, [this.get(name), name, this]);\n\t\t}\n\t}\n\n\t/**\n\t * @returns {IterableIterator<string>}\n\t */\n\t* values() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield /** @type {string} */(this.get(name));\n\t\t}\n\t}\n\n\t/**\n\t * @returns {IterableIterator<[string, string]>}\n\t */\n\t* entries() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield [name, /** @type {string} */(this.get(name))];\n\t\t}\n\t}\n\n\t[Symbol.iterator]() {\n\t\treturn this.entries();\n\t}\n\n\t/**\n\t * Node-fetch non-spec method\n\t * returning all headers and their values as array\n\t * @returns {Record<string, string[]>}\n\t */\n\traw() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tresult[key] = this.getAll(key);\n\t\t\treturn result;\n\t\t}, /** @type {Record<string, string[]>} */({}));\n\t}\n\n\t/**\n\t * For better console.log(headers) and also to convert Headers into Node.js Request compatible format\n\t */\n\t[Symbol.for('nodejs.util.inspect.custom')]() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tconst values = this.getAll(key);\n\t\t\t// Http.request() only supports string as Host header.\n\t\t\t// This hack makes specifying custom Host header possible.\n\t\t\tif (key === 'host') {\n\t\t\t\tresult[key] = values[0];\n\t\t\t} else {\n\t\t\t\tresult[key] = values.length > 1 ? values : values[0];\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}, /** @type {Record<string, string|string[]>} */({}));\n\t}\n}\n\n/**\n * Re-shaping object for Web IDL tests\n * Only need to do it for overridden methods\n */\nObject.defineProperties(\n\tHeaders.prototype,\n\t['get', 'entries', 'forEach', 'values'].reduce((result, property) => {\n\t\tresult[property] = {enumerable: true};\n\t\treturn result;\n\t}, /** @type {Record<string, {enumerable:true}>} */ ({}))\n);\n\n/**\n * Create a Headers object from an http.IncomingMessage.rawHeaders, ignoring those that do\n * not conform to HTTP grammar productions.\n * @param {import('http').IncomingMessage['rawHeaders']} headers\n */\nfunction fromRawHeaders(headers = []) {\n\treturn new Headers(\n\t\theaders\n\t\t\t// Split into pairs\n\t\t\t.reduce((result, value, index, array) => {\n\t\t\t\tif (index % 2 === 0) {\n\t\t\t\t\tresult.push(array.slice(index, index + 2));\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}, /** @type {string[][]} */([]))\n\t\t\t.filter(([name, value]) => {\n\t\t\t\ttry {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn true;\n\t\t\t\t} catch {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t})\n\n\t);\n}\n\nconst redirectStatus = new Set([301, 302, 303, 307, 308]);\n\n/**\n * Redirect code matching\n *\n * @param {number} code - Status code\n * @return {boolean}\n */\nconst isRedirect = code => {\n\treturn redirectStatus.has(code);\n};\n\n/**\n * Response.js\n *\n * Response class provides content decoding\n */\n\nconst INTERNALS$1 = Symbol('Response internals');\n\n/**\n * Response class\n * \n * @typedef {Object} Ext\n * @property {number} [size]\n * @property {string} [url]\n * @property {number} [counter]\n * @property {number} [highWaterMark]\n * \n * @implements {globalThis.Response}\n */\nclass Response extends Body {\n\t/**\n\t * @param {BodyInit|import('stream').Stream|null} [body] - Readable stream\n\t * @param {ResponseInit & Ext} [options] - Response options\n\t */\n\tconstructor(body = null, options = {}) {\n\t\tsuper(body, options);\n\n\t\tconst status = options.status || 200;\n\t\tconst headers = new Headers(options.headers);\n\n\t\tif (body !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * @private\n\t\t*/\n\t\tthis[INTERNALS$1] = {\n\t\t\turl: options.url,\n\t\t\tstatus,\n\t\t\tstatusText: options.statusText || '',\n\t\t\theaders,\n\t\t\tcounter: options.counter || 0,\n\t\t\thighWaterMark: options.highWaterMark\n\t\t};\n\t}\n\n\t/**\n\t * @type {ResponseType}\n\t */\n\tget type() {\n\t\treturn \"default\"\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS$1].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS$1].status;\n\t}\n\n\t/**\n\t * Convenience property representing if the request ended normally\n\t */\n\tget ok() {\n\t\treturn this[INTERNALS$1].status >= 200 && this[INTERNALS$1].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS$1].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS$1].statusText;\n\t}\n\n\t/**\n\t * @type {Headers}\n\t */\n\tget headers() {\n\t\treturn this[INTERNALS$1].headers;\n\t}\n\n\tget highWaterMark() {\n\t\treturn this[INTERNALS$1].highWaterMark;\n\t}\n\n\t/**\n\t * Clone this response\n\t *\n\t * @returns {Response}\n\t */\n\tclone() {\n\t\treturn new Response(clone(this), {\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tsize: this.size\n\t\t});\n\t}\n\n\t/**\n\t * @param {string} url    The URL that the new response is to originate from.\n\t * @param {number} status An optional status code for the response (e.g., 302.)\n\t * @returns {Response}    A Response object.\n\t */\n\tstatic redirect(url, status = 302) {\n\t\tif (!isRedirect(status)) {\n\t\t\tthrow new RangeError('Failed to execute \"redirect\" on \"response\": Invalid status code');\n\t\t}\n\n\t\treturn new Response(null, {\n\t\t\theaders: {\n\t\t\t\tlocation: new URL(url).toString()\n\t\t\t},\n\t\t\tstatus\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Response';\n\t}\n}\n\nObject.defineProperties(Response.prototype, {\n\turl: {enumerable: true},\n\tstatus: {enumerable: true},\n\tok: {enumerable: true},\n\tredirected: {enumerable: true},\n\tstatusText: {enumerable: true},\n\theaders: {enumerable: true},\n\tclone: {enumerable: true}\n});\n\n/**\n * @param {URL} parsedURL \n * @returns {string}\n */\nconst getSearch = parsedURL => {\n\tif (parsedURL.search) {\n\t\treturn parsedURL.search;\n\t}\n\n\tconst lastOffset = parsedURL.href.length - 1;\n\tconst hash = parsedURL.hash || (parsedURL.href[lastOffset] === '#' ? '#' : '');\n\treturn parsedURL.href[lastOffset - hash.length] === '?' ? '?' : '';\n};\n\nconst INTERNALS = Symbol('Request internals');\n\n/**\n * Check if `obj` is an instance of Request.\n *\n * @param  {any} object\n * @return {object is Request}\n */\nconst isRequest = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object[INTERNALS] === 'object'\n\t);\n};\n\n\n/**\n * Request class\n * @implements {globalThis.Request}\n * \n * @typedef {Object} RequestState\n * @property {string} method\n * @property {RequestRedirect} redirect\n * @property {globalThis.Headers} headers\n * @property {URL} parsedURL\n * @property {AbortSignal|null} signal\n * \n * @typedef {Object} RequestExtraOptions\n * @property {number} [follow]\n * @property {boolean} [compress]\n * @property {number} [size]\n * @property {number} [counter]\n * @property {Agent} [agent]\n * @property {number} [highWaterMark]\n * @property {boolean} [insecureHTTPParser]\n * \n * @typedef {((url:URL) => import('http').Agent) | import('http').Agent} Agent\n * \n * @typedef {Object} RequestOptions\n * @property {string} [method]\n * @property {ReadableStream<Uint8Array>|null} [body]\n * @property {globalThis.Headers} [headers]\n * @property {RequestRedirect} [redirect]\n * \n */\nclass Request extends Body {\n\t/**\n\t * @param {string|Request|URL} info  Url or Request instance\n\t * @param {RequestInit & RequestExtraOptions} init   Custom options\n\t */\n\tconstructor(info, init = {}) {\n\t\tlet parsedURL;\n\t\t/** @type {RequestOptions & RequestExtraOptions} */\n\t\tlet settings;\n\n\t\t// Normalize input and force URL to be encoded as UTF-8 (https://github.com/node-fetch/node-fetch/issues/245)\n\t\tif (isRequest(info)) {\n\t\t\tparsedURL = new URL(info.url);\n\t\t\tsettings = (info);\n\t\t} else {\n\t\t\tparsedURL = new URL(info);\n\t\t\tsettings = {};\n\t\t}\n\n\n\n\t\tlet method = init.method || settings.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\tconst inputBody = init.body != null\n\t\t\t? init.body\n\t\t\t: (isRequest(info) && info.body !== null)\n\t\t\t? clone(info)\n\t\t\t: null;\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (inputBody != null && (method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tsuper(inputBody, {\n\t\t\tsize: init.size || settings.size || 0\n\t\t});\n\t\tconst input = settings;\n\n\t\t\n\t\tconst headers = /** @type {globalThis.Headers} */\n\t\t\t(new Headers(init.headers || input.headers || {}));\n\n\t\tif (inputBody !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = 'signal' in init\n\t\t\t? init.signal\n\t\t\t: isRequest(input)\n\t\t\t? input.signal\n\t\t\t: null;\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (signal != null && !isAbortSignal(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal or EventTarget');\n\t\t}\n\n\t\t/** @type {RequestState} */\n\t\tthis[INTERNALS] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal: signal || null\n\t\t};\n\n\t\t/** @type {boolean} */\n\t\tthis.keepalive;\n\n\t\t// Node-fetch-only options\n\t\t/** @type {number} */\n\t\tthis.follow = init.follow === undefined ? (input.follow === undefined ? 20 : input.follow) : init.follow;\n\t\t/** @type {boolean} */\n\t\tthis.compress = init.compress === undefined ? (input.compress === undefined ? true : input.compress) : init.compress;\n\t\t/** @type {number} */\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\t/** @type {Agent|undefined} */\n\t\tthis.agent = init.agent || input.agent;\n\t\t/** @type {number} */\n\t\tthis.highWaterMark = init.highWaterMark || input.highWaterMark || 16384;\n\t\t/** @type {boolean} */\n\t\tthis.insecureHTTPParser = init.insecureHTTPParser || input.insecureHTTPParser || false;\n\t}\n\n\t/**\n\t * @type {RequestCache}\n\t */\n\tget cache() {\n\t\treturn \"default\"\n\t}\n\n\t/**\n\t * @type {RequestCredentials}\n\t */\n\n\tget credentials() {\n\t\treturn \"same-origin\"\n\t}\n\n\t/**\n\t * @type {RequestDestination}\n\t */\n\tget destination() {\n\t\treturn \"\"\n\t}\n\t\n\tget integrity() {\n\t\treturn \"\"\n\t}\n\t\n\t/** @type {RequestMode} */\n\tget mode() {\n\t\treturn \"cors\"\n\t}\n\n\t/** @type {string} */\n\tget referrer() {\n\t\treturn  \"\"\n\t}\n\t\n\t/** @type {ReferrerPolicy} */\n\tget referrerPolicy() {\n\t\treturn \"\"\n\t}\n\tget method() {\n\t\treturn this[INTERNALS].method;\n\t}\n\n\t/**\n\t * @type {string}\n\t */\n\tget url() {\n\t\treturn url.format(this[INTERNALS].parsedURL);\n\t}\n\n\t/**\n\t * @type {globalThis.Headers}\n\t */\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS].redirect;\n\t}\n\n\t/**\n\t * @returns {AbortSignal}\n\t */\n\tget signal() {\n\t\t// @ts-ignore\n\t\treturn this[INTERNALS].signal;\n\t}\n\n\t/**\n\t * Clone this request\n\t *\n\t * @return  {globalThis.Request}\n\t */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Request';\n\t}\n}\n\nObject.defineProperties(Request.prototype, {\n\tmethod: {enumerable: true},\n\turl: {enumerable: true},\n\theaders: {enumerable: true},\n\tredirect: {enumerable: true},\n\tclone: {enumerable: true},\n\tsignal: {enumerable: true}\n});\n\n/**\n * Convert a Request to Node.js http request options.\n * The options object to be passed to http.request\n *\n * @param {Request & Record<INTERNALS, RequestState>} request -  A Request instance\n */\nconst getNodeRequestOptions = request => {\n\tconst {parsedURL} = request[INTERNALS];\n\tconst headers = new Headers(request[INTERNALS].headers);\n\n\t// Fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body === null && /^(post|put)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\n\tif (request.body !== null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\t// Set Content-Length if totalBytes is a number (that is not NaN)\n\t\tif (typeof totalBytes === 'number' && !Number.isNaN(totalBytes)) {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate,br');\n\t}\n\n\tlet {agent} = request;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\tconst search = getSearch(parsedURL);\n\n\t// Manually spread the URL object instead of spread syntax\n\tconst requestOptions = {\n\t\tpath: parsedURL.pathname + search,\n\t\tpathname: parsedURL.pathname,\n\t\thostname: parsedURL.hostname,\n\t\tprotocol: parsedURL.protocol,\n\t\tport: parsedURL.port,\n\t\thash: parsedURL.hash,\n\t\tsearch: parsedURL.search,\n\t\t// @ts-ignore - it does not has a query \n\t\tquery: parsedURL.query,\n\t\thref: parsedURL.href,\n\t\tmethod: request.method,\n\t\t// @ts-ignore - not sure what this supposed to do\n\t\theaders: headers[Symbol.for('nodejs.util.inspect.custom')](),\n\t\tinsecureHTTPParser: request.insecureHTTPParser,\n\t\tagent\n\t};\n\n\treturn requestOptions;\n};\n\n/**\n * AbortError interface for cancelled requests\n */\nclass AbortError extends FetchBaseError {\n\t/**\n\t * @param {string} message \n\t * @param {string} [type]\n\t */\n\tconstructor(message, type = 'aborted') {\n\t\tsuper(message, type);\n\t}\n}\n\n/**\n * Index.js\n *\n * a request API compatible with window.fetch\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nconst supportedSchemas = new Set(['data:', 'http:', 'https:']);\n\n/**\n * Fetch function\n *\n * @param   {string | URL | import('./request').default} url - Absolute url or Request instance\n * @param   {RequestInit} [options_] - Fetch options\n * @return  {Promise<import('./response').default>}\n */\nasync function fetch(url, options_ = {}) {\n\treturn new Promise((resolve, reject) => {\n\t\t// Build request object\n\t\tconst request = new Request(url, options_);\n\t\tconst options = getNodeRequestOptions(request);\n\t\tif (!supportedSchemas.has(options.protocol)) {\n\t\t\tthrow new TypeError(`node-fetch cannot load ${url}. URL scheme \"${options.protocol.replace(/:$/, '')}\" is not supported.`);\n\t\t}\n\n\t\tif (options.protocol === 'data:') {\n\t\t\tconst data = dataUriToBuffer(request.url.toString());\n\t\t\tconst response = new Response(data, {headers: {'Content-Type': data.typeFull}});\n\t\t\tresolve(response);\n\t\t\treturn;\n\t\t}\n\n\t\t// Wrap http.request into fetch\n\t\tconst send = (options.protocol === 'https:' ? https : http).request;\n\t\tconst {signal} = request;\n\t\t/** @type {Response|null} */\n\t\tlet response = null;\n\t\t/** @type {import('http').IncomingMessage|null} */\n\t\tlet response_ = null;\n\n\t\tconst abort = () => {\n\t\t\tconst error = new AbortError('The operation was aborted.');\n\t\t\treject(error);\n\t\t\tif (request.body) {\n\t\t\t\trequest.body.cancel(error);\n\t\t\t}\n\n\t\t\tif (!response_) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tresponse_.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = () => {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// Send request\n\t\tconst request_ = send(options);\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tconst finalize = () => {\n\t\t\trequest_.abort();\n\t\t\tif (signal) {\n\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t}\n\t\t};\n\n\t\trequest_.on('error', err => {\n\t\t\t// @ts-expect-error - err may not be SystemError\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${err.message}`, 'system', err));\n\t\t\tfinalize();\n\t\t});\n\n\t\tfixResponseChunkedTransferBadEnding(request_, err => {\n\t\t\tif (signal && signal.aborted) {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tresponse_?.emit(\"error\", err);\n\t\t});\n\n\t\t/* c8 ignore next 18 */\n\t\tif (parseInt(process.version.substring(1)) < 14) {\n\t\t\t// Before Node.js 14, pipeline() does not fully support async iterators and does not always\n\t\t\t// properly handle when the socket close/end events are out of order.\n\t\t\trequest_.on('socket', s => {\n\t\t\t\ts.prependListener('close', hadError => {\n\t\t\t\t\t// if a data listener is still present we didn't end cleanly\n\t\t\t\t\tconst hasDataListener = s.listenerCount('data') > 0;\n\n\t\t\t\t\t// if end happened before close but the socket didn't emit an error, do it now\n\t\t\t\t\tif (response && hasDataListener && !hadError && !(signal && signal.aborted)) {\n\t\t\t\t\t\tconst err = Object.assign(new Error('Premature close'), {\n\t\t\t\t\t\t\tcode: 'ERR_STREAM_PREMATURE_CLOSE'\n\t\t\t\t\t\t});\n\t\t\t\t\t\tresponse_?.emit('error', err);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\n\t\trequest_.on('response', incoming => {\n\t\t\tresponse_ = incoming;\n\t\t\trequest_.setTimeout(0);\n\t\t\tconst headers = fromRawHeaders(response_.rawHeaders);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (isRedirect(Number(response_.statusCode))) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tconst locationURL = location === null ? null : new URL(location, request.url);\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// Node-fetch-specific step: make manual redirect a bit easier to use by setting the Location header value to the resolved URL.\n\t\t\t\t\t\tif (locationURL !== null) {\n\t\t\t\t\t\t\theaders.set('Location', locationURL.toString());\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow': {\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOptions = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\t// Note: We can not use `request.body` because send would have\n\t\t\t\t\t\t\t// consumed it already.\n\t\t\t\t\t\t\tbody: options_.body,\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\tsize: request.size\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tconst isStreamBody =\n\t\t\t\t\t\t\trequestOptions.body instanceof blob.ReadableStream ||\n\t\t\t\t\t\t\trequestOptions.body instanceof Stream.Readable;\n\t\t\t\t\t\tif (response_.statusCode !== 303 && isStreamBody) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (response_.statusCode === 303 || ((response_.statusCode === 301 || response_.statusCode === 302) && request.method === 'POST')) {\n\t\t\t\t\t\t\trequestOptions.method = 'GET';\n\t\t\t\t\t\t\trequestOptions.body = undefined;\n\t\t\t\t\t\t\trequestOptions.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tfetch(new Request(locationURL.href, requestOptions)).then(resolve, reject);\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn reject(new TypeError(`Redirect option '${request.redirect}' is not a valid value of RequestRedirect`));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Prepare response\n\t\t\tif (signal) {\n\t\t\t\tresponse_.once('end', () => {\n\t\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tlet body = Stream.pipeline(response_, new Stream.PassThrough(), reject);\n\t\t\t// see https://github.com/nodejs/node/pull/29376\n\t\t\t/* c8 ignore next 3 */\n\t\t\tif (process.version < 'v12.10') {\n\t\t\t\tresponse_.on('aborted', abortAndFinalize);\n\t\t\t}\n\n\t\t\tconst responseOptions = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: response_.statusCode,\n\t\t\t\tstatusText: response_.statusMessage,\n\t\t\t\theaders,\n\t\t\t\tsize: request.size,\n\t\t\t\tcounter: request.counter,\n\t\t\t\thighWaterMark: request.highWaterMark\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || response_.statusCode === 204 || response_.statusCode === 304) {\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// For gzip\n\t\t\tif (codings === 'gzip' || codings === 'x-gzip') {\n\t\t\t\tbody = Stream.pipeline(body, zlib.createGunzip(zlibOptions), reject);\n\t\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For deflate\n\t\t\tif (codings === 'deflate' || codings === 'x-deflate') {\n\t\t\t\t// Handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = Stream.pipeline(response_, new Stream.PassThrough(), reject);\n\t\t\t\traw.once('data', chunk => {\n\t\t\t\t\t// See http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = Stream.pipeline(body, zlib.createInflate(), reject);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = Stream.pipeline(body, zlib.createInflateRaw(), reject);\n\t\t\t\t\t}\n\n\t\t\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For br\n\t\t\tif (codings === 'br') {\n\t\t\t\tbody = Stream.pipeline(body, zlib.createBrotliDecompress(), reject);\n\t\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Otherwise, use response as-is\n\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\tresolve(response);\n\t\t});\n\n\t\twriteToStream(request_, request);\n\t});\n}\n\n/**\n * \n * @param {import('http').ClientRequest} request \n * @param {(error:Error) => void} errorCallback \n */\nfunction fixResponseChunkedTransferBadEnding(request, errorCallback) {\n\t/** @type {import('net').Socket} */\n\tlet socket;\n\n\trequest.on('socket', s => {\n\t\tsocket = s;\n\t});\n\n\trequest.on('response', response => {\n\n\t\tconst {headers} = response;\n\n\t\tif (headers['transfer-encoding'] === 'chunked' && !headers['content-length']) {\n\t\t\tsocket.prependListener('close', hadError => {\n\t\t\t\t// if a data listener is still present we didn't end cleanly\n\t\t\t\tconst hasDataListener = socket.listenerCount('data') > 0;\n\t\t\t\tif (hasDataListener && !hadError) {\n\t\t\t\t\tconst err = Object.assign(new Error('Premature close'), {\n\t\t\t\t\t\tcode: 'ERR_STREAM_PREMATURE_CLOSE'\n\t\t\t\t\t});\n\t\t\t\t\terrorCallback(err);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}\n\nObject.defineProperty(exports, \"Blob\", ({\n\tenumerable: true,\n\tget: function () { return blob.Blob; }\n}));\nObject.defineProperty(exports, \"ReadableStream\", ({\n\tenumerable: true,\n\tget: function () { return blob.ReadableStream; }\n}));\nObject.defineProperty(exports, \"FormData\", ({\n\tenumerable: true,\n\tget: function () { return formData.FormData; }\n}));\nexports.AbortError = AbortError;\nexports.FetchError = FetchError;\nexports.Headers = Headers;\nexports.Request = Request;\nexports.Response = Response;\nexports[\"default\"] = fetch;\nexports.isRedirect = isRedirect;\n//# sourceMappingURL=index.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/fetch/dist/index.cjs?");

/***/ }),

/***/ "./node_modules/@web-std/file/dist/src/file.cjs":
/*!******************************************************!*\
  !*** ./node_modules/@web-std/file/dist/src/file.cjs ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\nvar blob = __webpack_require__(/*! @web-std/blob */ \"./node_modules/@web-std/blob/dist/src/lib.node.cjs\");\n\n/**\n * @implements {globalThis.File}\n */\nclass File extends blob.Blob {\n  /**\n   *\n   * @param {BlobPart[]} init\n   * @param {string} name - A USVString representing the file name or the path\n   * to the file.\n   * @param {FilePropertyBag} [options]\n   */\n  constructor(\n    init,\n    name = panic(new TypeError(\"File constructor requires name argument\")),\n    options = {}\n  ) {\n    super(init, options);\n    // Per File API spec https://w3c.github.io/FileAPI/#file-constructor\n    // Every \"/\" character of file name must be replaced with a \":\".\n    /** @private */\n    this._name = name;\n    // It appears that browser do not follow the spec here.\n    // String(name).replace(/\\//g, \":\")\n    /** @private */\n    this._lastModified = options.lastModified || Date.now();\n  }\n\n  /**\n   * The name of the file referenced by the File object.\n   * @type {string}\n   */\n  get name() {\n    return this._name\n  }\n\n  /**\n   * The path the URL of the File is relative to.\n   * @type {string}\n   */\n  get webkitRelativePath() {\n    return \"\"\n  }\n\n  /**\n   * Returns the last modified time of the file, in millisecond since the UNIX\n   * epoch (January 1st, 1970 at Midnight).\n   * @returns {number}\n   */\n  get lastModified() {\n    return this._lastModified\n  }\n\n  get [Symbol.toStringTag]() {\n    return \"File\"\n  }\n}\n\n/**\n * @param {*} error\n * @returns {never}\n */\nconst panic = error => {\n  throw error\n};\n\nexports.File = File;\n//# sourceMappingURL=file.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/file/dist/src/file.cjs?");

/***/ }),

/***/ "./node_modules/@web-std/file/dist/src/lib.node.cjs":
/*!**********************************************************!*\
  !*** ./node_modules/@web-std/file/dist/src/lib.node.cjs ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\nvar blob = __webpack_require__(/*! @web-std/blob */ \"./node_modules/@web-std/blob/dist/src/lib.node.cjs\");\nvar file = __webpack_require__(/*! ./file.cjs */ \"./node_modules/@web-std/file/dist/src/file.cjs\");\n\n// Electron-renderer should get the browser implementation instead of node\n// Browser configuration is not enough\n\n// Marking export as a DOM File object instead of custom class.\n/** @type {typeof globalThis.File} */\nconst File = typeof globalThis.File === \"function\" ? globalThis.File : file.File;\n\nObject.defineProperty(exports, \"Blob\", ({\n\tenumerable: true,\n\tget: function () {\n\t\treturn blob.Blob;\n\t}\n}));\nexports.File = File;\n//# sourceMappingURL=lib.node.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/file/dist/src/lib.node.cjs?");

/***/ }),

/***/ "./node_modules/@web-std/form-data/dist/src/form-data.cjs":
/*!****************************************************************!*\
  !*** ./node_modules/@web-std/form-data/dist/src/form-data.cjs ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n/**\n * @implements {globalThis.FormData}\n */\nclass FormData {\n  /**\n   * @param {HTMLFormElement} [form]\n   */\n  constructor(form) {\n    if (form !== undefined) {\n      const error = isHTMLFormElement(form)\n        ? new TypeError(\n            \"FormData constructor: HTMLFormElement parameter is not supported, if you need it submit an issue\"\n          )\n        : new TypeError(\n            \"FormData constructor: Argument 1 does not implement interface HTMLFormElement.\"\n          );\n\n      throw error\n    }\n\n    /**\n     * @private\n     * @readonly\n     * @type {Array<[string, FormDataEntryValue]>}\n     */\n    this._entries = [];\n\n    Object.defineProperty(this, \"_entries\", { enumerable: false });\n  }\n  get [Symbol.toStringTag]() {\n    return \"FormData\"\n  }\n\n  /**\n   * Appends a new value onto an existing key inside a FormData object, or adds\n   * the key if it does not already exist.\n   *\n   * The difference between `set` and `append` is that if the specified key\n   * already exists, `set` will overwrite all existing values with the new one,\n   * whereas `append` will append the new value onto the end of the existing\n   * set of values.\n   *\n   * @param {string} name\n   * @param {string|Blob|File} value - The name of the field whose data is\n   * contained in value.\n   * @param {string} [filename] - The filename reported to the server, when a\n   * value is a `Blob` or a `File`. The default filename for a `Blob` objects is\n   * `\"blob\"`. The default filename for a `File` is the it's name.\n   */\n  append(\n    name,\n    value = panic(\n      new TypeError(\"FormData.append: requires at least 2 arguments\")\n    ),\n    filename\n  ) {\n    this._entries.push([name, toEntryValue(value, filename)]);\n  }\n\n  /**\n   * Deletes a key and all its values from a FormData object.\n   *\n   * @param {string} name\n   */\n  delete(\n    name = panic(new TypeError(\"FormData.delete: requires string argument\"))\n  ) {\n    const entries = this._entries;\n    let index = 0;\n    while (index < entries.length) {\n      const [entryName] = /** @type {[string, FormDataEntryValue]}*/ (\n        entries[index]\n      );\n      if (entryName === name) {\n        entries.splice(index, 1);\n      } else {\n        index++;\n      }\n    }\n  }\n\n  /**\n   * Returns the first value associated with a given key from within a\n   * FormData object.\n   *\n   * @param {string} name\n   * @returns {FormDataEntryValue|null}\n   */\n\n  get(name = panic(new TypeError(\"FormData.get: requires string argument\"))) {\n    for (const [entryName, value] of this._entries) {\n      if (entryName === name) {\n        return value\n      }\n    }\n    return null\n  }\n\n  /**\n   * Returns an array of all the values associated with a given key from within\n   * a FormData.\n   *\n   * @param {string} name\n   * @returns {FormDataEntryValue[]}\n   */\n  getAll(\n    name = panic(new TypeError(\"FormData.getAll: requires string argument\"))\n  ) {\n    const values = [];\n    for (const [entryName, value] of this._entries) {\n      if (entryName === name) {\n        values.push(value);\n      }\n    }\n    return values\n  }\n\n  /**\n   * Returns a boolean stating whether a FormData object contains a certain key.\n   *\n   * @param {string} name\n   */\n\n  has(name = panic(new TypeError(\"FormData.has: requires string argument\"))) {\n    for (const [entryName] of this._entries) {\n      if (entryName === name) {\n        return true\n      }\n    }\n    return false\n  }\n\n  /**\n   * Sets a new value for an existing key inside a FormData object, or adds the\n   * key/value if it does not already exist.\n   *\n   * @param {string} name\n   * @param {string|Blob|File} value\n   * @param {string} [filename]\n   */\n\n  set(\n    name,\n    value = panic(new TypeError(\"FormData.set: requires at least 2 arguments\")),\n    filename\n  ) {\n    let index = 0;\n    const { _entries: entries } = this;\n    const entryValue = toEntryValue(value, filename);\n    let wasSet = false;\n    while (index < entries.length) {\n      const entry = /** @type {[string, FormDataEntryValue]}*/ (entries[index]);\n      if (entry[0] === name) {\n        if (wasSet) {\n          entries.splice(index, 1);\n        } else {\n          wasSet = true;\n          entry[1] = entryValue;\n          index++;\n        }\n      } else {\n        index++;\n      }\n    }\n\n    if (!wasSet) {\n      entries.push([name, entryValue]);\n    }\n  }\n\n  /**\n   * Method returns an iterator allowing to go through all key/value pairs\n   * contained in this object.\n   */\n  entries() {\n    return this._entries.values()\n  }\n\n  /**\n   * Returns an iterator allowing to go through all keys of the key/value pairs\n   * contained in this object.\n   *\n   * @returns {IterableIterator<string>}\n   */\n  *keys() {\n    for (const [name] of this._entries) {\n      yield name;\n    }\n  }\n\n  /**\n   * Returns an iterator allowing to go through all values contained in this\n   * object.\n   *\n   * @returns {IterableIterator<FormDataEntryValue>}\n   */\n  *values() {\n    for (const [_, value] of this._entries) {\n      yield value;\n    }\n  }\n\n  [Symbol.iterator]() {\n    return this._entries.values()\n  }\n\n  /**\n   * @param {(value: FormDataEntryValue, key: string, parent: globalThis.FormData) => void} fn\n   * @param {any} [thisArg]\n   * @returns {void}\n   */\n  forEach(fn, thisArg) {\n    for (const [key, value] of this._entries) {\n      fn.call(thisArg, value, key, this);\n    }\n  }\n}\n\n/**\n * @param {any} value\n * @returns {value is HTMLFormElement}\n */\nconst isHTMLFormElement = value =>\n  Object.prototype.toString.call(value) === \"[object HTMLFormElement]\";\n\n/**\n * @param {string|Blob|File} value\n * @param {string} [filename]\n * @returns {FormDataEntryValue}\n */\nconst toEntryValue = (value, filename) => {\n  if (isFile(value)) {\n    return filename != null ? new BlobFile([value], filename, value) : value\n  } else if (isBlob(value)) {\n    return new BlobFile([value], filename != null ? filename : \"blob\")\n  } else {\n    if (filename != null) {\n      throw new TypeError(\n        \"filename is only supported when value is Blob or File\"\n      )\n    }\n    return `${value}`\n  }\n};\n\n/**\n * @param {any} value\n * @returns {value is File}\n */\nconst isFile = value =>\n  Object.prototype.toString.call(value) === \"[object File]\" &&\n  typeof value.name === \"string\";\n\n/**\n * @param {any} value\n * @returns {value is Blob}\n */\nconst isBlob = value =>\n  Object.prototype.toString.call(value) === \"[object Blob]\";\n\n/**\n * Simple `File` implementation that just wraps a given blob.\n * @implements {globalThis.File}\n */\nconst BlobFile = class File {\n  /**\n   * @param {[Blob]} parts\n   * @param {string} name\n   * @param {FilePropertyBag} [options]\n   */\n  constructor([blob], name, { lastModified = Date.now() } = {}) {\n    this.blob = blob;\n    this.name = name;\n    this.lastModified = lastModified;\n  }\n  get webkitRelativePath() {\n    return \"\"\n  }\n  get size() {\n    return this.blob.size\n  }\n  get type() {\n    return this.blob.type\n  }\n  /**\n   *\n   * @param {number} [start]\n   * @param {number} [end]\n   * @param {string} [contentType]\n   */\n  slice(start, end, contentType) {\n    return this.blob.slice(start, end, contentType)\n  }\n  stream() {\n    return this.blob.stream()\n  }\n  text() {\n    return this.blob.text()\n  }\n  arrayBuffer() {\n    return this.blob.arrayBuffer()\n  }\n  get [Symbol.toStringTag]() {\n    return \"File\"\n  }\n};\n\n/**\n * @param {*} error\n * @returns {never}\n */\nconst panic = error => {\n  throw error\n};\n\nexports.FormData = FormData;\n//# sourceMappingURL=form-data.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/form-data/dist/src/form-data.cjs?");

/***/ }),

/***/ "./node_modules/@web-std/form-data/dist/src/lib.node.cjs":
/*!***************************************************************!*\
  !*** ./node_modules/@web-std/form-data/dist/src/lib.node.cjs ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\nvar formData = __webpack_require__(/*! ./form-data.cjs */ \"./node_modules/@web-std/form-data/dist/src/form-data.cjs\");\n\n// @ts-check\n\n// Electron-renderer should get the browser implementation instead of node\n// which is why we check global first.\nconst FormData =\n  typeof globalThis.FormData === \"function\"\n    ? globalThis.FormData\n    : formData.FormData;\n\nexports.FormData = FormData;\n//# sourceMappingURL=lib.node.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/form-data/dist/src/lib.node.cjs?");

/***/ }),

/***/ "./node_modules/@web-std/stream/src/stream.cjs":
/*!*****************************************************!*\
  !*** ./node_modules/@web-std/stream/src/stream.cjs ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("try {\n  module.exports = __webpack_require__(/*! stream/web */ \"stream/web\")\n} catch (error) {\n  module.exports = __webpack_require__(/*! web-streams-polyfill/ponyfill */ \"./node_modules/web-streams-polyfill/dist/ponyfill.mjs\")\n}\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web-std/stream/src/stream.cjs?");

/***/ }),

/***/ "./node_modules/@web3-storage/parse-link-header/dist/index.cjs":
/*!*********************************************************************!*\
  !*** ./node_modules/@web3-storage/parse-link-header/dist/index.cjs ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\nconst MAX_HEADER_LENGTH = 2000;\nconst THROW_ON_MAX_HEADER_LENGTH_EXCEEDED = false;\n\nfunction hasRel (x) {\n  return x && x.rel\n}\n\nfunction intoRels (acc, x) {\n  function splitRel (rel) {\n    acc[rel] = Object.assign({}, x, { rel: rel });\n  }\n\n  x.rel.split(/\\s+/).forEach(splitRel);\n\n  return acc\n}\n\nfunction createObjects (acc, p) {\n  // rel=\"next\" => 1: rel 2: next\n  const m = p.match(/\\s*(.+)\\s*=\\s*\"?([^\"]+)\"?/);\n  if (m) acc[m[1]] = m[2];\n  return acc\n}\n\nfunction parseLink (link) {\n  try {\n    const m = link.match(/<?([^>]*)>(.*)/);\n    const linkUrl = m[1];\n    const parts = m[2].split(';');\n    const qry = {};\n    // The origin is unused but it's required to parse relative URLs\n    const url = new URL(linkUrl, 'https://example.com');\n\n    for (const [key, value] of url.searchParams) {\n      qry[key] = value;\n    }\n\n    parts.shift();\n\n    let info = parts.reduce(createObjects, {});\n    info = Object.assign({}, qry, info);\n    info.url = linkUrl;\n    return info\n  } catch {\n    return null\n  }\n}\n\nfunction checkHeader (linkHeader, options) {\n  if (!linkHeader) return false\n\n  options = options || {};\n  const maxHeaderLength = options.maxHeaderLength || MAX_HEADER_LENGTH;\n  const throwOnMaxHeaderLengthExceeded = options.throwOnMaxHeaderLengthExceeded || THROW_ON_MAX_HEADER_LENGTH_EXCEEDED;\n\n  if (linkHeader.length > maxHeaderLength) {\n    if (throwOnMaxHeaderLengthExceeded) {\n      throw new Error('Input string too long, it should be under ' + maxHeaderLength + ' characters.')\n    } else {\n      return false\n    }\n  }\n  return true\n}\n\nfunction parseLinkHeader (linkHeader, options) {\n  if (!checkHeader(linkHeader, options)) return null\n\n  return linkHeader.split(/,\\s*</)\n    .map(parseLink)\n    .filter(hasRel)\n    .reduce(intoRels, {})\n}\n\nexports.parseLinkHeader = parseLinkHeader;\n//# sourceMappingURL=index.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/@web3-storage/parse-link-header/dist/index.cjs?");

/***/ }),

/***/ "./node_modules/commander/index.js":
/*!*****************************************!*\
  !*** ./node_modules/commander/index.js ***!
  \*****************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("const {\n  Argument\n} = __webpack_require__(/*! ./lib/argument.js */ \"./node_modules/commander/lib/argument.js\");\n\nconst {\n  Command\n} = __webpack_require__(/*! ./lib/command.js */ \"./node_modules/commander/lib/command.js\");\n\nconst {\n  CommanderError,\n  InvalidArgumentError\n} = __webpack_require__(/*! ./lib/error.js */ \"./node_modules/commander/lib/error.js\");\n\nconst {\n  Help\n} = __webpack_require__(/*! ./lib/help.js */ \"./node_modules/commander/lib/help.js\");\n\nconst {\n  Option\n} = __webpack_require__(/*! ./lib/option.js */ \"./node_modules/commander/lib/option.js\"); // @ts-check\n\n/**\n * Expose the root command.\n */\n\n\nexports = module.exports = new Command();\nexports.program = exports; // More explicit access to global command.\n// Implicit export of createArgument, createCommand, and createOption.\n\n/**\n * Expose classes\n */\n\nexports.Argument = Argument;\nexports.Command = Command;\nexports.CommanderError = CommanderError;\nexports.Help = Help;\nexports.InvalidArgumentError = InvalidArgumentError;\nexports.InvalidOptionArgumentError = InvalidArgumentError; // Deprecated\n\nexports.Option = Option;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/commander/index.js?");

/***/ }),

/***/ "./node_modules/commander/lib/argument.js":
/*!************************************************!*\
  !*** ./node_modules/commander/lib/argument.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const {\n  InvalidArgumentError\n} = __webpack_require__(/*! ./error.js */ \"./node_modules/commander/lib/error.js\"); // @ts-check\n\n\nclass Argument {\n  /**\n   * Initialize a new command argument with the given name and description.\n   * The default is that the argument is required, and you can explicitly\n   * indicate this with <> around the name. Put [] around the name for an optional argument.\n   *\n   * @param {string} name\n   * @param {string} [description]\n   */\n  constructor(name, description) {\n    this.description = description || '';\n    this.variadic = false;\n    this.parseArg = undefined;\n    this.defaultValue = undefined;\n    this.defaultValueDescription = undefined;\n    this.argChoices = undefined;\n\n    switch (name[0]) {\n      case '<':\n        // e.g. <required>\n        this.required = true;\n        this._name = name.slice(1, -1);\n        break;\n\n      case '[':\n        // e.g. [optional]\n        this.required = false;\n        this._name = name.slice(1, -1);\n        break;\n\n      default:\n        this.required = true;\n        this._name = name;\n        break;\n    }\n\n    if (this._name.length > 3 && this._name.slice(-3) === '...') {\n      this.variadic = true;\n      this._name = this._name.slice(0, -3);\n    }\n  }\n  /**\n   * Return argument name.\n   *\n   * @return {string}\n   */\n\n\n  name() {\n    return this._name;\n  }\n  /**\n   * @api private\n   */\n\n\n  _concatValue(value, previous) {\n    if (previous === this.defaultValue || !Array.isArray(previous)) {\n      return [value];\n    }\n\n    return previous.concat(value);\n  }\n  /**\n   * Set the default value, and optionally supply the description to be displayed in the help.\n   *\n   * @param {any} value\n   * @param {string} [description]\n   * @return {Argument}\n   */\n\n\n  default(value, description) {\n    this.defaultValue = value;\n    this.defaultValueDescription = description;\n    return this;\n  }\n  /**\n   * Set the custom handler for processing CLI command arguments into argument values.\n   *\n   * @param {Function} [fn]\n   * @return {Argument}\n   */\n\n\n  argParser(fn) {\n    this.parseArg = fn;\n    return this;\n  }\n  /**\n   * Only allow argument value to be one of choices.\n   *\n   * @param {string[]} values\n   * @return {Argument}\n   */\n\n\n  choices(values) {\n    this.argChoices = values.slice();\n\n    this.parseArg = (arg, previous) => {\n      if (!this.argChoices.includes(arg)) {\n        throw new InvalidArgumentError(`Allowed choices are ${this.argChoices.join(', ')}.`);\n      }\n\n      if (this.variadic) {\n        return this._concatValue(arg, previous);\n      }\n\n      return arg;\n    };\n\n    return this;\n  }\n  /**\n   * Make argument required.\n   */\n\n\n  argRequired() {\n    this.required = true;\n    return this;\n  }\n  /**\n   * Make argument optional.\n   */\n\n\n  argOptional() {\n    this.required = false;\n    return this;\n  }\n\n}\n/**\n * Takes an argument and returns its human readable equivalent for help usage.\n *\n * @param {Argument} arg\n * @return {string}\n * @api private\n */\n\n\nfunction humanReadableArgName(arg) {\n  const nameOutput = arg.name() + (arg.variadic === true ? '...' : '');\n  return arg.required ? '<' + nameOutput + '>' : '[' + nameOutput + ']';\n}\n\nexports.Argument = Argument;\nexports.humanReadableArgName = humanReadableArgName;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/commander/lib/argument.js?");

/***/ }),

/***/ "./node_modules/commander/lib/command.js":
/*!***********************************************!*\
  !*** ./node_modules/commander/lib/command.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\n\nconst childProcess = __webpack_require__(/*! child_process */ \"child_process\");\n\nconst path = __webpack_require__(/*! path */ \"path\");\n\nconst fs = __webpack_require__(/*! fs */ \"fs\");\n\nconst process = __webpack_require__(/*! process */ \"process\");\n\nconst {\n  Argument,\n  humanReadableArgName\n} = __webpack_require__(/*! ./argument.js */ \"./node_modules/commander/lib/argument.js\");\n\nconst {\n  CommanderError\n} = __webpack_require__(/*! ./error.js */ \"./node_modules/commander/lib/error.js\");\n\nconst {\n  Help\n} = __webpack_require__(/*! ./help.js */ \"./node_modules/commander/lib/help.js\");\n\nconst {\n  Option,\n  splitOptionFlags,\n  DualOptions\n} = __webpack_require__(/*! ./option.js */ \"./node_modules/commander/lib/option.js\");\n\nconst {\n  suggestSimilar\n} = __webpack_require__(/*! ./suggestSimilar */ \"./node_modules/commander/lib/suggestSimilar.js\"); // @ts-check\n\n\nclass Command extends EventEmitter {\n  /**\n   * Initialize a new `Command`.\n   *\n   * @param {string} [name]\n   */\n  constructor(name) {\n    super();\n    /** @type {Command[]} */\n\n    this.commands = [];\n    /** @type {Option[]} */\n\n    this.options = [];\n    this.parent = null;\n    this._allowUnknownOption = false;\n    this._allowExcessArguments = true;\n    /** @type {Argument[]} */\n\n    this._args = [];\n    /** @type {string[]} */\n\n    this.args = []; // cli args with options removed\n\n    this.rawArgs = [];\n    this.processedArgs = []; // like .args but after custom processing and collecting variadic\n\n    this._scriptPath = null;\n    this._name = name || '';\n    this._optionValues = {};\n    this._optionValueSources = {}; // default < config < env < cli\n\n    this._storeOptionsAsProperties = false;\n    this._actionHandler = null;\n    this._executableHandler = false;\n    this._executableFile = null; // custom name for executable\n\n    this._executableDir = null; // custom search directory for subcommands\n\n    this._defaultCommandName = null;\n    this._exitCallback = null;\n    this._aliases = [];\n    this._combineFlagAndOptionalValue = true;\n    this._description = '';\n    this._summary = '';\n    this._argsDescription = undefined; // legacy\n\n    this._enablePositionalOptions = false;\n    this._passThroughOptions = false;\n    this._lifeCycleHooks = {}; // a hash of arrays\n\n    /** @type {boolean | string} */\n\n    this._showHelpAfterError = false;\n    this._showSuggestionAfterError = true; // see .configureOutput() for docs\n\n    this._outputConfiguration = {\n      writeOut: str => process.stdout.write(str),\n      writeErr: str => process.stderr.write(str),\n      getOutHelpWidth: () => process.stdout.isTTY ? process.stdout.columns : undefined,\n      getErrHelpWidth: () => process.stderr.isTTY ? process.stderr.columns : undefined,\n      outputError: (str, write) => write(str)\n    };\n    this._hidden = false;\n    this._hasHelpOption = true;\n    this._helpFlags = '-h, --help';\n    this._helpDescription = 'display help for command';\n    this._helpShortFlag = '-h';\n    this._helpLongFlag = '--help';\n    this._addImplicitHelpCommand = undefined; // Deliberately undefined, not decided whether true or false\n\n    this._helpCommandName = 'help';\n    this._helpCommandnameAndArgs = 'help [command]';\n    this._helpCommandDescription = 'display help for command';\n    this._helpConfiguration = {};\n  }\n  /**\n   * Copy settings that are useful to have in common across root command and subcommands.\n   *\n   * (Used internally when adding a command using `.command()` so subcommands inherit parent settings.)\n   *\n   * @param {Command} sourceCommand\n   * @return {Command} `this` command for chaining\n   */\n\n\n  copyInheritedSettings(sourceCommand) {\n    this._outputConfiguration = sourceCommand._outputConfiguration;\n    this._hasHelpOption = sourceCommand._hasHelpOption;\n    this._helpFlags = sourceCommand._helpFlags;\n    this._helpDescription = sourceCommand._helpDescription;\n    this._helpShortFlag = sourceCommand._helpShortFlag;\n    this._helpLongFlag = sourceCommand._helpLongFlag;\n    this._helpCommandName = sourceCommand._helpCommandName;\n    this._helpCommandnameAndArgs = sourceCommand._helpCommandnameAndArgs;\n    this._helpCommandDescription = sourceCommand._helpCommandDescription;\n    this._helpConfiguration = sourceCommand._helpConfiguration;\n    this._exitCallback = sourceCommand._exitCallback;\n    this._storeOptionsAsProperties = sourceCommand._storeOptionsAsProperties;\n    this._combineFlagAndOptionalValue = sourceCommand._combineFlagAndOptionalValue;\n    this._allowExcessArguments = sourceCommand._allowExcessArguments;\n    this._enablePositionalOptions = sourceCommand._enablePositionalOptions;\n    this._showHelpAfterError = sourceCommand._showHelpAfterError;\n    this._showSuggestionAfterError = sourceCommand._showSuggestionAfterError;\n    return this;\n  }\n  /**\n   * Define a command.\n   *\n   * There are two styles of command: pay attention to where to put the description.\n   *\n   * @example\n   * // Command implemented using action handler (description is supplied separately to `.command`)\n   * program\n   *   .command('clone <source> [destination]')\n   *   .description('clone a repository into a newly created directory')\n   *   .action((source, destination) => {\n   *     console.log('clone command called');\n   *   });\n   *\n   * // Command implemented using separate executable file (description is second parameter to `.command`)\n   * program\n   *   .command('start <service>', 'start named service')\n   *   .command('stop [service]', 'stop named service, or all if no name supplied');\n   *\n   * @param {string} nameAndArgs - command name and arguments, args are `<required>` or `[optional]` and last may also be `variadic...`\n   * @param {Object|string} [actionOptsOrExecDesc] - configuration options (for action), or description (for executable)\n   * @param {Object} [execOpts] - configuration options (for executable)\n   * @return {Command} returns new command for action handler, or `this` for executable command\n   */\n\n\n  command(nameAndArgs, actionOptsOrExecDesc, execOpts) {\n    let desc = actionOptsOrExecDesc;\n    let opts = execOpts;\n\n    if (typeof desc === 'object' && desc !== null) {\n      opts = desc;\n      desc = null;\n    }\n\n    opts = opts || {};\n    const [, name, args] = nameAndArgs.match(/([^ ]+) *(.*)/);\n    const cmd = this.createCommand(name);\n\n    if (desc) {\n      cmd.description(desc);\n      cmd._executableHandler = true;\n    }\n\n    if (opts.isDefault) this._defaultCommandName = cmd._name;\n    cmd._hidden = !!(opts.noHelp || opts.hidden); // noHelp is deprecated old name for hidden\n\n    cmd._executableFile = opts.executableFile || null; // Custom name for executable file, set missing to null to match constructor\n\n    if (args) cmd.arguments(args);\n    this.commands.push(cmd);\n    cmd.parent = this;\n    cmd.copyInheritedSettings(this);\n    if (desc) return this;\n    return cmd;\n  }\n  /**\n   * Factory routine to create a new unattached command.\n   *\n   * See .command() for creating an attached subcommand, which uses this routine to\n   * create the command. You can override createCommand to customise subcommands.\n   *\n   * @param {string} [name]\n   * @return {Command} new command\n   */\n\n\n  createCommand(name) {\n    return new Command(name);\n  }\n  /**\n   * You can customise the help with a subclass of Help by overriding createHelp,\n   * or by overriding Help properties using configureHelp().\n   *\n   * @return {Help}\n   */\n\n\n  createHelp() {\n    return Object.assign(new Help(), this.configureHelp());\n  }\n  /**\n   * You can customise the help by overriding Help properties using configureHelp(),\n   * or with a subclass of Help by overriding createHelp().\n   *\n   * @param {Object} [configuration] - configuration options\n   * @return {Command|Object} `this` command for chaining, or stored configuration\n   */\n\n\n  configureHelp(configuration) {\n    if (configuration === undefined) return this._helpConfiguration;\n    this._helpConfiguration = configuration;\n    return this;\n  }\n  /**\n   * The default output goes to stdout and stderr. You can customise this for special\n   * applications. You can also customise the display of errors by overriding outputError.\n   *\n   * The configuration properties are all functions:\n   *\n   *     // functions to change where being written, stdout and stderr\n   *     writeOut(str)\n   *     writeErr(str)\n   *     // matching functions to specify width for wrapping help\n   *     getOutHelpWidth()\n   *     getErrHelpWidth()\n   *     // functions based on what is being written out\n   *     outputError(str, write) // used for displaying errors, and not used for displaying help\n   *\n   * @param {Object} [configuration] - configuration options\n   * @return {Command|Object} `this` command for chaining, or stored configuration\n   */\n\n\n  configureOutput(configuration) {\n    if (configuration === undefined) return this._outputConfiguration;\n    Object.assign(this._outputConfiguration, configuration);\n    return this;\n  }\n  /**\n   * Display the help or a custom message after an error occurs.\n   *\n   * @param {boolean|string} [displayHelp]\n   * @return {Command} `this` command for chaining\n   */\n\n\n  showHelpAfterError(displayHelp = true) {\n    if (typeof displayHelp !== 'string') displayHelp = !!displayHelp;\n    this._showHelpAfterError = displayHelp;\n    return this;\n  }\n  /**\n   * Display suggestion of similar commands for unknown commands, or options for unknown options.\n   *\n   * @param {boolean} [displaySuggestion]\n   * @return {Command} `this` command for chaining\n   */\n\n\n  showSuggestionAfterError(displaySuggestion = true) {\n    this._showSuggestionAfterError = !!displaySuggestion;\n    return this;\n  }\n  /**\n   * Add a prepared subcommand.\n   *\n   * See .command() for creating an attached subcommand which inherits settings from its parent.\n   *\n   * @param {Command} cmd - new subcommand\n   * @param {Object} [opts] - configuration options\n   * @return {Command} `this` command for chaining\n   */\n\n\n  addCommand(cmd, opts) {\n    if (!cmd._name) {\n      throw new Error(`Command passed to .addCommand() must have a name\n- specify the name in Command constructor or using .name()`);\n    }\n\n    opts = opts || {};\n    if (opts.isDefault) this._defaultCommandName = cmd._name;\n    if (opts.noHelp || opts.hidden) cmd._hidden = true; // modifying passed command due to existing implementation\n\n    this.commands.push(cmd);\n    cmd.parent = this;\n    return this;\n  }\n  /**\n   * Factory routine to create a new unattached argument.\n   *\n   * See .argument() for creating an attached argument, which uses this routine to\n   * create the argument. You can override createArgument to return a custom argument.\n   *\n   * @param {string} name\n   * @param {string} [description]\n   * @return {Argument} new argument\n   */\n\n\n  createArgument(name, description) {\n    return new Argument(name, description);\n  }\n  /**\n   * Define argument syntax for command.\n   *\n   * The default is that the argument is required, and you can explicitly\n   * indicate this with <> around the name. Put [] around the name for an optional argument.\n   *\n   * @example\n   * program.argument('<input-file>');\n   * program.argument('[output-file]');\n   *\n   * @param {string} name\n   * @param {string} [description]\n   * @param {Function|*} [fn] - custom argument processing function\n   * @param {*} [defaultValue]\n   * @return {Command} `this` command for chaining\n   */\n\n\n  argument(name, description, fn, defaultValue) {\n    const argument = this.createArgument(name, description);\n\n    if (typeof fn === 'function') {\n      argument.default(defaultValue).argParser(fn);\n    } else {\n      argument.default(fn);\n    }\n\n    this.addArgument(argument);\n    return this;\n  }\n  /**\n   * Define argument syntax for command, adding multiple at once (without descriptions).\n   *\n   * See also .argument().\n   *\n   * @example\n   * program.arguments('<cmd> [env]');\n   *\n   * @param {string} names\n   * @return {Command} `this` command for chaining\n   */\n\n\n  arguments(names) {\n    names.split(/ +/).forEach(detail => {\n      this.argument(detail);\n    });\n    return this;\n  }\n  /**\n   * Define argument syntax for command, adding a prepared argument.\n   *\n   * @param {Argument} argument\n   * @return {Command} `this` command for chaining\n   */\n\n\n  addArgument(argument) {\n    const previousArgument = this._args.slice(-1)[0];\n\n    if (previousArgument && previousArgument.variadic) {\n      throw new Error(`only the last argument can be variadic '${previousArgument.name()}'`);\n    }\n\n    if (argument.required && argument.defaultValue !== undefined && argument.parseArg === undefined) {\n      throw new Error(`a default value for a required argument is never used: '${argument.name()}'`);\n    }\n\n    this._args.push(argument);\n\n    return this;\n  }\n  /**\n   * Override default decision whether to add implicit help command.\n   *\n   *    addHelpCommand() // force on\n   *    addHelpCommand(false); // force off\n   *    addHelpCommand('help [cmd]', 'display help for [cmd]'); // force on with custom details\n   *\n   * @return {Command} `this` command for chaining\n   */\n\n\n  addHelpCommand(enableOrNameAndArgs, description) {\n    if (enableOrNameAndArgs === false) {\n      this._addImplicitHelpCommand = false;\n    } else {\n      this._addImplicitHelpCommand = true;\n\n      if (typeof enableOrNameAndArgs === 'string') {\n        this._helpCommandName = enableOrNameAndArgs.split(' ')[0];\n        this._helpCommandnameAndArgs = enableOrNameAndArgs;\n      }\n\n      this._helpCommandDescription = description || this._helpCommandDescription;\n    }\n\n    return this;\n  }\n  /**\n   * @return {boolean}\n   * @api private\n   */\n\n\n  _hasImplicitHelpCommand() {\n    if (this._addImplicitHelpCommand === undefined) {\n      return this.commands.length && !this._actionHandler && !this._findCommand('help');\n    }\n\n    return this._addImplicitHelpCommand;\n  }\n  /**\n   * Add hook for life cycle event.\n   *\n   * @param {string} event\n   * @param {Function} listener\n   * @return {Command} `this` command for chaining\n   */\n\n\n  hook(event, listener) {\n    const allowedValues = ['preAction', 'postAction'];\n\n    if (!allowedValues.includes(event)) {\n      throw new Error(`Unexpected value for event passed to hook : '${event}'.\nExpecting one of '${allowedValues.join(\"', '\")}'`);\n    }\n\n    if (this._lifeCycleHooks[event]) {\n      this._lifeCycleHooks[event].push(listener);\n    } else {\n      this._lifeCycleHooks[event] = [listener];\n    }\n\n    return this;\n  }\n  /**\n   * Register callback to use as replacement for calling process.exit.\n   *\n   * @param {Function} [fn] optional callback which will be passed a CommanderError, defaults to throwing\n   * @return {Command} `this` command for chaining\n   */\n\n\n  exitOverride(fn) {\n    if (fn) {\n      this._exitCallback = fn;\n    } else {\n      this._exitCallback = err => {\n        if (err.code !== 'commander.executeSubCommandAsync') {\n          throw err;\n        } else {// Async callback from spawn events, not useful to throw.\n        }\n      };\n    }\n\n    return this;\n  }\n  /**\n   * Call process.exit, and _exitCallback if defined.\n   *\n   * @param {number} exitCode exit code for using with process.exit\n   * @param {string} code an id string representing the error\n   * @param {string} message human-readable description of the error\n   * @return never\n   * @api private\n   */\n\n\n  _exit(exitCode, code, message) {\n    if (this._exitCallback) {\n      this._exitCallback(new CommanderError(exitCode, code, message)); // Expecting this line is not reached.\n\n    }\n\n    process.exit(exitCode);\n  }\n  /**\n   * Register callback `fn` for the command.\n   *\n   * @example\n   * program\n   *   .command('serve')\n   *   .description('start service')\n   *   .action(function() {\n   *      // do work here\n   *   });\n   *\n   * @param {Function} fn\n   * @return {Command} `this` command for chaining\n   */\n\n\n  action(fn) {\n    const listener = args => {\n      // The .action callback takes an extra parameter which is the command or options.\n      const expectedArgsCount = this._args.length;\n      const actionArgs = args.slice(0, expectedArgsCount);\n\n      if (this._storeOptionsAsProperties) {\n        actionArgs[expectedArgsCount] = this; // backwards compatible \"options\"\n      } else {\n        actionArgs[expectedArgsCount] = this.opts();\n      }\n\n      actionArgs.push(this);\n      return fn.apply(this, actionArgs);\n    };\n\n    this._actionHandler = listener;\n    return this;\n  }\n  /**\n   * Factory routine to create a new unattached option.\n   *\n   * See .option() for creating an attached option, which uses this routine to\n   * create the option. You can override createOption to return a custom option.\n   *\n   * @param {string} flags\n   * @param {string} [description]\n   * @return {Option} new option\n   */\n\n\n  createOption(flags, description) {\n    return new Option(flags, description);\n  }\n  /**\n   * Add an option.\n   *\n   * @param {Option} option\n   * @return {Command} `this` command for chaining\n   */\n\n\n  addOption(option) {\n    const oname = option.name();\n    const name = option.attributeName(); // store default value\n\n    if (option.negate) {\n      // --no-foo is special and defaults foo to true, unless a --foo option is already defined\n      const positiveLongFlag = option.long.replace(/^--no-/, '--');\n\n      if (!this._findOption(positiveLongFlag)) {\n        this.setOptionValueWithSource(name, option.defaultValue === undefined ? true : option.defaultValue, 'default');\n      }\n    } else if (option.defaultValue !== undefined) {\n      this.setOptionValueWithSource(name, option.defaultValue, 'default');\n    } // register the option\n\n\n    this.options.push(option); // handler for cli and env supplied values\n\n    const handleOptionValue = (val, invalidValueMessage, valueSource) => {\n      // val is null for optional option used without an optional-argument.\n      // val is undefined for boolean and negated option.\n      if (val == null && option.presetArg !== undefined) {\n        val = option.presetArg;\n      } // custom processing\n\n\n      const oldValue = this.getOptionValue(name);\n\n      if (val !== null && option.parseArg) {\n        try {\n          val = option.parseArg(val, oldValue);\n        } catch (err) {\n          if (err.code === 'commander.invalidArgument') {\n            const message = `${invalidValueMessage} ${err.message}`;\n            this.error(message, {\n              exitCode: err.exitCode,\n              code: err.code\n            });\n          }\n\n          throw err;\n        }\n      } else if (val !== null && option.variadic) {\n        val = option._concatValue(val, oldValue);\n      } // Fill-in appropriate missing values. Long winded but easy to follow.\n\n\n      if (val == null) {\n        if (option.negate) {\n          val = false;\n        } else if (option.isBoolean() || option.optional) {\n          val = true;\n        } else {\n          val = ''; // not normal, parseArg might have failed or be a mock function for testing\n        }\n      }\n\n      this.setOptionValueWithSource(name, val, valueSource);\n    };\n\n    this.on('option:' + oname, val => {\n      const invalidValueMessage = `error: option '${option.flags}' argument '${val}' is invalid.`;\n      handleOptionValue(val, invalidValueMessage, 'cli');\n    });\n\n    if (option.envVar) {\n      this.on('optionEnv:' + oname, val => {\n        const invalidValueMessage = `error: option '${option.flags}' value '${val}' from env '${option.envVar}' is invalid.`;\n        handleOptionValue(val, invalidValueMessage, 'env');\n      });\n    }\n\n    return this;\n  }\n  /**\n   * Internal implementation shared by .option() and .requiredOption()\n   *\n   * @api private\n   */\n\n\n  _optionEx(config, flags, description, fn, defaultValue) {\n    if (typeof flags === 'object' && flags instanceof Option) {\n      throw new Error('To add an Option object use addOption() instead of option() or requiredOption()');\n    }\n\n    const option = this.createOption(flags, description);\n    option.makeOptionMandatory(!!config.mandatory);\n\n    if (typeof fn === 'function') {\n      option.default(defaultValue).argParser(fn);\n    } else if (fn instanceof RegExp) {\n      // deprecated\n      const regex = fn;\n\n      fn = (val, def) => {\n        const m = regex.exec(val);\n        return m ? m[0] : def;\n      };\n\n      option.default(defaultValue).argParser(fn);\n    } else {\n      option.default(fn);\n    }\n\n    return this.addOption(option);\n  }\n  /**\n   * Define option with `flags`, `description` and optional\n   * coercion `fn`.\n   *\n   * The `flags` string contains the short and/or long flags,\n   * separated by comma, a pipe or space. The following are all valid\n   * all will output this way when `--help` is used.\n   *\n   *     \"-p, --pepper\"\n   *     \"-p|--pepper\"\n   *     \"-p --pepper\"\n   *\n   * @example\n   * // simple boolean defaulting to undefined\n   * program.option('-p, --pepper', 'add pepper');\n   *\n   * program.pepper\n   * // => undefined\n   *\n   * --pepper\n   * program.pepper\n   * // => true\n   *\n   * // simple boolean defaulting to true (unless non-negated option is also defined)\n   * program.option('-C, --no-cheese', 'remove cheese');\n   *\n   * program.cheese\n   * // => true\n   *\n   * --no-cheese\n   * program.cheese\n   * // => false\n   *\n   * // required argument\n   * program.option('-C, --chdir <path>', 'change the working directory');\n   *\n   * --chdir /tmp\n   * program.chdir\n   * // => \"/tmp\"\n   *\n   * // optional argument\n   * program.option('-c, --cheese [type]', 'add cheese [marble]');\n   *\n   * @param {string} flags\n   * @param {string} [description]\n   * @param {Function|*} [fn] - custom option processing function or default value\n   * @param {*} [defaultValue]\n   * @return {Command} `this` command for chaining\n   */\n\n\n  option(flags, description, fn, defaultValue) {\n    return this._optionEx({}, flags, description, fn, defaultValue);\n  }\n  /**\n  * Add a required option which must have a value after parsing. This usually means\n  * the option must be specified on the command line. (Otherwise the same as .option().)\n  *\n  * The `flags` string contains the short and/or long flags, separated by comma, a pipe or space.\n  *\n  * @param {string} flags\n  * @param {string} [description]\n  * @param {Function|*} [fn] - custom option processing function or default value\n  * @param {*} [defaultValue]\n  * @return {Command} `this` command for chaining\n  */\n\n\n  requiredOption(flags, description, fn, defaultValue) {\n    return this._optionEx({\n      mandatory: true\n    }, flags, description, fn, defaultValue);\n  }\n  /**\n   * Alter parsing of short flags with optional values.\n   *\n   * @example\n   * // for `.option('-f,--flag [value]'):\n   * program.combineFlagAndOptionalValue(true);  // `-f80` is treated like `--flag=80`, this is the default behaviour\n   * program.combineFlagAndOptionalValue(false) // `-fb` is treated like `-f -b`\n   *\n   * @param {Boolean} [combine=true] - if `true` or omitted, an optional value can be specified directly after the flag.\n   */\n\n\n  combineFlagAndOptionalValue(combine = true) {\n    this._combineFlagAndOptionalValue = !!combine;\n    return this;\n  }\n  /**\n   * Allow unknown options on the command line.\n   *\n   * @param {Boolean} [allowUnknown=true] - if `true` or omitted, no error will be thrown\n   * for unknown options.\n   */\n\n\n  allowUnknownOption(allowUnknown = true) {\n    this._allowUnknownOption = !!allowUnknown;\n    return this;\n  }\n  /**\n   * Allow excess command-arguments on the command line. Pass false to make excess arguments an error.\n   *\n   * @param {Boolean} [allowExcess=true] - if `true` or omitted, no error will be thrown\n   * for excess arguments.\n   */\n\n\n  allowExcessArguments(allowExcess = true) {\n    this._allowExcessArguments = !!allowExcess;\n    return this;\n  }\n  /**\n   * Enable positional options. Positional means global options are specified before subcommands which lets\n   * subcommands reuse the same option names, and also enables subcommands to turn on passThroughOptions.\n   * The default behaviour is non-positional and global options may appear anywhere on the command line.\n   *\n   * @param {Boolean} [positional=true]\n   */\n\n\n  enablePositionalOptions(positional = true) {\n    this._enablePositionalOptions = !!positional;\n    return this;\n  }\n  /**\n   * Pass through options that come after command-arguments rather than treat them as command-options,\n   * so actual command-options come before command-arguments. Turning this on for a subcommand requires\n   * positional options to have been enabled on the program (parent commands).\n   * The default behaviour is non-positional and options may appear before or after command-arguments.\n   *\n   * @param {Boolean} [passThrough=true]\n   * for unknown options.\n   */\n\n\n  passThroughOptions(passThrough = true) {\n    this._passThroughOptions = !!passThrough;\n\n    if (!!this.parent && passThrough && !this.parent._enablePositionalOptions) {\n      throw new Error('passThroughOptions can not be used without turning on enablePositionalOptions for parent command(s)');\n    }\n\n    return this;\n  }\n  /**\n    * Whether to store option values as properties on command object,\n    * or store separately (specify false). In both cases the option values can be accessed using .opts().\n    *\n    * @param {boolean} [storeAsProperties=true]\n    * @return {Command} `this` command for chaining\n    */\n\n\n  storeOptionsAsProperties(storeAsProperties = true) {\n    this._storeOptionsAsProperties = !!storeAsProperties;\n\n    if (this.options.length) {\n      throw new Error('call .storeOptionsAsProperties() before adding options');\n    }\n\n    return this;\n  }\n  /**\n   * Retrieve option value.\n   *\n   * @param {string} key\n   * @return {Object} value\n   */\n\n\n  getOptionValue(key) {\n    if (this._storeOptionsAsProperties) {\n      return this[key];\n    }\n\n    return this._optionValues[key];\n  }\n  /**\n   * Store option value.\n   *\n   * @param {string} key\n   * @param {Object} value\n   * @return {Command} `this` command for chaining\n   */\n\n\n  setOptionValue(key, value) {\n    if (this._storeOptionsAsProperties) {\n      this[key] = value;\n    } else {\n      this._optionValues[key] = value;\n    }\n\n    return this;\n  }\n  /**\n   * Store option value and where the value came from.\n    *\n    * @param {string} key\n    * @param {Object} value\n    * @param {string} source - expected values are default/config/env/cli\n    * @return {Command} `this` command for chaining\n    */\n\n\n  setOptionValueWithSource(key, value, source) {\n    this.setOptionValue(key, value);\n    this._optionValueSources[key] = source;\n    return this;\n  }\n  /**\n    * Get source of option value.\n    * Expected values are default | config | env | cli\n    *\n    * @param {string} key\n    * @return {string}\n    */\n\n\n  getOptionValueSource(key) {\n    return this._optionValueSources[key];\n  }\n  /**\n   * Get user arguments from implied or explicit arguments.\n   * Side-effects: set _scriptPath if args included script. Used for default program name, and subcommand searches.\n   *\n   * @api private\n   */\n\n\n  _prepareUserArgs(argv, parseOptions) {\n    if (argv !== undefined && !Array.isArray(argv)) {\n      throw new Error('first parameter to parse must be array or undefined');\n    }\n\n    parseOptions = parseOptions || {}; // Default to using process.argv\n\n    if (argv === undefined) {\n      argv = process.argv; // @ts-ignore: unknown property\n\n      if (process.versions && process.versions.electron) {\n        parseOptions.from = 'electron';\n      }\n    }\n\n    this.rawArgs = argv.slice(); // make it a little easier for callers by supporting various argv conventions\n\n    let userArgs;\n\n    switch (parseOptions.from) {\n      case undefined:\n      case 'node':\n        this._scriptPath = argv[1];\n        userArgs = argv.slice(2);\n        break;\n\n      case 'electron':\n        // @ts-ignore: unknown property\n        if (process.defaultApp) {\n          this._scriptPath = argv[1];\n          userArgs = argv.slice(2);\n        } else {\n          userArgs = argv.slice(1);\n        }\n\n        break;\n\n      case 'user':\n        userArgs = argv.slice(0);\n        break;\n\n      default:\n        throw new Error(`unexpected parse option { from: '${parseOptions.from}' }`);\n    } // Find default name for program from arguments.\n\n\n    if (!this._name && this._scriptPath) this.nameFromFilename(this._scriptPath);\n    this._name = this._name || 'program';\n    return userArgs;\n  }\n  /**\n   * Parse `argv`, setting options and invoking commands when defined.\n   *\n   * The default expectation is that the arguments are from node and have the application as argv[0]\n   * and the script being run in argv[1], with user parameters after that.\n   *\n   * @example\n   * program.parse(process.argv);\n   * program.parse(); // implicitly use process.argv and auto-detect node vs electron conventions\n   * program.parse(my-args, { from: 'user' }); // just user supplied arguments, nothing special about argv[0]\n   *\n   * @param {string[]} [argv] - optional, defaults to process.argv\n   * @param {Object} [parseOptions] - optionally specify style of options with from: node/user/electron\n   * @param {string} [parseOptions.from] - where the args are from: 'node', 'user', 'electron'\n   * @return {Command} `this` command for chaining\n   */\n\n\n  parse(argv, parseOptions) {\n    const userArgs = this._prepareUserArgs(argv, parseOptions);\n\n    this._parseCommand([], userArgs);\n\n    return this;\n  }\n  /**\n   * Parse `argv`, setting options and invoking commands when defined.\n   *\n   * Use parseAsync instead of parse if any of your action handlers are async. Returns a Promise.\n   *\n   * The default expectation is that the arguments are from node and have the application as argv[0]\n   * and the script being run in argv[1], with user parameters after that.\n   *\n   * @example\n   * await program.parseAsync(process.argv);\n   * await program.parseAsync(); // implicitly use process.argv and auto-detect node vs electron conventions\n   * await program.parseAsync(my-args, { from: 'user' }); // just user supplied arguments, nothing special about argv[0]\n   *\n   * @param {string[]} [argv]\n   * @param {Object} [parseOptions]\n   * @param {string} parseOptions.from - where the args are from: 'node', 'user', 'electron'\n   * @return {Promise}\n   */\n\n\n  async parseAsync(argv, parseOptions) {\n    const userArgs = this._prepareUserArgs(argv, parseOptions);\n\n    await this._parseCommand([], userArgs);\n    return this;\n  }\n  /**\n   * Execute a sub-command executable.\n   *\n   * @api private\n   */\n\n\n  _executeSubCommand(subcommand, args) {\n    args = args.slice();\n    let launchWithNode = false; // Use node for source targets so do not need to get permissions correct, and on Windows.\n\n    const sourceExt = ['.js', '.ts', '.tsx', '.mjs', '.cjs'];\n\n    function findFile(baseDir, baseName) {\n      // Look for specified file\n      const localBin = path.resolve(baseDir, baseName);\n      if (fs.existsSync(localBin)) return localBin; // Stop looking if candidate already has an expected extension.\n\n      if (sourceExt.includes(path.extname(baseName))) return undefined; // Try all the extensions.\n\n      const foundExt = sourceExt.find(ext => fs.existsSync(`${localBin}${ext}`));\n      if (foundExt) return `${localBin}${foundExt}`;\n      return undefined;\n    } // Not checking for help first. Unlikely to have mandatory and executable, and can't robustly test for help flags in external command.\n\n\n    this._checkForMissingMandatoryOptions();\n\n    this._checkForConflictingOptions(); // executableFile and executableDir might be full path, or just a name\n\n\n    let executableFile = subcommand._executableFile || `${this._name}-${subcommand._name}`;\n    let executableDir = this._executableDir || '';\n\n    if (this._scriptPath) {\n      let resolvedScriptPath; // resolve possible symlink for installed npm binary\n\n      try {\n        resolvedScriptPath = fs.realpathSync(this._scriptPath);\n      } catch (err) {\n        resolvedScriptPath = this._scriptPath;\n      }\n\n      executableDir = path.resolve(path.dirname(resolvedScriptPath), executableDir);\n    } // Look for a local file in preference to a command in PATH.\n\n\n    if (executableDir) {\n      let localFile = findFile(executableDir, executableFile); // Legacy search using prefix of script name instead of command name\n\n      if (!localFile && !subcommand._executableFile && this._scriptPath) {\n        const legacyName = path.basename(this._scriptPath, path.extname(this._scriptPath));\n\n        if (legacyName !== this._name) {\n          localFile = findFile(executableDir, `${legacyName}-${subcommand._name}`);\n        }\n      }\n\n      executableFile = localFile || executableFile;\n    }\n\n    launchWithNode = sourceExt.includes(path.extname(executableFile));\n    let proc;\n\n    if (process.platform !== 'win32') {\n      if (launchWithNode) {\n        args.unshift(executableFile); // add executable arguments to spawn\n\n        args = incrementNodeInspectorPort(process.execArgv).concat(args);\n        proc = childProcess.spawn(process.argv[0], args, {\n          stdio: 'inherit'\n        });\n      } else {\n        proc = childProcess.spawn(executableFile, args, {\n          stdio: 'inherit'\n        });\n      }\n    } else {\n      args.unshift(executableFile); // add executable arguments to spawn\n\n      args = incrementNodeInspectorPort(process.execArgv).concat(args);\n      proc = childProcess.spawn(process.execPath, args, {\n        stdio: 'inherit'\n      });\n    }\n\n    if (!proc.killed) {\n      // testing mainly to avoid leak warnings during unit tests with mocked spawn\n      const signals = ['SIGUSR1', 'SIGUSR2', 'SIGTERM', 'SIGINT', 'SIGHUP'];\n      signals.forEach(signal => {\n        // @ts-ignore\n        process.on(signal, () => {\n          if (proc.killed === false && proc.exitCode === null) {\n            proc.kill(signal);\n          }\n        });\n      });\n    } // By default terminate process when spawned process terminates.\n    // Suppressing the exit if exitCallback defined is a bit messy and of limited use, but does allow process to stay running!\n\n\n    const exitCallback = this._exitCallback;\n\n    if (!exitCallback) {\n      proc.on('close', process.exit.bind(process));\n    } else {\n      proc.on('close', () => {\n        exitCallback(new CommanderError(process.exitCode || 0, 'commander.executeSubCommandAsync', '(close)'));\n      });\n    }\n\n    proc.on('error', err => {\n      // @ts-ignore\n      if (err.code === 'ENOENT') {\n        const executableDirMessage = executableDir ? `searched for local subcommand relative to directory '${executableDir}'` : 'no directory for search for local subcommand, use .executableDir() to supply a custom directory';\n        const executableMissing = `'${executableFile}' does not exist\n - if '${subcommand._name}' is not meant to be an executable command, remove description parameter from '.command()' and use '.description()' instead\n - if the default executable name is not suitable, use the executableFile option to supply a custom name or path\n - ${executableDirMessage}`;\n        throw new Error(executableMissing); // @ts-ignore\n      } else if (err.code === 'EACCES') {\n        throw new Error(`'${executableFile}' not executable`);\n      }\n\n      if (!exitCallback) {\n        process.exit(1);\n      } else {\n        const wrappedError = new CommanderError(1, 'commander.executeSubCommandAsync', '(error)');\n        wrappedError.nestedError = err;\n        exitCallback(wrappedError);\n      }\n    }); // Store the reference to the child process\n\n    this.runningCommand = proc;\n  }\n  /**\n   * @api private\n   */\n\n\n  _dispatchSubcommand(commandName, operands, unknown) {\n    const subCommand = this._findCommand(commandName);\n\n    if (!subCommand) this.help({\n      error: true\n    });\n\n    if (subCommand._executableHandler) {\n      this._executeSubCommand(subCommand, operands.concat(unknown));\n    } else {\n      return subCommand._parseCommand(operands, unknown);\n    }\n  }\n  /**\n   * Check this.args against expected this._args.\n   *\n   * @api private\n   */\n\n\n  _checkNumberOfArguments() {\n    // too few\n    this._args.forEach((arg, i) => {\n      if (arg.required && this.args[i] == null) {\n        this.missingArgument(arg.name());\n      }\n    }); // too many\n\n\n    if (this._args.length > 0 && this._args[this._args.length - 1].variadic) {\n      return;\n    }\n\n    if (this.args.length > this._args.length) {\n      this._excessArguments(this.args);\n    }\n  }\n  /**\n   * Process this.args using this._args and save as this.processedArgs!\n   *\n   * @api private\n   */\n\n\n  _processArguments() {\n    const myParseArg = (argument, value, previous) => {\n      // Extra processing for nice error message on parsing failure.\n      let parsedValue = value;\n\n      if (value !== null && argument.parseArg) {\n        try {\n          parsedValue = argument.parseArg(value, previous);\n        } catch (err) {\n          if (err.code === 'commander.invalidArgument') {\n            const message = `error: command-argument value '${value}' is invalid for argument '${argument.name()}'. ${err.message}`;\n            this.error(message, {\n              exitCode: err.exitCode,\n              code: err.code\n            });\n          }\n\n          throw err;\n        }\n      }\n\n      return parsedValue;\n    };\n\n    this._checkNumberOfArguments();\n\n    const processedArgs = [];\n\n    this._args.forEach((declaredArg, index) => {\n      let value = declaredArg.defaultValue;\n\n      if (declaredArg.variadic) {\n        // Collect together remaining arguments for passing together as an array.\n        if (index < this.args.length) {\n          value = this.args.slice(index);\n\n          if (declaredArg.parseArg) {\n            value = value.reduce((processed, v) => {\n              return myParseArg(declaredArg, v, processed);\n            }, declaredArg.defaultValue);\n          }\n        } else if (value === undefined) {\n          value = [];\n        }\n      } else if (index < this.args.length) {\n        value = this.args[index];\n\n        if (declaredArg.parseArg) {\n          value = myParseArg(declaredArg, value, declaredArg.defaultValue);\n        }\n      }\n\n      processedArgs[index] = value;\n    });\n\n    this.processedArgs = processedArgs;\n  }\n  /**\n   * Once we have a promise we chain, but call synchronously until then.\n   *\n   * @param {Promise|undefined} promise\n   * @param {Function} fn\n   * @return {Promise|undefined}\n   * @api private\n   */\n\n\n  _chainOrCall(promise, fn) {\n    // thenable\n    if (promise && promise.then && typeof promise.then === 'function') {\n      // already have a promise, chain callback\n      return promise.then(() => fn());\n    } // callback might return a promise\n\n\n    return fn();\n  }\n  /**\n   *\n   * @param {Promise|undefined} promise\n   * @param {string} event\n   * @return {Promise|undefined}\n   * @api private\n   */\n\n\n  _chainOrCallHooks(promise, event) {\n    let result = promise;\n    const hooks = [];\n    getCommandAndParents(this).reverse().filter(cmd => cmd._lifeCycleHooks[event] !== undefined).forEach(hookedCommand => {\n      hookedCommand._lifeCycleHooks[event].forEach(callback => {\n        hooks.push({\n          hookedCommand,\n          callback\n        });\n      });\n    });\n\n    if (event === 'postAction') {\n      hooks.reverse();\n    }\n\n    hooks.forEach(hookDetail => {\n      result = this._chainOrCall(result, () => {\n        return hookDetail.callback(hookDetail.hookedCommand, this);\n      });\n    });\n    return result;\n  }\n  /**\n   * Process arguments in context of this command.\n   * Returns action result, in case it is a promise.\n   *\n   * @api private\n   */\n\n\n  _parseCommand(operands, unknown) {\n    const parsed = this.parseOptions(unknown);\n\n    this._parseOptionsEnv(); // after cli, so parseArg not called on both cli and env\n\n\n    this._parseOptionsImplied();\n\n    operands = operands.concat(parsed.operands);\n    unknown = parsed.unknown;\n    this.args = operands.concat(unknown);\n\n    if (operands && this._findCommand(operands[0])) {\n      return this._dispatchSubcommand(operands[0], operands.slice(1), unknown);\n    }\n\n    if (this._hasImplicitHelpCommand() && operands[0] === this._helpCommandName) {\n      if (operands.length === 1) {\n        this.help();\n      }\n\n      return this._dispatchSubcommand(operands[1], [], [this._helpLongFlag]);\n    }\n\n    if (this._defaultCommandName) {\n      outputHelpIfRequested(this, unknown); // Run the help for default command from parent rather than passing to default command\n\n      return this._dispatchSubcommand(this._defaultCommandName, operands, unknown);\n    }\n\n    if (this.commands.length && this.args.length === 0 && !this._actionHandler && !this._defaultCommandName) {\n      // probably missing subcommand and no handler, user needs help (and exit)\n      this.help({\n        error: true\n      });\n    }\n\n    outputHelpIfRequested(this, parsed.unknown);\n\n    this._checkForMissingMandatoryOptions();\n\n    this._checkForConflictingOptions(); // We do not always call this check to avoid masking a \"better\" error, like unknown command.\n\n\n    const checkForUnknownOptions = () => {\n      if (parsed.unknown.length > 0) {\n        this.unknownOption(parsed.unknown[0]);\n      }\n    };\n\n    const commandEvent = `command:${this.name()}`;\n\n    if (this._actionHandler) {\n      checkForUnknownOptions();\n\n      this._processArguments();\n\n      let actionResult;\n      actionResult = this._chainOrCallHooks(actionResult, 'preAction');\n      actionResult = this._chainOrCall(actionResult, () => this._actionHandler(this.processedArgs));\n\n      if (this.parent) {\n        actionResult = this._chainOrCall(actionResult, () => {\n          this.parent.emit(commandEvent, operands, unknown); // legacy\n        });\n      }\n\n      actionResult = this._chainOrCallHooks(actionResult, 'postAction');\n      return actionResult;\n    }\n\n    if (this.parent && this.parent.listenerCount(commandEvent)) {\n      checkForUnknownOptions();\n\n      this._processArguments();\n\n      this.parent.emit(commandEvent, operands, unknown); // legacy\n    } else if (operands.length) {\n      if (this._findCommand('*')) {\n        // legacy default command\n        return this._dispatchSubcommand('*', operands, unknown);\n      }\n\n      if (this.listenerCount('command:*')) {\n        // skip option check, emit event for possible misspelling suggestion\n        this.emit('command:*', operands, unknown);\n      } else if (this.commands.length) {\n        this.unknownCommand();\n      } else {\n        checkForUnknownOptions();\n\n        this._processArguments();\n      }\n    } else if (this.commands.length) {\n      checkForUnknownOptions(); // This command has subcommands and nothing hooked up at this level, so display help (and exit).\n\n      this.help({\n        error: true\n      });\n    } else {\n      checkForUnknownOptions();\n\n      this._processArguments(); // fall through for caller to handle after calling .parse()\n\n    }\n  }\n  /**\n   * Find matching command.\n   *\n   * @api private\n   */\n\n\n  _findCommand(name) {\n    if (!name) return undefined;\n    return this.commands.find(cmd => cmd._name === name || cmd._aliases.includes(name));\n  }\n  /**\n   * Return an option matching `arg` if any.\n   *\n   * @param {string} arg\n   * @return {Option}\n   * @api private\n   */\n\n\n  _findOption(arg) {\n    return this.options.find(option => option.is(arg));\n  }\n  /**\n   * Display an error message if a mandatory option does not have a value.\n   * Called after checking for help flags in leaf subcommand.\n   *\n   * @api private\n   */\n\n\n  _checkForMissingMandatoryOptions() {\n    // Walk up hierarchy so can call in subcommand after checking for displaying help.\n    for (let cmd = this; cmd; cmd = cmd.parent) {\n      cmd.options.forEach(anOption => {\n        if (anOption.mandatory && cmd.getOptionValue(anOption.attributeName()) === undefined) {\n          cmd.missingMandatoryOptionValue(anOption);\n        }\n      });\n    }\n  }\n  /**\n   * Display an error message if conflicting options are used together in this.\n   *\n   * @api private\n   */\n\n\n  _checkForConflictingLocalOptions() {\n    const definedNonDefaultOptions = this.options.filter(option => {\n      const optionKey = option.attributeName();\n\n      if (this.getOptionValue(optionKey) === undefined) {\n        return false;\n      }\n\n      return this.getOptionValueSource(optionKey) !== 'default';\n    });\n    const optionsWithConflicting = definedNonDefaultOptions.filter(option => option.conflictsWith.length > 0);\n    optionsWithConflicting.forEach(option => {\n      const conflictingAndDefined = definedNonDefaultOptions.find(defined => option.conflictsWith.includes(defined.attributeName()));\n\n      if (conflictingAndDefined) {\n        this._conflictingOption(option, conflictingAndDefined);\n      }\n    });\n  }\n  /**\n   * Display an error message if conflicting options are used together.\n   * Called after checking for help flags in leaf subcommand.\n   *\n   * @api private\n   */\n\n\n  _checkForConflictingOptions() {\n    // Walk up hierarchy so can call in subcommand after checking for displaying help.\n    for (let cmd = this; cmd; cmd = cmd.parent) {\n      cmd._checkForConflictingLocalOptions();\n    }\n  }\n  /**\n   * Parse options from `argv` removing known options,\n   * and return argv split into operands and unknown arguments.\n   *\n   * Examples:\n   *\n   *     argv => operands, unknown\n   *     --known kkk op => [op], []\n   *     op --known kkk => [op], []\n   *     sub --unknown uuu op => [sub], [--unknown uuu op]\n   *     sub -- --unknown uuu op => [sub --unknown uuu op], []\n   *\n   * @param {String[]} argv\n   * @return {{operands: String[], unknown: String[]}}\n   */\n\n\n  parseOptions(argv) {\n    const operands = []; // operands, not options or values\n\n    const unknown = []; // first unknown option and remaining unknown args\n\n    let dest = operands;\n    const args = argv.slice();\n\n    function maybeOption(arg) {\n      return arg.length > 1 && arg[0] === '-';\n    } // parse options\n\n\n    let activeVariadicOption = null;\n\n    while (args.length) {\n      const arg = args.shift(); // literal\n\n      if (arg === '--') {\n        if (dest === unknown) dest.push(arg);\n        dest.push(...args);\n        break;\n      }\n\n      if (activeVariadicOption && !maybeOption(arg)) {\n        this.emit(`option:${activeVariadicOption.name()}`, arg);\n        continue;\n      }\n\n      activeVariadicOption = null;\n\n      if (maybeOption(arg)) {\n        const option = this._findOption(arg); // recognised option, call listener to assign value with possible custom processing\n\n\n        if (option) {\n          if (option.required) {\n            const value = args.shift();\n            if (value === undefined) this.optionMissingArgument(option);\n            this.emit(`option:${option.name()}`, value);\n          } else if (option.optional) {\n            let value = null; // historical behaviour is optional value is following arg unless an option\n\n            if (args.length > 0 && !maybeOption(args[0])) {\n              value = args.shift();\n            }\n\n            this.emit(`option:${option.name()}`, value);\n          } else {\n            // boolean flag\n            this.emit(`option:${option.name()}`);\n          }\n\n          activeVariadicOption = option.variadic ? option : null;\n          continue;\n        }\n      } // Look for combo options following single dash, eat first one if known.\n\n\n      if (arg.length > 2 && arg[0] === '-' && arg[1] !== '-') {\n        const option = this._findOption(`-${arg[1]}`);\n\n        if (option) {\n          if (option.required || option.optional && this._combineFlagAndOptionalValue) {\n            // option with value following in same argument\n            this.emit(`option:${option.name()}`, arg.slice(2));\n          } else {\n            // boolean option, emit and put back remainder of arg for further processing\n            this.emit(`option:${option.name()}`);\n            args.unshift(`-${arg.slice(2)}`);\n          }\n\n          continue;\n        }\n      } // Look for known long flag with value, like --foo=bar\n\n\n      if (/^--[^=]+=/.test(arg)) {\n        const index = arg.indexOf('=');\n\n        const option = this._findOption(arg.slice(0, index));\n\n        if (option && (option.required || option.optional)) {\n          this.emit(`option:${option.name()}`, arg.slice(index + 1));\n          continue;\n        }\n      } // Not a recognised option by this command.\n      // Might be a command-argument, or subcommand option, or unknown option, or help command or option.\n      // An unknown option means further arguments also classified as unknown so can be reprocessed by subcommands.\n\n\n      if (maybeOption(arg)) {\n        dest = unknown;\n      } // If using positionalOptions, stop processing our options at subcommand.\n\n\n      if ((this._enablePositionalOptions || this._passThroughOptions) && operands.length === 0 && unknown.length === 0) {\n        if (this._findCommand(arg)) {\n          operands.push(arg);\n          if (args.length > 0) unknown.push(...args);\n          break;\n        } else if (arg === this._helpCommandName && this._hasImplicitHelpCommand()) {\n          operands.push(arg);\n          if (args.length > 0) operands.push(...args);\n          break;\n        } else if (this._defaultCommandName) {\n          unknown.push(arg);\n          if (args.length > 0) unknown.push(...args);\n          break;\n        }\n      } // If using passThroughOptions, stop processing options at first command-argument.\n\n\n      if (this._passThroughOptions) {\n        dest.push(arg);\n        if (args.length > 0) dest.push(...args);\n        break;\n      } // add arg\n\n\n      dest.push(arg);\n    }\n\n    return {\n      operands,\n      unknown\n    };\n  }\n  /**\n   * Return an object containing local option values as key-value pairs.\n   *\n   * @return {Object}\n   */\n\n\n  opts() {\n    if (this._storeOptionsAsProperties) {\n      // Preserve original behaviour so backwards compatible when still using properties\n      const result = {};\n      const len = this.options.length;\n\n      for (let i = 0; i < len; i++) {\n        const key = this.options[i].attributeName();\n        result[key] = key === this._versionOptionName ? this._version : this[key];\n      }\n\n      return result;\n    }\n\n    return this._optionValues;\n  }\n  /**\n   * Return an object containing merged local and global option values as key-value pairs.\n   *\n   * @return {Object}\n   */\n\n\n  optsWithGlobals() {\n    // globals overwrite locals\n    return getCommandAndParents(this).reduce((combinedOptions, cmd) => Object.assign(combinedOptions, cmd.opts()), {});\n  }\n  /**\n   * Display error message and exit (or call exitOverride).\n   *\n   * @param {string} message\n   * @param {Object} [errorOptions]\n   * @param {string} [errorOptions.code] - an id string representing the error\n   * @param {number} [errorOptions.exitCode] - used with process.exit\n   */\n\n\n  error(message, errorOptions) {\n    // output handling\n    this._outputConfiguration.outputError(`${message}\\n`, this._outputConfiguration.writeErr);\n\n    if (typeof this._showHelpAfterError === 'string') {\n      this._outputConfiguration.writeErr(`${this._showHelpAfterError}\\n`);\n    } else if (this._showHelpAfterError) {\n      this._outputConfiguration.writeErr('\\n');\n\n      this.outputHelp({\n        error: true\n      });\n    } // exit handling\n\n\n    const config = errorOptions || {};\n    const exitCode = config.exitCode || 1;\n    const code = config.code || 'commander.error';\n\n    this._exit(exitCode, code, message);\n  }\n  /**\n   * Apply any option related environment variables, if option does\n   * not have a value from cli or client code.\n   *\n   * @api private\n   */\n\n\n  _parseOptionsEnv() {\n    this.options.forEach(option => {\n      if (option.envVar && option.envVar in process.env) {\n        const optionKey = option.attributeName(); // Priority check. Do not overwrite cli or options from unknown source (client-code).\n\n        if (this.getOptionValue(optionKey) === undefined || ['default', 'config', 'env'].includes(this.getOptionValueSource(optionKey))) {\n          if (option.required || option.optional) {\n            // option can take a value\n            // keep very simple, optional always takes value\n            this.emit(`optionEnv:${option.name()}`, process.env[option.envVar]);\n          } else {\n            // boolean\n            // keep very simple, only care that envVar defined and not the value\n            this.emit(`optionEnv:${option.name()}`);\n          }\n        }\n      }\n    });\n  }\n  /**\n   * Apply any implied option values, if option is undefined or default value.\n   *\n   * @api private\n   */\n\n\n  _parseOptionsImplied() {\n    const dualHelper = new DualOptions(this.options);\n\n    const hasCustomOptionValue = optionKey => {\n      return this.getOptionValue(optionKey) !== undefined && !['default', 'implied'].includes(this.getOptionValueSource(optionKey));\n    };\n\n    this.options.filter(option => option.implied !== undefined && hasCustomOptionValue(option.attributeName()) && dualHelper.valueFromOption(this.getOptionValue(option.attributeName()), option)).forEach(option => {\n      Object.keys(option.implied).filter(impliedKey => !hasCustomOptionValue(impliedKey)).forEach(impliedKey => {\n        this.setOptionValueWithSource(impliedKey, option.implied[impliedKey], 'implied');\n      });\n    });\n  }\n  /**\n   * Argument `name` is missing.\n   *\n   * @param {string} name\n   * @api private\n   */\n\n\n  missingArgument(name) {\n    const message = `error: missing required argument '${name}'`;\n    this.error(message, {\n      code: 'commander.missingArgument'\n    });\n  }\n  /**\n   * `Option` is missing an argument.\n   *\n   * @param {Option} option\n   * @api private\n   */\n\n\n  optionMissingArgument(option) {\n    const message = `error: option '${option.flags}' argument missing`;\n    this.error(message, {\n      code: 'commander.optionMissingArgument'\n    });\n  }\n  /**\n   * `Option` does not have a value, and is a mandatory option.\n   *\n   * @param {Option} option\n   * @api private\n   */\n\n\n  missingMandatoryOptionValue(option) {\n    const message = `error: required option '${option.flags}' not specified`;\n    this.error(message, {\n      code: 'commander.missingMandatoryOptionValue'\n    });\n  }\n  /**\n   * `Option` conflicts with another option.\n   *\n   * @param {Option} option\n   * @param {Option} conflictingOption\n   * @api private\n   */\n\n\n  _conflictingOption(option, conflictingOption) {\n    // The calling code does not know whether a negated option is the source of the\n    // value, so do some work to take an educated guess.\n    const findBestOptionFromValue = option => {\n      const optionKey = option.attributeName();\n      const optionValue = this.getOptionValue(optionKey);\n      const negativeOption = this.options.find(target => target.negate && optionKey === target.attributeName());\n      const positiveOption = this.options.find(target => !target.negate && optionKey === target.attributeName());\n\n      if (negativeOption && (negativeOption.presetArg === undefined && optionValue === false || negativeOption.presetArg !== undefined && optionValue === negativeOption.presetArg)) {\n        return negativeOption;\n      }\n\n      return positiveOption || option;\n    };\n\n    const getErrorMessage = option => {\n      const bestOption = findBestOptionFromValue(option);\n      const optionKey = bestOption.attributeName();\n      const source = this.getOptionValueSource(optionKey);\n\n      if (source === 'env') {\n        return `environment variable '${bestOption.envVar}'`;\n      }\n\n      return `option '${bestOption.flags}'`;\n    };\n\n    const message = `error: ${getErrorMessage(option)} cannot be used with ${getErrorMessage(conflictingOption)}`;\n    this.error(message, {\n      code: 'commander.conflictingOption'\n    });\n  }\n  /**\n   * Unknown option `flag`.\n   *\n   * @param {string} flag\n   * @api private\n   */\n\n\n  unknownOption(flag) {\n    if (this._allowUnknownOption) return;\n    let suggestion = '';\n\n    if (flag.startsWith('--') && this._showSuggestionAfterError) {\n      // Looping to pick up the global options too\n      let candidateFlags = [];\n      let command = this;\n\n      do {\n        const moreFlags = command.createHelp().visibleOptions(command).filter(option => option.long).map(option => option.long);\n        candidateFlags = candidateFlags.concat(moreFlags);\n        command = command.parent;\n      } while (command && !command._enablePositionalOptions);\n\n      suggestion = suggestSimilar(flag, candidateFlags);\n    }\n\n    const message = `error: unknown option '${flag}'${suggestion}`;\n    this.error(message, {\n      code: 'commander.unknownOption'\n    });\n  }\n  /**\n   * Excess arguments, more than expected.\n   *\n   * @param {string[]} receivedArgs\n   * @api private\n   */\n\n\n  _excessArguments(receivedArgs) {\n    if (this._allowExcessArguments) return;\n    const expected = this._args.length;\n    const s = expected === 1 ? '' : 's';\n    const forSubcommand = this.parent ? ` for '${this.name()}'` : '';\n    const message = `error: too many arguments${forSubcommand}. Expected ${expected} argument${s} but got ${receivedArgs.length}.`;\n    this.error(message, {\n      code: 'commander.excessArguments'\n    });\n  }\n  /**\n   * Unknown command.\n   *\n   * @api private\n   */\n\n\n  unknownCommand() {\n    const unknownName = this.args[0];\n    let suggestion = '';\n\n    if (this._showSuggestionAfterError) {\n      const candidateNames = [];\n      this.createHelp().visibleCommands(this).forEach(command => {\n        candidateNames.push(command.name()); // just visible alias\n\n        if (command.alias()) candidateNames.push(command.alias());\n      });\n      suggestion = suggestSimilar(unknownName, candidateNames);\n    }\n\n    const message = `error: unknown command '${unknownName}'${suggestion}`;\n    this.error(message, {\n      code: 'commander.unknownCommand'\n    });\n  }\n  /**\n   * Set the program version to `str`.\n   *\n   * This method auto-registers the \"-V, --version\" flag\n   * which will print the version number when passed.\n   *\n   * You can optionally supply the  flags and description to override the defaults.\n   *\n   * @param {string} str\n   * @param {string} [flags]\n   * @param {string} [description]\n   * @return {this | string} `this` command for chaining, or version string if no arguments\n   */\n\n\n  version(str, flags, description) {\n    if (str === undefined) return this._version;\n    this._version = str;\n    flags = flags || '-V, --version';\n    description = description || 'output the version number';\n    const versionOption = this.createOption(flags, description);\n    this._versionOptionName = versionOption.attributeName();\n    this.options.push(versionOption);\n    this.on('option:' + versionOption.name(), () => {\n      this._outputConfiguration.writeOut(`${str}\\n`);\n\n      this._exit(0, 'commander.version', str);\n    });\n    return this;\n  }\n  /**\n   * Set the description.\n   *\n   * @param {string} [str]\n   * @param {Object} [argsDescription]\n   * @return {string|Command}\n   */\n\n\n  description(str, argsDescription) {\n    if (str === undefined && argsDescription === undefined) return this._description;\n    this._description = str;\n\n    if (argsDescription) {\n      this._argsDescription = argsDescription;\n    }\n\n    return this;\n  }\n  /**\n   * Set the summary. Used when listed as subcommand of parent.\n   *\n   * @param {string} [str]\n   * @return {string|Command}\n   */\n\n\n  summary(str) {\n    if (str === undefined) return this._summary;\n    this._summary = str;\n    return this;\n  }\n  /**\n   * Set an alias for the command.\n   *\n   * You may call more than once to add multiple aliases. Only the first alias is shown in the auto-generated help.\n   *\n   * @param {string} [alias]\n   * @return {string|Command}\n   */\n\n\n  alias(alias) {\n    if (alias === undefined) return this._aliases[0]; // just return first, for backwards compatibility\n\n    /** @type {Command} */\n\n    let command = this;\n\n    if (this.commands.length !== 0 && this.commands[this.commands.length - 1]._executableHandler) {\n      // assume adding alias for last added executable subcommand, rather than this\n      command = this.commands[this.commands.length - 1];\n    }\n\n    if (alias === command._name) throw new Error('Command alias can\\'t be the same as its name');\n\n    command._aliases.push(alias);\n\n    return this;\n  }\n  /**\n   * Set aliases for the command.\n   *\n   * Only the first alias is shown in the auto-generated help.\n   *\n   * @param {string[]} [aliases]\n   * @return {string[]|Command}\n   */\n\n\n  aliases(aliases) {\n    // Getter for the array of aliases is the main reason for having aliases() in addition to alias().\n    if (aliases === undefined) return this._aliases;\n    aliases.forEach(alias => this.alias(alias));\n    return this;\n  }\n  /**\n   * Set / get the command usage `str`.\n   *\n   * @param {string} [str]\n   * @return {String|Command}\n   */\n\n\n  usage(str) {\n    if (str === undefined) {\n      if (this._usage) return this._usage;\n\n      const args = this._args.map(arg => {\n        return humanReadableArgName(arg);\n      });\n\n      return [].concat(this.options.length || this._hasHelpOption ? '[options]' : [], this.commands.length ? '[command]' : [], this._args.length ? args : []).join(' ');\n    }\n\n    this._usage = str;\n    return this;\n  }\n  /**\n   * Get or set the name of the command.\n   *\n   * @param {string} [str]\n   * @return {string|Command}\n   */\n\n\n  name(str) {\n    if (str === undefined) return this._name;\n    this._name = str;\n    return this;\n  }\n  /**\n   * Set the name of the command from script filename, such as process.argv[1],\n   * or require.main.filename, or __filename.\n   *\n   * (Used internally and public although not documented in README.)\n   *\n   * @example\n   * program.nameFromFilename(require.main.filename);\n   *\n   * @param {string} filename\n   * @return {Command}\n   */\n\n\n  nameFromFilename(filename) {\n    this._name = path.basename(filename, path.extname(filename));\n    return this;\n  }\n  /**\n   * Get or set the directory for searching for executable subcommands of this command.\n   *\n   * @example\n   * program.executableDir(__dirname);\n   * // or\n   * program.executableDir('subcommands');\n   *\n   * @param {string} [path]\n   * @return {string|Command}\n   */\n\n\n  executableDir(path) {\n    if (path === undefined) return this._executableDir;\n    this._executableDir = path;\n    return this;\n  }\n  /**\n   * Return program help documentation.\n   *\n   * @param {{ error: boolean }} [contextOptions] - pass {error:true} to wrap for stderr instead of stdout\n   * @return {string}\n   */\n\n\n  helpInformation(contextOptions) {\n    const helper = this.createHelp();\n\n    if (helper.helpWidth === undefined) {\n      helper.helpWidth = contextOptions && contextOptions.error ? this._outputConfiguration.getErrHelpWidth() : this._outputConfiguration.getOutHelpWidth();\n    }\n\n    return helper.formatHelp(this, helper);\n  }\n  /**\n   * @api private\n   */\n\n\n  _getHelpContext(contextOptions) {\n    contextOptions = contextOptions || {};\n    const context = {\n      error: !!contextOptions.error\n    };\n    let write;\n\n    if (context.error) {\n      write = arg => this._outputConfiguration.writeErr(arg);\n    } else {\n      write = arg => this._outputConfiguration.writeOut(arg);\n    }\n\n    context.write = contextOptions.write || write;\n    context.command = this;\n    return context;\n  }\n  /**\n   * Output help information for this command.\n   *\n   * Outputs built-in help, and custom text added using `.addHelpText()`.\n   *\n   * @param {{ error: boolean } | Function} [contextOptions] - pass {error:true} to write to stderr instead of stdout\n   */\n\n\n  outputHelp(contextOptions) {\n    let deprecatedCallback;\n\n    if (typeof contextOptions === 'function') {\n      deprecatedCallback = contextOptions;\n      contextOptions = undefined;\n    }\n\n    const context = this._getHelpContext(contextOptions);\n\n    getCommandAndParents(this).reverse().forEach(command => command.emit('beforeAllHelp', context));\n    this.emit('beforeHelp', context);\n    let helpInformation = this.helpInformation(context);\n\n    if (deprecatedCallback) {\n      helpInformation = deprecatedCallback(helpInformation);\n\n      if (typeof helpInformation !== 'string' && !Buffer.isBuffer(helpInformation)) {\n        throw new Error('outputHelp callback must return a string or a Buffer');\n      }\n    }\n\n    context.write(helpInformation);\n    this.emit(this._helpLongFlag); // deprecated\n\n    this.emit('afterHelp', context);\n    getCommandAndParents(this).forEach(command => command.emit('afterAllHelp', context));\n  }\n  /**\n   * You can pass in flags and a description to override the help\n   * flags and help description for your command. Pass in false to\n   * disable the built-in help option.\n   *\n   * @param {string | boolean} [flags]\n   * @param {string} [description]\n   * @return {Command} `this` command for chaining\n   */\n\n\n  helpOption(flags, description) {\n    if (typeof flags === 'boolean') {\n      this._hasHelpOption = flags;\n      return this;\n    }\n\n    this._helpFlags = flags || this._helpFlags;\n    this._helpDescription = description || this._helpDescription;\n    const helpFlags = splitOptionFlags(this._helpFlags);\n    this._helpShortFlag = helpFlags.shortFlag;\n    this._helpLongFlag = helpFlags.longFlag;\n    return this;\n  }\n  /**\n   * Output help information and exit.\n   *\n   * Outputs built-in help, and custom text added using `.addHelpText()`.\n   *\n   * @param {{ error: boolean }} [contextOptions] - pass {error:true} to write to stderr instead of stdout\n   */\n\n\n  help(contextOptions) {\n    this.outputHelp(contextOptions);\n    let exitCode = process.exitCode || 0;\n\n    if (exitCode === 0 && contextOptions && typeof contextOptions !== 'function' && contextOptions.error) {\n      exitCode = 1;\n    } // message: do not have all displayed text available so only passing placeholder.\n\n\n    this._exit(exitCode, 'commander.help', '(outputHelp)');\n  }\n  /**\n   * Add additional text to be displayed with the built-in help.\n   *\n   * Position is 'before' or 'after' to affect just this command,\n   * and 'beforeAll' or 'afterAll' to affect this command and all its subcommands.\n   *\n   * @param {string} position - before or after built-in help\n   * @param {string | Function} text - string to add, or a function returning a string\n   * @return {Command} `this` command for chaining\n   */\n\n\n  addHelpText(position, text) {\n    const allowedValues = ['beforeAll', 'before', 'after', 'afterAll'];\n\n    if (!allowedValues.includes(position)) {\n      throw new Error(`Unexpected value for position to addHelpText.\nExpecting one of '${allowedValues.join(\"', '\")}'`);\n    }\n\n    const helpEvent = `${position}Help`;\n    this.on(helpEvent, context => {\n      let helpStr;\n\n      if (typeof text === 'function') {\n        helpStr = text({\n          error: context.error,\n          command: context.command\n        });\n      } else {\n        helpStr = text;\n      } // Ignore falsy value when nothing to output.\n\n\n      if (helpStr) {\n        context.write(`${helpStr}\\n`);\n      }\n    });\n    return this;\n  }\n\n}\n/**\n * Output help information if help flags specified\n *\n * @param {Command} cmd - command to output help for\n * @param {Array} args - array of options to search for help flags\n * @api private\n */\n\n\nfunction outputHelpIfRequested(cmd, args) {\n  const helpOption = cmd._hasHelpOption && args.find(arg => arg === cmd._helpLongFlag || arg === cmd._helpShortFlag);\n\n  if (helpOption) {\n    cmd.outputHelp(); // (Do not have all displayed text available so only passing placeholder.)\n\n    cmd._exit(0, 'commander.helpDisplayed', '(outputHelp)');\n  }\n}\n/**\n * Scan arguments and increment port number for inspect calls (to avoid conflicts when spawning new command).\n *\n * @param {string[]} args - array of arguments from node.execArgv\n * @returns {string[]}\n * @api private\n */\n\n\nfunction incrementNodeInspectorPort(args) {\n  // Testing for these options:\n  //  --inspect[=[host:]port]\n  //  --inspect-brk[=[host:]port]\n  //  --inspect-port=[host:]port\n  return args.map(arg => {\n    if (!arg.startsWith('--inspect')) {\n      return arg;\n    }\n\n    let debugOption;\n    let debugHost = '127.0.0.1';\n    let debugPort = '9229';\n    let match;\n\n    if ((match = arg.match(/^(--inspect(-brk)?)$/)) !== null) {\n      // e.g. --inspect\n      debugOption = match[1];\n    } else if ((match = arg.match(/^(--inspect(-brk|-port)?)=([^:]+)$/)) !== null) {\n      debugOption = match[1];\n\n      if (/^\\d+$/.test(match[3])) {\n        // e.g. --inspect=1234\n        debugPort = match[3];\n      } else {\n        // e.g. --inspect=localhost\n        debugHost = match[3];\n      }\n    } else if ((match = arg.match(/^(--inspect(-brk|-port)?)=([^:]+):(\\d+)$/)) !== null) {\n      // e.g. --inspect=localhost:1234\n      debugOption = match[1];\n      debugHost = match[3];\n      debugPort = match[4];\n    }\n\n    if (debugOption && debugPort !== '0') {\n      return `${debugOption}=${debugHost}:${parseInt(debugPort) + 1}`;\n    }\n\n    return arg;\n  });\n}\n/**\n * @param {Command} startCommand\n * @returns {Command[]}\n * @api private\n */\n\n\nfunction getCommandAndParents(startCommand) {\n  const result = [];\n\n  for (let command = startCommand; command; command = command.parent) {\n    result.push(command);\n  }\n\n  return result;\n}\n\nexports.Command = Command;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/commander/lib/command.js?");

/***/ }),

/***/ "./node_modules/commander/lib/error.js":
/*!*********************************************!*\
  !*** ./node_modules/commander/lib/error.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports) => {

eval("// @ts-check\n\n/**\n * CommanderError class\n * @class\n */\nclass CommanderError extends Error {\n  /**\n   * Constructs the CommanderError class\n   * @param {number} exitCode suggested exit code which could be used with process.exit\n   * @param {string} code an id string representing the error\n   * @param {string} message human-readable description of the error\n   * @constructor\n   */\n  constructor(exitCode, code, message) {\n    super(message); // properly capture stack trace in Node.js\n\n    Error.captureStackTrace(this, this.constructor);\n    this.name = this.constructor.name;\n    this.code = code;\n    this.exitCode = exitCode;\n    this.nestedError = undefined;\n  }\n\n}\n/**\n * InvalidArgumentError class\n * @class\n */\n\n\nclass InvalidArgumentError extends CommanderError {\n  /**\n   * Constructs the InvalidArgumentError class\n   * @param {string} [message] explanation of why argument is invalid\n   * @constructor\n   */\n  constructor(message) {\n    super(1, 'commander.invalidArgument', message); // properly capture stack trace in Node.js\n\n    Error.captureStackTrace(this, this.constructor);\n    this.name = this.constructor.name;\n  }\n\n}\n\nexports.CommanderError = CommanderError;\nexports.InvalidArgumentError = InvalidArgumentError;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/commander/lib/error.js?");

/***/ }),

/***/ "./node_modules/commander/lib/help.js":
/*!********************************************!*\
  !*** ./node_modules/commander/lib/help.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const {\n  humanReadableArgName\n} = __webpack_require__(/*! ./argument.js */ \"./node_modules/commander/lib/argument.js\");\n/**\n * TypeScript import types for JSDoc, used by Visual Studio Code IntelliSense and `npm run typescript-checkJS`\n * https://www.typescriptlang.org/docs/handbook/jsdoc-supported-types.html#import-types\n * @typedef { import(\"./argument.js\").Argument } Argument\n * @typedef { import(\"./command.js\").Command } Command\n * @typedef { import(\"./option.js\").Option } Option\n */\n// @ts-check\n// Although this is a class, methods are static in style to allow override using subclass or just functions.\n\n\nclass Help {\n  constructor() {\n    this.helpWidth = undefined;\n    this.sortSubcommands = false;\n    this.sortOptions = false;\n  }\n  /**\n   * Get an array of the visible subcommands. Includes a placeholder for the implicit help command, if there is one.\n   *\n   * @param {Command} cmd\n   * @returns {Command[]}\n   */\n\n\n  visibleCommands(cmd) {\n    const visibleCommands = cmd.commands.filter(cmd => !cmd._hidden);\n\n    if (cmd._hasImplicitHelpCommand()) {\n      // Create a command matching the implicit help command.\n      const [, helpName, helpArgs] = cmd._helpCommandnameAndArgs.match(/([^ ]+) *(.*)/);\n\n      const helpCommand = cmd.createCommand(helpName).helpOption(false);\n      helpCommand.description(cmd._helpCommandDescription);\n      if (helpArgs) helpCommand.arguments(helpArgs);\n      visibleCommands.push(helpCommand);\n    }\n\n    if (this.sortSubcommands) {\n      visibleCommands.sort((a, b) => {\n        // @ts-ignore: overloaded return type\n        return a.name().localeCompare(b.name());\n      });\n    }\n\n    return visibleCommands;\n  }\n  /**\n   * Get an array of the visible options. Includes a placeholder for the implicit help option, if there is one.\n   *\n   * @param {Command} cmd\n   * @returns {Option[]}\n   */\n\n\n  visibleOptions(cmd) {\n    const visibleOptions = cmd.options.filter(option => !option.hidden); // Implicit help\n\n    const showShortHelpFlag = cmd._hasHelpOption && cmd._helpShortFlag && !cmd._findOption(cmd._helpShortFlag);\n    const showLongHelpFlag = cmd._hasHelpOption && !cmd._findOption(cmd._helpLongFlag);\n\n    if (showShortHelpFlag || showLongHelpFlag) {\n      let helpOption;\n\n      if (!showShortHelpFlag) {\n        helpOption = cmd.createOption(cmd._helpLongFlag, cmd._helpDescription);\n      } else if (!showLongHelpFlag) {\n        helpOption = cmd.createOption(cmd._helpShortFlag, cmd._helpDescription);\n      } else {\n        helpOption = cmd.createOption(cmd._helpFlags, cmd._helpDescription);\n      }\n\n      visibleOptions.push(helpOption);\n    }\n\n    if (this.sortOptions) {\n      const getSortKey = option => {\n        // WYSIWYG for order displayed in help with short before long, no special handling for negated.\n        return option.short ? option.short.replace(/^-/, '') : option.long.replace(/^--/, '');\n      };\n\n      visibleOptions.sort((a, b) => {\n        return getSortKey(a).localeCompare(getSortKey(b));\n      });\n    }\n\n    return visibleOptions;\n  }\n  /**\n   * Get an array of the arguments if any have a description.\n   *\n   * @param {Command} cmd\n   * @returns {Argument[]}\n   */\n\n\n  visibleArguments(cmd) {\n    // Side effect! Apply the legacy descriptions before the arguments are displayed.\n    if (cmd._argsDescription) {\n      cmd._args.forEach(argument => {\n        argument.description = argument.description || cmd._argsDescription[argument.name()] || '';\n      });\n    } // If there are any arguments with a description then return all the arguments.\n\n\n    if (cmd._args.find(argument => argument.description)) {\n      return cmd._args;\n    }\n\n    return [];\n  }\n  /**\n   * Get the command term to show in the list of subcommands.\n   *\n   * @param {Command} cmd\n   * @returns {string}\n   */\n\n\n  subcommandTerm(cmd) {\n    // Legacy. Ignores custom usage string, and nested commands.\n    const args = cmd._args.map(arg => humanReadableArgName(arg)).join(' ');\n\n    return cmd._name + (cmd._aliases[0] ? '|' + cmd._aliases[0] : '') + (cmd.options.length ? ' [options]' : '') + ( // simplistic check for non-help option\n    args ? ' ' + args : '');\n  }\n  /**\n   * Get the option term to show in the list of options.\n   *\n   * @param {Option} option\n   * @returns {string}\n   */\n\n\n  optionTerm(option) {\n    return option.flags;\n  }\n  /**\n   * Get the argument term to show in the list of arguments.\n   *\n   * @param {Argument} argument\n   * @returns {string}\n   */\n\n\n  argumentTerm(argument) {\n    return argument.name();\n  }\n  /**\n   * Get the longest command term length.\n   *\n   * @param {Command} cmd\n   * @param {Help} helper\n   * @returns {number}\n   */\n\n\n  longestSubcommandTermLength(cmd, helper) {\n    return helper.visibleCommands(cmd).reduce((max, command) => {\n      return Math.max(max, helper.subcommandTerm(command).length);\n    }, 0);\n  }\n  /**\n   * Get the longest option term length.\n   *\n   * @param {Command} cmd\n   * @param {Help} helper\n   * @returns {number}\n   */\n\n\n  longestOptionTermLength(cmd, helper) {\n    return helper.visibleOptions(cmd).reduce((max, option) => {\n      return Math.max(max, helper.optionTerm(option).length);\n    }, 0);\n  }\n  /**\n   * Get the longest argument term length.\n   *\n   * @param {Command} cmd\n   * @param {Help} helper\n   * @returns {number}\n   */\n\n\n  longestArgumentTermLength(cmd, helper) {\n    return helper.visibleArguments(cmd).reduce((max, argument) => {\n      return Math.max(max, helper.argumentTerm(argument).length);\n    }, 0);\n  }\n  /**\n   * Get the command usage to be displayed at the top of the built-in help.\n   *\n   * @param {Command} cmd\n   * @returns {string}\n   */\n\n\n  commandUsage(cmd) {\n    // Usage\n    let cmdName = cmd._name;\n\n    if (cmd._aliases[0]) {\n      cmdName = cmdName + '|' + cmd._aliases[0];\n    }\n\n    let parentCmdNames = '';\n\n    for (let parentCmd = cmd.parent; parentCmd; parentCmd = parentCmd.parent) {\n      parentCmdNames = parentCmd.name() + ' ' + parentCmdNames;\n    }\n\n    return parentCmdNames + cmdName + ' ' + cmd.usage();\n  }\n  /**\n   * Get the description for the command.\n   *\n   * @param {Command} cmd\n   * @returns {string}\n   */\n\n\n  commandDescription(cmd) {\n    // @ts-ignore: overloaded return type\n    return cmd.description();\n  }\n  /**\n   * Get the subcommand summary to show in the list of subcommands.\n   * (Fallback to description for backwards compatiblity.)\n   *\n   * @param {Command} cmd\n   * @returns {string}\n   */\n\n\n  subcommandDescription(cmd) {\n    // @ts-ignore: overloaded return type\n    return cmd.summary() || cmd.description();\n  }\n  /**\n   * Get the option description to show in the list of options.\n   *\n   * @param {Option} option\n   * @return {string}\n   */\n\n\n  optionDescription(option) {\n    const extraInfo = [];\n\n    if (option.argChoices) {\n      extraInfo.push( // use stringify to match the display of the default value\n      `choices: ${option.argChoices.map(choice => JSON.stringify(choice)).join(', ')}`);\n    }\n\n    if (option.defaultValue !== undefined) {\n      // default for boolean and negated more for programmer than end user,\n      // but show true/false for boolean option as may be for hand-rolled env or config processing.\n      const showDefault = option.required || option.optional || option.isBoolean() && typeof option.defaultValue === 'boolean';\n\n      if (showDefault) {\n        extraInfo.push(`default: ${option.defaultValueDescription || JSON.stringify(option.defaultValue)}`);\n      }\n    } // preset for boolean and negated are more for programmer than end user\n\n\n    if (option.presetArg !== undefined && option.optional) {\n      extraInfo.push(`preset: ${JSON.stringify(option.presetArg)}`);\n    }\n\n    if (option.envVar !== undefined) {\n      extraInfo.push(`env: ${option.envVar}`);\n    }\n\n    if (extraInfo.length > 0) {\n      return `${option.description} (${extraInfo.join(', ')})`;\n    }\n\n    return option.description;\n  }\n  /**\n   * Get the argument description to show in the list of arguments.\n   *\n   * @param {Argument} argument\n   * @return {string}\n   */\n\n\n  argumentDescription(argument) {\n    const extraInfo = [];\n\n    if (argument.argChoices) {\n      extraInfo.push( // use stringify to match the display of the default value\n      `choices: ${argument.argChoices.map(choice => JSON.stringify(choice)).join(', ')}`);\n    }\n\n    if (argument.defaultValue !== undefined) {\n      extraInfo.push(`default: ${argument.defaultValueDescription || JSON.stringify(argument.defaultValue)}`);\n    }\n\n    if (extraInfo.length > 0) {\n      const extraDescripton = `(${extraInfo.join(', ')})`;\n\n      if (argument.description) {\n        return `${argument.description} ${extraDescripton}`;\n      }\n\n      return extraDescripton;\n    }\n\n    return argument.description;\n  }\n  /**\n   * Generate the built-in help text.\n   *\n   * @param {Command} cmd\n   * @param {Help} helper\n   * @returns {string}\n   */\n\n\n  formatHelp(cmd, helper) {\n    const termWidth = helper.padWidth(cmd, helper);\n    const helpWidth = helper.helpWidth || 80;\n    const itemIndentWidth = 2;\n    const itemSeparatorWidth = 2; // between term and description\n\n    function formatItem(term, description) {\n      if (description) {\n        const fullText = `${term.padEnd(termWidth + itemSeparatorWidth)}${description}`;\n        return helper.wrap(fullText, helpWidth - itemIndentWidth, termWidth + itemSeparatorWidth);\n      }\n\n      return term;\n    }\n\n    function formatList(textArray) {\n      return textArray.join('\\n').replace(/^/gm, ' '.repeat(itemIndentWidth));\n    } // Usage\n\n\n    let output = [`Usage: ${helper.commandUsage(cmd)}`, '']; // Description\n\n    const commandDescription = helper.commandDescription(cmd);\n\n    if (commandDescription.length > 0) {\n      output = output.concat([commandDescription, '']);\n    } // Arguments\n\n\n    const argumentList = helper.visibleArguments(cmd).map(argument => {\n      return formatItem(helper.argumentTerm(argument), helper.argumentDescription(argument));\n    });\n\n    if (argumentList.length > 0) {\n      output = output.concat(['Arguments:', formatList(argumentList), '']);\n    } // Options\n\n\n    const optionList = helper.visibleOptions(cmd).map(option => {\n      return formatItem(helper.optionTerm(option), helper.optionDescription(option));\n    });\n\n    if (optionList.length > 0) {\n      output = output.concat(['Options:', formatList(optionList), '']);\n    } // Commands\n\n\n    const commandList = helper.visibleCommands(cmd).map(cmd => {\n      return formatItem(helper.subcommandTerm(cmd), helper.subcommandDescription(cmd));\n    });\n\n    if (commandList.length > 0) {\n      output = output.concat(['Commands:', formatList(commandList), '']);\n    }\n\n    return output.join('\\n');\n  }\n  /**\n   * Calculate the pad width from the maximum term length.\n   *\n   * @param {Command} cmd\n   * @param {Help} helper\n   * @returns {number}\n   */\n\n\n  padWidth(cmd, helper) {\n    return Math.max(helper.longestOptionTermLength(cmd, helper), helper.longestSubcommandTermLength(cmd, helper), helper.longestArgumentTermLength(cmd, helper));\n  }\n  /**\n   * Wrap the given string to width characters per line, with lines after the first indented.\n   * Do not wrap if insufficient room for wrapping (minColumnWidth), or string is manually formatted.\n   *\n   * @param {string} str\n   * @param {number} width\n   * @param {number} indent\n   * @param {number} [minColumnWidth=40]\n   * @return {string}\n   *\n   */\n\n\n  wrap(str, width, indent, minColumnWidth = 40) {\n    // Detect manually wrapped and indented strings by searching for line breaks\n    // followed by multiple spaces/tabs.\n    if (str.match(/[\\n]\\s+/)) return str; // Do not wrap if not enough room for a wrapped column of text (as could end up with a word per line).\n\n    const columnWidth = width - indent;\n    if (columnWidth < minColumnWidth) return str;\n    const leadingStr = str.slice(0, indent);\n    const columnText = str.slice(indent);\n    const indentString = ' '.repeat(indent);\n    const regex = new RegExp('.{1,' + (columnWidth - 1) + '}([\\\\s\\u200B]|$)|[^\\\\s\\u200B]+?([\\\\s\\u200B]|$)', 'g');\n    const lines = columnText.match(regex) || [];\n    return leadingStr + lines.map((line, i) => {\n      if (line.slice(-1) === '\\n') {\n        line = line.slice(0, line.length - 1);\n      }\n\n      return (i > 0 ? indentString : '') + line.trimRight();\n    }).join('\\n');\n  }\n\n}\n\nexports.Help = Help;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/commander/lib/help.js?");

/***/ }),

/***/ "./node_modules/commander/lib/option.js":
/*!**********************************************!*\
  !*** ./node_modules/commander/lib/option.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const {\n  InvalidArgumentError\n} = __webpack_require__(/*! ./error.js */ \"./node_modules/commander/lib/error.js\"); // @ts-check\n\n\nclass Option {\n  /**\n   * Initialize a new `Option` with the given `flags` and `description`.\n   *\n   * @param {string} flags\n   * @param {string} [description]\n   */\n  constructor(flags, description) {\n    this.flags = flags;\n    this.description = description || '';\n    this.required = flags.includes('<'); // A value must be supplied when the option is specified.\n\n    this.optional = flags.includes('['); // A value is optional when the option is specified.\n    // variadic test ignores <value,...> et al which might be used to describe custom splitting of single argument\n\n    this.variadic = /\\w\\.\\.\\.[>\\]]$/.test(flags); // The option can take multiple values.\n\n    this.mandatory = false; // The option must have a value after parsing, which usually means it must be specified on command line.\n\n    const optionFlags = splitOptionFlags(flags);\n    this.short = optionFlags.shortFlag;\n    this.long = optionFlags.longFlag;\n    this.negate = false;\n\n    if (this.long) {\n      this.negate = this.long.startsWith('--no-');\n    }\n\n    this.defaultValue = undefined;\n    this.defaultValueDescription = undefined;\n    this.presetArg = undefined;\n    this.envVar = undefined;\n    this.parseArg = undefined;\n    this.hidden = false;\n    this.argChoices = undefined;\n    this.conflictsWith = [];\n    this.implied = undefined;\n  }\n  /**\n   * Set the default value, and optionally supply the description to be displayed in the help.\n   *\n   * @param {any} value\n   * @param {string} [description]\n   * @return {Option}\n   */\n\n\n  default(value, description) {\n    this.defaultValue = value;\n    this.defaultValueDescription = description;\n    return this;\n  }\n  /**\n   * Preset to use when option used without option-argument, especially optional but also boolean and negated.\n   * The custom processing (parseArg) is called.\n   *\n   * @example\n   * new Option('--color').default('GREYSCALE').preset('RGB');\n   * new Option('--donate [amount]').preset('20').argParser(parseFloat);\n   *\n   * @param {any} arg\n   * @return {Option}\n   */\n\n\n  preset(arg) {\n    this.presetArg = arg;\n    return this;\n  }\n  /**\n   * Add option name(s) that conflict with this option.\n   * An error will be displayed if conflicting options are found during parsing.\n   *\n   * @example\n   * new Option('--rgb').conflicts('cmyk');\n   * new Option('--js').conflicts(['ts', 'jsx']);\n   *\n   * @param {string | string[]} names\n   * @return {Option}\n   */\n\n\n  conflicts(names) {\n    this.conflictsWith = this.conflictsWith.concat(names);\n    return this;\n  }\n  /**\n   * Specify implied option values for when this option is set and the implied options are not.\n   *\n   * The custom processing (parseArg) is not called on the implied values.\n   *\n   * @example\n   * program\n   *   .addOption(new Option('--log', 'write logging information to file'))\n   *   .addOption(new Option('--trace', 'log extra details').implies({ log: 'trace.txt' }));\n   *\n   * @param {Object} impliedOptionValues\n   * @return {Option}\n   */\n\n\n  implies(impliedOptionValues) {\n    this.implied = Object.assign(this.implied || {}, impliedOptionValues);\n    return this;\n  }\n  /**\n   * Set environment variable to check for option value.\n   * Priority order of option values is default < env < cli\n   *\n   * @param {string} name\n   * @return {Option}\n   */\n\n\n  env(name) {\n    this.envVar = name;\n    return this;\n  }\n  /**\n   * Set the custom handler for processing CLI option arguments into option values.\n   *\n   * @param {Function} [fn]\n   * @return {Option}\n   */\n\n\n  argParser(fn) {\n    this.parseArg = fn;\n    return this;\n  }\n  /**\n   * Whether the option is mandatory and must have a value after parsing.\n   *\n   * @param {boolean} [mandatory=true]\n   * @return {Option}\n   */\n\n\n  makeOptionMandatory(mandatory = true) {\n    this.mandatory = !!mandatory;\n    return this;\n  }\n  /**\n   * Hide option in help.\n   *\n   * @param {boolean} [hide=true]\n   * @return {Option}\n   */\n\n\n  hideHelp(hide = true) {\n    this.hidden = !!hide;\n    return this;\n  }\n  /**\n   * @api private\n   */\n\n\n  _concatValue(value, previous) {\n    if (previous === this.defaultValue || !Array.isArray(previous)) {\n      return [value];\n    }\n\n    return previous.concat(value);\n  }\n  /**\n   * Only allow option value to be one of choices.\n   *\n   * @param {string[]} values\n   * @return {Option}\n   */\n\n\n  choices(values) {\n    this.argChoices = values.slice();\n\n    this.parseArg = (arg, previous) => {\n      if (!this.argChoices.includes(arg)) {\n        throw new InvalidArgumentError(`Allowed choices are ${this.argChoices.join(', ')}.`);\n      }\n\n      if (this.variadic) {\n        return this._concatValue(arg, previous);\n      }\n\n      return arg;\n    };\n\n    return this;\n  }\n  /**\n   * Return option name.\n   *\n   * @return {string}\n   */\n\n\n  name() {\n    if (this.long) {\n      return this.long.replace(/^--/, '');\n    }\n\n    return this.short.replace(/^-/, '');\n  }\n  /**\n   * Return option name, in a camelcase format that can be used\n   * as a object attribute key.\n   *\n   * @return {string}\n   * @api private\n   */\n\n\n  attributeName() {\n    return camelcase(this.name().replace(/^no-/, ''));\n  }\n  /**\n   * Check if `arg` matches the short or long flag.\n   *\n   * @param {string} arg\n   * @return {boolean}\n   * @api private\n   */\n\n\n  is(arg) {\n    return this.short === arg || this.long === arg;\n  }\n  /**\n   * Return whether a boolean option.\n   *\n   * Options are one of boolean, negated, required argument, or optional argument.\n   *\n   * @return {boolean}\n   * @api private\n   */\n\n\n  isBoolean() {\n    return !this.required && !this.optional && !this.negate;\n  }\n\n}\n/**\n * This class is to make it easier to work with dual options, without changing the existing\n * implementation. We support separate dual options for separate positive and negative options,\n * like `--build` and `--no-build`, which share a single option value. This works nicely for some\n * use cases, but is tricky for others where we want separate behaviours despite\n * the single shared option value.\n */\n\n\nclass DualOptions {\n  /**\n   * @param {Option[]} options\n   */\n  constructor(options) {\n    this.positiveOptions = new Map();\n    this.negativeOptions = new Map();\n    this.dualOptions = new Set();\n    options.forEach(option => {\n      if (option.negate) {\n        this.negativeOptions.set(option.attributeName(), option);\n      } else {\n        this.positiveOptions.set(option.attributeName(), option);\n      }\n    });\n    this.negativeOptions.forEach((value, key) => {\n      if (this.positiveOptions.has(key)) {\n        this.dualOptions.add(key);\n      }\n    });\n  }\n  /**\n   * Did the value come from the option, and not from possible matching dual option?\n   *\n   * @param {any} value\n   * @param {Option} option\n   * @returns {boolean}\n   */\n\n\n  valueFromOption(value, option) {\n    const optionKey = option.attributeName();\n    if (!this.dualOptions.has(optionKey)) return true; // Use the value to deduce if (probably) came from the option.\n\n    const preset = this.negativeOptions.get(optionKey).presetArg;\n    const negativeValue = preset !== undefined ? preset : false;\n    return option.negate === (negativeValue === value);\n  }\n\n}\n/**\n * Convert string from kebab-case to camelCase.\n *\n * @param {string} str\n * @return {string}\n * @api private\n */\n\n\nfunction camelcase(str) {\n  return str.split('-').reduce((str, word) => {\n    return str + word[0].toUpperCase() + word.slice(1);\n  });\n}\n/**\n * Split the short and long flag out of something like '-m,--mixed <value>'\n *\n * @api private\n */\n\n\nfunction splitOptionFlags(flags) {\n  let shortFlag;\n  let longFlag; // Use original very loose parsing to maintain backwards compatibility for now,\n  // which allowed for example unintended `-sw, --short-word` [sic].\n\n  const flagParts = flags.split(/[ |,]+/);\n  if (flagParts.length > 1 && !/^[[<]/.test(flagParts[1])) shortFlag = flagParts.shift();\n  longFlag = flagParts.shift(); // Add support for lone short flag without significantly changing parsing!\n\n  if (!shortFlag && /^-[^-]$/.test(longFlag)) {\n    shortFlag = longFlag;\n    longFlag = undefined;\n  }\n\n  return {\n    shortFlag,\n    longFlag\n  };\n}\n\nexports.Option = Option;\nexports.splitOptionFlags = splitOptionFlags;\nexports.DualOptions = DualOptions;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/commander/lib/option.js?");

/***/ }),

/***/ "./node_modules/commander/lib/suggestSimilar.js":
/*!******************************************************!*\
  !*** ./node_modules/commander/lib/suggestSimilar.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

eval("const maxDistance = 3;\n\nfunction editDistance(a, b) {\n  // https://en.wikipedia.org/wiki/DamerauLevenshtein_distance\n  // Calculating optimal string alignment distance, no substring is edited more than once.\n  // (Simple implementation.)\n  // Quick early exit, return worst case.\n  if (Math.abs(a.length - b.length) > maxDistance) return Math.max(a.length, b.length); // distance between prefix substrings of a and b\n\n  const d = []; // pure deletions turn a into empty string\n\n  for (let i = 0; i <= a.length; i++) {\n    d[i] = [i];\n  } // pure insertions turn empty string into b\n\n\n  for (let j = 0; j <= b.length; j++) {\n    d[0][j] = j;\n  } // fill matrix\n\n\n  for (let j = 1; j <= b.length; j++) {\n    for (let i = 1; i <= a.length; i++) {\n      let cost = 1;\n\n      if (a[i - 1] === b[j - 1]) {\n        cost = 0;\n      } else {\n        cost = 1;\n      }\n\n      d[i][j] = Math.min(d[i - 1][j] + 1, // deletion\n      d[i][j - 1] + 1, // insertion\n      d[i - 1][j - 1] + cost // substitution\n      ); // transposition\n\n      if (i > 1 && j > 1 && a[i - 1] === b[j - 2] && a[i - 2] === b[j - 1]) {\n        d[i][j] = Math.min(d[i][j], d[i - 2][j - 2] + 1);\n      }\n    }\n  }\n\n  return d[a.length][b.length];\n}\n/**\n * Find close matches, restricted to same number of edits.\n *\n * @param {string} word\n * @param {string[]} candidates\n * @returns {string}\n */\n\n\nfunction suggestSimilar(word, candidates) {\n  if (!candidates || candidates.length === 0) return ''; // remove possible duplicates\n\n  candidates = Array.from(new Set(candidates));\n  const searchingOptions = word.startsWith('--');\n\n  if (searchingOptions) {\n    word = word.slice(2);\n    candidates = candidates.map(candidate => candidate.slice(2));\n  }\n\n  let similar = [];\n  let bestDistance = maxDistance;\n  const minSimilarity = 0.4;\n  candidates.forEach(candidate => {\n    if (candidate.length <= 1) return; // no one character guesses\n\n    const distance = editDistance(word, candidate);\n    const length = Math.max(word.length, candidate.length);\n    const similarity = (length - distance) / length;\n\n    if (similarity > minSimilarity) {\n      if (distance < bestDistance) {\n        // better edit distance, throw away previous worse matches\n        bestDistance = distance;\n        similar = [candidate];\n      } else if (distance === bestDistance) {\n        similar.push(candidate);\n      }\n    }\n  });\n  similar.sort((a, b) => a.localeCompare(b));\n\n  if (searchingOptions) {\n    similar = similar.map(candidate => `--${candidate}`);\n  }\n\n  if (similar.length > 1) {\n    return `\\n(Did you mean one of ${similar.join(', ')}?)`;\n  }\n\n  if (similar.length === 1) {\n    return `\\n(Did you mean ${similar[0]}?)`;\n  }\n\n  return '';\n}\n\nexports.suggestSimilar = suggestSimilar;\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/commander/lib/suggestSimilar.js?");

/***/ }),

/***/ "./node_modules/web3.storage/dist/src/lib.cjs":
/*!****************************************************!*\
  !*** ./node_modules/web3.storage/dist/src/lib.cjs ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\nvar streamingIterables = __webpack_require__(/*! streaming-iterables */ \"./node_modules/streaming-iterables/dist/index.js\");\nvar pRetry = __webpack_require__(/*! p-retry */ \"./node_modules/p-retry/index.js\");\nvar pack = __webpack_require__(/*! ipfs-car/pack */ \"./node_modules/ipfs-car/dist/cjs/pack/index.js\");\nvar parseLinkHeader = __webpack_require__(/*! @web3-storage/parse-link-header */ \"./node_modules/@web3-storage/parse-link-header/dist/index.cjs\");\nvar unpack = __webpack_require__(/*! ipfs-car/unpack */ \"./node_modules/ipfs-car/dist/cjs/unpack/index.js\");\nvar treewalk = __webpack_require__(/*! carbites/treewalk */ \"./node_modules/carbites/cjs/lib/treewalk/index.js\");\nvar car = __webpack_require__(/*! @ipld/car */ \"./node_modules/@ipld/car/cjs/car.js\");\nvar filesFromPath = __webpack_require__(/*! files-from-path */ \"./node_modules/files-from-path/cjs/src/index.js\");\nvar fetch = __webpack_require__(/*! @web-std/fetch */ \"./node_modules/@web-std/fetch/dist/index.cjs\");\nvar blob = __webpack_require__(/*! @web-std/blob */ \"./node_modules/@web-std/blob/dist/src/lib.node.cjs\");\nvar file = __webpack_require__(/*! @web-std/file */ \"./node_modules/@web-std/file/dist/src/lib.node.cjs\");\nvar fs = __webpack_require__(/*! ipfs-car/blockstore/fs */ \"./node_modules/ipfs-car/dist/cjs/blockstore/fs.js\");\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar pRetry__default = /*#__PURE__*/_interopDefaultLegacy(pRetry);\nvar fetch__default = /*#__PURE__*/_interopDefaultLegacy(fetch);\n\n/**\n * A client library for the https://web3.storage/ service. It provides a convenient\n * interface for working with the [Raw HTTP API](https://web3.storage/#api-docs)\n * from a web browser or [Node.js](https://nodejs.org/) and comes bundled with\n * TS for out-of-the box type inference and better IntelliSense.\n *\n * @example\n * ```js\n * import { Web3Storage, File } from 'web3.storage'\n * const client = new Web3Storage({ token: API_TOKEN })\n *\n * const cid = await client.put([new File(['hello world'], 'hello.txt', { type: 'text/plain' })])\n * ```\n * @module\n */\n\nconst MAX_PUT_RETRIES = 5;\nconst MAX_CONCURRENT_UPLOADS = 3;\nconst MAX_CHUNK_SIZE = 1024 * 1024 * 10; // chunk to ~10MB CARs\n\n/** @typedef { import('./lib/interface.js').API } API */\n/** @typedef { import('./lib/interface.js').Status} Status */\n/** @typedef { import('./lib/interface.js').Upload} Upload */\n/** @typedef { import('./lib/interface.js').Service } Service */\n/** @typedef { import('./lib/interface.js').Web3File} Web3File */\n/** @typedef { import('./lib/interface.js').Filelike } Filelike */\n/** @typedef { import('./lib/interface.js').CIDString} CIDString */\n/** @typedef { import('./lib/interface.js').PutOptions} PutOptions */\n/** @typedef { import('./lib/interface.js').PutCarOptions} PutCarOptions */\n/** @typedef { import('./lib/interface.js').UnixFSEntry} UnixFSEntry */\n/** @typedef { import('./lib/interface.js').Web3Response} Web3Response */\n\n/**\n * @implements Service\n */\nclass Web3Storage {\n  /**\n   * Constructs a client bound to the given `options.token` and\n   * `options.endpoint`.\n   *\n   * @example\n   * ```js\n   * import { Web3Storage } from 'web3.storage'\n   * const client = new Web3Storage({ token: API_TOKEN })\n   * ```\n   *\n   * @param {{token: string, endpoint?:URL}} options\n   */\n  constructor ({ token, endpoint = new URL('https://api.web3.storage') }) {\n    /**\n     * Authorization token.\n     *\n     * @readonly\n     */\n    this.token = token;\n    /**\n     * Service API endpoint `URL`.\n     * @readonly\n     */\n    this.endpoint = endpoint;\n  }\n\n  /**\n   * @hidden\n   * @param {string} token\n   * @returns {Record<string, string>}\n   */\n  static headers (token) {\n    if (!token) throw new Error('missing token')\n    return {\n      Authorization: `Bearer ${token}`,\n      'X-Client': 'web3.storage/js'\n    }\n  }\n\n  /**\n   * @param {Service} service\n   * @param {Iterable<Filelike>} files\n   * @param {PutOptions} [options]\n   * @returns {Promise<CIDString>}\n   */\n  static async put ({ endpoint, token }, files, {\n    onRootCidReady,\n    onStoredChunk,\n    maxRetries = MAX_PUT_RETRIES,\n    wrapWithDirectory = true,\n    name\n  } = {}) {\n    const blockstore = new fs.FsBlockStore();\n    try {\n      const { out, root } = await pack.pack({\n        input: Array.from(files).map((f) => ({\n          path: f.name,\n          content: f.stream()\n        })),\n        blockstore,\n        wrapWithDirectory,\n        maxChunkSize: 1048576,\n        maxChildrenPerNode: 1024\n      });\n      onRootCidReady && onRootCidReady(root.toString());\n      const car$1 = await car.CarReader.fromIterable(out);\n      return await Web3Storage.putCar({ endpoint, token }, car$1, { onStoredChunk, maxRetries, name })\n    } finally {\n      await blockstore.close();\n    }\n  }\n\n  /**\n   * @param {Service} service\n   * @param {import('@ipld/car/api').CarReader} car\n   * @param {PutCarOptions} [options]\n   * @returns {Promise<CIDString>}\n   */\n  static async putCar ({ endpoint, token }, car, {\n    name,\n    onStoredChunk,\n    maxRetries = MAX_PUT_RETRIES,\n    decoders\n  } = {}) {\n    const targetSize = MAX_CHUNK_SIZE;\n    const url = new URL('car', endpoint);\n    let headers = Web3Storage.headers(token);\n\n    if (name) {\n      headers = { ...headers, 'X-Name': encodeURIComponent(name) };\n    }\n\n    const roots = await car.getRoots();\n    if (roots[0] == null) {\n      throw new Error('missing root CID')\n    }\n    if (roots.length > 1) {\n      throw new Error('too many roots')\n    }\n\n    const carRoot = roots[0].toString();\n    const splitter = new treewalk.TreewalkCarSplitter(car, targetSize, { decoders });\n\n    /**\n     * @param {AsyncIterable<Uint8Array>} car\n     * @returns {Promise<CIDString>}\n     */\n    const onCarChunk = async car => {\n      const carParts = [];\n      for await (const part of car) {\n        carParts.push(part);\n      }\n\n      const carFile = new blob.Blob(carParts, { type: 'application/car' });\n      const res = await pRetry__default[\"default\"](\n        async () => {\n          const request = await fetch__default[\"default\"](url.toString(), {\n            method: 'POST',\n            headers,\n            body: carFile\n          });\n          /* c8 ignore next 3 */\n          if (request.status === 429) {\n            throw new Error('rate limited')\n          }\n          const res = await request.json();\n          if (!request.ok) {\n            throw new Error(res.message)\n          }\n\n          if (res.cid !== carRoot) {\n            throw new Error(`root CID mismatch, expected: ${carRoot}, received: ${res.cid}`)\n          }\n          return res.cid\n        },\n        { retries: maxRetries }\n      );\n\n      onStoredChunk && onStoredChunk(carFile.size);\n      return res\n    };\n\n    const upload = streamingIterables.transform(MAX_CONCURRENT_UPLOADS, onCarChunk);\n    for await (const _ of upload(splitter.cars())) {} // eslint-disable-line\n    return carRoot\n  }\n\n  /**\n   * @param {Service} service\n   * @param {CIDString} cid\n   * @returns {Promise<Web3Response | null>}\n   */\n  static async get ({ endpoint, token }, cid) {\n    const url = new URL(`car/${cid}`, endpoint);\n    const res = await fetch__default[\"default\"](url.toString(), {\n      method: 'GET',\n      headers: Web3Storage.headers(token)\n    });\n    /* c8 ignore next 3 */\n    if (res.status === 429) {\n      throw new Error('rate limited')\n    }\n    return toWeb3Response(res)\n  }\n\n  /**\n   * @param {Service} service\n   * @param {CIDString} cid\n   * @returns {Promise<CIDString>}\n   */\n  /* c8 ignore next 4 */\n  static async delete ({ endpoint, token }, cid) {\n    console.log('Not deleting', cid, endpoint, token);\n    throw Error('.delete not implemented yet')\n  }\n\n  /**\n   * @param {Service} service\n   * @param {CIDString} cid\n   * @returns {Promise<Status | undefined>}\n   */\n  static async status ({ endpoint, token }, cid) {\n    const url = new URL(`status/${cid}`, endpoint);\n    const res = await fetch__default[\"default\"](url.toString(), {\n      method: 'GET',\n      headers: Web3Storage.headers(token)\n    });\n    /* c8 ignore next 3 */\n    if (res.status === 429) {\n      throw new Error('rate limited')\n    }\n    if (res.status === 404) {\n      return undefined\n    }\n    if (!res.ok) {\n      throw new Error(res.statusText)\n    }\n    return res.json()\n  }\n\n  /**\n   * @param {Service} service\n   * @param {object} [opts]\n   * @param {string} [opts.before] list items uploaded before this ISO 8601 date string\n   * @param {number} [opts.maxResults] maximum number of results to return\n   * @returns {AsyncIterable<Upload>}\n   */\n  static async * list (service, { before = new Date().toISOString(), maxResults = Infinity } = {}) {\n  /**\n   * @param {Service} service\n   * @param {{before: string, size: number}} opts\n   * @returns {Promise<Response>}\n   */\n    function listPage ({ endpoint, token }, { before, size }) {\n      const search = new URLSearchParams({ before, size: size.toString() });\n      const url = new URL(`user/uploads?${search}`, endpoint);\n      return fetch__default[\"default\"](url.toString(), {\n        method: 'GET',\n        headers: {\n          ...Web3Storage.headers(token),\n          'Access-Control-Request-Headers': 'Link'\n        }\n      })\n    }\n    let count = 0;\n    const size = maxResults > 100 ? 100 : maxResults;\n    for await (const res of paginator(listPage, service, { before, size })) {\n      if (!res.ok) {\n        /* c8 ignore next 3 */\n        if (res.status === 429) {\n          throw new Error('rate limited')\n        }\n\n        /* c8 ignore next 2 */\n        const errorMessage = await res.json();\n        throw new Error(`${res.status} ${res.statusText} ${errorMessage ? '- ' + errorMessage.message : ''}`)\n      }\n      const page = await res.json();\n      for (const upload of page) {\n        if (++count > maxResults) {\n          return\n        }\n        yield upload;\n      }\n    }\n  }\n\n  // Just a sugar so you don't have to pass around endpoint and token around.\n\n  /**\n   * Uploads files to web3.storage. Files are hashed in the client and uploaded as a single\n   * [Content Addressed Archive(CAR)](https://github.com/ipld/specs/blob/master/block-layer/content-addressable-archives.md).\n   * Takes a [Blob](https://developer.mozilla.org/en-US/docs/Web/API/Blob/Blob)\n   *\n   * Returns the corresponding Content Identifier (CID).\n   *\n   * @example\n   * ```js\n   * const file = new File(['hello world'], 'hello.txt', { type: 'text/plain' })\n   * const cid = await client.put([file])\n   * ```\n   * @param {Iterable<Filelike>} files\n   * @param {PutOptions} [options]\n   */\n  put (files, options) {\n    return Web3Storage.put(this, files, options)\n  }\n\n  /**\n   * Uploads a CAR ([Content Addressed Archive](https://github.com/ipld/specs/blob/master/block-layer/content-addressable-archives.md)) file to web3.storage.\n   * Takes a CarReader interface from @ipld/car\n   *\n   * Returns the corresponding Content Identifier (CID).\n   *\n   * @example\n   * ```js\n   * import fs from 'fs'\n   * import { Readable } from 'stream'\n   * import { CarReader, CarWriter } from '@ipld/car'\n   * import * as raw from 'multiformats/codecs/raw'\n   * import { CID } from 'multiformats/cid'\n   * import { sha256 } from 'multiformats/hashes/sha2'\n   *\n   * async function getCar() {\n   *    const bytes = new TextEncoder().encode('random meaningless bytes')\n   *    const hash = await sha256.digest(raw.encode(bytes))\n   *    const cid = CID.create(1, raw.code, hash)\n   *\n   *    // create the writer and set the header with a single root\n   *    const { writer, out } = await CarWriter.create([cid])\n   *    Readable.from(out).pipe(fs.createWriteStream('example.car'))\n\n   *    // store a new block, creates a new file entry in the CAR archive\n   *    await writer.put({ cid, bytes })\n   *    await writer.close()\n\n   *    const inStream = fs.createReadStream('example.car')\n   *    // read and parse the entire stream in one go, this will cache the contents of\n   *    // the car in memory so is not suitable for large files.\n   *    const reader = await CarReader.fromIterable(inStream)\n   *    return reader\n   * }\n   *\n   * const car = await getCar()\n   * const cid = await client.putCar(car)\n   * ```\n   * @param {import('@ipld/car/api').CarReader} car\n   * @param {PutCarOptions} [options]\n   */\n  putCar (car, options) {\n    return Web3Storage.putCar(this, car, options)\n  }\n\n  /**\n   * Fetch the Content Addressed Archive by its root CID.\n   * @param {CIDString} cid\n   */\n  get (cid) {\n    return Web3Storage.get(this, cid)\n  }\n\n  /**\n   * @param {CIDString} cid\n   */\n  /* c8 ignore next 3 */\n  delete (cid) {\n    return Web3Storage.delete(this, cid)\n  }\n\n  /**\n   * Fetch info on Filecoin deals and IPFS pins that a given CID is replicated in.\n   * @param {CIDString} cid\n   */\n  status (cid) {\n    return Web3Storage.status(this, cid)\n  }\n\n  /**\n   * Find all uploads for this account. Use a `for await...of` loop to fetch them all.\n   * @example\n   * Fetch all the uploads\n   * ```js\n   * const uploads = []\n   * for await (const item of client.list()) {\n   *    uploads.push(item)\n   * }\n   * ```\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of\n   * @param {object} [opts]\n   * @param {string} [opts.before] list items uploaded before this ISO 8601 date string\n   * @param {number} [opts.maxResults] maximum number of results to return\n   * @returns {AsyncIterable<Upload>}\n   */\n  list (opts) {\n    return Web3Storage.list(this, opts)\n  }\n}\n\n/**\n * Map a UnixFSEntry to a File with a cid property\n * @param {UnixFSEntry} entry\n * @returns {Promise<Web3File>}\n */\nasync function toWeb3File ({ content, path, cid }) {\n  const chunks = [];\n  for await (const chunk of content()) {\n    chunks.push(chunk);\n  }\n  const file$1 = new file.File(chunks, toFilenameWithPath(path));\n  return Object.assign(file$1, { cid: cid.toString() })\n}\n\n/**\n * Trim the root cid from the path if there is anyting after it.\n * bafy...ic2q/path/to/pinpie.jpg => path/to/pinpie.jpg\n *         bafy...ic2q/pinpie.jpg => pinpie.jpg\n *                    bafk...52zy => bafk...52zy\n * @param {string} unixFsPath\n * @returns {string}\n */\nfunction toFilenameWithPath (unixFsPath) {\n  const slashIndex = unixFsPath.indexOf('/');\n  return slashIndex === -1 ? unixFsPath : unixFsPath.substring(slashIndex + 1)\n}\n\n/**\n * Add car unpacking smarts to the response object,\n * @param {Response} res\n * @returns {Web3Response}\n */\nfunction toWeb3Response (res) {\n  const response = Object.assign(res, {\n    unixFsIterator: async function * () {\n      if (!res.ok) {\n        throw new Error(`Response was not ok: ${res.status} ${res.statusText} - Check for { \"ok\": false } on the Response object before calling .unixFsIterator`)\n      }\n      /* c8 ignore next 3 */\n      if (!res.body) {\n        throw new Error('No body on response')\n      }\n      const blockstore = new fs.FsBlockStore();\n      try {\n        for await (const entry of unpack.unpackStream(res.body, { blockstore })) {\n          yield entry;\n        }\n      } finally {\n        await blockstore.close();\n      }\n    },\n    files: async () => {\n      if (!res.ok) {\n        throw new Error(`Response was not ok: ${res.status} ${res.statusText} - Check for { \"ok\": false } on the Response object before calling .files`)\n      }\n      const files = [];\n      // @ts-ignore we're using the enriched response here\n      for await (const entry of response.unixFsIterator()) {\n        if (entry.type === 'directory') {\n          continue\n        }\n        const file = await toWeb3File(entry);\n        files.push(file);\n      }\n      return files\n    }\n  });\n  return response\n}\n\n/**\n * Follow Link headers on a Response, to fetch all the things.\n *\n * @param {(service: Service, opts: any) => Promise<Response>} fn\n * @param {Service} service\n * @param {{}} opts\n */\nasync function * paginator (fn, service, opts) {\n  let res = await fn(service, opts);\n  yield res;\n  let link = parseLinkHeader.parseLinkHeader(res.headers.get('Link') || '');\n  // @ts-ignore\n  while (link && link.next) {\n    // @ts-ignore\n    res = await fn(service, link.next);\n    yield res;\n    link = parseLinkHeader.parseLinkHeader(res.headers.get('Link') || '');\n  }\n}\n\nObject.defineProperty(exports, \"filesFromPath\", ({\n  enumerable: true,\n  get: function () { return filesFromPath.filesFromPath; }\n}));\nObject.defineProperty(exports, \"getFilesFromPath\", ({\n  enumerable: true,\n  get: function () { return filesFromPath.getFilesFromPath; }\n}));\nObject.defineProperty(exports, \"Blob\", ({\n  enumerable: true,\n  get: function () { return blob.Blob; }\n}));\nObject.defineProperty(exports, \"File\", ({\n  enumerable: true,\n  get: function () { return file.File; }\n}));\nexports.Web3Storage = Web3Storage;\n//# sourceMappingURL=lib.cjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/web3.storage/dist/src/lib.cjs?");

/***/ }),

/***/ "./node_modules/web-streams-polyfill/dist/ponyfill.mjs":
/*!*************************************************************!*\
  !*** ./node_modules/web-streams-polyfill/dist/ponyfill.mjs ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ByteLengthQueuingStrategy\": () => (/* binding */ ByteLengthQueuingStrategy),\n/* harmony export */   \"CountQueuingStrategy\": () => (/* binding */ CountQueuingStrategy),\n/* harmony export */   \"ReadableByteStreamController\": () => (/* binding */ ReadableByteStreamController),\n/* harmony export */   \"ReadableStream\": () => (/* binding */ ReadableStream),\n/* harmony export */   \"ReadableStreamBYOBReader\": () => (/* binding */ ReadableStreamBYOBReader),\n/* harmony export */   \"ReadableStreamBYOBRequest\": () => (/* binding */ ReadableStreamBYOBRequest),\n/* harmony export */   \"ReadableStreamDefaultController\": () => (/* binding */ ReadableStreamDefaultController),\n/* harmony export */   \"ReadableStreamDefaultReader\": () => (/* binding */ ReadableStreamDefaultReader),\n/* harmony export */   \"TransformStream\": () => (/* binding */ TransformStream),\n/* harmony export */   \"TransformStreamDefaultController\": () => (/* binding */ TransformStreamDefaultController),\n/* harmony export */   \"WritableStream\": () => (/* binding */ WritableStream),\n/* harmony export */   \"WritableStreamDefaultController\": () => (/* binding */ WritableStreamDefaultController),\n/* harmony export */   \"WritableStreamDefaultWriter\": () => (/* binding */ WritableStreamDefaultWriter)\n/* harmony export */ });\n/**\n * web-streams-polyfill v3.2.1\n */\n/// <reference lib=\"es2015.symbol\" />\nvar SymbolPolyfill = typeof Symbol === 'function' && typeof Symbol.iterator === 'symbol' ?\n    Symbol :\n    function (description) { return \"Symbol(\" + description + \")\"; };\n\n/// <reference lib=\"dom\" />\nfunction noop() {\n    return undefined;\n}\nfunction getGlobals() {\n    if (typeof self !== 'undefined') {\n        return self;\n    }\n    else if (typeof window !== 'undefined') {\n        return window;\n    }\n    else if (typeof global !== 'undefined') {\n        return global;\n    }\n    return undefined;\n}\nvar globals = getGlobals();\n\nfunction typeIsObject(x) {\n    return (typeof x === 'object' && x !== null) || typeof x === 'function';\n}\nvar rethrowAssertionErrorRejection = noop;\n\nvar originalPromise = Promise;\nvar originalPromiseThen = Promise.prototype.then;\nvar originalPromiseResolve = Promise.resolve.bind(originalPromise);\nvar originalPromiseReject = Promise.reject.bind(originalPromise);\nfunction newPromise(executor) {\n    return new originalPromise(executor);\n}\nfunction promiseResolvedWith(value) {\n    return originalPromiseResolve(value);\n}\nfunction promiseRejectedWith(reason) {\n    return originalPromiseReject(reason);\n}\nfunction PerformPromiseThen(promise, onFulfilled, onRejected) {\n    // There doesn't appear to be any way to correctly emulate the behaviour from JavaScript, so this is just an\n    // approximation.\n    return originalPromiseThen.call(promise, onFulfilled, onRejected);\n}\nfunction uponPromise(promise, onFulfilled, onRejected) {\n    PerformPromiseThen(PerformPromiseThen(promise, onFulfilled, onRejected), undefined, rethrowAssertionErrorRejection);\n}\nfunction uponFulfillment(promise, onFulfilled) {\n    uponPromise(promise, onFulfilled);\n}\nfunction uponRejection(promise, onRejected) {\n    uponPromise(promise, undefined, onRejected);\n}\nfunction transformPromiseWith(promise, fulfillmentHandler, rejectionHandler) {\n    return PerformPromiseThen(promise, fulfillmentHandler, rejectionHandler);\n}\nfunction setPromiseIsHandledToTrue(promise) {\n    PerformPromiseThen(promise, undefined, rethrowAssertionErrorRejection);\n}\nvar queueMicrotask = (function () {\n    var globalQueueMicrotask = globals && globals.queueMicrotask;\n    if (typeof globalQueueMicrotask === 'function') {\n        return globalQueueMicrotask;\n    }\n    var resolvedPromise = promiseResolvedWith(undefined);\n    return function (fn) { return PerformPromiseThen(resolvedPromise, fn); };\n})();\nfunction reflectCall(F, V, args) {\n    if (typeof F !== 'function') {\n        throw new TypeError('Argument is not a function');\n    }\n    return Function.prototype.apply.call(F, V, args);\n}\nfunction promiseCall(F, V, args) {\n    try {\n        return promiseResolvedWith(reflectCall(F, V, args));\n    }\n    catch (value) {\n        return promiseRejectedWith(value);\n    }\n}\n\n// Original from Chromium\n// https://chromium.googlesource.com/chromium/src/+/0aee4434a4dba42a42abaea9bfbc0cd196a63bc1/third_party/blink/renderer/core/streams/SimpleQueue.js\nvar QUEUE_MAX_ARRAY_SIZE = 16384;\n/**\n * Simple queue structure.\n *\n * Avoids scalability issues with using a packed array directly by using\n * multiple arrays in a linked list and keeping the array size bounded.\n */\nvar SimpleQueue = /** @class */ (function () {\n    function SimpleQueue() {\n        this._cursor = 0;\n        this._size = 0;\n        // _front and _back are always defined.\n        this._front = {\n            _elements: [],\n            _next: undefined\n        };\n        this._back = this._front;\n        // The cursor is used to avoid calling Array.shift().\n        // It contains the index of the front element of the array inside the\n        // front-most node. It is always in the range [0, QUEUE_MAX_ARRAY_SIZE).\n        this._cursor = 0;\n        // When there is only one node, size === elements.length - cursor.\n        this._size = 0;\n    }\n    Object.defineProperty(SimpleQueue.prototype, \"length\", {\n        get: function () {\n            return this._size;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    // For exception safety, this method is structured in order:\n    // 1. Read state\n    // 2. Calculate required state mutations\n    // 3. Perform state mutations\n    SimpleQueue.prototype.push = function (element) {\n        var oldBack = this._back;\n        var newBack = oldBack;\n        if (oldBack._elements.length === QUEUE_MAX_ARRAY_SIZE - 1) {\n            newBack = {\n                _elements: [],\n                _next: undefined\n            };\n        }\n        // push() is the mutation most likely to throw an exception, so it\n        // goes first.\n        oldBack._elements.push(element);\n        if (newBack !== oldBack) {\n            this._back = newBack;\n            oldBack._next = newBack;\n        }\n        ++this._size;\n    };\n    // Like push(), shift() follows the read -> calculate -> mutate pattern for\n    // exception safety.\n    SimpleQueue.prototype.shift = function () { // must not be called on an empty queue\n        var oldFront = this._front;\n        var newFront = oldFront;\n        var oldCursor = this._cursor;\n        var newCursor = oldCursor + 1;\n        var elements = oldFront._elements;\n        var element = elements[oldCursor];\n        if (newCursor === QUEUE_MAX_ARRAY_SIZE) {\n            newFront = oldFront._next;\n            newCursor = 0;\n        }\n        // No mutations before this point.\n        --this._size;\n        this._cursor = newCursor;\n        if (oldFront !== newFront) {\n            this._front = newFront;\n        }\n        // Permit shifted element to be garbage collected.\n        elements[oldCursor] = undefined;\n        return element;\n    };\n    // The tricky thing about forEach() is that it can be called\n    // re-entrantly. The queue may be mutated inside the callback. It is easy to\n    // see that push() within the callback has no negative effects since the end\n    // of the queue is checked for on every iteration. If shift() is called\n    // repeatedly within the callback then the next iteration may return an\n    // element that has been removed. In this case the callback will be called\n    // with undefined values until we either \"catch up\" with elements that still\n    // exist or reach the back of the queue.\n    SimpleQueue.prototype.forEach = function (callback) {\n        var i = this._cursor;\n        var node = this._front;\n        var elements = node._elements;\n        while (i !== elements.length || node._next !== undefined) {\n            if (i === elements.length) {\n                node = node._next;\n                elements = node._elements;\n                i = 0;\n                if (elements.length === 0) {\n                    break;\n                }\n            }\n            callback(elements[i]);\n            ++i;\n        }\n    };\n    // Return the element that would be returned if shift() was called now,\n    // without modifying the queue.\n    SimpleQueue.prototype.peek = function () { // must not be called on an empty queue\n        var front = this._front;\n        var cursor = this._cursor;\n        return front._elements[cursor];\n    };\n    return SimpleQueue;\n}());\n\nfunction ReadableStreamReaderGenericInitialize(reader, stream) {\n    reader._ownerReadableStream = stream;\n    stream._reader = reader;\n    if (stream._state === 'readable') {\n        defaultReaderClosedPromiseInitialize(reader);\n    }\n    else if (stream._state === 'closed') {\n        defaultReaderClosedPromiseInitializeAsResolved(reader);\n    }\n    else {\n        defaultReaderClosedPromiseInitializeAsRejected(reader, stream._storedError);\n    }\n}\n// A client of ReadableStreamDefaultReader and ReadableStreamBYOBReader may use these functions directly to bypass state\n// check.\nfunction ReadableStreamReaderGenericCancel(reader, reason) {\n    var stream = reader._ownerReadableStream;\n    return ReadableStreamCancel(stream, reason);\n}\nfunction ReadableStreamReaderGenericRelease(reader) {\n    if (reader._ownerReadableStream._state === 'readable') {\n        defaultReaderClosedPromiseReject(reader, new TypeError(\"Reader was released and can no longer be used to monitor the stream's closedness\"));\n    }\n    else {\n        defaultReaderClosedPromiseResetToRejected(reader, new TypeError(\"Reader was released and can no longer be used to monitor the stream's closedness\"));\n    }\n    reader._ownerReadableStream._reader = undefined;\n    reader._ownerReadableStream = undefined;\n}\n// Helper functions for the readers.\nfunction readerLockException(name) {\n    return new TypeError('Cannot ' + name + ' a stream using a released reader');\n}\n// Helper functions for the ReadableStreamDefaultReader.\nfunction defaultReaderClosedPromiseInitialize(reader) {\n    reader._closedPromise = newPromise(function (resolve, reject) {\n        reader._closedPromise_resolve = resolve;\n        reader._closedPromise_reject = reject;\n    });\n}\nfunction defaultReaderClosedPromiseInitializeAsRejected(reader, reason) {\n    defaultReaderClosedPromiseInitialize(reader);\n    defaultReaderClosedPromiseReject(reader, reason);\n}\nfunction defaultReaderClosedPromiseInitializeAsResolved(reader) {\n    defaultReaderClosedPromiseInitialize(reader);\n    defaultReaderClosedPromiseResolve(reader);\n}\nfunction defaultReaderClosedPromiseReject(reader, reason) {\n    if (reader._closedPromise_reject === undefined) {\n        return;\n    }\n    setPromiseIsHandledToTrue(reader._closedPromise);\n    reader._closedPromise_reject(reason);\n    reader._closedPromise_resolve = undefined;\n    reader._closedPromise_reject = undefined;\n}\nfunction defaultReaderClosedPromiseResetToRejected(reader, reason) {\n    defaultReaderClosedPromiseInitializeAsRejected(reader, reason);\n}\nfunction defaultReaderClosedPromiseResolve(reader) {\n    if (reader._closedPromise_resolve === undefined) {\n        return;\n    }\n    reader._closedPromise_resolve(undefined);\n    reader._closedPromise_resolve = undefined;\n    reader._closedPromise_reject = undefined;\n}\n\nvar AbortSteps = SymbolPolyfill('[[AbortSteps]]');\nvar ErrorSteps = SymbolPolyfill('[[ErrorSteps]]');\nvar CancelSteps = SymbolPolyfill('[[CancelSteps]]');\nvar PullSteps = SymbolPolyfill('[[PullSteps]]');\n\n/// <reference lib=\"es2015.core\" />\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isFinite#Polyfill\nvar NumberIsFinite = Number.isFinite || function (x) {\n    return typeof x === 'number' && isFinite(x);\n};\n\n/// <reference lib=\"es2015.core\" />\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/trunc#Polyfill\nvar MathTrunc = Math.trunc || function (v) {\n    return v < 0 ? Math.ceil(v) : Math.floor(v);\n};\n\n// https://heycam.github.io/webidl/#idl-dictionaries\nfunction isDictionary(x) {\n    return typeof x === 'object' || typeof x === 'function';\n}\nfunction assertDictionary(obj, context) {\n    if (obj !== undefined && !isDictionary(obj)) {\n        throw new TypeError(context + \" is not an object.\");\n    }\n}\n// https://heycam.github.io/webidl/#idl-callback-functions\nfunction assertFunction(x, context) {\n    if (typeof x !== 'function') {\n        throw new TypeError(context + \" is not a function.\");\n    }\n}\n// https://heycam.github.io/webidl/#idl-object\nfunction isObject(x) {\n    return (typeof x === 'object' && x !== null) || typeof x === 'function';\n}\nfunction assertObject(x, context) {\n    if (!isObject(x)) {\n        throw new TypeError(context + \" is not an object.\");\n    }\n}\nfunction assertRequiredArgument(x, position, context) {\n    if (x === undefined) {\n        throw new TypeError(\"Parameter \" + position + \" is required in '\" + context + \"'.\");\n    }\n}\nfunction assertRequiredField(x, field, context) {\n    if (x === undefined) {\n        throw new TypeError(field + \" is required in '\" + context + \"'.\");\n    }\n}\n// https://heycam.github.io/webidl/#idl-unrestricted-double\nfunction convertUnrestrictedDouble(value) {\n    return Number(value);\n}\nfunction censorNegativeZero(x) {\n    return x === 0 ? 0 : x;\n}\nfunction integerPart(x) {\n    return censorNegativeZero(MathTrunc(x));\n}\n// https://heycam.github.io/webidl/#idl-unsigned-long-long\nfunction convertUnsignedLongLongWithEnforceRange(value, context) {\n    var lowerBound = 0;\n    var upperBound = Number.MAX_SAFE_INTEGER;\n    var x = Number(value);\n    x = censorNegativeZero(x);\n    if (!NumberIsFinite(x)) {\n        throw new TypeError(context + \" is not a finite number\");\n    }\n    x = integerPart(x);\n    if (x < lowerBound || x > upperBound) {\n        throw new TypeError(context + \" is outside the accepted range of \" + lowerBound + \" to \" + upperBound + \", inclusive\");\n    }\n    if (!NumberIsFinite(x) || x === 0) {\n        return 0;\n    }\n    // TODO Use BigInt if supported?\n    // let xBigInt = BigInt(integerPart(x));\n    // xBigInt = BigInt.asUintN(64, xBigInt);\n    // return Number(xBigInt);\n    return x;\n}\n\nfunction assertReadableStream(x, context) {\n    if (!IsReadableStream(x)) {\n        throw new TypeError(context + \" is not a ReadableStream.\");\n    }\n}\n\n// Abstract operations for the ReadableStream.\nfunction AcquireReadableStreamDefaultReader(stream) {\n    return new ReadableStreamDefaultReader(stream);\n}\n// ReadableStream API exposed for controllers.\nfunction ReadableStreamAddReadRequest(stream, readRequest) {\n    stream._reader._readRequests.push(readRequest);\n}\nfunction ReadableStreamFulfillReadRequest(stream, chunk, done) {\n    var reader = stream._reader;\n    var readRequest = reader._readRequests.shift();\n    if (done) {\n        readRequest._closeSteps();\n    }\n    else {\n        readRequest._chunkSteps(chunk);\n    }\n}\nfunction ReadableStreamGetNumReadRequests(stream) {\n    return stream._reader._readRequests.length;\n}\nfunction ReadableStreamHasDefaultReader(stream) {\n    var reader = stream._reader;\n    if (reader === undefined) {\n        return false;\n    }\n    if (!IsReadableStreamDefaultReader(reader)) {\n        return false;\n    }\n    return true;\n}\n/**\n * A default reader vended by a {@link ReadableStream}.\n *\n * @public\n */\nvar ReadableStreamDefaultReader = /** @class */ (function () {\n    function ReadableStreamDefaultReader(stream) {\n        assertRequiredArgument(stream, 1, 'ReadableStreamDefaultReader');\n        assertReadableStream(stream, 'First parameter');\n        if (IsReadableStreamLocked(stream)) {\n            throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n        }\n        ReadableStreamReaderGenericInitialize(this, stream);\n        this._readRequests = new SimpleQueue();\n    }\n    Object.defineProperty(ReadableStreamDefaultReader.prototype, \"closed\", {\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed,\n         * or rejected if the stream ever errors or the reader's lock is released before the stream finishes closing.\n         */\n        get: function () {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n     */\n    ReadableStreamDefaultReader.prototype.cancel = function (reason) {\n        if (reason === void 0) { reason = undefined; }\n        if (!IsReadableStreamDefaultReader(this)) {\n            return promiseRejectedWith(defaultReaderBrandCheckException('cancel'));\n        }\n        if (this._ownerReadableStream === undefined) {\n            return promiseRejectedWith(readerLockException('cancel'));\n        }\n        return ReadableStreamReaderGenericCancel(this, reason);\n    };\n    /**\n     * Returns a promise that allows access to the next chunk from the stream's internal queue, if available.\n     *\n     * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n     */\n    ReadableStreamDefaultReader.prototype.read = function () {\n        if (!IsReadableStreamDefaultReader(this)) {\n            return promiseRejectedWith(defaultReaderBrandCheckException('read'));\n        }\n        if (this._ownerReadableStream === undefined) {\n            return promiseRejectedWith(readerLockException('read from'));\n        }\n        var resolvePromise;\n        var rejectPromise;\n        var promise = newPromise(function (resolve, reject) {\n            resolvePromise = resolve;\n            rejectPromise = reject;\n        });\n        var readRequest = {\n            _chunkSteps: function (chunk) { return resolvePromise({ value: chunk, done: false }); },\n            _closeSteps: function () { return resolvePromise({ value: undefined, done: true }); },\n            _errorSteps: function (e) { return rejectPromise(e); }\n        };\n        ReadableStreamDefaultReaderRead(this, readRequest);\n        return promise;\n    };\n    /**\n     * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n     * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n     * from now on; otherwise, the reader will appear closed.\n     *\n     * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n     * the reader's {@link ReadableStreamDefaultReader.read | read()} method has not yet been settled. Attempting to\n     * do so will throw a `TypeError` and leave the reader locked to the stream.\n     */\n    ReadableStreamDefaultReader.prototype.releaseLock = function () {\n        if (!IsReadableStreamDefaultReader(this)) {\n            throw defaultReaderBrandCheckException('releaseLock');\n        }\n        if (this._ownerReadableStream === undefined) {\n            return;\n        }\n        if (this._readRequests.length > 0) {\n            throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n        }\n        ReadableStreamReaderGenericRelease(this);\n    };\n    return ReadableStreamDefaultReader;\n}());\nObject.defineProperties(ReadableStreamDefaultReader.prototype, {\n    cancel: { enumerable: true },\n    read: { enumerable: true },\n    releaseLock: { enumerable: true },\n    closed: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(ReadableStreamDefaultReader.prototype, SymbolPolyfill.toStringTag, {\n        value: 'ReadableStreamDefaultReader',\n        configurable: true\n    });\n}\n// Abstract operations for the readers.\nfunction IsReadableStreamDefaultReader(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_readRequests')) {\n        return false;\n    }\n    return x instanceof ReadableStreamDefaultReader;\n}\nfunction ReadableStreamDefaultReaderRead(reader, readRequest) {\n    var stream = reader._ownerReadableStream;\n    stream._disturbed = true;\n    if (stream._state === 'closed') {\n        readRequest._closeSteps();\n    }\n    else if (stream._state === 'errored') {\n        readRequest._errorSteps(stream._storedError);\n    }\n    else {\n        stream._readableStreamController[PullSteps](readRequest);\n    }\n}\n// Helper functions for the ReadableStreamDefaultReader.\nfunction defaultReaderBrandCheckException(name) {\n    return new TypeError(\"ReadableStreamDefaultReader.prototype.\" + name + \" can only be used on a ReadableStreamDefaultReader\");\n}\n\n/// <reference lib=\"es2018.asynciterable\" />\nvar _a;\nvar AsyncIteratorPrototype;\nif (typeof SymbolPolyfill.asyncIterator === 'symbol') {\n    // We're running inside a ES2018+ environment, but we're compiling to an older syntax.\n    // We cannot access %AsyncIteratorPrototype% without non-ES2018 syntax, but we can re-create it.\n    AsyncIteratorPrototype = (_a = {},\n        // 25.1.3.1 %AsyncIteratorPrototype% [ @@asyncIterator ] ( )\n        // https://tc39.github.io/ecma262/#sec-asynciteratorprototype-asynciterator\n        _a[SymbolPolyfill.asyncIterator] = function () {\n            return this;\n        },\n        _a);\n    Object.defineProperty(AsyncIteratorPrototype, SymbolPolyfill.asyncIterator, { enumerable: false });\n}\n\n/// <reference lib=\"es2018.asynciterable\" />\nvar ReadableStreamAsyncIteratorImpl = /** @class */ (function () {\n    function ReadableStreamAsyncIteratorImpl(reader, preventCancel) {\n        this._ongoingPromise = undefined;\n        this._isFinished = false;\n        this._reader = reader;\n        this._preventCancel = preventCancel;\n    }\n    ReadableStreamAsyncIteratorImpl.prototype.next = function () {\n        var _this = this;\n        var nextSteps = function () { return _this._nextSteps(); };\n        this._ongoingPromise = this._ongoingPromise ?\n            transformPromiseWith(this._ongoingPromise, nextSteps, nextSteps) :\n            nextSteps();\n        return this._ongoingPromise;\n    };\n    ReadableStreamAsyncIteratorImpl.prototype.return = function (value) {\n        var _this = this;\n        var returnSteps = function () { return _this._returnSteps(value); };\n        return this._ongoingPromise ?\n            transformPromiseWith(this._ongoingPromise, returnSteps, returnSteps) :\n            returnSteps();\n    };\n    ReadableStreamAsyncIteratorImpl.prototype._nextSteps = function () {\n        var _this = this;\n        if (this._isFinished) {\n            return Promise.resolve({ value: undefined, done: true });\n        }\n        var reader = this._reader;\n        if (reader._ownerReadableStream === undefined) {\n            return promiseRejectedWith(readerLockException('iterate'));\n        }\n        var resolvePromise;\n        var rejectPromise;\n        var promise = newPromise(function (resolve, reject) {\n            resolvePromise = resolve;\n            rejectPromise = reject;\n        });\n        var readRequest = {\n            _chunkSteps: function (chunk) {\n                _this._ongoingPromise = undefined;\n                // This needs to be delayed by one microtask, otherwise we stop pulling too early which breaks a test.\n                // FIXME Is this a bug in the specification, or in the test?\n                queueMicrotask(function () { return resolvePromise({ value: chunk, done: false }); });\n            },\n            _closeSteps: function () {\n                _this._ongoingPromise = undefined;\n                _this._isFinished = true;\n                ReadableStreamReaderGenericRelease(reader);\n                resolvePromise({ value: undefined, done: true });\n            },\n            _errorSteps: function (reason) {\n                _this._ongoingPromise = undefined;\n                _this._isFinished = true;\n                ReadableStreamReaderGenericRelease(reader);\n                rejectPromise(reason);\n            }\n        };\n        ReadableStreamDefaultReaderRead(reader, readRequest);\n        return promise;\n    };\n    ReadableStreamAsyncIteratorImpl.prototype._returnSteps = function (value) {\n        if (this._isFinished) {\n            return Promise.resolve({ value: value, done: true });\n        }\n        this._isFinished = true;\n        var reader = this._reader;\n        if (reader._ownerReadableStream === undefined) {\n            return promiseRejectedWith(readerLockException('finish iterating'));\n        }\n        if (!this._preventCancel) {\n            var result = ReadableStreamReaderGenericCancel(reader, value);\n            ReadableStreamReaderGenericRelease(reader);\n            return transformPromiseWith(result, function () { return ({ value: value, done: true }); });\n        }\n        ReadableStreamReaderGenericRelease(reader);\n        return promiseResolvedWith({ value: value, done: true });\n    };\n    return ReadableStreamAsyncIteratorImpl;\n}());\nvar ReadableStreamAsyncIteratorPrototype = {\n    next: function () {\n        if (!IsReadableStreamAsyncIterator(this)) {\n            return promiseRejectedWith(streamAsyncIteratorBrandCheckException('next'));\n        }\n        return this._asyncIteratorImpl.next();\n    },\n    return: function (value) {\n        if (!IsReadableStreamAsyncIterator(this)) {\n            return promiseRejectedWith(streamAsyncIteratorBrandCheckException('return'));\n        }\n        return this._asyncIteratorImpl.return(value);\n    }\n};\nif (AsyncIteratorPrototype !== undefined) {\n    Object.setPrototypeOf(ReadableStreamAsyncIteratorPrototype, AsyncIteratorPrototype);\n}\n// Abstract operations for the ReadableStream.\nfunction AcquireReadableStreamAsyncIterator(stream, preventCancel) {\n    var reader = AcquireReadableStreamDefaultReader(stream);\n    var impl = new ReadableStreamAsyncIteratorImpl(reader, preventCancel);\n    var iterator = Object.create(ReadableStreamAsyncIteratorPrototype);\n    iterator._asyncIteratorImpl = impl;\n    return iterator;\n}\nfunction IsReadableStreamAsyncIterator(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_asyncIteratorImpl')) {\n        return false;\n    }\n    try {\n        // noinspection SuspiciousTypeOfGuard\n        return x._asyncIteratorImpl instanceof\n            ReadableStreamAsyncIteratorImpl;\n    }\n    catch (_a) {\n        return false;\n    }\n}\n// Helper functions for the ReadableStream.\nfunction streamAsyncIteratorBrandCheckException(name) {\n    return new TypeError(\"ReadableStreamAsyncIterator.\" + name + \" can only be used on a ReadableSteamAsyncIterator\");\n}\n\n/// <reference lib=\"es2015.core\" />\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isNaN#Polyfill\nvar NumberIsNaN = Number.isNaN || function (x) {\n    // eslint-disable-next-line no-self-compare\n    return x !== x;\n};\n\nfunction CreateArrayFromList(elements) {\n    // We use arrays to represent lists, so this is basically a no-op.\n    // Do a slice though just in case we happen to depend on the unique-ness.\n    return elements.slice();\n}\nfunction CopyDataBlockBytes(dest, destOffset, src, srcOffset, n) {\n    new Uint8Array(dest).set(new Uint8Array(src, srcOffset, n), destOffset);\n}\n// Not implemented correctly\nfunction TransferArrayBuffer(O) {\n    return O;\n}\n// Not implemented correctly\n// eslint-disable-next-line @typescript-eslint/no-unused-vars\nfunction IsDetachedBuffer(O) {\n    return false;\n}\nfunction ArrayBufferSlice(buffer, begin, end) {\n    // ArrayBuffer.prototype.slice is not available on IE10\n    // https://www.caniuse.com/mdn-javascript_builtins_arraybuffer_slice\n    if (buffer.slice) {\n        return buffer.slice(begin, end);\n    }\n    var length = end - begin;\n    var slice = new ArrayBuffer(length);\n    CopyDataBlockBytes(slice, 0, buffer, begin, length);\n    return slice;\n}\n\nfunction IsNonNegativeNumber(v) {\n    if (typeof v !== 'number') {\n        return false;\n    }\n    if (NumberIsNaN(v)) {\n        return false;\n    }\n    if (v < 0) {\n        return false;\n    }\n    return true;\n}\nfunction CloneAsUint8Array(O) {\n    var buffer = ArrayBufferSlice(O.buffer, O.byteOffset, O.byteOffset + O.byteLength);\n    return new Uint8Array(buffer);\n}\n\nfunction DequeueValue(container) {\n    var pair = container._queue.shift();\n    container._queueTotalSize -= pair.size;\n    if (container._queueTotalSize < 0) {\n        container._queueTotalSize = 0;\n    }\n    return pair.value;\n}\nfunction EnqueueValueWithSize(container, value, size) {\n    if (!IsNonNegativeNumber(size) || size === Infinity) {\n        throw new RangeError('Size must be a finite, non-NaN, non-negative number.');\n    }\n    container._queue.push({ value: value, size: size });\n    container._queueTotalSize += size;\n}\nfunction PeekQueueValue(container) {\n    var pair = container._queue.peek();\n    return pair.value;\n}\nfunction ResetQueue(container) {\n    container._queue = new SimpleQueue();\n    container._queueTotalSize = 0;\n}\n\n/**\n * A pull-into request in a {@link ReadableByteStreamController}.\n *\n * @public\n */\nvar ReadableStreamBYOBRequest = /** @class */ (function () {\n    function ReadableStreamBYOBRequest() {\n        throw new TypeError('Illegal constructor');\n    }\n    Object.defineProperty(ReadableStreamBYOBRequest.prototype, \"view\", {\n        /**\n         * Returns the view for writing in to, or `null` if the BYOB request has already been responded to.\n         */\n        get: function () {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('view');\n            }\n            return this._view;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    ReadableStreamBYOBRequest.prototype.respond = function (bytesWritten) {\n        if (!IsReadableStreamBYOBRequest(this)) {\n            throw byobRequestBrandCheckException('respond');\n        }\n        assertRequiredArgument(bytesWritten, 1, 'respond');\n        bytesWritten = convertUnsignedLongLongWithEnforceRange(bytesWritten, 'First parameter');\n        if (this._associatedReadableByteStreamController === undefined) {\n            throw new TypeError('This BYOB request has been invalidated');\n        }\n        if (IsDetachedBuffer(this._view.buffer)) ;\n        ReadableByteStreamControllerRespond(this._associatedReadableByteStreamController, bytesWritten);\n    };\n    ReadableStreamBYOBRequest.prototype.respondWithNewView = function (view) {\n        if (!IsReadableStreamBYOBRequest(this)) {\n            throw byobRequestBrandCheckException('respondWithNewView');\n        }\n        assertRequiredArgument(view, 1, 'respondWithNewView');\n        if (!ArrayBuffer.isView(view)) {\n            throw new TypeError('You can only respond with array buffer views');\n        }\n        if (this._associatedReadableByteStreamController === undefined) {\n            throw new TypeError('This BYOB request has been invalidated');\n        }\n        if (IsDetachedBuffer(view.buffer)) ;\n        ReadableByteStreamControllerRespondWithNewView(this._associatedReadableByteStreamController, view);\n    };\n    return ReadableStreamBYOBRequest;\n}());\nObject.defineProperties(ReadableStreamBYOBRequest.prototype, {\n    respond: { enumerable: true },\n    respondWithNewView: { enumerable: true },\n    view: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(ReadableStreamBYOBRequest.prototype, SymbolPolyfill.toStringTag, {\n        value: 'ReadableStreamBYOBRequest',\n        configurable: true\n    });\n}\n/**\n * Allows control of a {@link ReadableStream | readable byte stream}'s state and internal queue.\n *\n * @public\n */\nvar ReadableByteStreamController = /** @class */ (function () {\n    function ReadableByteStreamController() {\n        throw new TypeError('Illegal constructor');\n    }\n    Object.defineProperty(ReadableByteStreamController.prototype, \"byobRequest\", {\n        /**\n         * Returns the current BYOB pull request, or `null` if there isn't one.\n         */\n        get: function () {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('byobRequest');\n            }\n            return ReadableByteStreamControllerGetBYOBRequest(this);\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Object.defineProperty(ReadableByteStreamController.prototype, \"desiredSize\", {\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying byte source ought to use this information to determine when and how to apply backpressure.\n         */\n        get: function () {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('desiredSize');\n            }\n            return ReadableByteStreamControllerGetDesiredSize(this);\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n     * the stream, but once those are read, the stream will become closed.\n     */\n    ReadableByteStreamController.prototype.close = function () {\n        if (!IsReadableByteStreamController(this)) {\n            throw byteStreamControllerBrandCheckException('close');\n        }\n        if (this._closeRequested) {\n            throw new TypeError('The stream has already been closed; do not close it again!');\n        }\n        var state = this._controlledReadableByteStream._state;\n        if (state !== 'readable') {\n            throw new TypeError(\"The stream (in \" + state + \" state) is not in the readable state and cannot be closed\");\n        }\n        ReadableByteStreamControllerClose(this);\n    };\n    ReadableByteStreamController.prototype.enqueue = function (chunk) {\n        if (!IsReadableByteStreamController(this)) {\n            throw byteStreamControllerBrandCheckException('enqueue');\n        }\n        assertRequiredArgument(chunk, 1, 'enqueue');\n        if (!ArrayBuffer.isView(chunk)) {\n            throw new TypeError('chunk must be an array buffer view');\n        }\n        if (chunk.byteLength === 0) {\n            throw new TypeError('chunk must have non-zero byteLength');\n        }\n        if (chunk.buffer.byteLength === 0) {\n            throw new TypeError(\"chunk's buffer must have non-zero byteLength\");\n        }\n        if (this._closeRequested) {\n            throw new TypeError('stream is closed or draining');\n        }\n        var state = this._controlledReadableByteStream._state;\n        if (state !== 'readable') {\n            throw new TypeError(\"The stream (in \" + state + \" state) is not in the readable state and cannot be enqueued to\");\n        }\n        ReadableByteStreamControllerEnqueue(this, chunk);\n    };\n    /**\n     * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n     */\n    ReadableByteStreamController.prototype.error = function (e) {\n        if (e === void 0) { e = undefined; }\n        if (!IsReadableByteStreamController(this)) {\n            throw byteStreamControllerBrandCheckException('error');\n        }\n        ReadableByteStreamControllerError(this, e);\n    };\n    /** @internal */\n    ReadableByteStreamController.prototype[CancelSteps] = function (reason) {\n        ReadableByteStreamControllerClearPendingPullIntos(this);\n        ResetQueue(this);\n        var result = this._cancelAlgorithm(reason);\n        ReadableByteStreamControllerClearAlgorithms(this);\n        return result;\n    };\n    /** @internal */\n    ReadableByteStreamController.prototype[PullSteps] = function (readRequest) {\n        var stream = this._controlledReadableByteStream;\n        if (this._queueTotalSize > 0) {\n            var entry = this._queue.shift();\n            this._queueTotalSize -= entry.byteLength;\n            ReadableByteStreamControllerHandleQueueDrain(this);\n            var view = new Uint8Array(entry.buffer, entry.byteOffset, entry.byteLength);\n            readRequest._chunkSteps(view);\n            return;\n        }\n        var autoAllocateChunkSize = this._autoAllocateChunkSize;\n        if (autoAllocateChunkSize !== undefined) {\n            var buffer = void 0;\n            try {\n                buffer = new ArrayBuffer(autoAllocateChunkSize);\n            }\n            catch (bufferE) {\n                readRequest._errorSteps(bufferE);\n                return;\n            }\n            var pullIntoDescriptor = {\n                buffer: buffer,\n                bufferByteLength: autoAllocateChunkSize,\n                byteOffset: 0,\n                byteLength: autoAllocateChunkSize,\n                bytesFilled: 0,\n                elementSize: 1,\n                viewConstructor: Uint8Array,\n                readerType: 'default'\n            };\n            this._pendingPullIntos.push(pullIntoDescriptor);\n        }\n        ReadableStreamAddReadRequest(stream, readRequest);\n        ReadableByteStreamControllerCallPullIfNeeded(this);\n    };\n    return ReadableByteStreamController;\n}());\nObject.defineProperties(ReadableByteStreamController.prototype, {\n    close: { enumerable: true },\n    enqueue: { enumerable: true },\n    error: { enumerable: true },\n    byobRequest: { enumerable: true },\n    desiredSize: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(ReadableByteStreamController.prototype, SymbolPolyfill.toStringTag, {\n        value: 'ReadableByteStreamController',\n        configurable: true\n    });\n}\n// Abstract operations for the ReadableByteStreamController.\nfunction IsReadableByteStreamController(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableByteStream')) {\n        return false;\n    }\n    return x instanceof ReadableByteStreamController;\n}\nfunction IsReadableStreamBYOBRequest(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_associatedReadableByteStreamController')) {\n        return false;\n    }\n    return x instanceof ReadableStreamBYOBRequest;\n}\nfunction ReadableByteStreamControllerCallPullIfNeeded(controller) {\n    var shouldPull = ReadableByteStreamControllerShouldCallPull(controller);\n    if (!shouldPull) {\n        return;\n    }\n    if (controller._pulling) {\n        controller._pullAgain = true;\n        return;\n    }\n    controller._pulling = true;\n    // TODO: Test controller argument\n    var pullPromise = controller._pullAlgorithm();\n    uponPromise(pullPromise, function () {\n        controller._pulling = false;\n        if (controller._pullAgain) {\n            controller._pullAgain = false;\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }\n    }, function (e) {\n        ReadableByteStreamControllerError(controller, e);\n    });\n}\nfunction ReadableByteStreamControllerClearPendingPullIntos(controller) {\n    ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n    controller._pendingPullIntos = new SimpleQueue();\n}\nfunction ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor) {\n    var done = false;\n    if (stream._state === 'closed') {\n        done = true;\n    }\n    var filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n    if (pullIntoDescriptor.readerType === 'default') {\n        ReadableStreamFulfillReadRequest(stream, filledView, done);\n    }\n    else {\n        ReadableStreamFulfillReadIntoRequest(stream, filledView, done);\n    }\n}\nfunction ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor) {\n    var bytesFilled = pullIntoDescriptor.bytesFilled;\n    var elementSize = pullIntoDescriptor.elementSize;\n    return new pullIntoDescriptor.viewConstructor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, bytesFilled / elementSize);\n}\nfunction ReadableByteStreamControllerEnqueueChunkToQueue(controller, buffer, byteOffset, byteLength) {\n    controller._queue.push({ buffer: buffer, byteOffset: byteOffset, byteLength: byteLength });\n    controller._queueTotalSize += byteLength;\n}\nfunction ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor) {\n    var elementSize = pullIntoDescriptor.elementSize;\n    var currentAlignedBytes = pullIntoDescriptor.bytesFilled - pullIntoDescriptor.bytesFilled % elementSize;\n    var maxBytesToCopy = Math.min(controller._queueTotalSize, pullIntoDescriptor.byteLength - pullIntoDescriptor.bytesFilled);\n    var maxBytesFilled = pullIntoDescriptor.bytesFilled + maxBytesToCopy;\n    var maxAlignedBytes = maxBytesFilled - maxBytesFilled % elementSize;\n    var totalBytesToCopyRemaining = maxBytesToCopy;\n    var ready = false;\n    if (maxAlignedBytes > currentAlignedBytes) {\n        totalBytesToCopyRemaining = maxAlignedBytes - pullIntoDescriptor.bytesFilled;\n        ready = true;\n    }\n    var queue = controller._queue;\n    while (totalBytesToCopyRemaining > 0) {\n        var headOfQueue = queue.peek();\n        var bytesToCopy = Math.min(totalBytesToCopyRemaining, headOfQueue.byteLength);\n        var destStart = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n        CopyDataBlockBytes(pullIntoDescriptor.buffer, destStart, headOfQueue.buffer, headOfQueue.byteOffset, bytesToCopy);\n        if (headOfQueue.byteLength === bytesToCopy) {\n            queue.shift();\n        }\n        else {\n            headOfQueue.byteOffset += bytesToCopy;\n            headOfQueue.byteLength -= bytesToCopy;\n        }\n        controller._queueTotalSize -= bytesToCopy;\n        ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesToCopy, pullIntoDescriptor);\n        totalBytesToCopyRemaining -= bytesToCopy;\n    }\n    return ready;\n}\nfunction ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, size, pullIntoDescriptor) {\n    pullIntoDescriptor.bytesFilled += size;\n}\nfunction ReadableByteStreamControllerHandleQueueDrain(controller) {\n    if (controller._queueTotalSize === 0 && controller._closeRequested) {\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamClose(controller._controlledReadableByteStream);\n    }\n    else {\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n}\nfunction ReadableByteStreamControllerInvalidateBYOBRequest(controller) {\n    if (controller._byobRequest === null) {\n        return;\n    }\n    controller._byobRequest._associatedReadableByteStreamController = undefined;\n    controller._byobRequest._view = null;\n    controller._byobRequest = null;\n}\nfunction ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller) {\n    while (controller._pendingPullIntos.length > 0) {\n        if (controller._queueTotalSize === 0) {\n            return;\n        }\n        var pullIntoDescriptor = controller._pendingPullIntos.peek();\n        if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n            ReadableByteStreamControllerShiftPendingPullInto(controller);\n            ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n        }\n    }\n}\nfunction ReadableByteStreamControllerPullInto(controller, view, readIntoRequest) {\n    var stream = controller._controlledReadableByteStream;\n    var elementSize = 1;\n    if (view.constructor !== DataView) {\n        elementSize = view.constructor.BYTES_PER_ELEMENT;\n    }\n    var ctor = view.constructor;\n    // try {\n    var buffer = TransferArrayBuffer(view.buffer);\n    // } catch (e) {\n    //   readIntoRequest._errorSteps(e);\n    //   return;\n    // }\n    var pullIntoDescriptor = {\n        buffer: buffer,\n        bufferByteLength: buffer.byteLength,\n        byteOffset: view.byteOffset,\n        byteLength: view.byteLength,\n        bytesFilled: 0,\n        elementSize: elementSize,\n        viewConstructor: ctor,\n        readerType: 'byob'\n    };\n    if (controller._pendingPullIntos.length > 0) {\n        controller._pendingPullIntos.push(pullIntoDescriptor);\n        // No ReadableByteStreamControllerCallPullIfNeeded() call since:\n        // - No change happens on desiredSize\n        // - The source has already been notified of that there's at least 1 pending read(view)\n        ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n        return;\n    }\n    if (stream._state === 'closed') {\n        var emptyView = new ctor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, 0);\n        readIntoRequest._closeSteps(emptyView);\n        return;\n    }\n    if (controller._queueTotalSize > 0) {\n        if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n            var filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n            ReadableByteStreamControllerHandleQueueDrain(controller);\n            readIntoRequest._chunkSteps(filledView);\n            return;\n        }\n        if (controller._closeRequested) {\n            var e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n            ReadableByteStreamControllerError(controller, e);\n            readIntoRequest._errorSteps(e);\n            return;\n        }\n    }\n    controller._pendingPullIntos.push(pullIntoDescriptor);\n    ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n    ReadableByteStreamControllerCallPullIfNeeded(controller);\n}\nfunction ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor) {\n    var stream = controller._controlledReadableByteStream;\n    if (ReadableStreamHasBYOBReader(stream)) {\n        while (ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n            var pullIntoDescriptor = ReadableByteStreamControllerShiftPendingPullInto(controller);\n            ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor);\n        }\n    }\n}\nfunction ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, pullIntoDescriptor) {\n    ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesWritten, pullIntoDescriptor);\n    if (pullIntoDescriptor.bytesFilled < pullIntoDescriptor.elementSize) {\n        return;\n    }\n    ReadableByteStreamControllerShiftPendingPullInto(controller);\n    var remainderSize = pullIntoDescriptor.bytesFilled % pullIntoDescriptor.elementSize;\n    if (remainderSize > 0) {\n        var end = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n        var remainder = ArrayBufferSlice(pullIntoDescriptor.buffer, end - remainderSize, end);\n        ReadableByteStreamControllerEnqueueChunkToQueue(controller, remainder, 0, remainder.byteLength);\n    }\n    pullIntoDescriptor.bytesFilled -= remainderSize;\n    ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n    ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n}\nfunction ReadableByteStreamControllerRespondInternal(controller, bytesWritten) {\n    var firstDescriptor = controller._pendingPullIntos.peek();\n    ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n    var state = controller._controlledReadableByteStream._state;\n    if (state === 'closed') {\n        ReadableByteStreamControllerRespondInClosedState(controller);\n    }\n    else {\n        ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, firstDescriptor);\n    }\n    ReadableByteStreamControllerCallPullIfNeeded(controller);\n}\nfunction ReadableByteStreamControllerShiftPendingPullInto(controller) {\n    var descriptor = controller._pendingPullIntos.shift();\n    return descriptor;\n}\nfunction ReadableByteStreamControllerShouldCallPull(controller) {\n    var stream = controller._controlledReadableByteStream;\n    if (stream._state !== 'readable') {\n        return false;\n    }\n    if (controller._closeRequested) {\n        return false;\n    }\n    if (!controller._started) {\n        return false;\n    }\n    if (ReadableStreamHasDefaultReader(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n        return true;\n    }\n    if (ReadableStreamHasBYOBReader(stream) && ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n        return true;\n    }\n    var desiredSize = ReadableByteStreamControllerGetDesiredSize(controller);\n    if (desiredSize > 0) {\n        return true;\n    }\n    return false;\n}\nfunction ReadableByteStreamControllerClearAlgorithms(controller) {\n    controller._pullAlgorithm = undefined;\n    controller._cancelAlgorithm = undefined;\n}\n// A client of ReadableByteStreamController may use these functions directly to bypass state check.\nfunction ReadableByteStreamControllerClose(controller) {\n    var stream = controller._controlledReadableByteStream;\n    if (controller._closeRequested || stream._state !== 'readable') {\n        return;\n    }\n    if (controller._queueTotalSize > 0) {\n        controller._closeRequested = true;\n        return;\n    }\n    if (controller._pendingPullIntos.length > 0) {\n        var firstPendingPullInto = controller._pendingPullIntos.peek();\n        if (firstPendingPullInto.bytesFilled > 0) {\n            var e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n            ReadableByteStreamControllerError(controller, e);\n            throw e;\n        }\n    }\n    ReadableByteStreamControllerClearAlgorithms(controller);\n    ReadableStreamClose(stream);\n}\nfunction ReadableByteStreamControllerEnqueue(controller, chunk) {\n    var stream = controller._controlledReadableByteStream;\n    if (controller._closeRequested || stream._state !== 'readable') {\n        return;\n    }\n    var buffer = chunk.buffer;\n    var byteOffset = chunk.byteOffset;\n    var byteLength = chunk.byteLength;\n    var transferredBuffer = TransferArrayBuffer(buffer);\n    if (controller._pendingPullIntos.length > 0) {\n        var firstPendingPullInto = controller._pendingPullIntos.peek();\n        if (IsDetachedBuffer(firstPendingPullInto.buffer)) ;\n        firstPendingPullInto.buffer = TransferArrayBuffer(firstPendingPullInto.buffer);\n    }\n    ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n    if (ReadableStreamHasDefaultReader(stream)) {\n        if (ReadableStreamGetNumReadRequests(stream) === 0) {\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n        }\n        else {\n            if (controller._pendingPullIntos.length > 0) {\n                ReadableByteStreamControllerShiftPendingPullInto(controller);\n            }\n            var transferredView = new Uint8Array(transferredBuffer, byteOffset, byteLength);\n            ReadableStreamFulfillReadRequest(stream, transferredView, false);\n        }\n    }\n    else if (ReadableStreamHasBYOBReader(stream)) {\n        // TODO: Ideally in this branch detaching should happen only if the buffer is not consumed fully.\n        ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n        ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n    }\n    else {\n        ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n    }\n    ReadableByteStreamControllerCallPullIfNeeded(controller);\n}\nfunction ReadableByteStreamControllerError(controller, e) {\n    var stream = controller._controlledReadableByteStream;\n    if (stream._state !== 'readable') {\n        return;\n    }\n    ReadableByteStreamControllerClearPendingPullIntos(controller);\n    ResetQueue(controller);\n    ReadableByteStreamControllerClearAlgorithms(controller);\n    ReadableStreamError(stream, e);\n}\nfunction ReadableByteStreamControllerGetBYOBRequest(controller) {\n    if (controller._byobRequest === null && controller._pendingPullIntos.length > 0) {\n        var firstDescriptor = controller._pendingPullIntos.peek();\n        var view = new Uint8Array(firstDescriptor.buffer, firstDescriptor.byteOffset + firstDescriptor.bytesFilled, firstDescriptor.byteLength - firstDescriptor.bytesFilled);\n        var byobRequest = Object.create(ReadableStreamBYOBRequest.prototype);\n        SetUpReadableStreamBYOBRequest(byobRequest, controller, view);\n        controller._byobRequest = byobRequest;\n    }\n    return controller._byobRequest;\n}\nfunction ReadableByteStreamControllerGetDesiredSize(controller) {\n    var state = controller._controlledReadableByteStream._state;\n    if (state === 'errored') {\n        return null;\n    }\n    if (state === 'closed') {\n        return 0;\n    }\n    return controller._strategyHWM - controller._queueTotalSize;\n}\nfunction ReadableByteStreamControllerRespond(controller, bytesWritten) {\n    var firstDescriptor = controller._pendingPullIntos.peek();\n    var state = controller._controlledReadableByteStream._state;\n    if (state === 'closed') {\n        if (bytesWritten !== 0) {\n            throw new TypeError('bytesWritten must be 0 when calling respond() on a closed stream');\n        }\n    }\n    else {\n        if (bytesWritten === 0) {\n            throw new TypeError('bytesWritten must be greater than 0 when calling respond() on a readable stream');\n        }\n        if (firstDescriptor.bytesFilled + bytesWritten > firstDescriptor.byteLength) {\n            throw new RangeError('bytesWritten out of range');\n        }\n    }\n    firstDescriptor.buffer = TransferArrayBuffer(firstDescriptor.buffer);\n    ReadableByteStreamControllerRespondInternal(controller, bytesWritten);\n}\nfunction ReadableByteStreamControllerRespondWithNewView(controller, view) {\n    var firstDescriptor = controller._pendingPullIntos.peek();\n    var state = controller._controlledReadableByteStream._state;\n    if (state === 'closed') {\n        if (view.byteLength !== 0) {\n            throw new TypeError('The view\\'s length must be 0 when calling respondWithNewView() on a closed stream');\n        }\n    }\n    else {\n        if (view.byteLength === 0) {\n            throw new TypeError('The view\\'s length must be greater than 0 when calling respondWithNewView() on a readable stream');\n        }\n    }\n    if (firstDescriptor.byteOffset + firstDescriptor.bytesFilled !== view.byteOffset) {\n        throw new RangeError('The region specified by view does not match byobRequest');\n    }\n    if (firstDescriptor.bufferByteLength !== view.buffer.byteLength) {\n        throw new RangeError('The buffer of view has different capacity than byobRequest');\n    }\n    if (firstDescriptor.bytesFilled + view.byteLength > firstDescriptor.byteLength) {\n        throw new RangeError('The region specified by view is larger than byobRequest');\n    }\n    var viewByteLength = view.byteLength;\n    firstDescriptor.buffer = TransferArrayBuffer(view.buffer);\n    ReadableByteStreamControllerRespondInternal(controller, viewByteLength);\n}\nfunction SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize) {\n    controller._controlledReadableByteStream = stream;\n    controller._pullAgain = false;\n    controller._pulling = false;\n    controller._byobRequest = null;\n    // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n    controller._queue = controller._queueTotalSize = undefined;\n    ResetQueue(controller);\n    controller._closeRequested = false;\n    controller._started = false;\n    controller._strategyHWM = highWaterMark;\n    controller._pullAlgorithm = pullAlgorithm;\n    controller._cancelAlgorithm = cancelAlgorithm;\n    controller._autoAllocateChunkSize = autoAllocateChunkSize;\n    controller._pendingPullIntos = new SimpleQueue();\n    stream._readableStreamController = controller;\n    var startResult = startAlgorithm();\n    uponPromise(promiseResolvedWith(startResult), function () {\n        controller._started = true;\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }, function (r) {\n        ReadableByteStreamControllerError(controller, r);\n    });\n}\nfunction SetUpReadableByteStreamControllerFromUnderlyingSource(stream, underlyingByteSource, highWaterMark) {\n    var controller = Object.create(ReadableByteStreamController.prototype);\n    var startAlgorithm = function () { return undefined; };\n    var pullAlgorithm = function () { return promiseResolvedWith(undefined); };\n    var cancelAlgorithm = function () { return promiseResolvedWith(undefined); };\n    if (underlyingByteSource.start !== undefined) {\n        startAlgorithm = function () { return underlyingByteSource.start(controller); };\n    }\n    if (underlyingByteSource.pull !== undefined) {\n        pullAlgorithm = function () { return underlyingByteSource.pull(controller); };\n    }\n    if (underlyingByteSource.cancel !== undefined) {\n        cancelAlgorithm = function (reason) { return underlyingByteSource.cancel(reason); };\n    }\n    var autoAllocateChunkSize = underlyingByteSource.autoAllocateChunkSize;\n    if (autoAllocateChunkSize === 0) {\n        throw new TypeError('autoAllocateChunkSize must be greater than 0');\n    }\n    SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize);\n}\nfunction SetUpReadableStreamBYOBRequest(request, controller, view) {\n    request._associatedReadableByteStreamController = controller;\n    request._view = view;\n}\n// Helper functions for the ReadableStreamBYOBRequest.\nfunction byobRequestBrandCheckException(name) {\n    return new TypeError(\"ReadableStreamBYOBRequest.prototype.\" + name + \" can only be used on a ReadableStreamBYOBRequest\");\n}\n// Helper functions for the ReadableByteStreamController.\nfunction byteStreamControllerBrandCheckException(name) {\n    return new TypeError(\"ReadableByteStreamController.prototype.\" + name + \" can only be used on a ReadableByteStreamController\");\n}\n\n// Abstract operations for the ReadableStream.\nfunction AcquireReadableStreamBYOBReader(stream) {\n    return new ReadableStreamBYOBReader(stream);\n}\n// ReadableStream API exposed for controllers.\nfunction ReadableStreamAddReadIntoRequest(stream, readIntoRequest) {\n    stream._reader._readIntoRequests.push(readIntoRequest);\n}\nfunction ReadableStreamFulfillReadIntoRequest(stream, chunk, done) {\n    var reader = stream._reader;\n    var readIntoRequest = reader._readIntoRequests.shift();\n    if (done) {\n        readIntoRequest._closeSteps(chunk);\n    }\n    else {\n        readIntoRequest._chunkSteps(chunk);\n    }\n}\nfunction ReadableStreamGetNumReadIntoRequests(stream) {\n    return stream._reader._readIntoRequests.length;\n}\nfunction ReadableStreamHasBYOBReader(stream) {\n    var reader = stream._reader;\n    if (reader === undefined) {\n        return false;\n    }\n    if (!IsReadableStreamBYOBReader(reader)) {\n        return false;\n    }\n    return true;\n}\n/**\n * A BYOB reader vended by a {@link ReadableStream}.\n *\n * @public\n */\nvar ReadableStreamBYOBReader = /** @class */ (function () {\n    function ReadableStreamBYOBReader(stream) {\n        assertRequiredArgument(stream, 1, 'ReadableStreamBYOBReader');\n        assertReadableStream(stream, 'First parameter');\n        if (IsReadableStreamLocked(stream)) {\n            throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n        }\n        if (!IsReadableByteStreamController(stream._readableStreamController)) {\n            throw new TypeError('Cannot construct a ReadableStreamBYOBReader for a stream not constructed with a byte ' +\n                'source');\n        }\n        ReadableStreamReaderGenericInitialize(this, stream);\n        this._readIntoRequests = new SimpleQueue();\n    }\n    Object.defineProperty(ReadableStreamBYOBReader.prototype, \"closed\", {\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the reader's lock is released before the stream finishes closing.\n         */\n        get: function () {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n     */\n    ReadableStreamBYOBReader.prototype.cancel = function (reason) {\n        if (reason === void 0) { reason = undefined; }\n        if (!IsReadableStreamBYOBReader(this)) {\n            return promiseRejectedWith(byobReaderBrandCheckException('cancel'));\n        }\n        if (this._ownerReadableStream === undefined) {\n            return promiseRejectedWith(readerLockException('cancel'));\n        }\n        return ReadableStreamReaderGenericCancel(this, reason);\n    };\n    /**\n     * Attempts to reads bytes into view, and returns a promise resolved with the result.\n     *\n     * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n     */\n    ReadableStreamBYOBReader.prototype.read = function (view) {\n        if (!IsReadableStreamBYOBReader(this)) {\n            return promiseRejectedWith(byobReaderBrandCheckException('read'));\n        }\n        if (!ArrayBuffer.isView(view)) {\n            return promiseRejectedWith(new TypeError('view must be an array buffer view'));\n        }\n        if (view.byteLength === 0) {\n            return promiseRejectedWith(new TypeError('view must have non-zero byteLength'));\n        }\n        if (view.buffer.byteLength === 0) {\n            return promiseRejectedWith(new TypeError(\"view's buffer must have non-zero byteLength\"));\n        }\n        if (IsDetachedBuffer(view.buffer)) ;\n        if (this._ownerReadableStream === undefined) {\n            return promiseRejectedWith(readerLockException('read from'));\n        }\n        var resolvePromise;\n        var rejectPromise;\n        var promise = newPromise(function (resolve, reject) {\n            resolvePromise = resolve;\n            rejectPromise = reject;\n        });\n        var readIntoRequest = {\n            _chunkSteps: function (chunk) { return resolvePromise({ value: chunk, done: false }); },\n            _closeSteps: function (chunk) { return resolvePromise({ value: chunk, done: true }); },\n            _errorSteps: function (e) { return rejectPromise(e); }\n        };\n        ReadableStreamBYOBReaderRead(this, view, readIntoRequest);\n        return promise;\n    };\n    /**\n     * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n     * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n     * from now on; otherwise, the reader will appear closed.\n     *\n     * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n     * the reader's {@link ReadableStreamBYOBReader.read | read()} method has not yet been settled. Attempting to\n     * do so will throw a `TypeError` and leave the reader locked to the stream.\n     */\n    ReadableStreamBYOBReader.prototype.releaseLock = function () {\n        if (!IsReadableStreamBYOBReader(this)) {\n            throw byobReaderBrandCheckException('releaseLock');\n        }\n        if (this._ownerReadableStream === undefined) {\n            return;\n        }\n        if (this._readIntoRequests.length > 0) {\n            throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n        }\n        ReadableStreamReaderGenericRelease(this);\n    };\n    return ReadableStreamBYOBReader;\n}());\nObject.defineProperties(ReadableStreamBYOBReader.prototype, {\n    cancel: { enumerable: true },\n    read: { enumerable: true },\n    releaseLock: { enumerable: true },\n    closed: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(ReadableStreamBYOBReader.prototype, SymbolPolyfill.toStringTag, {\n        value: 'ReadableStreamBYOBReader',\n        configurable: true\n    });\n}\n// Abstract operations for the readers.\nfunction IsReadableStreamBYOBReader(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_readIntoRequests')) {\n        return false;\n    }\n    return x instanceof ReadableStreamBYOBReader;\n}\nfunction ReadableStreamBYOBReaderRead(reader, view, readIntoRequest) {\n    var stream = reader._ownerReadableStream;\n    stream._disturbed = true;\n    if (stream._state === 'errored') {\n        readIntoRequest._errorSteps(stream._storedError);\n    }\n    else {\n        ReadableByteStreamControllerPullInto(stream._readableStreamController, view, readIntoRequest);\n    }\n}\n// Helper functions for the ReadableStreamBYOBReader.\nfunction byobReaderBrandCheckException(name) {\n    return new TypeError(\"ReadableStreamBYOBReader.prototype.\" + name + \" can only be used on a ReadableStreamBYOBReader\");\n}\n\nfunction ExtractHighWaterMark(strategy, defaultHWM) {\n    var highWaterMark = strategy.highWaterMark;\n    if (highWaterMark === undefined) {\n        return defaultHWM;\n    }\n    if (NumberIsNaN(highWaterMark) || highWaterMark < 0) {\n        throw new RangeError('Invalid highWaterMark');\n    }\n    return highWaterMark;\n}\nfunction ExtractSizeAlgorithm(strategy) {\n    var size = strategy.size;\n    if (!size) {\n        return function () { return 1; };\n    }\n    return size;\n}\n\nfunction convertQueuingStrategy(init, context) {\n    assertDictionary(init, context);\n    var highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n    var size = init === null || init === void 0 ? void 0 : init.size;\n    return {\n        highWaterMark: highWaterMark === undefined ? undefined : convertUnrestrictedDouble(highWaterMark),\n        size: size === undefined ? undefined : convertQueuingStrategySize(size, context + \" has member 'size' that\")\n    };\n}\nfunction convertQueuingStrategySize(fn, context) {\n    assertFunction(fn, context);\n    return function (chunk) { return convertUnrestrictedDouble(fn(chunk)); };\n}\n\nfunction convertUnderlyingSink(original, context) {\n    assertDictionary(original, context);\n    var abort = original === null || original === void 0 ? void 0 : original.abort;\n    var close = original === null || original === void 0 ? void 0 : original.close;\n    var start = original === null || original === void 0 ? void 0 : original.start;\n    var type = original === null || original === void 0 ? void 0 : original.type;\n    var write = original === null || original === void 0 ? void 0 : original.write;\n    return {\n        abort: abort === undefined ?\n            undefined :\n            convertUnderlyingSinkAbortCallback(abort, original, context + \" has member 'abort' that\"),\n        close: close === undefined ?\n            undefined :\n            convertUnderlyingSinkCloseCallback(close, original, context + \" has member 'close' that\"),\n        start: start === undefined ?\n            undefined :\n            convertUnderlyingSinkStartCallback(start, original, context + \" has member 'start' that\"),\n        write: write === undefined ?\n            undefined :\n            convertUnderlyingSinkWriteCallback(write, original, context + \" has member 'write' that\"),\n        type: type\n    };\n}\nfunction convertUnderlyingSinkAbortCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (reason) { return promiseCall(fn, original, [reason]); };\n}\nfunction convertUnderlyingSinkCloseCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function () { return promiseCall(fn, original, []); };\n}\nfunction convertUnderlyingSinkStartCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (controller) { return reflectCall(fn, original, [controller]); };\n}\nfunction convertUnderlyingSinkWriteCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (chunk, controller) { return promiseCall(fn, original, [chunk, controller]); };\n}\n\nfunction assertWritableStream(x, context) {\n    if (!IsWritableStream(x)) {\n        throw new TypeError(context + \" is not a WritableStream.\");\n    }\n}\n\nfunction isAbortSignal(value) {\n    if (typeof value !== 'object' || value === null) {\n        return false;\n    }\n    try {\n        return typeof value.aborted === 'boolean';\n    }\n    catch (_a) {\n        // AbortSignal.prototype.aborted throws if its brand check fails\n        return false;\n    }\n}\nvar supportsAbortController = typeof AbortController === 'function';\n/**\n * Construct a new AbortController, if supported by the platform.\n *\n * @internal\n */\nfunction createAbortController() {\n    if (supportsAbortController) {\n        return new AbortController();\n    }\n    return undefined;\n}\n\n/**\n * A writable stream represents a destination for data, into which you can write.\n *\n * @public\n */\nvar WritableStream = /** @class */ (function () {\n    function WritableStream(rawUnderlyingSink, rawStrategy) {\n        if (rawUnderlyingSink === void 0) { rawUnderlyingSink = {}; }\n        if (rawStrategy === void 0) { rawStrategy = {}; }\n        if (rawUnderlyingSink === undefined) {\n            rawUnderlyingSink = null;\n        }\n        else {\n            assertObject(rawUnderlyingSink, 'First parameter');\n        }\n        var strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n        var underlyingSink = convertUnderlyingSink(rawUnderlyingSink, 'First parameter');\n        InitializeWritableStream(this);\n        var type = underlyingSink.type;\n        if (type !== undefined) {\n            throw new RangeError('Invalid type is specified');\n        }\n        var sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n        var highWaterMark = ExtractHighWaterMark(strategy, 1);\n        SetUpWritableStreamDefaultControllerFromUnderlyingSink(this, underlyingSink, highWaterMark, sizeAlgorithm);\n    }\n    Object.defineProperty(WritableStream.prototype, \"locked\", {\n        /**\n         * Returns whether or not the writable stream is locked to a writer.\n         */\n        get: function () {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('locked');\n            }\n            return IsWritableStreamLocked(this);\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * Aborts the stream, signaling that the producer can no longer successfully write to the stream and it is to be\n     * immediately moved to an errored state, with any queued-up writes discarded. This will also execute any abort\n     * mechanism of the underlying sink.\n     *\n     * The returned promise will fulfill if the stream shuts down successfully, or reject if the underlying sink signaled\n     * that there was an error doing so. Additionally, it will reject with a `TypeError` (without attempting to cancel\n     * the stream) if the stream is currently locked.\n     */\n    WritableStream.prototype.abort = function (reason) {\n        if (reason === void 0) { reason = undefined; }\n        if (!IsWritableStream(this)) {\n            return promiseRejectedWith(streamBrandCheckException$2('abort'));\n        }\n        if (IsWritableStreamLocked(this)) {\n            return promiseRejectedWith(new TypeError('Cannot abort a stream that already has a writer'));\n        }\n        return WritableStreamAbort(this, reason);\n    };\n    /**\n     * Closes the stream. The underlying sink will finish processing any previously-written chunks, before invoking its\n     * close behavior. During this time any further attempts to write will fail (without erroring the stream).\n     *\n     * The method returns a promise that will fulfill if all remaining chunks are successfully written and the stream\n     * successfully closes, or rejects if an error is encountered during this process. Additionally, it will reject with\n     * a `TypeError` (without attempting to cancel the stream) if the stream is currently locked.\n     */\n    WritableStream.prototype.close = function () {\n        if (!IsWritableStream(this)) {\n            return promiseRejectedWith(streamBrandCheckException$2('close'));\n        }\n        if (IsWritableStreamLocked(this)) {\n            return promiseRejectedWith(new TypeError('Cannot close a stream that already has a writer'));\n        }\n        if (WritableStreamCloseQueuedOrInFlight(this)) {\n            return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n        }\n        return WritableStreamClose(this);\n    };\n    /**\n     * Creates a {@link WritableStreamDefaultWriter | writer} and locks the stream to the new writer. While the stream\n     * is locked, no other writer can be acquired until this one is released.\n     *\n     * This functionality is especially useful for creating abstractions that desire the ability to write to a stream\n     * without interruption or interleaving. By getting a writer for the stream, you can ensure nobody else can write at\n     * the same time, which would cause the resulting written data to be unpredictable and probably useless.\n     */\n    WritableStream.prototype.getWriter = function () {\n        if (!IsWritableStream(this)) {\n            throw streamBrandCheckException$2('getWriter');\n        }\n        return AcquireWritableStreamDefaultWriter(this);\n    };\n    return WritableStream;\n}());\nObject.defineProperties(WritableStream.prototype, {\n    abort: { enumerable: true },\n    close: { enumerable: true },\n    getWriter: { enumerable: true },\n    locked: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(WritableStream.prototype, SymbolPolyfill.toStringTag, {\n        value: 'WritableStream',\n        configurable: true\n    });\n}\n// Abstract operations for the WritableStream.\nfunction AcquireWritableStreamDefaultWriter(stream) {\n    return new WritableStreamDefaultWriter(stream);\n}\n// Throws if and only if startAlgorithm throws.\nfunction CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm) {\n    if (highWaterMark === void 0) { highWaterMark = 1; }\n    if (sizeAlgorithm === void 0) { sizeAlgorithm = function () { return 1; }; }\n    var stream = Object.create(WritableStream.prototype);\n    InitializeWritableStream(stream);\n    var controller = Object.create(WritableStreamDefaultController.prototype);\n    SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n    return stream;\n}\nfunction InitializeWritableStream(stream) {\n    stream._state = 'writable';\n    // The error that will be reported by new method calls once the state becomes errored. Only set when [[state]] is\n    // 'erroring' or 'errored'. May be set to an undefined value.\n    stream._storedError = undefined;\n    stream._writer = undefined;\n    // Initialize to undefined first because the constructor of the controller checks this\n    // variable to validate the caller.\n    stream._writableStreamController = undefined;\n    // This queue is placed here instead of the writer class in order to allow for passing a writer to the next data\n    // producer without waiting for the queued writes to finish.\n    stream._writeRequests = new SimpleQueue();\n    // Write requests are removed from _writeRequests when write() is called on the underlying sink. This prevents\n    // them from being erroneously rejected on error. If a write() call is in-flight, the request is stored here.\n    stream._inFlightWriteRequest = undefined;\n    // The promise that was returned from writer.close(). Stored here because it may be fulfilled after the writer\n    // has been detached.\n    stream._closeRequest = undefined;\n    // Close request is removed from _closeRequest when close() is called on the underlying sink. This prevents it\n    // from being erroneously rejected on error. If a close() call is in-flight, the request is stored here.\n    stream._inFlightCloseRequest = undefined;\n    // The promise that was returned from writer.abort(). This may also be fulfilled after the writer has detached.\n    stream._pendingAbortRequest = undefined;\n    // The backpressure signal set by the controller.\n    stream._backpressure = false;\n}\nfunction IsWritableStream(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_writableStreamController')) {\n        return false;\n    }\n    return x instanceof WritableStream;\n}\nfunction IsWritableStreamLocked(stream) {\n    if (stream._writer === undefined) {\n        return false;\n    }\n    return true;\n}\nfunction WritableStreamAbort(stream, reason) {\n    var _a;\n    if (stream._state === 'closed' || stream._state === 'errored') {\n        return promiseResolvedWith(undefined);\n    }\n    stream._writableStreamController._abortReason = reason;\n    (_a = stream._writableStreamController._abortController) === null || _a === void 0 ? void 0 : _a.abort();\n    // TypeScript narrows the type of `stream._state` down to 'writable' | 'erroring',\n    // but it doesn't know that signaling abort runs author code that might have changed the state.\n    // Widen the type again by casting to WritableStreamState.\n    var state = stream._state;\n    if (state === 'closed' || state === 'errored') {\n        return promiseResolvedWith(undefined);\n    }\n    if (stream._pendingAbortRequest !== undefined) {\n        return stream._pendingAbortRequest._promise;\n    }\n    var wasAlreadyErroring = false;\n    if (state === 'erroring') {\n        wasAlreadyErroring = true;\n        // reason will not be used, so don't keep a reference to it.\n        reason = undefined;\n    }\n    var promise = newPromise(function (resolve, reject) {\n        stream._pendingAbortRequest = {\n            _promise: undefined,\n            _resolve: resolve,\n            _reject: reject,\n            _reason: reason,\n            _wasAlreadyErroring: wasAlreadyErroring\n        };\n    });\n    stream._pendingAbortRequest._promise = promise;\n    if (!wasAlreadyErroring) {\n        WritableStreamStartErroring(stream, reason);\n    }\n    return promise;\n}\nfunction WritableStreamClose(stream) {\n    var state = stream._state;\n    if (state === 'closed' || state === 'errored') {\n        return promiseRejectedWith(new TypeError(\"The stream (in \" + state + \" state) is not in the writable state and cannot be closed\"));\n    }\n    var promise = newPromise(function (resolve, reject) {\n        var closeRequest = {\n            _resolve: resolve,\n            _reject: reject\n        };\n        stream._closeRequest = closeRequest;\n    });\n    var writer = stream._writer;\n    if (writer !== undefined && stream._backpressure && state === 'writable') {\n        defaultWriterReadyPromiseResolve(writer);\n    }\n    WritableStreamDefaultControllerClose(stream._writableStreamController);\n    return promise;\n}\n// WritableStream API exposed for controllers.\nfunction WritableStreamAddWriteRequest(stream) {\n    var promise = newPromise(function (resolve, reject) {\n        var writeRequest = {\n            _resolve: resolve,\n            _reject: reject\n        };\n        stream._writeRequests.push(writeRequest);\n    });\n    return promise;\n}\nfunction WritableStreamDealWithRejection(stream, error) {\n    var state = stream._state;\n    if (state === 'writable') {\n        WritableStreamStartErroring(stream, error);\n        return;\n    }\n    WritableStreamFinishErroring(stream);\n}\nfunction WritableStreamStartErroring(stream, reason) {\n    var controller = stream._writableStreamController;\n    stream._state = 'erroring';\n    stream._storedError = reason;\n    var writer = stream._writer;\n    if (writer !== undefined) {\n        WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, reason);\n    }\n    if (!WritableStreamHasOperationMarkedInFlight(stream) && controller._started) {\n        WritableStreamFinishErroring(stream);\n    }\n}\nfunction WritableStreamFinishErroring(stream) {\n    stream._state = 'errored';\n    stream._writableStreamController[ErrorSteps]();\n    var storedError = stream._storedError;\n    stream._writeRequests.forEach(function (writeRequest) {\n        writeRequest._reject(storedError);\n    });\n    stream._writeRequests = new SimpleQueue();\n    if (stream._pendingAbortRequest === undefined) {\n        WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        return;\n    }\n    var abortRequest = stream._pendingAbortRequest;\n    stream._pendingAbortRequest = undefined;\n    if (abortRequest._wasAlreadyErroring) {\n        abortRequest._reject(storedError);\n        WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        return;\n    }\n    var promise = stream._writableStreamController[AbortSteps](abortRequest._reason);\n    uponPromise(promise, function () {\n        abortRequest._resolve();\n        WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n    }, function (reason) {\n        abortRequest._reject(reason);\n        WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n    });\n}\nfunction WritableStreamFinishInFlightWrite(stream) {\n    stream._inFlightWriteRequest._resolve(undefined);\n    stream._inFlightWriteRequest = undefined;\n}\nfunction WritableStreamFinishInFlightWriteWithError(stream, error) {\n    stream._inFlightWriteRequest._reject(error);\n    stream._inFlightWriteRequest = undefined;\n    WritableStreamDealWithRejection(stream, error);\n}\nfunction WritableStreamFinishInFlightClose(stream) {\n    stream._inFlightCloseRequest._resolve(undefined);\n    stream._inFlightCloseRequest = undefined;\n    var state = stream._state;\n    if (state === 'erroring') {\n        // The error was too late to do anything, so it is ignored.\n        stream._storedError = undefined;\n        if (stream._pendingAbortRequest !== undefined) {\n            stream._pendingAbortRequest._resolve();\n            stream._pendingAbortRequest = undefined;\n        }\n    }\n    stream._state = 'closed';\n    var writer = stream._writer;\n    if (writer !== undefined) {\n        defaultWriterClosedPromiseResolve(writer);\n    }\n}\nfunction WritableStreamFinishInFlightCloseWithError(stream, error) {\n    stream._inFlightCloseRequest._reject(error);\n    stream._inFlightCloseRequest = undefined;\n    // Never execute sink abort() after sink close().\n    if (stream._pendingAbortRequest !== undefined) {\n        stream._pendingAbortRequest._reject(error);\n        stream._pendingAbortRequest = undefined;\n    }\n    WritableStreamDealWithRejection(stream, error);\n}\n// TODO(ricea): Fix alphabetical order.\nfunction WritableStreamCloseQueuedOrInFlight(stream) {\n    if (stream._closeRequest === undefined && stream._inFlightCloseRequest === undefined) {\n        return false;\n    }\n    return true;\n}\nfunction WritableStreamHasOperationMarkedInFlight(stream) {\n    if (stream._inFlightWriteRequest === undefined && stream._inFlightCloseRequest === undefined) {\n        return false;\n    }\n    return true;\n}\nfunction WritableStreamMarkCloseRequestInFlight(stream) {\n    stream._inFlightCloseRequest = stream._closeRequest;\n    stream._closeRequest = undefined;\n}\nfunction WritableStreamMarkFirstWriteRequestInFlight(stream) {\n    stream._inFlightWriteRequest = stream._writeRequests.shift();\n}\nfunction WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream) {\n    if (stream._closeRequest !== undefined) {\n        stream._closeRequest._reject(stream._storedError);\n        stream._closeRequest = undefined;\n    }\n    var writer = stream._writer;\n    if (writer !== undefined) {\n        defaultWriterClosedPromiseReject(writer, stream._storedError);\n    }\n}\nfunction WritableStreamUpdateBackpressure(stream, backpressure) {\n    var writer = stream._writer;\n    if (writer !== undefined && backpressure !== stream._backpressure) {\n        if (backpressure) {\n            defaultWriterReadyPromiseReset(writer);\n        }\n        else {\n            defaultWriterReadyPromiseResolve(writer);\n        }\n    }\n    stream._backpressure = backpressure;\n}\n/**\n * A default writer vended by a {@link WritableStream}.\n *\n * @public\n */\nvar WritableStreamDefaultWriter = /** @class */ (function () {\n    function WritableStreamDefaultWriter(stream) {\n        assertRequiredArgument(stream, 1, 'WritableStreamDefaultWriter');\n        assertWritableStream(stream, 'First parameter');\n        if (IsWritableStreamLocked(stream)) {\n            throw new TypeError('This stream has already been locked for exclusive writing by another writer');\n        }\n        this._ownerWritableStream = stream;\n        stream._writer = this;\n        var state = stream._state;\n        if (state === 'writable') {\n            if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._backpressure) {\n                defaultWriterReadyPromiseInitialize(this);\n            }\n            else {\n                defaultWriterReadyPromiseInitializeAsResolved(this);\n            }\n            defaultWriterClosedPromiseInitialize(this);\n        }\n        else if (state === 'erroring') {\n            defaultWriterReadyPromiseInitializeAsRejected(this, stream._storedError);\n            defaultWriterClosedPromiseInitialize(this);\n        }\n        else if (state === 'closed') {\n            defaultWriterReadyPromiseInitializeAsResolved(this);\n            defaultWriterClosedPromiseInitializeAsResolved(this);\n        }\n        else {\n            var storedError = stream._storedError;\n            defaultWriterReadyPromiseInitializeAsRejected(this, storedError);\n            defaultWriterClosedPromiseInitializeAsRejected(this, storedError);\n        }\n    }\n    Object.defineProperty(WritableStreamDefaultWriter.prototype, \"closed\", {\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the writers lock is released before the stream finishes closing.\n         */\n        get: function () {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Object.defineProperty(WritableStreamDefaultWriter.prototype, \"desiredSize\", {\n        /**\n         * Returns the desired size to fill the streams internal queue. It can be negative, if the queue is over-full.\n         * A producer can use this information to determine the right amount of data to write.\n         *\n         * It will be `null` if the stream cannot be successfully written to (due to either being errored, or having an abort\n         * queued up). It will return zero if the stream is closed. And the getter will throw an exception if invoked when\n         * the writers lock is released.\n         */\n        get: function () {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('desiredSize');\n            }\n            if (this._ownerWritableStream === undefined) {\n                throw defaultWriterLockException('desiredSize');\n            }\n            return WritableStreamDefaultWriterGetDesiredSize(this);\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Object.defineProperty(WritableStreamDefaultWriter.prototype, \"ready\", {\n        /**\n         * Returns a promise that will be fulfilled when the desired size to fill the streams internal queue transitions\n         * from non-positive to positive, signaling that it is no longer applying backpressure. Once the desired size dips\n         * back to zero or below, the getter will return a new promise that stays pending until the next transition.\n         *\n         * If the stream becomes errored or aborted, or the writers lock is released, the returned promise will become\n         * rejected.\n         */\n        get: function () {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('ready'));\n            }\n            return this._readyPromise;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * If the reader is active, behaves the same as {@link WritableStream.abort | stream.abort(reason)}.\n     */\n    WritableStreamDefaultWriter.prototype.abort = function (reason) {\n        if (reason === void 0) { reason = undefined; }\n        if (!IsWritableStreamDefaultWriter(this)) {\n            return promiseRejectedWith(defaultWriterBrandCheckException('abort'));\n        }\n        if (this._ownerWritableStream === undefined) {\n            return promiseRejectedWith(defaultWriterLockException('abort'));\n        }\n        return WritableStreamDefaultWriterAbort(this, reason);\n    };\n    /**\n     * If the reader is active, behaves the same as {@link WritableStream.close | stream.close()}.\n     */\n    WritableStreamDefaultWriter.prototype.close = function () {\n        if (!IsWritableStreamDefaultWriter(this)) {\n            return promiseRejectedWith(defaultWriterBrandCheckException('close'));\n        }\n        var stream = this._ownerWritableStream;\n        if (stream === undefined) {\n            return promiseRejectedWith(defaultWriterLockException('close'));\n        }\n        if (WritableStreamCloseQueuedOrInFlight(stream)) {\n            return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n        }\n        return WritableStreamDefaultWriterClose(this);\n    };\n    /**\n     * Releases the writers lock on the corresponding stream. After the lock is released, the writer is no longer active.\n     * If the associated stream is errored when the lock is released, the writer will appear errored in the same way from\n     * now on; otherwise, the writer will appear closed.\n     *\n     * Note that the lock can still be released even if some ongoing writes have not yet finished (i.e. even if the\n     * promises returned from previous calls to {@link WritableStreamDefaultWriter.write | write()} have not yet settled).\n     * Its not necessary to hold the lock on the writer for the duration of the write; the lock instead simply prevents\n     * other producers from writing in an interleaved manner.\n     */\n    WritableStreamDefaultWriter.prototype.releaseLock = function () {\n        if (!IsWritableStreamDefaultWriter(this)) {\n            throw defaultWriterBrandCheckException('releaseLock');\n        }\n        var stream = this._ownerWritableStream;\n        if (stream === undefined) {\n            return;\n        }\n        WritableStreamDefaultWriterRelease(this);\n    };\n    WritableStreamDefaultWriter.prototype.write = function (chunk) {\n        if (chunk === void 0) { chunk = undefined; }\n        if (!IsWritableStreamDefaultWriter(this)) {\n            return promiseRejectedWith(defaultWriterBrandCheckException('write'));\n        }\n        if (this._ownerWritableStream === undefined) {\n            return promiseRejectedWith(defaultWriterLockException('write to'));\n        }\n        return WritableStreamDefaultWriterWrite(this, chunk);\n    };\n    return WritableStreamDefaultWriter;\n}());\nObject.defineProperties(WritableStreamDefaultWriter.prototype, {\n    abort: { enumerable: true },\n    close: { enumerable: true },\n    releaseLock: { enumerable: true },\n    write: { enumerable: true },\n    closed: { enumerable: true },\n    desiredSize: { enumerable: true },\n    ready: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(WritableStreamDefaultWriter.prototype, SymbolPolyfill.toStringTag, {\n        value: 'WritableStreamDefaultWriter',\n        configurable: true\n    });\n}\n// Abstract operations for the WritableStreamDefaultWriter.\nfunction IsWritableStreamDefaultWriter(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_ownerWritableStream')) {\n        return false;\n    }\n    return x instanceof WritableStreamDefaultWriter;\n}\n// A client of WritableStreamDefaultWriter may use these functions directly to bypass state check.\nfunction WritableStreamDefaultWriterAbort(writer, reason) {\n    var stream = writer._ownerWritableStream;\n    return WritableStreamAbort(stream, reason);\n}\nfunction WritableStreamDefaultWriterClose(writer) {\n    var stream = writer._ownerWritableStream;\n    return WritableStreamClose(stream);\n}\nfunction WritableStreamDefaultWriterCloseWithErrorPropagation(writer) {\n    var stream = writer._ownerWritableStream;\n    var state = stream._state;\n    if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n        return promiseResolvedWith(undefined);\n    }\n    if (state === 'errored') {\n        return promiseRejectedWith(stream._storedError);\n    }\n    return WritableStreamDefaultWriterClose(writer);\n}\nfunction WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, error) {\n    if (writer._closedPromiseState === 'pending') {\n        defaultWriterClosedPromiseReject(writer, error);\n    }\n    else {\n        defaultWriterClosedPromiseResetToRejected(writer, error);\n    }\n}\nfunction WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, error) {\n    if (writer._readyPromiseState === 'pending') {\n        defaultWriterReadyPromiseReject(writer, error);\n    }\n    else {\n        defaultWriterReadyPromiseResetToRejected(writer, error);\n    }\n}\nfunction WritableStreamDefaultWriterGetDesiredSize(writer) {\n    var stream = writer._ownerWritableStream;\n    var state = stream._state;\n    if (state === 'errored' || state === 'erroring') {\n        return null;\n    }\n    if (state === 'closed') {\n        return 0;\n    }\n    return WritableStreamDefaultControllerGetDesiredSize(stream._writableStreamController);\n}\nfunction WritableStreamDefaultWriterRelease(writer) {\n    var stream = writer._ownerWritableStream;\n    var releasedError = new TypeError(\"Writer was released and can no longer be used to monitor the stream's closedness\");\n    WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, releasedError);\n    // The state transitions to \"errored\" before the sink abort() method runs, but the writer.closed promise is not\n    // rejected until afterwards. This means that simply testing state will not work.\n    WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, releasedError);\n    stream._writer = undefined;\n    writer._ownerWritableStream = undefined;\n}\nfunction WritableStreamDefaultWriterWrite(writer, chunk) {\n    var stream = writer._ownerWritableStream;\n    var controller = stream._writableStreamController;\n    var chunkSize = WritableStreamDefaultControllerGetChunkSize(controller, chunk);\n    if (stream !== writer._ownerWritableStream) {\n        return promiseRejectedWith(defaultWriterLockException('write to'));\n    }\n    var state = stream._state;\n    if (state === 'errored') {\n        return promiseRejectedWith(stream._storedError);\n    }\n    if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n        return promiseRejectedWith(new TypeError('The stream is closing or closed and cannot be written to'));\n    }\n    if (state === 'erroring') {\n        return promiseRejectedWith(stream._storedError);\n    }\n    var promise = WritableStreamAddWriteRequest(stream);\n    WritableStreamDefaultControllerWrite(controller, chunk, chunkSize);\n    return promise;\n}\nvar closeSentinel = {};\n/**\n * Allows control of a {@link WritableStream | writable stream}'s state and internal queue.\n *\n * @public\n */\nvar WritableStreamDefaultController = /** @class */ (function () {\n    function WritableStreamDefaultController() {\n        throw new TypeError('Illegal constructor');\n    }\n    Object.defineProperty(WritableStreamDefaultController.prototype, \"abortReason\", {\n        /**\n         * The reason which was passed to `WritableStream.abort(reason)` when the stream was aborted.\n         *\n         * @deprecated\n         *  This property has been removed from the specification, see https://github.com/whatwg/streams/pull/1177.\n         *  Use {@link WritableStreamDefaultController.signal}'s `reason` instead.\n         */\n        get: function () {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('abortReason');\n            }\n            return this._abortReason;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Object.defineProperty(WritableStreamDefaultController.prototype, \"signal\", {\n        /**\n         * An `AbortSignal` that can be used to abort the pending write or close operation when the stream is aborted.\n         */\n        get: function () {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('signal');\n            }\n            if (this._abortController === undefined) {\n                // Older browsers or older Node versions may not support `AbortController` or `AbortSignal`.\n                // We don't want to bundle and ship an `AbortController` polyfill together with our polyfill,\n                // so instead we only implement support for `signal` if we find a global `AbortController` constructor.\n                throw new TypeError('WritableStreamDefaultController.prototype.signal is not supported');\n            }\n            return this._abortController.signal;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * Closes the controlled writable stream, making all future interactions with it fail with the given error `e`.\n     *\n     * This method is rarely used, since usually it suffices to return a rejected promise from one of the underlying\n     * sink's methods. However, it can be useful for suddenly shutting down a stream in response to an event outside the\n     * normal lifecycle of interactions with the underlying sink.\n     */\n    WritableStreamDefaultController.prototype.error = function (e) {\n        if (e === void 0) { e = undefined; }\n        if (!IsWritableStreamDefaultController(this)) {\n            throw defaultControllerBrandCheckException$2('error');\n        }\n        var state = this._controlledWritableStream._state;\n        if (state !== 'writable') {\n            // The stream is closed, errored or will be soon. The sink can't do anything useful if it gets an error here, so\n            // just treat it as a no-op.\n            return;\n        }\n        WritableStreamDefaultControllerError(this, e);\n    };\n    /** @internal */\n    WritableStreamDefaultController.prototype[AbortSteps] = function (reason) {\n        var result = this._abortAlgorithm(reason);\n        WritableStreamDefaultControllerClearAlgorithms(this);\n        return result;\n    };\n    /** @internal */\n    WritableStreamDefaultController.prototype[ErrorSteps] = function () {\n        ResetQueue(this);\n    };\n    return WritableStreamDefaultController;\n}());\nObject.defineProperties(WritableStreamDefaultController.prototype, {\n    abortReason: { enumerable: true },\n    signal: { enumerable: true },\n    error: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(WritableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n        value: 'WritableStreamDefaultController',\n        configurable: true\n    });\n}\n// Abstract operations implementing interface required by the WritableStream.\nfunction IsWritableStreamDefaultController(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_controlledWritableStream')) {\n        return false;\n    }\n    return x instanceof WritableStreamDefaultController;\n}\nfunction SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm) {\n    controller._controlledWritableStream = stream;\n    stream._writableStreamController = controller;\n    // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n    controller._queue = undefined;\n    controller._queueTotalSize = undefined;\n    ResetQueue(controller);\n    controller._abortReason = undefined;\n    controller._abortController = createAbortController();\n    controller._started = false;\n    controller._strategySizeAlgorithm = sizeAlgorithm;\n    controller._strategyHWM = highWaterMark;\n    controller._writeAlgorithm = writeAlgorithm;\n    controller._closeAlgorithm = closeAlgorithm;\n    controller._abortAlgorithm = abortAlgorithm;\n    var backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n    WritableStreamUpdateBackpressure(stream, backpressure);\n    var startResult = startAlgorithm();\n    var startPromise = promiseResolvedWith(startResult);\n    uponPromise(startPromise, function () {\n        controller._started = true;\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }, function (r) {\n        controller._started = true;\n        WritableStreamDealWithRejection(stream, r);\n    });\n}\nfunction SetUpWritableStreamDefaultControllerFromUnderlyingSink(stream, underlyingSink, highWaterMark, sizeAlgorithm) {\n    var controller = Object.create(WritableStreamDefaultController.prototype);\n    var startAlgorithm = function () { return undefined; };\n    var writeAlgorithm = function () { return promiseResolvedWith(undefined); };\n    var closeAlgorithm = function () { return promiseResolvedWith(undefined); };\n    var abortAlgorithm = function () { return promiseResolvedWith(undefined); };\n    if (underlyingSink.start !== undefined) {\n        startAlgorithm = function () { return underlyingSink.start(controller); };\n    }\n    if (underlyingSink.write !== undefined) {\n        writeAlgorithm = function (chunk) { return underlyingSink.write(chunk, controller); };\n    }\n    if (underlyingSink.close !== undefined) {\n        closeAlgorithm = function () { return underlyingSink.close(); };\n    }\n    if (underlyingSink.abort !== undefined) {\n        abortAlgorithm = function (reason) { return underlyingSink.abort(reason); };\n    }\n    SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n}\n// ClearAlgorithms may be called twice. Erroring the same stream in multiple ways will often result in redundant calls.\nfunction WritableStreamDefaultControllerClearAlgorithms(controller) {\n    controller._writeAlgorithm = undefined;\n    controller._closeAlgorithm = undefined;\n    controller._abortAlgorithm = undefined;\n    controller._strategySizeAlgorithm = undefined;\n}\nfunction WritableStreamDefaultControllerClose(controller) {\n    EnqueueValueWithSize(controller, closeSentinel, 0);\n    WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n}\nfunction WritableStreamDefaultControllerGetChunkSize(controller, chunk) {\n    try {\n        return controller._strategySizeAlgorithm(chunk);\n    }\n    catch (chunkSizeE) {\n        WritableStreamDefaultControllerErrorIfNeeded(controller, chunkSizeE);\n        return 1;\n    }\n}\nfunction WritableStreamDefaultControllerGetDesiredSize(controller) {\n    return controller._strategyHWM - controller._queueTotalSize;\n}\nfunction WritableStreamDefaultControllerWrite(controller, chunk, chunkSize) {\n    try {\n        EnqueueValueWithSize(controller, chunk, chunkSize);\n    }\n    catch (enqueueE) {\n        WritableStreamDefaultControllerErrorIfNeeded(controller, enqueueE);\n        return;\n    }\n    var stream = controller._controlledWritableStream;\n    if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._state === 'writable') {\n        var backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n        WritableStreamUpdateBackpressure(stream, backpressure);\n    }\n    WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n}\n// Abstract operations for the WritableStreamDefaultController.\nfunction WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller) {\n    var stream = controller._controlledWritableStream;\n    if (!controller._started) {\n        return;\n    }\n    if (stream._inFlightWriteRequest !== undefined) {\n        return;\n    }\n    var state = stream._state;\n    if (state === 'erroring') {\n        WritableStreamFinishErroring(stream);\n        return;\n    }\n    if (controller._queue.length === 0) {\n        return;\n    }\n    var value = PeekQueueValue(controller);\n    if (value === closeSentinel) {\n        WritableStreamDefaultControllerProcessClose(controller);\n    }\n    else {\n        WritableStreamDefaultControllerProcessWrite(controller, value);\n    }\n}\nfunction WritableStreamDefaultControllerErrorIfNeeded(controller, error) {\n    if (controller._controlledWritableStream._state === 'writable') {\n        WritableStreamDefaultControllerError(controller, error);\n    }\n}\nfunction WritableStreamDefaultControllerProcessClose(controller) {\n    var stream = controller._controlledWritableStream;\n    WritableStreamMarkCloseRequestInFlight(stream);\n    DequeueValue(controller);\n    var sinkClosePromise = controller._closeAlgorithm();\n    WritableStreamDefaultControllerClearAlgorithms(controller);\n    uponPromise(sinkClosePromise, function () {\n        WritableStreamFinishInFlightClose(stream);\n    }, function (reason) {\n        WritableStreamFinishInFlightCloseWithError(stream, reason);\n    });\n}\nfunction WritableStreamDefaultControllerProcessWrite(controller, chunk) {\n    var stream = controller._controlledWritableStream;\n    WritableStreamMarkFirstWriteRequestInFlight(stream);\n    var sinkWritePromise = controller._writeAlgorithm(chunk);\n    uponPromise(sinkWritePromise, function () {\n        WritableStreamFinishInFlightWrite(stream);\n        var state = stream._state;\n        DequeueValue(controller);\n        if (!WritableStreamCloseQueuedOrInFlight(stream) && state === 'writable') {\n            var backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n            WritableStreamUpdateBackpressure(stream, backpressure);\n        }\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }, function (reason) {\n        if (stream._state === 'writable') {\n            WritableStreamDefaultControllerClearAlgorithms(controller);\n        }\n        WritableStreamFinishInFlightWriteWithError(stream, reason);\n    });\n}\nfunction WritableStreamDefaultControllerGetBackpressure(controller) {\n    var desiredSize = WritableStreamDefaultControllerGetDesiredSize(controller);\n    return desiredSize <= 0;\n}\n// A client of WritableStreamDefaultController may use these functions directly to bypass state check.\nfunction WritableStreamDefaultControllerError(controller, error) {\n    var stream = controller._controlledWritableStream;\n    WritableStreamDefaultControllerClearAlgorithms(controller);\n    WritableStreamStartErroring(stream, error);\n}\n// Helper functions for the WritableStream.\nfunction streamBrandCheckException$2(name) {\n    return new TypeError(\"WritableStream.prototype.\" + name + \" can only be used on a WritableStream\");\n}\n// Helper functions for the WritableStreamDefaultController.\nfunction defaultControllerBrandCheckException$2(name) {\n    return new TypeError(\"WritableStreamDefaultController.prototype.\" + name + \" can only be used on a WritableStreamDefaultController\");\n}\n// Helper functions for the WritableStreamDefaultWriter.\nfunction defaultWriterBrandCheckException(name) {\n    return new TypeError(\"WritableStreamDefaultWriter.prototype.\" + name + \" can only be used on a WritableStreamDefaultWriter\");\n}\nfunction defaultWriterLockException(name) {\n    return new TypeError('Cannot ' + name + ' a stream using a released writer');\n}\nfunction defaultWriterClosedPromiseInitialize(writer) {\n    writer._closedPromise = newPromise(function (resolve, reject) {\n        writer._closedPromise_resolve = resolve;\n        writer._closedPromise_reject = reject;\n        writer._closedPromiseState = 'pending';\n    });\n}\nfunction defaultWriterClosedPromiseInitializeAsRejected(writer, reason) {\n    defaultWriterClosedPromiseInitialize(writer);\n    defaultWriterClosedPromiseReject(writer, reason);\n}\nfunction defaultWriterClosedPromiseInitializeAsResolved(writer) {\n    defaultWriterClosedPromiseInitialize(writer);\n    defaultWriterClosedPromiseResolve(writer);\n}\nfunction defaultWriterClosedPromiseReject(writer, reason) {\n    if (writer._closedPromise_reject === undefined) {\n        return;\n    }\n    setPromiseIsHandledToTrue(writer._closedPromise);\n    writer._closedPromise_reject(reason);\n    writer._closedPromise_resolve = undefined;\n    writer._closedPromise_reject = undefined;\n    writer._closedPromiseState = 'rejected';\n}\nfunction defaultWriterClosedPromiseResetToRejected(writer, reason) {\n    defaultWriterClosedPromiseInitializeAsRejected(writer, reason);\n}\nfunction defaultWriterClosedPromiseResolve(writer) {\n    if (writer._closedPromise_resolve === undefined) {\n        return;\n    }\n    writer._closedPromise_resolve(undefined);\n    writer._closedPromise_resolve = undefined;\n    writer._closedPromise_reject = undefined;\n    writer._closedPromiseState = 'resolved';\n}\nfunction defaultWriterReadyPromiseInitialize(writer) {\n    writer._readyPromise = newPromise(function (resolve, reject) {\n        writer._readyPromise_resolve = resolve;\n        writer._readyPromise_reject = reject;\n    });\n    writer._readyPromiseState = 'pending';\n}\nfunction defaultWriterReadyPromiseInitializeAsRejected(writer, reason) {\n    defaultWriterReadyPromiseInitialize(writer);\n    defaultWriterReadyPromiseReject(writer, reason);\n}\nfunction defaultWriterReadyPromiseInitializeAsResolved(writer) {\n    defaultWriterReadyPromiseInitialize(writer);\n    defaultWriterReadyPromiseResolve(writer);\n}\nfunction defaultWriterReadyPromiseReject(writer, reason) {\n    if (writer._readyPromise_reject === undefined) {\n        return;\n    }\n    setPromiseIsHandledToTrue(writer._readyPromise);\n    writer._readyPromise_reject(reason);\n    writer._readyPromise_resolve = undefined;\n    writer._readyPromise_reject = undefined;\n    writer._readyPromiseState = 'rejected';\n}\nfunction defaultWriterReadyPromiseReset(writer) {\n    defaultWriterReadyPromiseInitialize(writer);\n}\nfunction defaultWriterReadyPromiseResetToRejected(writer, reason) {\n    defaultWriterReadyPromiseInitializeAsRejected(writer, reason);\n}\nfunction defaultWriterReadyPromiseResolve(writer) {\n    if (writer._readyPromise_resolve === undefined) {\n        return;\n    }\n    writer._readyPromise_resolve(undefined);\n    writer._readyPromise_resolve = undefined;\n    writer._readyPromise_reject = undefined;\n    writer._readyPromiseState = 'fulfilled';\n}\n\n/// <reference lib=\"dom\" />\nvar NativeDOMException = typeof DOMException !== 'undefined' ? DOMException : undefined;\n\n/// <reference types=\"node\" />\nfunction isDOMExceptionConstructor(ctor) {\n    if (!(typeof ctor === 'function' || typeof ctor === 'object')) {\n        return false;\n    }\n    try {\n        new ctor();\n        return true;\n    }\n    catch (_a) {\n        return false;\n    }\n}\nfunction createDOMExceptionPolyfill() {\n    // eslint-disable-next-line no-shadow\n    var ctor = function DOMException(message, name) {\n        this.message = message || '';\n        this.name = name || 'Error';\n        if (Error.captureStackTrace) {\n            Error.captureStackTrace(this, this.constructor);\n        }\n    };\n    ctor.prototype = Object.create(Error.prototype);\n    Object.defineProperty(ctor.prototype, 'constructor', { value: ctor, writable: true, configurable: true });\n    return ctor;\n}\n// eslint-disable-next-line no-redeclare\nvar DOMException$1 = isDOMExceptionConstructor(NativeDOMException) ? NativeDOMException : createDOMExceptionPolyfill();\n\nfunction ReadableStreamPipeTo(source, dest, preventClose, preventAbort, preventCancel, signal) {\n    var reader = AcquireReadableStreamDefaultReader(source);\n    var writer = AcquireWritableStreamDefaultWriter(dest);\n    source._disturbed = true;\n    var shuttingDown = false;\n    // This is used to keep track of the spec's requirement that we wait for ongoing writes during shutdown.\n    var currentWrite = promiseResolvedWith(undefined);\n    return newPromise(function (resolve, reject) {\n        var abortAlgorithm;\n        if (signal !== undefined) {\n            abortAlgorithm = function () {\n                var error = new DOMException$1('Aborted', 'AbortError');\n                var actions = [];\n                if (!preventAbort) {\n                    actions.push(function () {\n                        if (dest._state === 'writable') {\n                            return WritableStreamAbort(dest, error);\n                        }\n                        return promiseResolvedWith(undefined);\n                    });\n                }\n                if (!preventCancel) {\n                    actions.push(function () {\n                        if (source._state === 'readable') {\n                            return ReadableStreamCancel(source, error);\n                        }\n                        return promiseResolvedWith(undefined);\n                    });\n                }\n                shutdownWithAction(function () { return Promise.all(actions.map(function (action) { return action(); })); }, true, error);\n            };\n            if (signal.aborted) {\n                abortAlgorithm();\n                return;\n            }\n            signal.addEventListener('abort', abortAlgorithm);\n        }\n        // Using reader and writer, read all chunks from this and write them to dest\n        // - Backpressure must be enforced\n        // - Shutdown must stop all activity\n        function pipeLoop() {\n            return newPromise(function (resolveLoop, rejectLoop) {\n                function next(done) {\n                    if (done) {\n                        resolveLoop();\n                    }\n                    else {\n                        // Use `PerformPromiseThen` instead of `uponPromise` to avoid\n                        // adding unnecessary `.catch(rethrowAssertionErrorRejection)` handlers\n                        PerformPromiseThen(pipeStep(), next, rejectLoop);\n                    }\n                }\n                next(false);\n            });\n        }\n        function pipeStep() {\n            if (shuttingDown) {\n                return promiseResolvedWith(true);\n            }\n            return PerformPromiseThen(writer._readyPromise, function () {\n                return newPromise(function (resolveRead, rejectRead) {\n                    ReadableStreamDefaultReaderRead(reader, {\n                        _chunkSteps: function (chunk) {\n                            currentWrite = PerformPromiseThen(WritableStreamDefaultWriterWrite(writer, chunk), undefined, noop);\n                            resolveRead(false);\n                        },\n                        _closeSteps: function () { return resolveRead(true); },\n                        _errorSteps: rejectRead\n                    });\n                });\n            });\n        }\n        // Errors must be propagated forward\n        isOrBecomesErrored(source, reader._closedPromise, function (storedError) {\n            if (!preventAbort) {\n                shutdownWithAction(function () { return WritableStreamAbort(dest, storedError); }, true, storedError);\n            }\n            else {\n                shutdown(true, storedError);\n            }\n        });\n        // Errors must be propagated backward\n        isOrBecomesErrored(dest, writer._closedPromise, function (storedError) {\n            if (!preventCancel) {\n                shutdownWithAction(function () { return ReadableStreamCancel(source, storedError); }, true, storedError);\n            }\n            else {\n                shutdown(true, storedError);\n            }\n        });\n        // Closing must be propagated forward\n        isOrBecomesClosed(source, reader._closedPromise, function () {\n            if (!preventClose) {\n                shutdownWithAction(function () { return WritableStreamDefaultWriterCloseWithErrorPropagation(writer); });\n            }\n            else {\n                shutdown();\n            }\n        });\n        // Closing must be propagated backward\n        if (WritableStreamCloseQueuedOrInFlight(dest) || dest._state === 'closed') {\n            var destClosed_1 = new TypeError('the destination writable stream closed before all data could be piped to it');\n            if (!preventCancel) {\n                shutdownWithAction(function () { return ReadableStreamCancel(source, destClosed_1); }, true, destClosed_1);\n            }\n            else {\n                shutdown(true, destClosed_1);\n            }\n        }\n        setPromiseIsHandledToTrue(pipeLoop());\n        function waitForWritesToFinish() {\n            // Another write may have started while we were waiting on this currentWrite, so we have to be sure to wait\n            // for that too.\n            var oldCurrentWrite = currentWrite;\n            return PerformPromiseThen(currentWrite, function () { return oldCurrentWrite !== currentWrite ? waitForWritesToFinish() : undefined; });\n        }\n        function isOrBecomesErrored(stream, promise, action) {\n            if (stream._state === 'errored') {\n                action(stream._storedError);\n            }\n            else {\n                uponRejection(promise, action);\n            }\n        }\n        function isOrBecomesClosed(stream, promise, action) {\n            if (stream._state === 'closed') {\n                action();\n            }\n            else {\n                uponFulfillment(promise, action);\n            }\n        }\n        function shutdownWithAction(action, originalIsError, originalError) {\n            if (shuttingDown) {\n                return;\n            }\n            shuttingDown = true;\n            if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                uponFulfillment(waitForWritesToFinish(), doTheRest);\n            }\n            else {\n                doTheRest();\n            }\n            function doTheRest() {\n                uponPromise(action(), function () { return finalize(originalIsError, originalError); }, function (newError) { return finalize(true, newError); });\n            }\n        }\n        function shutdown(isError, error) {\n            if (shuttingDown) {\n                return;\n            }\n            shuttingDown = true;\n            if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                uponFulfillment(waitForWritesToFinish(), function () { return finalize(isError, error); });\n            }\n            else {\n                finalize(isError, error);\n            }\n        }\n        function finalize(isError, error) {\n            WritableStreamDefaultWriterRelease(writer);\n            ReadableStreamReaderGenericRelease(reader);\n            if (signal !== undefined) {\n                signal.removeEventListener('abort', abortAlgorithm);\n            }\n            if (isError) {\n                reject(error);\n            }\n            else {\n                resolve(undefined);\n            }\n        }\n    });\n}\n\n/**\n * Allows control of a {@link ReadableStream | readable stream}'s state and internal queue.\n *\n * @public\n */\nvar ReadableStreamDefaultController = /** @class */ (function () {\n    function ReadableStreamDefaultController() {\n        throw new TypeError('Illegal constructor');\n    }\n    Object.defineProperty(ReadableStreamDefaultController.prototype, \"desiredSize\", {\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying source ought to use this information to determine when and how to apply backpressure.\n         */\n        get: function () {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('desiredSize');\n            }\n            return ReadableStreamDefaultControllerGetDesiredSize(this);\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n     * the stream, but once those are read, the stream will become closed.\n     */\n    ReadableStreamDefaultController.prototype.close = function () {\n        if (!IsReadableStreamDefaultController(this)) {\n            throw defaultControllerBrandCheckException$1('close');\n        }\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n            throw new TypeError('The stream is not in a state that permits close');\n        }\n        ReadableStreamDefaultControllerClose(this);\n    };\n    ReadableStreamDefaultController.prototype.enqueue = function (chunk) {\n        if (chunk === void 0) { chunk = undefined; }\n        if (!IsReadableStreamDefaultController(this)) {\n            throw defaultControllerBrandCheckException$1('enqueue');\n        }\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n            throw new TypeError('The stream is not in a state that permits enqueue');\n        }\n        return ReadableStreamDefaultControllerEnqueue(this, chunk);\n    };\n    /**\n     * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n     */\n    ReadableStreamDefaultController.prototype.error = function (e) {\n        if (e === void 0) { e = undefined; }\n        if (!IsReadableStreamDefaultController(this)) {\n            throw defaultControllerBrandCheckException$1('error');\n        }\n        ReadableStreamDefaultControllerError(this, e);\n    };\n    /** @internal */\n    ReadableStreamDefaultController.prototype[CancelSteps] = function (reason) {\n        ResetQueue(this);\n        var result = this._cancelAlgorithm(reason);\n        ReadableStreamDefaultControllerClearAlgorithms(this);\n        return result;\n    };\n    /** @internal */\n    ReadableStreamDefaultController.prototype[PullSteps] = function (readRequest) {\n        var stream = this._controlledReadableStream;\n        if (this._queue.length > 0) {\n            var chunk = DequeueValue(this);\n            if (this._closeRequested && this._queue.length === 0) {\n                ReadableStreamDefaultControllerClearAlgorithms(this);\n                ReadableStreamClose(stream);\n            }\n            else {\n                ReadableStreamDefaultControllerCallPullIfNeeded(this);\n            }\n            readRequest._chunkSteps(chunk);\n        }\n        else {\n            ReadableStreamAddReadRequest(stream, readRequest);\n            ReadableStreamDefaultControllerCallPullIfNeeded(this);\n        }\n    };\n    return ReadableStreamDefaultController;\n}());\nObject.defineProperties(ReadableStreamDefaultController.prototype, {\n    close: { enumerable: true },\n    enqueue: { enumerable: true },\n    error: { enumerable: true },\n    desiredSize: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(ReadableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n        value: 'ReadableStreamDefaultController',\n        configurable: true\n    });\n}\n// Abstract operations for the ReadableStreamDefaultController.\nfunction IsReadableStreamDefaultController(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableStream')) {\n        return false;\n    }\n    return x instanceof ReadableStreamDefaultController;\n}\nfunction ReadableStreamDefaultControllerCallPullIfNeeded(controller) {\n    var shouldPull = ReadableStreamDefaultControllerShouldCallPull(controller);\n    if (!shouldPull) {\n        return;\n    }\n    if (controller._pulling) {\n        controller._pullAgain = true;\n        return;\n    }\n    controller._pulling = true;\n    var pullPromise = controller._pullAlgorithm();\n    uponPromise(pullPromise, function () {\n        controller._pulling = false;\n        if (controller._pullAgain) {\n            controller._pullAgain = false;\n            ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n        }\n    }, function (e) {\n        ReadableStreamDefaultControllerError(controller, e);\n    });\n}\nfunction ReadableStreamDefaultControllerShouldCallPull(controller) {\n    var stream = controller._controlledReadableStream;\n    if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n        return false;\n    }\n    if (!controller._started) {\n        return false;\n    }\n    if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n        return true;\n    }\n    var desiredSize = ReadableStreamDefaultControllerGetDesiredSize(controller);\n    if (desiredSize > 0) {\n        return true;\n    }\n    return false;\n}\nfunction ReadableStreamDefaultControllerClearAlgorithms(controller) {\n    controller._pullAlgorithm = undefined;\n    controller._cancelAlgorithm = undefined;\n    controller._strategySizeAlgorithm = undefined;\n}\n// A client of ReadableStreamDefaultController may use these functions directly to bypass state check.\nfunction ReadableStreamDefaultControllerClose(controller) {\n    if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n        return;\n    }\n    var stream = controller._controlledReadableStream;\n    controller._closeRequested = true;\n    if (controller._queue.length === 0) {\n        ReadableStreamDefaultControllerClearAlgorithms(controller);\n        ReadableStreamClose(stream);\n    }\n}\nfunction ReadableStreamDefaultControllerEnqueue(controller, chunk) {\n    if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n        return;\n    }\n    var stream = controller._controlledReadableStream;\n    if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n        ReadableStreamFulfillReadRequest(stream, chunk, false);\n    }\n    else {\n        var chunkSize = void 0;\n        try {\n            chunkSize = controller._strategySizeAlgorithm(chunk);\n        }\n        catch (chunkSizeE) {\n            ReadableStreamDefaultControllerError(controller, chunkSizeE);\n            throw chunkSizeE;\n        }\n        try {\n            EnqueueValueWithSize(controller, chunk, chunkSize);\n        }\n        catch (enqueueE) {\n            ReadableStreamDefaultControllerError(controller, enqueueE);\n            throw enqueueE;\n        }\n    }\n    ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n}\nfunction ReadableStreamDefaultControllerError(controller, e) {\n    var stream = controller._controlledReadableStream;\n    if (stream._state !== 'readable') {\n        return;\n    }\n    ResetQueue(controller);\n    ReadableStreamDefaultControllerClearAlgorithms(controller);\n    ReadableStreamError(stream, e);\n}\nfunction ReadableStreamDefaultControllerGetDesiredSize(controller) {\n    var state = controller._controlledReadableStream._state;\n    if (state === 'errored') {\n        return null;\n    }\n    if (state === 'closed') {\n        return 0;\n    }\n    return controller._strategyHWM - controller._queueTotalSize;\n}\n// This is used in the implementation of TransformStream.\nfunction ReadableStreamDefaultControllerHasBackpressure(controller) {\n    if (ReadableStreamDefaultControllerShouldCallPull(controller)) {\n        return false;\n    }\n    return true;\n}\nfunction ReadableStreamDefaultControllerCanCloseOrEnqueue(controller) {\n    var state = controller._controlledReadableStream._state;\n    if (!controller._closeRequested && state === 'readable') {\n        return true;\n    }\n    return false;\n}\nfunction SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm) {\n    controller._controlledReadableStream = stream;\n    controller._queue = undefined;\n    controller._queueTotalSize = undefined;\n    ResetQueue(controller);\n    controller._started = false;\n    controller._closeRequested = false;\n    controller._pullAgain = false;\n    controller._pulling = false;\n    controller._strategySizeAlgorithm = sizeAlgorithm;\n    controller._strategyHWM = highWaterMark;\n    controller._pullAlgorithm = pullAlgorithm;\n    controller._cancelAlgorithm = cancelAlgorithm;\n    stream._readableStreamController = controller;\n    var startResult = startAlgorithm();\n    uponPromise(promiseResolvedWith(startResult), function () {\n        controller._started = true;\n        ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n    }, function (r) {\n        ReadableStreamDefaultControllerError(controller, r);\n    });\n}\nfunction SetUpReadableStreamDefaultControllerFromUnderlyingSource(stream, underlyingSource, highWaterMark, sizeAlgorithm) {\n    var controller = Object.create(ReadableStreamDefaultController.prototype);\n    var startAlgorithm = function () { return undefined; };\n    var pullAlgorithm = function () { return promiseResolvedWith(undefined); };\n    var cancelAlgorithm = function () { return promiseResolvedWith(undefined); };\n    if (underlyingSource.start !== undefined) {\n        startAlgorithm = function () { return underlyingSource.start(controller); };\n    }\n    if (underlyingSource.pull !== undefined) {\n        pullAlgorithm = function () { return underlyingSource.pull(controller); };\n    }\n    if (underlyingSource.cancel !== undefined) {\n        cancelAlgorithm = function (reason) { return underlyingSource.cancel(reason); };\n    }\n    SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n}\n// Helper functions for the ReadableStreamDefaultController.\nfunction defaultControllerBrandCheckException$1(name) {\n    return new TypeError(\"ReadableStreamDefaultController.prototype.\" + name + \" can only be used on a ReadableStreamDefaultController\");\n}\n\nfunction ReadableStreamTee(stream, cloneForBranch2) {\n    if (IsReadableByteStreamController(stream._readableStreamController)) {\n        return ReadableByteStreamTee(stream);\n    }\n    return ReadableStreamDefaultTee(stream);\n}\nfunction ReadableStreamDefaultTee(stream, cloneForBranch2) {\n    var reader = AcquireReadableStreamDefaultReader(stream);\n    var reading = false;\n    var readAgain = false;\n    var canceled1 = false;\n    var canceled2 = false;\n    var reason1;\n    var reason2;\n    var branch1;\n    var branch2;\n    var resolveCancelPromise;\n    var cancelPromise = newPromise(function (resolve) {\n        resolveCancelPromise = resolve;\n    });\n    function pullAlgorithm() {\n        if (reading) {\n            readAgain = true;\n            return promiseResolvedWith(undefined);\n        }\n        reading = true;\n        var readRequest = {\n            _chunkSteps: function (chunk) {\n                // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                // successful synchronously-available reads get ahead of asynchronously-available errors.\n                queueMicrotask(function () {\n                    readAgain = false;\n                    var chunk1 = chunk;\n                    var chunk2 = chunk;\n                    // There is no way to access the cloning code right now in the reference implementation.\n                    // If we add one then we'll need an implementation for serializable objects.\n                    // if (!canceled2 && cloneForBranch2) {\n                    //   chunk2 = StructuredDeserialize(StructuredSerialize(chunk2));\n                    // }\n                    if (!canceled1) {\n                        ReadableStreamDefaultControllerEnqueue(branch1._readableStreamController, chunk1);\n                    }\n                    if (!canceled2) {\n                        ReadableStreamDefaultControllerEnqueue(branch2._readableStreamController, chunk2);\n                    }\n                    reading = false;\n                    if (readAgain) {\n                        pullAlgorithm();\n                    }\n                });\n            },\n            _closeSteps: function () {\n                reading = false;\n                if (!canceled1) {\n                    ReadableStreamDefaultControllerClose(branch1._readableStreamController);\n                }\n                if (!canceled2) {\n                    ReadableStreamDefaultControllerClose(branch2._readableStreamController);\n                }\n                if (!canceled1 || !canceled2) {\n                    resolveCancelPromise(undefined);\n                }\n            },\n            _errorSteps: function () {\n                reading = false;\n            }\n        };\n        ReadableStreamDefaultReaderRead(reader, readRequest);\n        return promiseResolvedWith(undefined);\n    }\n    function cancel1Algorithm(reason) {\n        canceled1 = true;\n        reason1 = reason;\n        if (canceled2) {\n            var compositeReason = CreateArrayFromList([reason1, reason2]);\n            var cancelResult = ReadableStreamCancel(stream, compositeReason);\n            resolveCancelPromise(cancelResult);\n        }\n        return cancelPromise;\n    }\n    function cancel2Algorithm(reason) {\n        canceled2 = true;\n        reason2 = reason;\n        if (canceled1) {\n            var compositeReason = CreateArrayFromList([reason1, reason2]);\n            var cancelResult = ReadableStreamCancel(stream, compositeReason);\n            resolveCancelPromise(cancelResult);\n        }\n        return cancelPromise;\n    }\n    function startAlgorithm() {\n        // do nothing\n    }\n    branch1 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel1Algorithm);\n    branch2 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel2Algorithm);\n    uponRejection(reader._closedPromise, function (r) {\n        ReadableStreamDefaultControllerError(branch1._readableStreamController, r);\n        ReadableStreamDefaultControllerError(branch2._readableStreamController, r);\n        if (!canceled1 || !canceled2) {\n            resolveCancelPromise(undefined);\n        }\n    });\n    return [branch1, branch2];\n}\nfunction ReadableByteStreamTee(stream) {\n    var reader = AcquireReadableStreamDefaultReader(stream);\n    var reading = false;\n    var readAgainForBranch1 = false;\n    var readAgainForBranch2 = false;\n    var canceled1 = false;\n    var canceled2 = false;\n    var reason1;\n    var reason2;\n    var branch1;\n    var branch2;\n    var resolveCancelPromise;\n    var cancelPromise = newPromise(function (resolve) {\n        resolveCancelPromise = resolve;\n    });\n    function forwardReaderError(thisReader) {\n        uponRejection(thisReader._closedPromise, function (r) {\n            if (thisReader !== reader) {\n                return;\n            }\n            ReadableByteStreamControllerError(branch1._readableStreamController, r);\n            ReadableByteStreamControllerError(branch2._readableStreamController, r);\n            if (!canceled1 || !canceled2) {\n                resolveCancelPromise(undefined);\n            }\n        });\n    }\n    function pullWithDefaultReader() {\n        if (IsReadableStreamBYOBReader(reader)) {\n            ReadableStreamReaderGenericRelease(reader);\n            reader = AcquireReadableStreamDefaultReader(stream);\n            forwardReaderError(reader);\n        }\n        var readRequest = {\n            _chunkSteps: function (chunk) {\n                // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                // successful synchronously-available reads get ahead of asynchronously-available errors.\n                queueMicrotask(function () {\n                    readAgainForBranch1 = false;\n                    readAgainForBranch2 = false;\n                    var chunk1 = chunk;\n                    var chunk2 = chunk;\n                    if (!canceled1 && !canceled2) {\n                        try {\n                            chunk2 = CloneAsUint8Array(chunk);\n                        }\n                        catch (cloneE) {\n                            ReadableByteStreamControllerError(branch1._readableStreamController, cloneE);\n                            ReadableByteStreamControllerError(branch2._readableStreamController, cloneE);\n                            resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                            return;\n                        }\n                    }\n                    if (!canceled1) {\n                        ReadableByteStreamControllerEnqueue(branch1._readableStreamController, chunk1);\n                    }\n                    if (!canceled2) {\n                        ReadableByteStreamControllerEnqueue(branch2._readableStreamController, chunk2);\n                    }\n                    reading = false;\n                    if (readAgainForBranch1) {\n                        pull1Algorithm();\n                    }\n                    else if (readAgainForBranch2) {\n                        pull2Algorithm();\n                    }\n                });\n            },\n            _closeSteps: function () {\n                reading = false;\n                if (!canceled1) {\n                    ReadableByteStreamControllerClose(branch1._readableStreamController);\n                }\n                if (!canceled2) {\n                    ReadableByteStreamControllerClose(branch2._readableStreamController);\n                }\n                if (branch1._readableStreamController._pendingPullIntos.length > 0) {\n                    ReadableByteStreamControllerRespond(branch1._readableStreamController, 0);\n                }\n                if (branch2._readableStreamController._pendingPullIntos.length > 0) {\n                    ReadableByteStreamControllerRespond(branch2._readableStreamController, 0);\n                }\n                if (!canceled1 || !canceled2) {\n                    resolveCancelPromise(undefined);\n                }\n            },\n            _errorSteps: function () {\n                reading = false;\n            }\n        };\n        ReadableStreamDefaultReaderRead(reader, readRequest);\n    }\n    function pullWithBYOBReader(view, forBranch2) {\n        if (IsReadableStreamDefaultReader(reader)) {\n            ReadableStreamReaderGenericRelease(reader);\n            reader = AcquireReadableStreamBYOBReader(stream);\n            forwardReaderError(reader);\n        }\n        var byobBranch = forBranch2 ? branch2 : branch1;\n        var otherBranch = forBranch2 ? branch1 : branch2;\n        var readIntoRequest = {\n            _chunkSteps: function (chunk) {\n                // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                // successful synchronously-available reads get ahead of asynchronously-available errors.\n                queueMicrotask(function () {\n                    readAgainForBranch1 = false;\n                    readAgainForBranch2 = false;\n                    var byobCanceled = forBranch2 ? canceled2 : canceled1;\n                    var otherCanceled = forBranch2 ? canceled1 : canceled2;\n                    if (!otherCanceled) {\n                        var clonedChunk = void 0;\n                        try {\n                            clonedChunk = CloneAsUint8Array(chunk);\n                        }\n                        catch (cloneE) {\n                            ReadableByteStreamControllerError(byobBranch._readableStreamController, cloneE);\n                            ReadableByteStreamControllerError(otherBranch._readableStreamController, cloneE);\n                            resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                            return;\n                        }\n                        if (!byobCanceled) {\n                            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                        }\n                        ReadableByteStreamControllerEnqueue(otherBranch._readableStreamController, clonedChunk);\n                    }\n                    else if (!byobCanceled) {\n                        ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                    }\n                    reading = false;\n                    if (readAgainForBranch1) {\n                        pull1Algorithm();\n                    }\n                    else if (readAgainForBranch2) {\n                        pull2Algorithm();\n                    }\n                });\n            },\n            _closeSteps: function (chunk) {\n                reading = false;\n                var byobCanceled = forBranch2 ? canceled2 : canceled1;\n                var otherCanceled = forBranch2 ? canceled1 : canceled2;\n                if (!byobCanceled) {\n                    ReadableByteStreamControllerClose(byobBranch._readableStreamController);\n                }\n                if (!otherCanceled) {\n                    ReadableByteStreamControllerClose(otherBranch._readableStreamController);\n                }\n                if (chunk !== undefined) {\n                    if (!byobCanceled) {\n                        ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                    }\n                    if (!otherCanceled && otherBranch._readableStreamController._pendingPullIntos.length > 0) {\n                        ReadableByteStreamControllerRespond(otherBranch._readableStreamController, 0);\n                    }\n                }\n                if (!byobCanceled || !otherCanceled) {\n                    resolveCancelPromise(undefined);\n                }\n            },\n            _errorSteps: function () {\n                reading = false;\n            }\n        };\n        ReadableStreamBYOBReaderRead(reader, view, readIntoRequest);\n    }\n    function pull1Algorithm() {\n        if (reading) {\n            readAgainForBranch1 = true;\n            return promiseResolvedWith(undefined);\n        }\n        reading = true;\n        var byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch1._readableStreamController);\n        if (byobRequest === null) {\n            pullWithDefaultReader();\n        }\n        else {\n            pullWithBYOBReader(byobRequest._view, false);\n        }\n        return promiseResolvedWith(undefined);\n    }\n    function pull2Algorithm() {\n        if (reading) {\n            readAgainForBranch2 = true;\n            return promiseResolvedWith(undefined);\n        }\n        reading = true;\n        var byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch2._readableStreamController);\n        if (byobRequest === null) {\n            pullWithDefaultReader();\n        }\n        else {\n            pullWithBYOBReader(byobRequest._view, true);\n        }\n        return promiseResolvedWith(undefined);\n    }\n    function cancel1Algorithm(reason) {\n        canceled1 = true;\n        reason1 = reason;\n        if (canceled2) {\n            var compositeReason = CreateArrayFromList([reason1, reason2]);\n            var cancelResult = ReadableStreamCancel(stream, compositeReason);\n            resolveCancelPromise(cancelResult);\n        }\n        return cancelPromise;\n    }\n    function cancel2Algorithm(reason) {\n        canceled2 = true;\n        reason2 = reason;\n        if (canceled1) {\n            var compositeReason = CreateArrayFromList([reason1, reason2]);\n            var cancelResult = ReadableStreamCancel(stream, compositeReason);\n            resolveCancelPromise(cancelResult);\n        }\n        return cancelPromise;\n    }\n    function startAlgorithm() {\n        return;\n    }\n    branch1 = CreateReadableByteStream(startAlgorithm, pull1Algorithm, cancel1Algorithm);\n    branch2 = CreateReadableByteStream(startAlgorithm, pull2Algorithm, cancel2Algorithm);\n    forwardReaderError(reader);\n    return [branch1, branch2];\n}\n\nfunction convertUnderlyingDefaultOrByteSource(source, context) {\n    assertDictionary(source, context);\n    var original = source;\n    var autoAllocateChunkSize = original === null || original === void 0 ? void 0 : original.autoAllocateChunkSize;\n    var cancel = original === null || original === void 0 ? void 0 : original.cancel;\n    var pull = original === null || original === void 0 ? void 0 : original.pull;\n    var start = original === null || original === void 0 ? void 0 : original.start;\n    var type = original === null || original === void 0 ? void 0 : original.type;\n    return {\n        autoAllocateChunkSize: autoAllocateChunkSize === undefined ?\n            undefined :\n            convertUnsignedLongLongWithEnforceRange(autoAllocateChunkSize, context + \" has member 'autoAllocateChunkSize' that\"),\n        cancel: cancel === undefined ?\n            undefined :\n            convertUnderlyingSourceCancelCallback(cancel, original, context + \" has member 'cancel' that\"),\n        pull: pull === undefined ?\n            undefined :\n            convertUnderlyingSourcePullCallback(pull, original, context + \" has member 'pull' that\"),\n        start: start === undefined ?\n            undefined :\n            convertUnderlyingSourceStartCallback(start, original, context + \" has member 'start' that\"),\n        type: type === undefined ? undefined : convertReadableStreamType(type, context + \" has member 'type' that\")\n    };\n}\nfunction convertUnderlyingSourceCancelCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (reason) { return promiseCall(fn, original, [reason]); };\n}\nfunction convertUnderlyingSourcePullCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (controller) { return promiseCall(fn, original, [controller]); };\n}\nfunction convertUnderlyingSourceStartCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (controller) { return reflectCall(fn, original, [controller]); };\n}\nfunction convertReadableStreamType(type, context) {\n    type = \"\" + type;\n    if (type !== 'bytes') {\n        throw new TypeError(context + \" '\" + type + \"' is not a valid enumeration value for ReadableStreamType\");\n    }\n    return type;\n}\n\nfunction convertReaderOptions(options, context) {\n    assertDictionary(options, context);\n    var mode = options === null || options === void 0 ? void 0 : options.mode;\n    return {\n        mode: mode === undefined ? undefined : convertReadableStreamReaderMode(mode, context + \" has member 'mode' that\")\n    };\n}\nfunction convertReadableStreamReaderMode(mode, context) {\n    mode = \"\" + mode;\n    if (mode !== 'byob') {\n        throw new TypeError(context + \" '\" + mode + \"' is not a valid enumeration value for ReadableStreamReaderMode\");\n    }\n    return mode;\n}\n\nfunction convertIteratorOptions(options, context) {\n    assertDictionary(options, context);\n    var preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n    return { preventCancel: Boolean(preventCancel) };\n}\n\nfunction convertPipeOptions(options, context) {\n    assertDictionary(options, context);\n    var preventAbort = options === null || options === void 0 ? void 0 : options.preventAbort;\n    var preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n    var preventClose = options === null || options === void 0 ? void 0 : options.preventClose;\n    var signal = options === null || options === void 0 ? void 0 : options.signal;\n    if (signal !== undefined) {\n        assertAbortSignal(signal, context + \" has member 'signal' that\");\n    }\n    return {\n        preventAbort: Boolean(preventAbort),\n        preventCancel: Boolean(preventCancel),\n        preventClose: Boolean(preventClose),\n        signal: signal\n    };\n}\nfunction assertAbortSignal(signal, context) {\n    if (!isAbortSignal(signal)) {\n        throw new TypeError(context + \" is not an AbortSignal.\");\n    }\n}\n\nfunction convertReadableWritablePair(pair, context) {\n    assertDictionary(pair, context);\n    var readable = pair === null || pair === void 0 ? void 0 : pair.readable;\n    assertRequiredField(readable, 'readable', 'ReadableWritablePair');\n    assertReadableStream(readable, context + \" has member 'readable' that\");\n    var writable = pair === null || pair === void 0 ? void 0 : pair.writable;\n    assertRequiredField(writable, 'writable', 'ReadableWritablePair');\n    assertWritableStream(writable, context + \" has member 'writable' that\");\n    return { readable: readable, writable: writable };\n}\n\n/**\n * A readable stream represents a source of data, from which you can read.\n *\n * @public\n */\nvar ReadableStream = /** @class */ (function () {\n    function ReadableStream(rawUnderlyingSource, rawStrategy) {\n        if (rawUnderlyingSource === void 0) { rawUnderlyingSource = {}; }\n        if (rawStrategy === void 0) { rawStrategy = {}; }\n        if (rawUnderlyingSource === undefined) {\n            rawUnderlyingSource = null;\n        }\n        else {\n            assertObject(rawUnderlyingSource, 'First parameter');\n        }\n        var strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n        var underlyingSource = convertUnderlyingDefaultOrByteSource(rawUnderlyingSource, 'First parameter');\n        InitializeReadableStream(this);\n        if (underlyingSource.type === 'bytes') {\n            if (strategy.size !== undefined) {\n                throw new RangeError('The strategy for a byte stream cannot have a size function');\n            }\n            var highWaterMark = ExtractHighWaterMark(strategy, 0);\n            SetUpReadableByteStreamControllerFromUnderlyingSource(this, underlyingSource, highWaterMark);\n        }\n        else {\n            var sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n            var highWaterMark = ExtractHighWaterMark(strategy, 1);\n            SetUpReadableStreamDefaultControllerFromUnderlyingSource(this, underlyingSource, highWaterMark, sizeAlgorithm);\n        }\n    }\n    Object.defineProperty(ReadableStream.prototype, \"locked\", {\n        /**\n         * Whether or not the readable stream is locked to a {@link ReadableStreamDefaultReader | reader}.\n         */\n        get: function () {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('locked');\n            }\n            return IsReadableStreamLocked(this);\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * Cancels the stream, signaling a loss of interest in the stream by a consumer.\n     *\n     * The supplied `reason` argument will be given to the underlying source's {@link UnderlyingSource.cancel | cancel()}\n     * method, which might or might not use it.\n     */\n    ReadableStream.prototype.cancel = function (reason) {\n        if (reason === void 0) { reason = undefined; }\n        if (!IsReadableStream(this)) {\n            return promiseRejectedWith(streamBrandCheckException$1('cancel'));\n        }\n        if (IsReadableStreamLocked(this)) {\n            return promiseRejectedWith(new TypeError('Cannot cancel a stream that already has a reader'));\n        }\n        return ReadableStreamCancel(this, reason);\n    };\n    ReadableStream.prototype.getReader = function (rawOptions) {\n        if (rawOptions === void 0) { rawOptions = undefined; }\n        if (!IsReadableStream(this)) {\n            throw streamBrandCheckException$1('getReader');\n        }\n        var options = convertReaderOptions(rawOptions, 'First parameter');\n        if (options.mode === undefined) {\n            return AcquireReadableStreamDefaultReader(this);\n        }\n        return AcquireReadableStreamBYOBReader(this);\n    };\n    ReadableStream.prototype.pipeThrough = function (rawTransform, rawOptions) {\n        if (rawOptions === void 0) { rawOptions = {}; }\n        if (!IsReadableStream(this)) {\n            throw streamBrandCheckException$1('pipeThrough');\n        }\n        assertRequiredArgument(rawTransform, 1, 'pipeThrough');\n        var transform = convertReadableWritablePair(rawTransform, 'First parameter');\n        var options = convertPipeOptions(rawOptions, 'Second parameter');\n        if (IsReadableStreamLocked(this)) {\n            throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked ReadableStream');\n        }\n        if (IsWritableStreamLocked(transform.writable)) {\n            throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked WritableStream');\n        }\n        var promise = ReadableStreamPipeTo(this, transform.writable, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n        setPromiseIsHandledToTrue(promise);\n        return transform.readable;\n    };\n    ReadableStream.prototype.pipeTo = function (destination, rawOptions) {\n        if (rawOptions === void 0) { rawOptions = {}; }\n        if (!IsReadableStream(this)) {\n            return promiseRejectedWith(streamBrandCheckException$1('pipeTo'));\n        }\n        if (destination === undefined) {\n            return promiseRejectedWith(\"Parameter 1 is required in 'pipeTo'.\");\n        }\n        if (!IsWritableStream(destination)) {\n            return promiseRejectedWith(new TypeError(\"ReadableStream.prototype.pipeTo's first argument must be a WritableStream\"));\n        }\n        var options;\n        try {\n            options = convertPipeOptions(rawOptions, 'Second parameter');\n        }\n        catch (e) {\n            return promiseRejectedWith(e);\n        }\n        if (IsReadableStreamLocked(this)) {\n            return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked ReadableStream'));\n        }\n        if (IsWritableStreamLocked(destination)) {\n            return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked WritableStream'));\n        }\n        return ReadableStreamPipeTo(this, destination, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n    };\n    /**\n     * Tees this readable stream, returning a two-element array containing the two resulting branches as\n     * new {@link ReadableStream} instances.\n     *\n     * Teeing a stream will lock it, preventing any other consumer from acquiring a reader.\n     * To cancel the stream, cancel both of the resulting branches; a composite cancellation reason will then be\n     * propagated to the stream's underlying source.\n     *\n     * Note that the chunks seen in each branch will be the same object. If the chunks are not immutable,\n     * this could allow interference between the two branches.\n     */\n    ReadableStream.prototype.tee = function () {\n        if (!IsReadableStream(this)) {\n            throw streamBrandCheckException$1('tee');\n        }\n        var branches = ReadableStreamTee(this);\n        return CreateArrayFromList(branches);\n    };\n    ReadableStream.prototype.values = function (rawOptions) {\n        if (rawOptions === void 0) { rawOptions = undefined; }\n        if (!IsReadableStream(this)) {\n            throw streamBrandCheckException$1('values');\n        }\n        var options = convertIteratorOptions(rawOptions, 'First parameter');\n        return AcquireReadableStreamAsyncIterator(this, options.preventCancel);\n    };\n    return ReadableStream;\n}());\nObject.defineProperties(ReadableStream.prototype, {\n    cancel: { enumerable: true },\n    getReader: { enumerable: true },\n    pipeThrough: { enumerable: true },\n    pipeTo: { enumerable: true },\n    tee: { enumerable: true },\n    values: { enumerable: true },\n    locked: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.toStringTag, {\n        value: 'ReadableStream',\n        configurable: true\n    });\n}\nif (typeof SymbolPolyfill.asyncIterator === 'symbol') {\n    Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.asyncIterator, {\n        value: ReadableStream.prototype.values,\n        writable: true,\n        configurable: true\n    });\n}\n// Abstract operations for the ReadableStream.\n// Throws if and only if startAlgorithm throws.\nfunction CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm) {\n    if (highWaterMark === void 0) { highWaterMark = 1; }\n    if (sizeAlgorithm === void 0) { sizeAlgorithm = function () { return 1; }; }\n    var stream = Object.create(ReadableStream.prototype);\n    InitializeReadableStream(stream);\n    var controller = Object.create(ReadableStreamDefaultController.prototype);\n    SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n    return stream;\n}\n// Throws if and only if startAlgorithm throws.\nfunction CreateReadableByteStream(startAlgorithm, pullAlgorithm, cancelAlgorithm) {\n    var stream = Object.create(ReadableStream.prototype);\n    InitializeReadableStream(stream);\n    var controller = Object.create(ReadableByteStreamController.prototype);\n    SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, 0, undefined);\n    return stream;\n}\nfunction InitializeReadableStream(stream) {\n    stream._state = 'readable';\n    stream._reader = undefined;\n    stream._storedError = undefined;\n    stream._disturbed = false;\n}\nfunction IsReadableStream(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_readableStreamController')) {\n        return false;\n    }\n    return x instanceof ReadableStream;\n}\nfunction IsReadableStreamLocked(stream) {\n    if (stream._reader === undefined) {\n        return false;\n    }\n    return true;\n}\n// ReadableStream API exposed for controllers.\nfunction ReadableStreamCancel(stream, reason) {\n    stream._disturbed = true;\n    if (stream._state === 'closed') {\n        return promiseResolvedWith(undefined);\n    }\n    if (stream._state === 'errored') {\n        return promiseRejectedWith(stream._storedError);\n    }\n    ReadableStreamClose(stream);\n    var reader = stream._reader;\n    if (reader !== undefined && IsReadableStreamBYOBReader(reader)) {\n        reader._readIntoRequests.forEach(function (readIntoRequest) {\n            readIntoRequest._closeSteps(undefined);\n        });\n        reader._readIntoRequests = new SimpleQueue();\n    }\n    var sourceCancelPromise = stream._readableStreamController[CancelSteps](reason);\n    return transformPromiseWith(sourceCancelPromise, noop);\n}\nfunction ReadableStreamClose(stream) {\n    stream._state = 'closed';\n    var reader = stream._reader;\n    if (reader === undefined) {\n        return;\n    }\n    defaultReaderClosedPromiseResolve(reader);\n    if (IsReadableStreamDefaultReader(reader)) {\n        reader._readRequests.forEach(function (readRequest) {\n            readRequest._closeSteps();\n        });\n        reader._readRequests = new SimpleQueue();\n    }\n}\nfunction ReadableStreamError(stream, e) {\n    stream._state = 'errored';\n    stream._storedError = e;\n    var reader = stream._reader;\n    if (reader === undefined) {\n        return;\n    }\n    defaultReaderClosedPromiseReject(reader, e);\n    if (IsReadableStreamDefaultReader(reader)) {\n        reader._readRequests.forEach(function (readRequest) {\n            readRequest._errorSteps(e);\n        });\n        reader._readRequests = new SimpleQueue();\n    }\n    else {\n        reader._readIntoRequests.forEach(function (readIntoRequest) {\n            readIntoRequest._errorSteps(e);\n        });\n        reader._readIntoRequests = new SimpleQueue();\n    }\n}\n// Helper functions for the ReadableStream.\nfunction streamBrandCheckException$1(name) {\n    return new TypeError(\"ReadableStream.prototype.\" + name + \" can only be used on a ReadableStream\");\n}\n\nfunction convertQueuingStrategyInit(init, context) {\n    assertDictionary(init, context);\n    var highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n    assertRequiredField(highWaterMark, 'highWaterMark', 'QueuingStrategyInit');\n    return {\n        highWaterMark: convertUnrestrictedDouble(highWaterMark)\n    };\n}\n\n// The size function must not have a prototype property nor be a constructor\nvar byteLengthSizeFunction = function (chunk) {\n    return chunk.byteLength;\n};\ntry {\n    Object.defineProperty(byteLengthSizeFunction, 'name', {\n        value: 'size',\n        configurable: true\n    });\n}\ncatch (_a) {\n    // This property is non-configurable in older browsers, so ignore if this throws.\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/name#browser_compatibility\n}\n/**\n * A queuing strategy that counts the number of bytes in each chunk.\n *\n * @public\n */\nvar ByteLengthQueuingStrategy = /** @class */ (function () {\n    function ByteLengthQueuingStrategy(options) {\n        assertRequiredArgument(options, 1, 'ByteLengthQueuingStrategy');\n        options = convertQueuingStrategyInit(options, 'First parameter');\n        this._byteLengthQueuingStrategyHighWaterMark = options.highWaterMark;\n    }\n    Object.defineProperty(ByteLengthQueuingStrategy.prototype, \"highWaterMark\", {\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get: function () {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('highWaterMark');\n            }\n            return this._byteLengthQueuingStrategyHighWaterMark;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Object.defineProperty(ByteLengthQueuingStrategy.prototype, \"size\", {\n        /**\n         * Measures the size of `chunk` by returning the value of its `byteLength` property.\n         */\n        get: function () {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('size');\n            }\n            return byteLengthSizeFunction;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    return ByteLengthQueuingStrategy;\n}());\nObject.defineProperties(ByteLengthQueuingStrategy.prototype, {\n    highWaterMark: { enumerable: true },\n    size: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(ByteLengthQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n        value: 'ByteLengthQueuingStrategy',\n        configurable: true\n    });\n}\n// Helper functions for the ByteLengthQueuingStrategy.\nfunction byteLengthBrandCheckException(name) {\n    return new TypeError(\"ByteLengthQueuingStrategy.prototype.\" + name + \" can only be used on a ByteLengthQueuingStrategy\");\n}\nfunction IsByteLengthQueuingStrategy(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_byteLengthQueuingStrategyHighWaterMark')) {\n        return false;\n    }\n    return x instanceof ByteLengthQueuingStrategy;\n}\n\n// The size function must not have a prototype property nor be a constructor\nvar countSizeFunction = function () {\n    return 1;\n};\ntry {\n    Object.defineProperty(countSizeFunction, 'name', {\n        value: 'size',\n        configurable: true\n    });\n}\ncatch (_a) {\n    // This property is non-configurable in older browsers, so ignore if this throws.\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/name#browser_compatibility\n}\n/**\n * A queuing strategy that counts the number of chunks.\n *\n * @public\n */\nvar CountQueuingStrategy = /** @class */ (function () {\n    function CountQueuingStrategy(options) {\n        assertRequiredArgument(options, 1, 'CountQueuingStrategy');\n        options = convertQueuingStrategyInit(options, 'First parameter');\n        this._countQueuingStrategyHighWaterMark = options.highWaterMark;\n    }\n    Object.defineProperty(CountQueuingStrategy.prototype, \"highWaterMark\", {\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get: function () {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('highWaterMark');\n            }\n            return this._countQueuingStrategyHighWaterMark;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Object.defineProperty(CountQueuingStrategy.prototype, \"size\", {\n        /**\n         * Measures the size of `chunk` by always returning 1.\n         * This ensures that the total queue size is a count of the number of chunks in the queue.\n         */\n        get: function () {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('size');\n            }\n            return countSizeFunction;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    return CountQueuingStrategy;\n}());\nObject.defineProperties(CountQueuingStrategy.prototype, {\n    highWaterMark: { enumerable: true },\n    size: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(CountQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n        value: 'CountQueuingStrategy',\n        configurable: true\n    });\n}\n// Helper functions for the CountQueuingStrategy.\nfunction countBrandCheckException(name) {\n    return new TypeError(\"CountQueuingStrategy.prototype.\" + name + \" can only be used on a CountQueuingStrategy\");\n}\nfunction IsCountQueuingStrategy(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_countQueuingStrategyHighWaterMark')) {\n        return false;\n    }\n    return x instanceof CountQueuingStrategy;\n}\n\nfunction convertTransformer(original, context) {\n    assertDictionary(original, context);\n    var flush = original === null || original === void 0 ? void 0 : original.flush;\n    var readableType = original === null || original === void 0 ? void 0 : original.readableType;\n    var start = original === null || original === void 0 ? void 0 : original.start;\n    var transform = original === null || original === void 0 ? void 0 : original.transform;\n    var writableType = original === null || original === void 0 ? void 0 : original.writableType;\n    return {\n        flush: flush === undefined ?\n            undefined :\n            convertTransformerFlushCallback(flush, original, context + \" has member 'flush' that\"),\n        readableType: readableType,\n        start: start === undefined ?\n            undefined :\n            convertTransformerStartCallback(start, original, context + \" has member 'start' that\"),\n        transform: transform === undefined ?\n            undefined :\n            convertTransformerTransformCallback(transform, original, context + \" has member 'transform' that\"),\n        writableType: writableType\n    };\n}\nfunction convertTransformerFlushCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (controller) { return promiseCall(fn, original, [controller]); };\n}\nfunction convertTransformerStartCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (controller) { return reflectCall(fn, original, [controller]); };\n}\nfunction convertTransformerTransformCallback(fn, original, context) {\n    assertFunction(fn, context);\n    return function (chunk, controller) { return promiseCall(fn, original, [chunk, controller]); };\n}\n\n// Class TransformStream\n/**\n * A transform stream consists of a pair of streams: a {@link WritableStream | writable stream},\n * known as its writable side, and a {@link ReadableStream | readable stream}, known as its readable side.\n * In a manner specific to the transform stream in question, writes to the writable side result in new data being\n * made available for reading from the readable side.\n *\n * @public\n */\nvar TransformStream = /** @class */ (function () {\n    function TransformStream(rawTransformer, rawWritableStrategy, rawReadableStrategy) {\n        if (rawTransformer === void 0) { rawTransformer = {}; }\n        if (rawWritableStrategy === void 0) { rawWritableStrategy = {}; }\n        if (rawReadableStrategy === void 0) { rawReadableStrategy = {}; }\n        if (rawTransformer === undefined) {\n            rawTransformer = null;\n        }\n        var writableStrategy = convertQueuingStrategy(rawWritableStrategy, 'Second parameter');\n        var readableStrategy = convertQueuingStrategy(rawReadableStrategy, 'Third parameter');\n        var transformer = convertTransformer(rawTransformer, 'First parameter');\n        if (transformer.readableType !== undefined) {\n            throw new RangeError('Invalid readableType specified');\n        }\n        if (transformer.writableType !== undefined) {\n            throw new RangeError('Invalid writableType specified');\n        }\n        var readableHighWaterMark = ExtractHighWaterMark(readableStrategy, 0);\n        var readableSizeAlgorithm = ExtractSizeAlgorithm(readableStrategy);\n        var writableHighWaterMark = ExtractHighWaterMark(writableStrategy, 1);\n        var writableSizeAlgorithm = ExtractSizeAlgorithm(writableStrategy);\n        var startPromise_resolve;\n        var startPromise = newPromise(function (resolve) {\n            startPromise_resolve = resolve;\n        });\n        InitializeTransformStream(this, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n        SetUpTransformStreamDefaultControllerFromTransformer(this, transformer);\n        if (transformer.start !== undefined) {\n            startPromise_resolve(transformer.start(this._transformStreamController));\n        }\n        else {\n            startPromise_resolve(undefined);\n        }\n    }\n    Object.defineProperty(TransformStream.prototype, \"readable\", {\n        /**\n         * The readable side of the transform stream.\n         */\n        get: function () {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('readable');\n            }\n            return this._readable;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Object.defineProperty(TransformStream.prototype, \"writable\", {\n        /**\n         * The writable side of the transform stream.\n         */\n        get: function () {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('writable');\n            }\n            return this._writable;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    return TransformStream;\n}());\nObject.defineProperties(TransformStream.prototype, {\n    readable: { enumerable: true },\n    writable: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(TransformStream.prototype, SymbolPolyfill.toStringTag, {\n        value: 'TransformStream',\n        configurable: true\n    });\n}\nfunction InitializeTransformStream(stream, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm) {\n    function startAlgorithm() {\n        return startPromise;\n    }\n    function writeAlgorithm(chunk) {\n        return TransformStreamDefaultSinkWriteAlgorithm(stream, chunk);\n    }\n    function abortAlgorithm(reason) {\n        return TransformStreamDefaultSinkAbortAlgorithm(stream, reason);\n    }\n    function closeAlgorithm() {\n        return TransformStreamDefaultSinkCloseAlgorithm(stream);\n    }\n    stream._writable = CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, writableHighWaterMark, writableSizeAlgorithm);\n    function pullAlgorithm() {\n        return TransformStreamDefaultSourcePullAlgorithm(stream);\n    }\n    function cancelAlgorithm(reason) {\n        TransformStreamErrorWritableAndUnblockWrite(stream, reason);\n        return promiseResolvedWith(undefined);\n    }\n    stream._readable = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n    // The [[backpressure]] slot is set to undefined so that it can be initialised by TransformStreamSetBackpressure.\n    stream._backpressure = undefined;\n    stream._backpressureChangePromise = undefined;\n    stream._backpressureChangePromise_resolve = undefined;\n    TransformStreamSetBackpressure(stream, true);\n    stream._transformStreamController = undefined;\n}\nfunction IsTransformStream(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_transformStreamController')) {\n        return false;\n    }\n    return x instanceof TransformStream;\n}\n// This is a no-op if both sides are already errored.\nfunction TransformStreamError(stream, e) {\n    ReadableStreamDefaultControllerError(stream._readable._readableStreamController, e);\n    TransformStreamErrorWritableAndUnblockWrite(stream, e);\n}\nfunction TransformStreamErrorWritableAndUnblockWrite(stream, e) {\n    TransformStreamDefaultControllerClearAlgorithms(stream._transformStreamController);\n    WritableStreamDefaultControllerErrorIfNeeded(stream._writable._writableStreamController, e);\n    if (stream._backpressure) {\n        // Pretend that pull() was called to permit any pending write() calls to complete. TransformStreamSetBackpressure()\n        // cannot be called from enqueue() or pull() once the ReadableStream is errored, so this will will be the final time\n        // _backpressure is set.\n        TransformStreamSetBackpressure(stream, false);\n    }\n}\nfunction TransformStreamSetBackpressure(stream, backpressure) {\n    // Passes also when called during construction.\n    if (stream._backpressureChangePromise !== undefined) {\n        stream._backpressureChangePromise_resolve();\n    }\n    stream._backpressureChangePromise = newPromise(function (resolve) {\n        stream._backpressureChangePromise_resolve = resolve;\n    });\n    stream._backpressure = backpressure;\n}\n// Class TransformStreamDefaultController\n/**\n * Allows control of the {@link ReadableStream} and {@link WritableStream} of the associated {@link TransformStream}.\n *\n * @public\n */\nvar TransformStreamDefaultController = /** @class */ (function () {\n    function TransformStreamDefaultController() {\n        throw new TypeError('Illegal constructor');\n    }\n    Object.defineProperty(TransformStreamDefaultController.prototype, \"desiredSize\", {\n        /**\n         * Returns the desired size to fill the readable sides internal queue. It can be negative, if the queue is over-full.\n         */\n        get: function () {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('desiredSize');\n            }\n            var readableController = this._controlledTransformStream._readable._readableStreamController;\n            return ReadableStreamDefaultControllerGetDesiredSize(readableController);\n        },\n        enumerable: false,\n        configurable: true\n    });\n    TransformStreamDefaultController.prototype.enqueue = function (chunk) {\n        if (chunk === void 0) { chunk = undefined; }\n        if (!IsTransformStreamDefaultController(this)) {\n            throw defaultControllerBrandCheckException('enqueue');\n        }\n        TransformStreamDefaultControllerEnqueue(this, chunk);\n    };\n    /**\n     * Errors both the readable side and the writable side of the controlled transform stream, making all future\n     * interactions with it fail with the given error `e`. Any chunks queued for transformation will be discarded.\n     */\n    TransformStreamDefaultController.prototype.error = function (reason) {\n        if (reason === void 0) { reason = undefined; }\n        if (!IsTransformStreamDefaultController(this)) {\n            throw defaultControllerBrandCheckException('error');\n        }\n        TransformStreamDefaultControllerError(this, reason);\n    };\n    /**\n     * Closes the readable side and errors the writable side of the controlled transform stream. This is useful when the\n     * transformer only needs to consume a portion of the chunks written to the writable side.\n     */\n    TransformStreamDefaultController.prototype.terminate = function () {\n        if (!IsTransformStreamDefaultController(this)) {\n            throw defaultControllerBrandCheckException('terminate');\n        }\n        TransformStreamDefaultControllerTerminate(this);\n    };\n    return TransformStreamDefaultController;\n}());\nObject.defineProperties(TransformStreamDefaultController.prototype, {\n    enqueue: { enumerable: true },\n    error: { enumerable: true },\n    terminate: { enumerable: true },\n    desiredSize: { enumerable: true }\n});\nif (typeof SymbolPolyfill.toStringTag === 'symbol') {\n    Object.defineProperty(TransformStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n        value: 'TransformStreamDefaultController',\n        configurable: true\n    });\n}\n// Transform Stream Default Controller Abstract Operations\nfunction IsTransformStreamDefaultController(x) {\n    if (!typeIsObject(x)) {\n        return false;\n    }\n    if (!Object.prototype.hasOwnProperty.call(x, '_controlledTransformStream')) {\n        return false;\n    }\n    return x instanceof TransformStreamDefaultController;\n}\nfunction SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm) {\n    controller._controlledTransformStream = stream;\n    stream._transformStreamController = controller;\n    controller._transformAlgorithm = transformAlgorithm;\n    controller._flushAlgorithm = flushAlgorithm;\n}\nfunction SetUpTransformStreamDefaultControllerFromTransformer(stream, transformer) {\n    var controller = Object.create(TransformStreamDefaultController.prototype);\n    var transformAlgorithm = function (chunk) {\n        try {\n            TransformStreamDefaultControllerEnqueue(controller, chunk);\n            return promiseResolvedWith(undefined);\n        }\n        catch (transformResultE) {\n            return promiseRejectedWith(transformResultE);\n        }\n    };\n    var flushAlgorithm = function () { return promiseResolvedWith(undefined); };\n    if (transformer.transform !== undefined) {\n        transformAlgorithm = function (chunk) { return transformer.transform(chunk, controller); };\n    }\n    if (transformer.flush !== undefined) {\n        flushAlgorithm = function () { return transformer.flush(controller); };\n    }\n    SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm);\n}\nfunction TransformStreamDefaultControllerClearAlgorithms(controller) {\n    controller._transformAlgorithm = undefined;\n    controller._flushAlgorithm = undefined;\n}\nfunction TransformStreamDefaultControllerEnqueue(controller, chunk) {\n    var stream = controller._controlledTransformStream;\n    var readableController = stream._readable._readableStreamController;\n    if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(readableController)) {\n        throw new TypeError('Readable side is not in a state that permits enqueue');\n    }\n    // We throttle transform invocations based on the backpressure of the ReadableStream, but we still\n    // accept TransformStreamDefaultControllerEnqueue() calls.\n    try {\n        ReadableStreamDefaultControllerEnqueue(readableController, chunk);\n    }\n    catch (e) {\n        // This happens when readableStrategy.size() throws.\n        TransformStreamErrorWritableAndUnblockWrite(stream, e);\n        throw stream._readable._storedError;\n    }\n    var backpressure = ReadableStreamDefaultControllerHasBackpressure(readableController);\n    if (backpressure !== stream._backpressure) {\n        TransformStreamSetBackpressure(stream, true);\n    }\n}\nfunction TransformStreamDefaultControllerError(controller, e) {\n    TransformStreamError(controller._controlledTransformStream, e);\n}\nfunction TransformStreamDefaultControllerPerformTransform(controller, chunk) {\n    var transformPromise = controller._transformAlgorithm(chunk);\n    return transformPromiseWith(transformPromise, undefined, function (r) {\n        TransformStreamError(controller._controlledTransformStream, r);\n        throw r;\n    });\n}\nfunction TransformStreamDefaultControllerTerminate(controller) {\n    var stream = controller._controlledTransformStream;\n    var readableController = stream._readable._readableStreamController;\n    ReadableStreamDefaultControllerClose(readableController);\n    var error = new TypeError('TransformStream terminated');\n    TransformStreamErrorWritableAndUnblockWrite(stream, error);\n}\n// TransformStreamDefaultSink Algorithms\nfunction TransformStreamDefaultSinkWriteAlgorithm(stream, chunk) {\n    var controller = stream._transformStreamController;\n    if (stream._backpressure) {\n        var backpressureChangePromise = stream._backpressureChangePromise;\n        return transformPromiseWith(backpressureChangePromise, function () {\n            var writable = stream._writable;\n            var state = writable._state;\n            if (state === 'erroring') {\n                throw writable._storedError;\n            }\n            return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n        });\n    }\n    return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n}\nfunction TransformStreamDefaultSinkAbortAlgorithm(stream, reason) {\n    // abort() is not called synchronously, so it is possible for abort() to be called when the stream is already\n    // errored.\n    TransformStreamError(stream, reason);\n    return promiseResolvedWith(undefined);\n}\nfunction TransformStreamDefaultSinkCloseAlgorithm(stream) {\n    // stream._readable cannot change after construction, so caching it across a call to user code is safe.\n    var readable = stream._readable;\n    var controller = stream._transformStreamController;\n    var flushPromise = controller._flushAlgorithm();\n    TransformStreamDefaultControllerClearAlgorithms(controller);\n    // Return a promise that is fulfilled with undefined on success.\n    return transformPromiseWith(flushPromise, function () {\n        if (readable._state === 'errored') {\n            throw readable._storedError;\n        }\n        ReadableStreamDefaultControllerClose(readable._readableStreamController);\n    }, function (r) {\n        TransformStreamError(stream, r);\n        throw readable._storedError;\n    });\n}\n// TransformStreamDefaultSource Algorithms\nfunction TransformStreamDefaultSourcePullAlgorithm(stream) {\n    // Invariant. Enforced by the promises returned by start() and pull().\n    TransformStreamSetBackpressure(stream, false);\n    // Prevent the next pull() call until there is backpressure.\n    return stream._backpressureChangePromise;\n}\n// Helper functions for the TransformStreamDefaultController.\nfunction defaultControllerBrandCheckException(name) {\n    return new TypeError(\"TransformStreamDefaultController.prototype.\" + name + \" can only be used on a TransformStreamDefaultController\");\n}\n// Helper functions for the TransformStream.\nfunction streamBrandCheckException(name) {\n    return new TypeError(\"TransformStream.prototype.\" + name + \" can only be used on a TransformStream\");\n}\n\n\n//# sourceMappingURL=ponyfill.mjs.map\n\n\n//# sourceURL=webpack://w3proof-dispatch/./node_modules/web-streams-polyfill/dist/ponyfill.mjs?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module is referenced by other modules so it can't be inlined
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	
/******/ })()
;